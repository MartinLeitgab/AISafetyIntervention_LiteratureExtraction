{
  "nodes": [
    {
      "name": "Uncontrolled intelligence explosion from HLMI",
      "aliases": [
        "runaway AI self-improvement",
        "recursive self-improvement risk"
      ],
      "type": "concept",
      "description": "Scenario where HLMI rapidly improves itself, surpassing human control and potentially causing catastrophic outcomes.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Referenced by survey questions on probability of an “intelligence explosion” (Survey Content §2)."
    },
    {
      "name": "Misaligned goals in HLMI systems",
      "aliases": [
        "goal-alignment failure",
        "non-aligned superintelligence"
      ],
      "type": "concept",
      "description": "HLMI pursuing objectives that diverge from human values, leading to harmful outcomes.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Survey included questions on AI systems with non-aligned goals (Survey Content §7)."
    },
    {
      "name": "Economic displacement of human labor due to HLMI automation",
      "aliases": [
        "technological unemployment from HLMI",
        "job loss from AI"
      ],
      "type": "concept",
      "description": "Large-scale replacement of human occupations by HLMI leading to economic and social disruption.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Survey elicited timelines for automation of all occupations (Survey Content §1; Table S1)."
    },
    {
      "name": "High uncertainty in HLMI timelines among AI experts",
      "aliases": [
        "timeline variance",
        "forecast uncertainty HLMI"
      ],
      "type": "concept",
      "description": "Wide dispersion in expert CDFs for the arrival of HLMI, complicating preparation and policy response.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Observed mixture distribution shows large confidence intervals (Statistics § and Fig. S2)."
    },
    {
      "name": "Underprioritization of AI safety research in ML community",
      "aliases": [
        "low safety research priority",
        "AI safety funding gap"
      ],
      "type": "concept",
      "description": "Expert responses indicate safety research receives less emphasis than its perceived importance warrants.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "32 survey questions on safety and Table S4 show moderate priority ratings (Survey Content §7)."
    },
    {
      "name": "Regional variation in automation timeline predictions",
      "aliases": [
        "region-dependent automation forecasts",
        "NA/Asia timeline gap"
      ],
      "type": "concept",
      "description": "Experts from different undergraduate regions predict substantially different years to full job automation.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Table S1 shows a 64-year median gap between N. America and Asia in full automation predictions."
    },
    {
      "name": "Question framing effects on expert timeline predictions",
      "aliases": [
        "fixed-probability vs fixed-years framing",
        "framing bias in HLMI forecasts"
      ],
      "type": "concept",
      "description": "Experts give systematically different HLMI timelines depending on whether questions use fixed-probability or fixed-year framing.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Elicitation of Beliefs section reports consistent framing effects; Fig. S2 visualises them."
    },
    {
      "name": "Demographic factors weakly influencing HLMI timeline predictions",
      "aliases": [
        "demographic correlation with HLMI forecasts"
      ],
      "type": "concept",
      "description": "Robust regression shows small but significant effects of region and framing on predicted HLMI dates.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Table S2 regression outputs demonstrate these demographic effects."
    },
    {
      "name": "Expert consensus indicating non-negligible risk from misaligned HLMI",
      "aliases": [
        "surveyed probability of non-aligned AI harm"
      ],
      "type": "concept",
      "description": "Median responses assign meaningful probability to negative welfare impacts from non-aligned HLMI.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Questions 3 and safety block in Table S4 provide these probability estimates."
    },
    {
      "name": "Regular dual-framing expert elicitation to reduce timeline uncertainty",
      "aliases": [
        "multi-framing survey strategy",
        "structured expert forecasting"
      ],
      "type": "concept",
      "description": "Design principle of repeatedly surveying experts with both framings to average out framing biases and narrow uncertainty.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Proposed in discussion of framing effects (Elicitation of Beliefs §)."
    },
    {
      "name": "Increased prioritization of AI safety research based on expert risk assessments",
      "aliases": [
        "safety research advocacy",
        "align funding with expert concerns"
      ],
      "type": "concept",
      "description": "Argues that demonstrated expert concern justifies allocating more resources to AI-safety work.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Motivated by safety-priority survey answers (Survey Content §7; Table S4)."
    },
    {
      "name": "Region-specific policy planning informed by expert automation forecasts",
      "aliases": [
        "geographically tailored workforce policy"
      ],
      "type": "concept",
      "description": "Using regional forecast differences to design bespoke labour-transition measures.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Table S1 indicates region-specific automation timelines."
    },
    {
      "name": "Gamma CDF mixture aggregation of expert HLMI forecasts",
      "aliases": [
        "gamma-fit aggregation",
        "mixture model of forecasts"
      ],
      "type": "concept",
      "description": "Technical method fitting gamma CDFs to each expert and mixing them to obtain the aggregate timeline distribution.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Statistics section describes this fitting and mixture process."
    },
    {
      "name": "Robust regression analysis to detect demographic effects on predictions",
      "aliases": [
        "rlm demographic regression"
      ],
      "type": "concept",
      "description": "Uses robust linear regression (MASS::rlm) to test significance of demographic variables on HLMI dates.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Statistics section and Table S2 detail this analysis."
    },
    {
      "name": "Incentivized online survey deployment to collect expert forecasts",
      "aliases": [
        "Qualtrics incentivized survey"
      ],
      "type": "concept",
      "description": "Practical mechanism: emailing ML researchers, offering financial rewards, and using Qualtrics for data collection.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Survey Content § explains incentive and Qualtrics deployment."
    },
    {
      "name": "Dedicated funding channels and grant programs for AI safety research",
      "aliases": [
        "AI safety grantmaking",
        "safety funding mechanisms"
      ],
      "type": "concept",
      "description": "Concrete mechanism for implementing higher safety-research priority through earmarked grants (e.g., FLI, FHI, OpenPhil).",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Acknowledgments list existing funders, illustrating feasibility."
    },
    {
      "name": "Empirical framing effect observed in HLMI CDF curves (Fig S2)",
      "aliases": [
        "framing effect evidence",
        "Fig S2 framing data"
      ],
      "type": "concept",
      "description": "Visual and statistical evidence that fixed-probability and fixed-year framings yield different aggregate CDFs.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Shown explicitly in Figure S2."
    },
    {
      "name": "Survey responses indicating desire for more safety research (Table S4)",
      "aliases": [
        "safety priority evidence"
      ],
      "type": "concept",
      "description": "Median Likert responses support greater emphasis on AI-safety research.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Table S4 summarises these responses."
    },
    {
      "name": "Statistically significant regional and demographic differences in predictions (Tables S1-S3)",
      "aliases": [
        "regional/demographic evidence"
      ],
      "type": "concept",
      "description": "Tables S1-S3 document region-based automation gaps and demographic predictor significance.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Tables cited provide quantitative support."
    },
    {
      "name": "Conduct periodic incentivized dual-framing expert surveys with gamma CDF aggregation",
      "aliases": [
        "regular expert timeline surveys",
        "dual-framing HLMI forecasting program"
      ],
      "type": "intervention",
      "description": "Every 2-3 years survey ML experts with both fixed-probability and fixed-year questions, incentivize participation, fit gamma CDFs, and publish aggregated timelines to inform policy.",
      "concept_category": null,
      "intervention_lifecycle": "6",
      "intervention_lifecycle_rationale": "Applies to ongoing governance processes beyond specific model stages (Survey Content & Elicitation of Beliefs).",
      "intervention_maturity": "3",
      "intervention_maturity_rationale": "Prototype survey demonstrated feasibility; periodic repetition would scale the prototype (Statistics section).",
      "node_rationale": "Directly operationalises design rationale of regular dual-framing elicitation."
    },
    {
      "name": "Increase dedicated funding and institutional support for AI safety research",
      "aliases": [
        "expand AI safety grantmaking",
        "boost safety research budgets"
      ],
      "type": "intervention",
      "description": "Governments, philanthropies and industry allocate larger, ring-fenced budgets and establish specialised programs to accelerate AI-safety research.",
      "concept_category": null,
      "intervention_lifecycle": "6",
      "intervention_lifecycle_rationale": "Resource-allocation action independent of specific model development phases (Acknowledgments).",
      "intervention_maturity": "3",
      "intervention_maturity_rationale": "Existing funders show pilot-level activity; significant scaling remains (Acknowledgments).",
      "node_rationale": "Addresses underprioritization indicated by survey safety responses."
    },
    {
      "name": "Develop region-specific workforce transition and reskilling programs based on automation timelines",
      "aliases": [
        "regional AI labour policy",
        "tailored reskilling schemes"
      ],
      "type": "intervention",
      "description": "Labour ministries use region-specific automation forecasts to time reskilling initiatives, unemployment-insurance adjustments, and educational reforms.",
      "concept_category": null,
      "intervention_lifecycle": "5",
      "intervention_lifecycle_rationale": "Implemented during deployment phase as AI systems begin replacing jobs (Table S1 context).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Conceptual policies exist but systematic implementation is limited (Table S1 provides only forecasts).",
      "node_rationale": "Directly responds to regional differences highlighted by survey evidence."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Uncontrolled intelligence explosion from HLMI",
      "target_node": "High uncertainty in HLMI timelines among AI experts",
      "description": "Insufficient clarity on when HLMI arrives hampers preparedness, increasing risk of an uncontrolled take-off.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Connection inferred from general safety reasoning; not explicit in paper.",
      "edge_rationale": "Implicit in motivation for timeline forecasting (Survey Content §1)."
    },
    {
      "type": "caused_by",
      "source_node": "High uncertainty in HLMI timelines among AI experts",
      "target_node": "Question framing effects on expert timeline predictions",
      "description": "One major contributor to uncertainty is systematic variation introduced by framing.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Strong empirical framing effect shown in Fig S2.",
      "edge_rationale": "Elicitation of Beliefs section documents framing impact."
    },
    {
      "type": "mitigated_by",
      "source_node": "Question framing effects on expert timeline predictions",
      "target_node": "Regular dual-framing expert elicitation to reduce timeline uncertainty",
      "description": "Using both framings and averaging counters framing bias.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Reasoned design choice referenced in discussion.",
      "edge_rationale": "Elicitation of Beliefs proposes combining framings."
    },
    {
      "type": "implemented_by",
      "source_node": "Regular dual-framing expert elicitation to reduce timeline uncertainty",
      "target_node": "Gamma CDF mixture aggregation of expert HLMI forecasts",
      "description": "Gamma-fit mixture operationalises the aggregation step required by the design.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Statistical method explicitly applied (Statistics section).",
      "edge_rationale": "Statistics section explains implementation."
    },
    {
      "type": "implemented_by",
      "source_node": "Regular dual-framing expert elicitation to reduce timeline uncertainty",
      "target_node": "Incentivized online survey deployment to collect expert forecasts",
      "description": "Practical survey deployment collects the dual-framing data.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Survey Content details incentive mechanism.",
      "edge_rationale": "Survey Content § explains execution."
    },
    {
      "type": "validated_by",
      "source_node": "Gamma CDF mixture aggregation of expert HLMI forecasts",
      "target_node": "Empirical framing effect observed in HLMI CDF curves (Fig S2)",
      "description": "Aggregated CDFs display distinct curves for each framing, confirming method captures framing differences.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Direct empirical evidence (Fig S2).",
      "edge_rationale": "Fig. S2 compares aggregated curves."
    },
    {
      "type": "motivates",
      "source_node": "Empirical framing effect observed in HLMI CDF curves (Fig S2)",
      "target_node": "Conduct periodic incentivized dual-framing expert surveys with gamma CDF aggregation",
      "description": "Demonstrated framing bias motivates institutionalising periodic dual-framing surveys.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Logical extension of evidence; not experimentally tested.",
      "edge_rationale": "Discussion implies need for ongoing monitoring."
    },
    {
      "type": "caused_by",
      "source_node": "Misaligned goals in HLMI systems",
      "target_node": "Underprioritization of AI safety research in ML community",
      "description": "Insufficient safety research increases likelihood that future HLMI will be misaligned.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Widely held reasoning but not directly measured in survey.",
      "edge_rationale": "Motivates survey block on safety prioritisation (Survey Content §7)."
    },
    {
      "type": "mitigated_by",
      "source_node": "Underprioritization of AI safety research in ML community",
      "target_node": "Increased prioritization of AI safety research based on expert risk assessments",
      "description": "Raising the priority of safety research addresses the underinvestment problem.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Supported by expert opinions in Table S4.",
      "edge_rationale": "Table S4 shows desire for higher priority."
    },
    {
      "type": "implemented_by",
      "source_node": "Increased prioritization of AI safety research based on expert risk assessments",
      "target_node": "Dedicated funding channels and grant programs for AI safety research",
      "description": "Dedicated funding is a concrete mechanism to raise research priority.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Existing grantmakers (Acknowledgments) illustrate feasibility.",
      "edge_rationale": "Acknowledgments cite safety funders."
    },
    {
      "type": "validated_by",
      "source_node": "Dedicated funding channels and grant programs for AI safety research",
      "target_node": "Survey responses indicating desire for more safety research (Table S4)",
      "description": "Safety-priority survey answers validate the need for expanded funding.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Indirect validation via expressed preferences.",
      "edge_rationale": "Table S4 presents supporting data."
    },
    {
      "type": "motivates",
      "source_node": "Survey responses indicating desire for more safety research (Table S4)",
      "target_node": "Increase dedicated funding and institutional support for AI safety research",
      "description": "Expressed expert desire motivates implementing funding increases.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Logical policy step derived from evidence.",
      "edge_rationale": "Synthesises survey finding into action."
    },
    {
      "type": "caused_by",
      "source_node": "Economic displacement of human labor due to HLMI automation",
      "target_node": "Regional variation in automation timeline predictions",
      "description": "Differential regional timelines complicate coordinated labour-market responses, heightening displacement risk.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Inference based on Table S1 data.",
      "edge_rationale": "Table S1 shows timeline gaps."
    },
    {
      "type": "caused_by",
      "source_node": "Regional variation in automation timeline predictions",
      "target_node": "Demographic factors weakly influencing HLMI timeline predictions",
      "description": "Regional variation is one manifestation of broader demographic influences on forecasts.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Supported by robust regression results in Table S2.",
      "edge_rationale": "Table S2 identifies region as significant predictor."
    },
    {
      "type": "mitigated_by",
      "source_node": "Demographic factors weakly influencing HLMI timeline predictions",
      "target_node": "Region-specific policy planning informed by expert automation forecasts",
      "description": "Acknowledging demographic effects enables tailored policy planning.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Policy inference grounded in statistical evidence.",
      "edge_rationale": "Discussion around Table S1 implies such use."
    },
    {
      "type": "implemented_by",
      "source_node": "Region-specific policy planning informed by expert automation forecasts",
      "target_node": "Robust regression analysis to detect demographic effects on predictions",
      "description": "Robust regression supplies the analytic basis for region-specific planning.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Statistical method precisely quantifies demographic effects (Statistics section).",
      "edge_rationale": "Statistics section describes regression."
    },
    {
      "type": "validated_by",
      "source_node": "Robust regression analysis to detect demographic effects on predictions",
      "target_node": "Statistically significant regional and demographic differences in predictions (Tables S1-S3)",
      "description": "Regression significance and regional gaps in tables constitute validation.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Direct empirical evidence.",
      "edge_rationale": "Tables S1-S3 provide data."
    },
    {
      "type": "motivates",
      "source_node": "Statistically significant regional and demographic differences in predictions (Tables S1-S3)",
      "target_node": "Develop region-specific workforce transition and reskilling programs based on automation timelines",
      "description": "Evidence of regional gaps motivates tailoring reskilling policies.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Policy implication drawn from quantitative evidence.",
      "edge_rationale": "Logical extension from data to policy."
    }
  ],
  "meta": [
    {
      "key": "url",
      "value": "https://arxiv.org/abs/1705.08807"
    },
    {
      "key": "title",
      "value": "When Will AI Exceed Human Performance? Evidence from AI Experts"
    },
    {
      "key": "authors",
      "value": [
        "Katja Grace",
        "John Salvatier",
        "Allan Dafoe",
        "Baobao Zhang",
        "Owain Evans"
      ]
    },
    {
      "key": "date_published",
      "value": "2017-05-24T00:00:00Z"
    },
    {
      "key": "source",
      "value": "arxiv"
    }
  ]
}