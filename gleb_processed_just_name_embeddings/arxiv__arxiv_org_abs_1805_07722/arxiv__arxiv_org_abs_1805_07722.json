{
  "nodes": [
    {
      "name": "Poor generalization of meta-learned models to unseen tasks",
      "aliases": [
        "generalization failure in meta-learning",
        "weak adaptation to new tasks"
      ],
      "type": "concept",
      "description": "Meta-learned systems sometimes perform poorly on tasks that were not represented in the meta-training distribution, undermining few-shot learning goals.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced in Section 1 Introduction as the motivating risk driving TAML."
    },
    {
      "name": "Biased initial model over-performs on sampled meta-training tasks",
      "aliases": [
        "task bias in initial meta-learner",
        "over-performance on training tasks"
      ],
      "type": "concept",
      "description": "When the initial meta-learned model is tuned to a subset of training tasks, its performance distribution is skewed, harming adaptation to dissimilar tasks.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Problem highlighted at the start of Section 2.1 Task-Agnostic Meta-Learning."
    },
    {
      "name": "Absence of task-agnostic prior leads to biased initial performance in meta-learning",
      "aliases": [
        "lack of task-agnostic prior",
        "unconstrained initial model hypothesis"
      ],
      "type": "concept",
      "description": "Without an explicit constraint encouraging equal initial performance across tasks, gradient-based meta-learning naturally favours tasks seen during training.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Theoretical reasoning in Section 2.1 motivating both TAML variants."
    },
    {
      "name": "Entropy regularization to enforce task-agnostic prior in classification tasks",
      "aliases": [
        "entropy-based TAML rationale",
        "maximum-entropy prior for meta-learning"
      ],
      "type": "concept",
      "description": "By maximising prediction entropy before adaptation (and optionally minimising it after), the initial model is discouraged from confident, task-specific predictions.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Detailed in Section 2.1.1 Entropy-Maximisation/Reduction TAML."
    },
    {
      "name": "λ(−H_before + H_after) entropy term in meta-training objective",
      "aliases": [
        "entropy reduction objective",
        "entropy-TAML implementation detail"
      ],
      "type": "concept",
      "description": "The meta-training loss is augmented with a weighted entropy-reduction term computed from soft-max outputs before and after one gradient step.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Equation in Section 2.1.1 and Algorithm 1 specify the mechanism."
    },
    {
      "name": "Entropy-TAML accuracy improvements on Omniglot and MiniImagenet benchmarks",
      "aliases": [
        "entropy-TAML experimental results",
        "classification gains with entropy regularisation"
      ],
      "type": "concept",
      "description": "Experiments in Section 4.1 show entropy-TAML surpasses MAML and other baselines across 1-shot and 5-shot settings.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Tables 1–3 provide quantitative evidence for effectiveness."
    },
    {
      "name": "Apply entropy-based task-agnostic regularization during meta-training",
      "aliases": [
        "train meta-learner with entropy TAML",
        "entropy-TAML intervention"
      ],
      "type": "intervention",
      "description": "During the meta-training phase, augment the objective with the entropy reduction term and perform joint optimisation of initial weights and update rule.",
      "concept_category": null,
      "intervention_lifecycle": "2",
      "intervention_lifecycle_rationale": "Occurs while pre-training the meta-learner (Section 2.1.1 Algorithm 1).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Technique validated only in experimental settings on standard benchmarks (Section 4.1).",
      "node_rationale": "Concrete actionable step derived from design and validation."
    },
    {
      "name": "Loss-inequality minimisation regularization to enforce task-agnostic prior",
      "aliases": [
        "inequality-based TAML rationale",
        "economic inequality measures in meta-learning"
      ],
      "type": "concept",
      "description": "Bias is reduced by directly minimising inequality across task losses using measures such as Theil, Gini, GE, Atkinson or Variance of Logs.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced in Section 2.1.2 Inequality-Minimisation TAML."
    },
    {
      "name": "IE({losses}) regularisation term with Theil, GE, Gini, Atkinson or VL indices",
      "aliases": [
        "inequality-measure objective",
        "loss inequality term implementation"
      ],
      "type": "concept",
      "description": "The meta-objective adds λ·IE where IE is computed over per-task losses in each batch; gradients flow through to initial parameters.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Equations (2)–(6) and Algorithm 2 in Section 2.2."
    },
    {
      "name": "Inequality-TAML performance gains on vision and RL tasks",
      "aliases": [
        "inequality-TAML experimental results",
        "task-loss inequality validation"
      ],
      "type": "concept",
      "description": "Tables 1–3 and Figure 1 show inequality-TAML surpasses MAML and Meta-SGD on Omniglot, MiniImagenet and 2-D navigation after multiple gradient steps.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Empirical confirmation of the proposed mechanism’s effectiveness."
    },
    {
      "name": "Apply inequality-measure based task-agnostic regularization during meta-training",
      "aliases": [
        "train meta-learner with inequality TAML",
        "inequality-TAML intervention"
      ],
      "type": "intervention",
      "description": "During meta-training, augment the loss with an inequality measure of task losses (e.g., Theil, Gini) and optimise jointly.",
      "concept_category": null,
      "intervention_lifecycle": "2",
      "intervention_lifecycle_rationale": "Executed during pre-training of the meta-learner (Section 2.1.2 Algorithm 2).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Validated only through proof-of-concept experiments (Sections 4.1 & 4.2).",
      "node_rationale": "Second actionable intervention derived from the inequality TAML branch."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Poor generalization of meta-learned models to unseen tasks",
      "target_node": "Biased initial model over-performs on sampled meta-training tasks",
      "description": "Performance degradation on novel tasks is traced to the initial model being skewed toward meta-training tasks.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicit statement in Section 1 that biased initial models harm unseen tasks.",
      "edge_rationale": "Connects risk to immediately underlying problem analysis."
    },
    {
      "type": "caused_by",
      "source_node": "Biased initial model over-performs on sampled meta-training tasks",
      "target_node": "Absence of task-agnostic prior leads to biased initial performance in meta-learning",
      "description": "Bias arises because no constraint forces equal initial performance across tasks.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Reasoning articulated in Section 2.1.",
      "edge_rationale": "Links problem manifestation to its theoretical cause."
    },
    {
      "type": "mitigated_by",
      "source_node": "Absence of task-agnostic prior leads to biased initial performance in meta-learning",
      "target_node": "Entropy regularization to enforce task-agnostic prior in classification tasks",
      "description": "Introducing entropy regularisation provides the missing task-agnostic prior.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 2.1.1 positions entropy approach as remedy.",
      "edge_rationale": "Establishes first design rationale as mitigation."
    },
    {
      "type": "mitigated_by",
      "source_node": "Absence of task-agnostic prior leads to biased initial performance in meta-learning",
      "target_node": "Loss-inequality minimisation regularization to enforce task-agnostic prior",
      "description": "Minimising loss inequality across tasks also supplies a task-agnostic prior.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 2.1.2 proposes inequality approach for same purpose.",
      "edge_rationale": "Second design rationale mitigating theoretical cause."
    },
    {
      "type": "implemented_by",
      "source_node": "Entropy regularization to enforce task-agnostic prior in classification tasks",
      "target_node": "λ(−H_before + H_after) entropy term in meta-training objective",
      "description": "The entropy regularisation is operationalised via the specified objective term.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Equation and algorithm explicitly define implementation.",
      "edge_rationale": "Maps design rationale to concrete mechanism."
    },
    {
      "type": "implemented_by",
      "source_node": "Loss-inequality minimisation regularization to enforce task-agnostic prior",
      "target_node": "IE({losses}) regularisation term with Theil, GE, Gini, Atkinson or VL indices",
      "description": "Inequality-based rationale is realised through the IE regularisation term.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Algorithm 2 and Section 2.2 equations specify mechanism.",
      "edge_rationale": "Maps second design rationale to concrete mechanism."
    },
    {
      "type": "validated_by",
      "source_node": "λ(−H_before + H_after) entropy term in meta-training objective",
      "target_node": "Entropy-TAML accuracy improvements on Omniglot and MiniImagenet benchmarks",
      "description": "Benchmark experiments confirm the effectiveness of the entropy mechanism.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Statistical results with confidence intervals in Tables 1–3.",
      "edge_rationale": "Provides empirical support."
    },
    {
      "type": "validated_by",
      "source_node": "IE({losses}) regularisation term with Theil, GE, Gini, Atkinson or VL indices",
      "target_node": "Inequality-TAML performance gains on vision and RL tasks",
      "description": "Empirical studies demonstrate improved performance using inequality measures.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Tables 1–3 and Figure 1 present consistent gains.",
      "edge_rationale": "Empirical support for second mechanism."
    },
    {
      "type": "motivates",
      "source_node": "Entropy-TAML accuracy improvements on Omniglot and MiniImagenet benchmarks",
      "target_node": "Apply entropy-based task-agnostic regularization during meta-training",
      "description": "Positive results encourage adoption of entropy-based regularisation as an intervention.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Strong experimental evidence in Section 4.1.",
      "edge_rationale": "Connects validation to actionable step."
    },
    {
      "type": "motivates",
      "source_node": "Inequality-TAML performance gains on vision and RL tasks",
      "target_node": "Apply inequality-measure based task-agnostic regularization during meta-training",
      "description": "Performance improvements motivate deploying inequality-based regularisation.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Results across multiple domains (Sections 4.1 & 4.2).",
      "edge_rationale": "Links second validation to its intervention."
    }
  ],
  "meta": [
    {
      "key": "title",
      "value": "Task-Agnostic Meta-Learning for Few-shot Learning"
    },
    {
      "key": "url",
      "value": "https://arxiv.org/abs/1805.07722"
    },
    {
      "key": "date_published",
      "value": "2018-05-20T00:00:00Z"
    },
    {
      "key": "authors",
      "value": [
        "Muhammad Abdullah Jamal",
        "Guo-Jun Qi",
        "Mubarak Shah"
      ]
    },
    {
      "key": "source",
      "value": "arxiv"
    }
  ]
}