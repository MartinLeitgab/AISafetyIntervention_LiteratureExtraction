{
  "nodes": [
    {
      "name": "Catastrophic outcomes from flawed decision-making in superintelligent AI",
      "aliases": [
        "AI catastrophe via bad decisions",
        "Failure of superintelligent AI decision procedures"
      ],
      "type": "concept",
      "description": "Potential existential or large-scale societal harms that arise when highly capable AI systems follow decision procedures that mis-optimise with respect to human values.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Explicitly identified in Introduction as the overarching threat motivating idealised decision theory."
    },
    {
      "name": "Unreliable counterfactual reasoning in evidential decision theory",
      "aliases": [
        "EDT counterfactual flaws",
        "News-managing behaviour of EDT"
      ],
      "type": "concept",
      "description": "EDT conditions on its own actions as evidence, leading to spurious correlations and vulnerability to ‘evidential blackmail’.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Detailed in Section 2.1 as a primary failure mode producing sub-optimal actions."
    },
    {
      "name": "Optimization target drift in causal decision theory with self-modification",
      "aliases": [
        "CDT target instability",
        "Shifting optimisation objective in CDT agents"
      ],
      "type": "concept",
      "description": "Because CDT recomputes counterfactuals after each update, a self-modifying agent’s optimisation target changes over time, preventing stable commitments.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Explained in Section 3 using time-indexed CDT examples."
    },
    {
      "name": "Exploitation in Newcomblike problems due to CDT vulnerability",
      "aliases": [
        "CDT loses one-shot PD",
        "CDT exploitation"
      ],
      "type": "concept",
      "description": "CDT defects in Prisoner’s Dilemma against correlated opponents, allowing predictors or copies to systematically exploit the agent.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Laid out in Section 2.2 with symmetric PD thought experiment."
    },
    {
      "name": "Instability under reflection of existing decision theories",
      "aliases": [
        "Non-self-recommending CDT/EDT",
        "Reflective inconsistency of standard DTs"
      ],
      "type": "concept",
      "description": "CDT and EDT agents resist or undo beneficial self-modifications, creating persistent vulnerabilities such as retro-blackmail.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Discussed in Sections 3 and 6 as a barrier to safe self-improvement."
    },
    {
      "name": "Need for policy selection over action conditioning to avoid blackmail vulnerabilities",
      "aliases": [
        "Updateless policy selection insight",
        "Global policy reasoning necessity"
      ],
      "type": "concept",
      "description": "Selecting entire observation-to-action mappings before observing eliminates incentives to ‘manage the news’ and defeats counterfactual blackmail.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced in Section 4 as first core idea behind UDT."
    },
    {
      "name": "Importance of logical counterfactuals to capture algorithmic correlations",
      "aliases": [
        "Logical dependence counterfactuals",
        "Need for reasoning about identical algorithms"
      ],
      "type": "concept",
      "description": "Counterfactuals must respect logical, not just causal, links; identical or correlated algorithms should be treated as co-varying when evaluating actions.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Developed in Section 5 with Prisoner’s Dilemma analysis."
    },
    {
      "name": "Optimization target defined by preferences plus counterfactual model",
      "aliases": [
        "Optimisation target concept",
        "Preferences + counterfactuals"
      ],
      "type": "concept",
      "description": "A decision procedure’s goal is fixed by both its utility function and the manner in which it constructs counterfactuals; errors in either part produce bad behaviour.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Formally articulated in Section 3 to diagnose CDT drift."
    },
    {
      "name": "Updateless decision theory combining policy selection and logical counterfactuals",
      "aliases": [
        "UDT high-level design",
        "UDT synthesis"
      ],
      "type": "concept",
      "description": "A proposed decision framework that first chooses a global policy and evaluates it using logical counterfactuals, aiming to stabilise optimisation targets and avoid exploitation.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Sections 4–5 present UDT as the main solution candidate."
    },
    {
      "name": "Indirect normativity approach to defer decision theory discovery",
      "aliases": [
        "Delegated ideal-advisor method",
        "Indirect normative fallback"
      ],
      "type": "concept",
      "description": "If ideal decision theory proves too hard, AI could instead learn what humans would endorse under reflection and defer exact decision-rule design to that process.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Outlined in Section 6 as a contingency plan."
    },
    {
      "name": "Proof-based UDT algorithm using formal proof search",
      "aliases": [
        "Proof-based implementation of UDT",
        "UDT proof search variant"
      ],
      "type": "concept",
      "description": "Implementation that searches for proofs of outcome values under the assumption the agent’s algorithm outputs each candidate policy, then selects the best provably-good policy.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Detailed in Section 5.2 (Algorithm 1) as concrete mechanism."
    },
    {
      "name": "Graphical UDT encoding logical relations in causal graphs",
      "aliases": [
        "Graph-based UDT",
        "Logical-causal graph UDT"
      ],
      "type": "concept",
      "description": "A variant of UDT that generalises Pearlian causal graphs to include nodes for algorithms and their logical dependencies.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Presented in Section 5.1 as an alternative implementation path."
    },
    {
      "name": "Thought experiments of counterfactual and retro blackmail demonstrating UDT advantage",
      "aliases": [
        "Blackmail scenarios as evidence",
        "EDT/CDT vs UDT blackmail results"
      ],
      "type": "concept",
      "description": "Analytical examples showing UDT agents refuse blackmail whereas EDT/CDT agents pay, supporting UDT’s safety claims.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Used throughout Sections 2–5 as primary qualitative validation."
    },
    {
      "name": "Symmetric Prisoner's Dilemma cooperation payoff illustrating UDT benefit",
      "aliases": [
        "UDT in PD evidence",
        "PD cooperation example"
      ],
      "type": "concept",
      "description": "Demonstration that UDT cooperates with identical copies to achieve higher payoffs than CDT, indicating robustness to Newcomblike exploitation.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 5 example serves as secondary validation."
    },
    {
      "name": "Research and develop formal logical counterfactual frameworks for AI decision-making",
      "aliases": [
        "Logical counterfactual research agenda",
        "Formalise logical dependencies"
      ],
      "type": "intervention",
      "description": "Launch foundational research programmes to create mathematically rigorous models of logical counterfactuals that can be embedded into AI planners.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Targets model-design foundations; see Section 5 discussion of unsolved formalisation issues.",
      "intervention_maturity": "1",
      "intervention_maturity_rationale": "Purely theoretical initiative with no prototypes yet (Section 5).",
      "node_rationale": "Translates unresolved formal gaps into an actionable research agenda."
    },
    {
      "name": "Integrate updateless decision theory principles in AI system design",
      "aliases": [
        "Embed UDT in planners",
        "UDT-based decision module"
      ],
      "type": "intervention",
      "description": "During architecture design, incorporate policy-selection and logical-counterfactual reasoning modules inspired by UDT to govern high-level choices.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Shapes architecture before training; aligns with Sections 4–5 recommendations.",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Only conceptual prototypes exist (proof-based / graphical sketches).",
      "node_rationale": "Direct design response to UDT’s proposed advantages."
    },
    {
      "name": "Adopt policy selection in AI decision algorithms to mitigate exploitability",
      "aliases": [
        "Updateless policy module",
        "Global policy commitment"
      ],
      "type": "intervention",
      "description": "Ensure agents choose entire policies prior to observation rather than conditioning at run-time, reducing susceptibility to counterfactual blackmail.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Implemented at decision-module design (Section 4).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Demonstrated only in analytic examples (no empirical validation).",
      "node_rationale": "Operationalises theoretical insight about policy selection."
    },
    {
      "name": "Analyze decision procedure self-modification effects for stability",
      "aliases": [
        "Self-modification safety analysis",
        "Reflective stability audits"
      ],
      "type": "intervention",
      "description": "Perform formal analysis of how an AI’s decision algorithm behaves under self-modification to prevent optimisation-target drift and retro-blackmail vulnerabilities.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Conducted during model design and verification phases (Sections 3 & 6).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Only theoretical criteria exist; no deployed audit pipelines.",
      "node_rationale": "Addresses reflective instability problems highlighted in the paper."
    },
    {
      "name": "Indirect normativity framework delegating decision theory discovery to AI",
      "aliases": [
        "Ideal-advisor indirect approach",
        "Delegated decision-theory search"
      ],
      "type": "concept",
      "description": "An implementation mechanism whereby AI models infer human-endorsed decision principles through idealised reflection instead of preset formalisms.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 6 proposes this as a concrete path if ideal DT remains unsolved."
    },
    {
      "name": "Conceptual argument that indirect normativity still requires decision theory advances",
      "aliases": [
        "Indirect approach limitation evidence",
        "Need for DT even with delegation"
      ],
      "type": "concept",
      "description": "Reasoning that delegating decision-theory work still presupposes enough understanding to trust the delegation step, indicating remaining theoretical gaps.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 6 argues this limitation, functioning as validation for needing further analysis."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Catastrophic outcomes from flawed decision-making in superintelligent AI",
      "target_node": "Unreliable counterfactual reasoning in evidential decision theory",
      "description": "EDT’s incorrect counterfactuals can drive an advanced AI to pay blackmail or otherwise act against human interests, leading to catastrophic loss.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Directly argued in Section 2.1 via Evidential Blackmail example.",
      "edge_rationale": "Links overarching risk to first specific failure mode."
    },
    {
      "type": "caused_by",
      "source_node": "Catastrophic outcomes from flawed decision-making in superintelligent AI",
      "target_node": "Optimization target drift in causal decision theory with self-modification",
      "description": "Shifting optimisation targets under CDT may let a system self-modify into harmful behaviours.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 3 illustrates drift leading to retro-blackmail vulnerability.",
      "edge_rationale": "Binds risk to CDT drift problem."
    },
    {
      "type": "caused_by",
      "source_node": "Catastrophic outcomes from flawed decision-making in superintelligent AI",
      "target_node": "Exploitation in Newcomblike problems due to CDT vulnerability",
      "description": "CDT’s defect-by-default leads to sub-optimal payoffs under algorithmic prediction, allowing external manipulation with high stakes.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 2.2 Prisoner’s Dilemma shows lower payoff.",
      "edge_rationale": "Connects global risk to exploitation scenario."
    },
    {
      "type": "caused_by",
      "source_node": "Catastrophic outcomes from flawed decision-making in superintelligent AI",
      "target_node": "Instability under reflection of existing decision theories",
      "description": "Reflective inconsistency may stop an AI from adopting safer decision rules, prolonging dangerous behaviour.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 3 retro-blackmail discussion.",
      "edge_rationale": "Highlights reflective instability as risk driver."
    },
    {
      "type": "addressed_by",
      "source_node": "Unreliable counterfactual reasoning in evidential decision theory",
      "target_node": "Need for policy selection over action conditioning to avoid blackmail vulnerabilities",
      "description": "Policy selection avoids EDT’s news-managing behaviour by evaluating policies before observation.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 4 contrasts EDT with policy selection.",
      "edge_rationale": "Shows theoretical insight answering EDT flaw."
    },
    {
      "type": "addressed_by",
      "source_node": "Optimization target drift in causal decision theory with self-modification",
      "target_node": "Optimization target defined by preferences plus counterfactual model",
      "description": "Explicitly defining stable optimisation targets counters CDT’s drift.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 3 introduces concept as remedy.",
      "edge_rationale": "Maps problem to insight."
    },
    {
      "type": "addressed_by",
      "source_node": "Exploitation in Newcomblike problems due to CDT vulnerability",
      "target_node": "Importance of logical counterfactuals to capture algorithmic correlations",
      "description": "Logical counterfactuals ensure correlated agents are considered when choosing actions, preventing exploitation.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 5 PD example explains necessity.",
      "edge_rationale": "Links CDT exploitation issue to insight."
    },
    {
      "type": "addressed_by",
      "source_node": "Instability under reflection of existing decision theories",
      "target_node": "Indirect normativity approach to defer decision theory discovery",
      "description": "Delegating decision-theory discovery to the AI can circumvent immediate reflective instability of CDT/EDT.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Explicitly suggested but acknowledged as partial fix in Section 6.",
      "edge_rationale": "Provides alternative strategy for reflection issue."
    },
    {
      "type": "mitigated_by",
      "source_node": "Need for policy selection over action conditioning to avoid blackmail vulnerabilities",
      "target_node": "Updateless decision theory combining policy selection and logical counterfactuals",
      "description": "UDT incorporates policy selection to neutralise blackmail incentives.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 4 positions UDT as implementation of policy insight.",
      "edge_rationale": "Shows transition from insight to design."
    },
    {
      "type": "mitigated_by",
      "source_node": "Importance of logical counterfactuals to capture algorithmic correlations",
      "target_node": "Updateless decision theory combining policy selection and logical counterfactuals",
      "description": "UDT embeds logical counterfactual reasoning to respect algorithmic correlations.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 5 synthesises elements into UDT.",
      "edge_rationale": "Connects second insight to UDT design."
    },
    {
      "type": "mitigated_by",
      "source_node": "Optimization target defined by preferences plus counterfactual model",
      "target_node": "Updateless decision theory combining policy selection and logical counterfactuals",
      "description": "UDT fixes both preference and counterfactual components, stabilising the optimisation target.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Implicit argument in Section 3 and conclusion.",
      "edge_rationale": "Links optimisation-target concept to UDT."
    },
    {
      "type": "implemented_by",
      "source_node": "Updateless decision theory combining policy selection and logical counterfactuals",
      "target_node": "Proof-based UDT algorithm using formal proof search",
      "description": "Proof-based variant realises UDT by searching for proofs of outcomes under policy assumptions.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Algorithm 1 in Section 5.2 provides concrete specification.",
      "edge_rationale": "Design to mechanism."
    },
    {
      "type": "implemented_by",
      "source_node": "Updateless decision theory combining policy selection and logical counterfactuals",
      "target_node": "Graphical UDT encoding logical relations in causal graphs",
      "description": "Graphical variant operationalises UDT by extending causal graphs with logical edges.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 5.1 outlines graphical scheme.",
      "edge_rationale": "Alternative implementation."
    },
    {
      "type": "validated_by",
      "source_node": "Proof-based UDT algorithm using formal proof search",
      "target_node": "Thought experiments of counterfactual and retro blackmail demonstrating UDT advantage",
      "description": "Proof-based UDT successfully refuses blackmail in formal reasoning examples.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Validation is theoretical only (Section 5.2).",
      "edge_rationale": "Mechanism backed by examples."
    },
    {
      "type": "validated_by",
      "source_node": "Graphical UDT encoding logical relations in causal graphs",
      "target_node": "Symmetric Prisoner's Dilemma cooperation payoff illustrating UDT benefit",
      "description": "Graphical UDT accounts for algorithmic symmetry, yielding cooperation and higher payoffs.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Section 5.1 thought experiment evidence.",
      "edge_rationale": "Graphical mechanism supported."
    },
    {
      "type": "motivates",
      "source_node": "Thought experiments of counterfactual and retro blackmail demonstrating UDT advantage",
      "target_node": "Integrate updateless decision theory principles in AI system design",
      "description": "Demonstrated superiority encourages embedding UDT principles in practical systems.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Logical impetus; no empirical data.",
      "edge_rationale": "Evidence inspires intervention."
    },
    {
      "type": "motivates",
      "source_node": "Thought experiments of counterfactual and retro blackmail demonstrating UDT advantage",
      "target_node": "Research and develop formal logical counterfactual frameworks for AI decision-making",
      "description": "Need for fuller proofs spurs foundational research agenda.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Paper calls for further theory (Section 5).",
      "edge_rationale": "Evidence drives research intervention."
    },
    {
      "type": "motivates",
      "source_node": "Symmetric Prisoner's Dilemma cooperation payoff illustrating UDT benefit",
      "target_node": "Adopt policy selection in AI decision algorithms to mitigate exploitability",
      "description": "Observed cooperation gains motivate adopting policy-selection modules.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Section 5 argument only.",
      "edge_rationale": "Validation to intervention."
    },
    {
      "type": "implemented_by",
      "source_node": "Indirect normativity approach to defer decision theory discovery",
      "target_node": "Indirect normativity framework delegating decision theory discovery to AI",
      "description": "Framework specifies how to operationalise the indirect approach inside an AI system.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Conceptual mechanism suggested in Section 6.",
      "edge_rationale": "Design rationale → mechanism."
    },
    {
      "type": "validated_by",
      "source_node": "Indirect normativity framework delegating decision theory discovery to AI",
      "target_node": "Conceptual argument that indirect normativity still requires decision theory advances",
      "description": "Paper notes remaining theoretical dependency, serving as a reality-check validation.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Reasoning in Section 6 only.",
      "edge_rationale": "Mechanism examined by argument."
    },
    {
      "type": "motivates",
      "source_node": "Conceptual argument that indirect normativity still requires decision theory advances",
      "target_node": "Analyze decision procedure self-modification effects for stability",
      "description": "Highlighting dependency motivates targeted analysis of self-modification and stability.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Inference from Section 6 discussion.",
      "edge_rationale": "Validation drives intervention."
    }
  ],
  "meta": [
    {
      "key": "title",
      "value": "Toward Idealized Decision Theory"
    },
    {
      "key": "url",
      "value": "https://arxiv.org/abs/1507.01986"
    },
    {
      "key": "date_published",
      "value": "2015-07-07T00:00:00Z"
    },
    {
      "key": "authors",
      "value": [
        "Nate Soares",
        "Benja Fallenstein"
      ]
    },
    {
      "key": "source",
      "value": "arxiv"
    }
  ]
}