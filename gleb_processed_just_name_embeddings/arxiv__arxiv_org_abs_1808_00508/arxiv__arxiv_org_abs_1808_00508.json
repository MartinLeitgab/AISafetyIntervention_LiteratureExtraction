{
  "nodes": [
    {
      "name": "numerical extrapolation failure in neural networks",
      "aliases": [
        "numeric generalization failure in neural nets",
        "out-of-range numeracy failure"
      ],
      "type": "concept",
      "description": "Neural networks often fail when asked to manipulate numbers that lie outside the range encountered during training, leading to large systematic errors.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Outlined in Section 1.1 Numerical Extrapolation Failures in Neural Networks as the primary motivation for the work."
    },
    {
      "name": "nonlinear activations causing localized numeric representations in neural networks",
      "aliases": [
        "activation-induced memorization",
        "non-linear activation hampers numeracy"
      ],
      "type": "concept",
      "description": "Widely-used nonlinearities (ReLU, tanh, sigmoid, etc.) encourage networks to memorise numeric values seen in training instead of encoding systematic arithmetic relations.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Documented in the identity-function auto-encoder experiment in Section 1.1."
    },
    {
      "name": "lack of inductive bias for arithmetic operations in neural networks",
      "aliases": [
        "missing arithmetic priors",
        "absence of arithmetic inductive bias"
      ],
      "type": "concept",
      "description": "Standard architectures do not contain explicit structural assumptions that favour addition, subtraction or multiplication, making systematic arithmetic extrapolation unlikely.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Discussed in Introduction and Related Work sections as the underlying cause of extrapolation failure."
    },
    {
      "name": "single-neuron numeric representation enables systematic computation in neural networks",
      "aliases": [
        "scalar neuron number coding",
        "single unit number representation"
      ],
      "type": "concept",
      "description": "Representing each number in a dedicated linear neuron without a nonlinearity permits global arithmetic operations to be expressed cleanly and generalise beyond observed ranges.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Explicit rationale in Section 2 introducing NAC & NALU."
    },
    {
      "name": "constraining weights to {-1,0,1} preserves numeric scale during accumulation",
      "aliases": [
        "signed unit weight constraint",
        "scale-preserving weight constraint"
      ],
      "type": "concept",
      "description": "Restricting transformation matrices to the values −1, 0 or 1 (or very near) prevents unwanted rescaling of numeric representations as they propagate through layers.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Motivated in Section 2 when formalising the NAC."
    },
    {
      "name": "architectural bias for additive accumulation via Neural Accumulator",
      "aliases": [
        "NAC additive bias",
        "Neural Accumulator design rationale"
      ],
      "type": "concept",
      "description": "Designing a module whose only learned behaviour is to add or subtract inputs builds a strong prior for linear arithmetic necessary for accurate extrapolation.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 2 describes this as the first step towards systematic numeracy."
    },
    {
      "name": "gated mixture of additive and multiplicative arithmetic in Neural Arithmetic Logic Unit",
      "aliases": [
        "NALU design rationale",
        "gated add-multiply architecture"
      ],
      "type": "concept",
      "description": "Extending the NAC with a gate that blends an additive sub-cell and a log-space multiplicative sub-cell supports a wider class of arithmetic operations (×, ÷, powers).",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Explained in Figure 2 and accompanying text."
    },
    {
      "name": "weight parameterization via tanh(^W)⊙σ(^M) to approximate {-1,0,1}",
      "aliases": [
        "tanh-sigmoid weight product",
        "continuous approximation of signed unit weights"
      ],
      "type": "concept",
      "description": "A differentiable re-parameterisation lets gradient descent learn weights that stay close to −1, 0 or 1, making NAC trainable end-to-end.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced in Section 2 as the practical implementation of the NAC."
    },
    {
      "name": "NALU log-space multiplication/division using exp(W log|x|)",
      "aliases": [
        "log-space NAC",
        "multiplicative sub-cell implementation"
      ],
      "type": "concept",
      "description": "By operating in log-space the multiplicative sub-cell can perform ×, ÷ and power functions while remaining differentiable and trainable.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Equation block underneath Figure 2 details this mechanism."
    },
    {
      "name": "integration of NAC/NALU modules into diverse neural architectures",
      "aliases": [
        "drop-in NAC/NALU layers",
        "architectural integration of arithmetic modules"
      ],
      "type": "concept",
      "description": "The proposed modules can replace standard linear layers in CNNs, RNNs, program evaluators and reinforcement learning agents without other changes.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Demonstrated across all Experiment subsections (Section 4)."
    },
    {
      "name": "identity function autoencoder extrapolation results",
      "aliases": [
        "scalar identity experiment",
        "identity task evidence"
      ],
      "type": "concept",
      "description": "Figure 1 shows that standard MLPs fail outside [−5,5] while NAC/NALU variants reconstruct accurately up to ±20, proving improved extrapolation.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Validation evidence from Section 1.1."
    },
    {
      "name": "synthetic arithmetic tasks demonstrating NAC/NALU extrapolation success",
      "aliases": [
        "Table 1 evidence",
        "simple function learning results"
      ],
      "type": "concept",
      "description": "Table 1 shows zero or near-zero error for NAC/NALU on unseen magnitudes across six arithmetic functions, unlike baselines.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Summarised in Section 4.1 Simple Function Learning Tasks."
    },
    {
      "name": "MNIST counting and addition tasks showing NAC/NALU extrapolation",
      "aliases": [
        "Table 2 evidence",
        "image counting extrapolation"
      ],
      "type": "concept",
      "description": "On sequence lengths 100 and 1000, only NAC/NALU maintain low error, indicating successful generalisation from images to large numeric ranges.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Documented in Section 4.2 MNIST Counting and Addition."
    },
    {
      "name": "language-to-number translation task improved generalization with NALU",
      "aliases": [
        "Table 3 evidence",
        "number word translation generalisation"
      ],
      "type": "concept",
      "description": "NALU yields ~0.4 MAE on unseen text numbers whereas LSTM baseline errors exceed 29, evidencing systematic numeric reasoning from language.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 4.3 Language to Number Translation Tasks."
    },
    {
      "name": "program evaluation task extrapolation success with NALU",
      "aliases": [
        "Figure 4 evidence",
        "program execution generalisation"
      ],
      "type": "concept",
      "description": "Only the LSTM-controlled NALU maintains high digit-match accuracy when extrapolated from 2-digit to 4-digit arithmetic programs.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Presented in Section 4.4 Program Evaluation."
    },
    {
      "name": "gridworld time tracking task generalization with NAC-enhanced agent",
      "aliases": [
        "Figure 5 evidence",
        "RL timing extrapolation"
      ],
      "type": "concept",
      "description": "An A3C agent supplied with a NAC generalises timing behaviour up to T=19, whereas a standard agent fails beyond T=13.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Evidence from Section 4.5 Learning to Track Time."
    },
    {
      "name": "MNIST parity task performance gain with NAC",
      "aliases": [
        "Table 4 evidence",
        "parity interpolation improvement"
      ],
      "type": "concept",
      "description": "Replacing the final affine layer with a NAC improves parity accuracy from 88.1 % to 93.1 %, confirming interpolation benefits of the inductive bias.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 4.6 MNIST Parity Prediction Task."
    },
    {
      "name": "Replace standard layers with Neural Accumulator layers during model design to enable additive extrapolation",
      "aliases": [
        "integrate NAC layer",
        "use Neural Accumulator in architecture"
      ],
      "type": "intervention",
      "description": "During initial architecture design, substitute conventional linear or nonlinear layers with NAC modules that constrain weights to −1,0,1, delivering reliable additive generalisation.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Design phase action described in Section 2 The Neural Accumulator.",
      "intervention_maturity": "3",
      "intervention_maturity_rationale": "Validated across multiple prototypes in Section 4 experiments; however no large-scale deployment reported.",
      "node_rationale": "Primary actionable recommendation of the paper for additive arithmetic robustness."
    },
    {
      "name": "Integrate Neural Arithmetic Logic Unit modules with gated additive and multiplicative operations during model design",
      "aliases": [
        "use NALU module",
        "include Neural Arithmetic Logic Units"
      ],
      "type": "intervention",
      "description": "Embed NALU cells that combine additive and multiplicative sub-cells via a learned gate within model architectures to support a wider range of arithmetic functions.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Module choice occurs at model design time (Section 2).",
      "intervention_maturity": "3",
      "intervention_maturity_rationale": "Extensive prototype validation across tasks (Sections 4.1-4.4) but not yet operationally deployed.",
      "node_rationale": "Recommended when tasks involve multiplicative or divisive reasoning."
    },
    {
      "name": "Embed Neural Accumulator module in reinforcement learning agents for time tracking and timing tasks",
      "aliases": [
        "NAC-enhanced RL agent",
        "RL with NAC time counter"
      ],
      "type": "intervention",
      "description": "Augment the agent network with a NAC pathway that receives timing instructions so that it can reliably count or track elapsed time beyond training horizons.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Architectural augmentation decided during agent design (Section 4.5).",
      "intervention_maturity": "3",
      "intervention_maturity_rationale": "Demonstrated in a prototype grid-world environment; broader validation pending.",
      "node_rationale": "Specific application of NAC to RL agents highlighted by the authors."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "numerical extrapolation failure in neural networks",
      "target_node": "nonlinear activations causing localized numeric representations in neural networks",
      "description": "Localized numeric encodings produced by common nonlinearities lead directly to extrapolation errors.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Identity-function experiment (Section 1.1) provides controlled evidence.",
      "edge_rationale": "Paper links extrapolation failure to the behaviour of activations."
    },
    {
      "type": "caused_by",
      "source_node": "nonlinear activations causing localized numeric representations in neural networks",
      "target_node": "lack of inductive bias for arithmetic operations in neural networks",
      "description": "Absence of arithmetic priors forces networks to rely on nonlinear memorisation.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Conceptual argument in Introduction; limited empirical isolation.",
      "edge_rationale": "Authors argue that without an inductive bias, activations default to memorisation."
    },
    {
      "type": "addressed_by",
      "source_node": "lack of inductive bias for arithmetic operations in neural networks",
      "target_node": "single-neuron numeric representation enables systematic computation in neural networks",
      "description": "Introducing an explicit scalar representation supplies the missing inductive bias.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Logical inference connecting theory to identified gap.",
      "edge_rationale": "Section 2 proposes scalar neurons to overcome absent bias."
    },
    {
      "type": "mitigated_by",
      "source_node": "single-neuron numeric representation enables systematic computation in neural networks",
      "target_node": "architectural bias for additive accumulation via Neural Accumulator",
      "description": "The NAC operationalises the single-neuron idea for addition/subtraction.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Design rationale clearly linked but mainly conceptual.",
      "edge_rationale": "Section 2 explains NAC as first realisation of the representation insight."
    },
    {
      "type": "mitigated_by",
      "source_node": "single-neuron numeric representation enables systematic computation in neural networks",
      "target_node": "gated mixture of additive and multiplicative arithmetic in Neural Arithmetic Logic Unit",
      "description": "The NALU extends the idea to multiplication and division via gating.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Direct design reasoning in Figure 2.",
      "edge_rationale": "Shows how the representation supports richer arithmetic."
    },
    {
      "type": "implemented_by",
      "source_node": "architectural bias for additive accumulation via Neural Accumulator",
      "target_node": "weight parameterization via tanh(^W)⊙σ(^M) to approximate {-1,0,1}",
      "description": "Specific differentiable parameterisation realises the NAC design.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Mathematical formulation given in Section 2.",
      "edge_rationale": "Implementation turns design into trainable module."
    },
    {
      "type": "implemented_by",
      "source_node": "gated mixture of additive and multiplicative arithmetic in Neural Arithmetic Logic Unit",
      "target_node": "NALU log-space multiplication/division using exp(W log|x|)",
      "description": "Log-space NAC plus gating instantiates the multiplicative sub-cell.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Equations and figure detail the implementation.",
      "edge_rationale": "Transforms design rationale into concrete mechanism."
    },
    {
      "type": "implemented_by",
      "source_node": "architectural bias for additive accumulation via Neural Accumulator",
      "target_node": "integration of NAC/NALU modules into diverse neural architectures",
      "description": "Drop-in replacement strategy realises NAC’s additive bias within actual systems.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Demonstrated across experiments but not deeply formalised.",
      "edge_rationale": "Section 4 shows NAC inserted into CNNs, RNNs, RL agents."
    },
    {
      "type": "implemented_by",
      "source_node": "gated mixture of additive and multiplicative arithmetic in Neural Arithmetic Logic Unit",
      "target_node": "integration of NAC/NALU modules into diverse neural architectures",
      "description": "Similarly, NALU cells are plugged into different networks for tasks requiring multiplication.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Empirical integration examples in Sections 4.1–4.4.",
      "edge_rationale": "Shows general applicability of the design."
    },
    {
      "type": "validated_by",
      "source_node": "weight parameterization via tanh(^W)⊙σ(^M) to approximate {-1,0,1}",
      "target_node": "identity function autoencoder extrapolation results",
      "description": "Constrained weights enable perfect identity extrapolation.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Clear quantitative comparison in Figure 1.",
      "edge_rationale": "Directly tests the parameterisation."
    },
    {
      "type": "validated_by",
      "source_node": "weight parameterization via tanh(^W)⊙σ(^M) to approximate {-1,0,1}",
      "target_node": "synthetic arithmetic tasks demonstrating NAC/NALU extrapolation success",
      "description": "Tables confirm zero error on unseen magnitudes.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Table 1 provides numeric evidence.",
      "edge_rationale": "Shows robustness across operations."
    },
    {
      "type": "validated_by",
      "source_node": "integration of NAC/NALU modules into diverse neural architectures",
      "target_node": "MNIST counting and addition tasks showing NAC/NALU extrapolation",
      "description": "Replacing layers with NAC/NALU yields low error over 100× longer sequences.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Table 2 results.",
      "edge_rationale": "Demonstrates effectiveness in vision-to-number pipeline."
    },
    {
      "type": "validated_by",
      "source_node": "NALU log-space multiplication/division using exp(W log|x|)",
      "target_node": "language-to-number translation task improved generalization with NALU",
      "description": "NALU’s multiplicative capacity enables near-perfect generalisation on novel number words.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Table 3 and Figure 3 data.",
      "edge_rationale": "Specific validation of multiplicative sub-cell."
    },
    {
      "type": "validated_by",
      "source_node": "NALU log-space multiplication/division using exp(W log|x|)",
      "target_node": "program evaluation task extrapolation success with NALU",
      "description": "Only NALU solves 4-digit program evaluation, confirming design.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Figure 4 performance curves.",
      "edge_rationale": "Shows general arithmetic reasoning."
    },
    {
      "type": "validated_by",
      "source_node": "integration of NAC/NALU modules into diverse neural architectures",
      "target_node": "gridworld time tracking task generalization with NAC-enhanced agent",
      "description": "NAC pathway allows RL agent to handle longer timing horizons.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Single-environment empirical result (Figure 5).",
      "edge_rationale": "Confirms internal arithmetic in RL setting."
    },
    {
      "type": "validated_by",
      "source_node": "integration of NAC/NALU modules into diverse neural architectures",
      "target_node": "MNIST parity task performance gain with NAC",
      "description": "NAC improves classification accuracy despite limited explicit numeracy.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Table 4 ablation study evidence.",
      "edge_rationale": "Shows inductive bias helps even pure classification."
    },
    {
      "type": "motivates",
      "source_node": "identity function autoencoder extrapolation results",
      "target_node": "Replace standard layers with Neural Accumulator layers during model design to enable additive extrapolation",
      "description": "Benchmark success suggests adopting NAC in place of standard layers.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Empirical improvement supports intervention.",
      "edge_rationale": "Direct translation of evidence to design advice."
    },
    {
      "type": "motivates",
      "source_node": "synthetic arithmetic tasks demonstrating NAC/NALU extrapolation success",
      "target_node": "Replace standard layers with Neural Accumulator layers during model design to enable additive extrapolation",
      "description": "Robust out-of-range performance encourages NAC adoption.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Strong quantitative margins in Table 1.",
      "edge_rationale": "Clear benefit to safety-relevant extrapolation."
    },
    {
      "type": "motivates",
      "source_node": "MNIST counting and addition tasks showing NAC/NALU extrapolation",
      "target_node": "Replace standard layers with Neural Accumulator layers during model design to enable additive extrapolation",
      "description": "Image-to-number results show NAC is plug-and-play.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Section 4.2 results generalise vision domain.",
      "edge_rationale": "Evidence across modalities strengthens case."
    },
    {
      "type": "motivates",
      "source_node": "MNIST parity task performance gain with NAC",
      "target_node": "Replace standard layers with Neural Accumulator layers during model design to enable additive extrapolation",
      "description": "Accuracy gains with minimal overhead incentivise NAC usage.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Ablation study provides supportive but domain-specific data.",
      "edge_rationale": "Shows no performance penalty in classification."
    },
    {
      "type": "motivates",
      "source_node": "synthetic arithmetic tasks demonstrating NAC/NALU extrapolation success",
      "target_node": "Integrate Neural Arithmetic Logic Unit modules with gated additive and multiplicative operations during model design",
      "description": "Successful multiplicative extrapolation implies NALU adoption where multiplication is needed.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Table 1 multiplicative rows.",
      "edge_rationale": "Direct demonstration of capability."
    },
    {
      "type": "motivates",
      "source_node": "language-to-number translation task improved generalization with NALU",
      "target_node": "Integrate Neural Arithmetic Logic Unit modules with gated additive and multiplicative operations during model design",
      "description": "Large generalisation advantage on language task recommends NALU.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Table 3 magnitude of improvement.",
      "edge_rationale": "Shows real-world NLP utility."
    },
    {
      "type": "motivates",
      "source_node": "program evaluation task extrapolation success with NALU",
      "target_node": "Integrate Neural Arithmetic Logic Unit modules with gated additive and multiplicative operations during model design",
      "description": "Only NALU solves larger program evaluation, advocating its use in code-understanding systems.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Figure 4 quantitative superiority.",
      "edge_rationale": "Evidence maps to intervention."
    },
    {
      "type": "motivates",
      "source_node": "gridworld time tracking task generalization with NAC-enhanced agent",
      "target_node": "Embed Neural Accumulator module in reinforcement learning agents for time tracking and timing tasks",
      "description": "Improved timing accuracy indicates value of NAC-based internal counters in RL.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Single-env prototype in Section 4.5.",
      "edge_rationale": "Evidence directly entails RL-specific intervention."
    }
  ],
  "meta": [
    {
      "key": "title",
      "value": "Neural Arithmetic Logic Units"
    },
    {
      "key": "date_published",
      "value": "2018-08-01T00:00:00Z"
    },
    {
      "key": "url",
      "value": "https://arxiv.org/abs/1808.00508"
    },
    {
      "key": "source",
      "value": "arxiv"
    },
    {
      "key": "authors",
      "value": [
        "Andrew Trask",
        "Felix Hill",
        "Scott Reed",
        "Jack Rae",
        "Chris Dyer",
        "Phil Blunsom"
      ]
    }
  ]
}