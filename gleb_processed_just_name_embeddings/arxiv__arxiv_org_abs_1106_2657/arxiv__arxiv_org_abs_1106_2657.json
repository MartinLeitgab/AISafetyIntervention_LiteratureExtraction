{
  "nodes": [
    {
      "name": "Suboptimal decision outcomes in AI systems due to ignored computational costs",
      "aliases": [
        "computationally-naïve decision risk",
        "resource-blind AI decisions"
      ],
      "type": "concept",
      "description": "When autonomous systems ignore the cost of computation they may choose actions that appear utility-maximising on paper but are actually inferior once resource expenditure or time delay is considered, leading to unsafe or inefficient behaviour.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Central risk motivating the entire costly-computation framework (Section 1 Introduction)."
    },
    {
      "name": "Unaccounted computation cost distorts expected utility calculations in autonomous agents",
      "aliases": [
        "ignored complexity alters utility",
        "computation cost omission"
      ],
      "type": "concept",
      "description": "If the running-time, memory or design effort of an algorithm is omitted from the utility model, the agent’s expected-utility estimates become systematically biased.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Explains the mechanism producing the top-level risk (Sections 1 & 2)."
    },
    {
      "name": "Conversation computation overhead outweighs informational benefit in autonomous agents",
      "aliases": [
        "low net value of costly conversation",
        "expensive information exchange problem"
      ],
      "type": "concept",
      "description": "Interactive information exchanges (conversations) may deliver little or no effective benefit when the computational work needed to interpret the messages exceeds the value of the information conveyed.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Highlighted by the factoring variant of the guess-the-number game (Example 3.5, Section 3.3)."
    },
    {
      "name": "Decision-making modeled as Turing machine selection with complexity-dependent utility captures computational constraints",
      "aliases": [
        "TM-selection decision model",
        "costly computation decision framework"
      ],
      "type": "concept",
      "description": "The agent is represented as choosing a Turing machine; utility is a function of payoff minus a complexity term that can encode running time, space or design difficulty.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Core formal insight enabling all subsequent reasoning (Section 2 A computational framework)."
    },
    {
      "name": "Value of computational information formalization quantifies benefit of information under computation cost",
      "aliases": [
        "computational VoI",
        "information value with complexity"
      ],
      "type": "concept",
      "description": "Extends classical value-of-information by comparing supremum expected utilities of Turing-machine policies before and after new information, explicitly including complexity costs.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Provides quantitative grounds for deciding when extra data or computation is worthwhile (Section 3.2)."
    },
    {
      "name": "Zero-knowledge proof value bounded by computational speedup in decision frameworks",
      "aliases": [
        "ZK value ≤ speedup value",
        "bounded conversation benefit theorem"
      ],
      "type": "concept",
      "description": "Theorem 3.6 shows that for monotone complexity-aware decision problems, the utility gained by interacting in a precise zero-knowledge proof is no higher than the utility gained by an equivalent computational speed-up.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Links cryptographic interaction to computational cost, guiding safe protocol design (Section 3.4)."
    },
    {
      "name": "Penalize computational complexity in AI utility functions to align decisions with resource constraints",
      "aliases": [
        "complexity penalty in utility",
        "resource-aware reward shaping"
      ],
      "type": "concept",
      "description": "Design principle: subtract an explicit complexity cost from reward so that actions requiring excessive computation become less attractive to the agent.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Direct solution approach derived from the TM-selection framework (Section 2)."
    },
    {
      "name": "Estimate value of computational information to guide compute and data acquisition",
      "aliases": [
        "compute-aware VoI planning",
        "selective data acquisition under cost"
      ],
      "type": "concept",
      "description": "Use the formal VoCI expression to decide whether obtaining extra information (e.g., more data or expert feedback) is worth the computational expense.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Strategy informed by Section 3.2’s VoCI formulation."
    },
    {
      "name": "Use zero-knowledge proof interactions to bound informational conversations and computation expenditure",
      "aliases": [
        "ZK protocols for safe interaction",
        "cost-bounded information exchange"
      ],
      "type": "concept",
      "description": "Adopt conversational protocols where the verifier gains no more utility than a predefined computational speed-up would provide, preventing wasteful or exploitable information flow.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Design choice justified by Theorem 3.6 (Section 3.4)."
    },
    {
      "name": "Complexity function integrated into reward calculation during planning or reinforcement learning",
      "aliases": [
        "reward minus complexity term",
        "runtime cost in objective"
      ],
      "type": "concept",
      "description": "Implementation technique: embed a callable C(·) estimator inside the agent’s evaluation loop, so expected return is computed as payoff – λ·C.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Operationalises the design rationale of complexity penalties (Section 2 Framework definition)."
    },
    {
      "name": "Supremum expected utility comparison over Turing machines for value-of-information computation",
      "aliases": [
        "sup-EU over TMs",
        "TM supremum evaluator"
      ],
      "type": "concept",
      "description": "Computational mechanism that evaluates the best-achievable expected utility across all candidate TMs before and after hypothetical information, enabling VoCI calculation.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Concrete procedure extracted from Equation (1) in Section 3.2."
    },
    {
      "name": "Precision-bounded simulator construction in zero-knowledge proofs linking conversation to speedup",
      "aliases": [
        "ZK simulator with precision p",
        "conversation-speedup simulator"
      ],
      "type": "concept",
      "description": "Builds a simulator that recreates verifier views within p(|x|,t) time, serving as the bridge between interaction and equivalent speed-up utility.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Implements the design rationale to bound conversation value (Section 3.4)."
    },
    {
      "name": "First-impression and belief polarization biases reproduced by computational cost model",
      "aliases": [
        "early-evidence overweighting example",
        "bias replication example"
      ],
      "type": "concept",
      "description": "Example 2.3 shows that a small per-signal processing cost leads agents to stop reading new evidence, thereby overweighting early signals and producing belief polarization.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Empirical-style validation that the complexity-aware model explains real biases."
    },
    {
      "name": "Status quo bias captured via analysis cost representation",
      "aliases": [
        "status-quo computational explanation",
        "plan analysis cost example"
      ],
      "type": "concept",
      "description": "Example 2.4 models healthcare-plan choice: When analysing alternatives costs compute, agents rationally stick with the current plan, mirroring observed status-quo bias.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Shows practical validity of complexity penalties in decision-making."
    },
    {
      "name": "Safe combination lock example shows high value of computational information when cost reduced",
      "aliases": [
        "combination lock VoCI example",
        "infeasible→feasible compute shift"
      ],
      "type": "concept",
      "description": "Example 3.3 demonstrates that revealing half the lock combination converts a 2^40 search into 2^20, making the task utility-positive and illustrating huge VoCI.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Validates the VoCI computation mechanism."
    },
    {
      "name": "Guess-the-number factoring example demonstrates minimal conversation value under hard computation",
      "aliases": [
        "factoring conversation low value",
        "Example 3.5 validation"
      ],
      "type": "concept",
      "description": "When the informant’s reply requires the agent to factor a large semi-prime, the expected utility net of computation remains near zero, confirming that costly conversations may add no value.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Empirically supports design choices about bounded conversation (Section 3.3)."
    },
    {
      "name": "Embed complexity-penalized utility modules into AI decision algorithms",
      "aliases": [
        "runtime-penalised decision design",
        "complexity-aware reward modules"
      ],
      "type": "intervention",
      "description": "During agent architecture design, add a dedicated module that queries an online complexity estimator and subtracts λ·C from predicted return so that planning and RL favour resource-efficient policies.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Applies at initial model design when specifying the reward/utility definition (Section 2 A computational framework).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Currently demonstrated only in theoretical examples; no large-scale deployment evidence (whole-paper examples).",
      "node_rationale": "Direct actionable step derived from framework to mitigate the identified risk."
    },
    {
      "name": "Apply value-of-computational-information analysis before large-scale model training to optimize compute allocation",
      "aliases": [
        "VoCI-guided compute budgeting",
        "information acquisition cost-benefit"
      ],
      "type": "intervention",
      "description": "Before pre-training, evaluate VoCI for candidate data sources or additional compute investments by comparing supremum expected utilities with and without the information, allocating resources only when VoCI>0.",
      "concept_category": null,
      "intervention_lifecycle": "2",
      "intervention_lifecycle_rationale": "Influences data/compute decisions during pre-training setup (Section 3.2 Value of computational information).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Method is defined theoretically; experimental tooling is emerging but not yet systematically validated.",
      "node_rationale": "Targets inefficient compute expenditure contributing to the top-level risk."
    },
    {
      "name": "Deploy zero-knowledge proof-based interaction protocols in safety evaluations to limit unnecessary computation",
      "aliases": [
        "ZK-bounded safety audits",
        "conversation cost-controlled protocols"
      ],
      "type": "intervention",
      "description": "During pre-deployment red-team or external-tool interaction, restrict protocols to precise zero-knowledge proofs so that any utility gained is provably bounded by an acceptable computational speed-up factor.",
      "concept_category": null,
      "intervention_lifecycle": "4",
      "intervention_lifecycle_rationale": "Implemented during pre-deployment testing phases where systems interact with evaluators (Section 3.4 Value of conversation & ZK).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Conceptual security protocols exist but are not yet mainstream in AI safety testing.",
      "node_rationale": "Mitigates the conversation-overhead problem and reduces attack surface."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Suboptimal decision outcomes in AI systems due to ignored computational costs",
      "target_node": "Unaccounted computation cost distorts expected utility calculations in autonomous agents",
      "description": "Omitting complexity directly leads to distorted expected-utility estimates that drive suboptimal actions.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicit textual argument in Section 1.",
      "edge_rationale": "Framework motivation establishes this causal link."
    },
    {
      "type": "caused_by",
      "source_node": "Suboptimal decision outcomes in AI systems due to ignored computational costs",
      "target_node": "Conversation computation overhead outweighs informational benefit in autonomous agents",
      "description": "Costly conversations that bring little benefit are a specific mechanism producing suboptimal outcomes.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Illustrated by Example 3.5.",
      "edge_rationale": "Shows one concrete path from risk to problem."
    },
    {
      "type": "mitigated_by",
      "source_node": "Unaccounted computation cost distorts expected utility calculations in autonomous agents",
      "target_node": "Decision-making modeled as Turing machine selection with complexity-dependent utility captures computational constraints",
      "description": "Including complexity within the utility formalism addresses the distortion.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 2 introduces model as fix.",
      "edge_rationale": "Standard remedy offered by authors."
    },
    {
      "type": "enabled_by",
      "source_node": "Decision-making modeled as Turing machine selection with complexity-dependent utility captures computational constraints",
      "target_node": "Penalize computational complexity in AI utility functions to align decisions with resource constraints",
      "description": "The formal model suggests adding an explicit complexity penalty when specifying utilities.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Direct design step discussed after model definition.",
      "edge_rationale": "Logical design follow-on."
    },
    {
      "type": "implemented_by",
      "source_node": "Penalize computational complexity in AI utility functions to align decisions with resource constraints",
      "target_node": "Complexity function integrated into reward calculation during planning or reinforcement learning",
      "description": "Operationalises the penalty by calling a complexity estimator in the reward loop.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Implementation detail inferred from Section 2 algorithms.",
      "edge_rationale": "Mechanism realises design rationale."
    },
    {
      "type": "validated_by",
      "source_node": "Complexity function integrated into reward calculation during planning or reinforcement learning",
      "target_node": "Status quo bias captured via analysis cost representation",
      "description": "Status-quo bias example shows the mechanism yields predictions matching observed behaviour.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Example 2.4 explicitly uses cost term.",
      "edge_rationale": "Provides empirical-style support."
    },
    {
      "type": "validated_by",
      "source_node": "Complexity function integrated into reward calculation during planning or reinforcement learning",
      "target_node": "First-impression and belief polarization biases reproduced by computational cost model",
      "description": "First-impression bias also emerges under the same complexity-aware reward mechanism.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Example 2.3.",
      "edge_rationale": "Further empirical support."
    },
    {
      "type": "motivates",
      "source_node": "Status quo bias captured via analysis cost representation",
      "target_node": "Embed complexity-penalized utility modules into AI decision algorithms",
      "description": "Successful bias explanation encourages adopting complexity-penalised utility in practice.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Moderate inference from illustrative example to intervention.",
      "edge_rationale": "Illustration suggests effectiveness of intervention."
    },
    {
      "type": "motivates",
      "source_node": "First-impression and belief polarization biases reproduced by computational cost model",
      "target_node": "Embed complexity-penalized utility modules into AI decision algorithms",
      "description": "Replicating multiple cognitive biases bolsters the case for embedding the penalty.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "As above, inference step.",
      "edge_rationale": "Multiple validations strengthen motivation."
    },
    {
      "type": "mitigated_by",
      "source_node": "Unaccounted computation cost distorts expected utility calculations in autonomous agents",
      "target_node": "Value of computational information formalization quantifies benefit of information under computation cost",
      "description": "VoCI allows agents to correctly weigh information benefits against computational effort.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 3.2 frames VoCI as solution.",
      "edge_rationale": "Connects problem to new insight."
    },
    {
      "type": "enabled_by",
      "source_node": "Value of computational information formalization quantifies benefit of information under computation cost",
      "target_node": "Estimate value of computational information to guide compute and data acquisition",
      "description": "The formal definition supports a concrete planning strategy.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Direct design follow-on from Equation (1).",
      "edge_rationale": "Turns theory into method."
    },
    {
      "type": "implemented_by",
      "source_node": "Estimate value of computational information to guide compute and data acquisition",
      "target_node": "Supremum expected utility comparison over Turing machines for value-of-information computation",
      "description": "Implementation runs supremum-EU before and after information to compute VoCI.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Implementation aligns with Equation (1).",
      "edge_rationale": "Mechanism realises design."
    },
    {
      "type": "validated_by",
      "source_node": "Supremum expected utility comparison over Turing machines for value-of-information computation",
      "target_node": "Safe combination lock example shows high value of computational information when cost reduced",
      "description": "Combination-lock example numerically demonstrates VoCI gains.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Example 3.3 provides explicit calculation.",
      "edge_rationale": "Empirical illustration validates mechanism."
    },
    {
      "type": "motivates",
      "source_node": "Safe combination lock example shows high value of computational information when cost reduced",
      "target_node": "Apply value-of-computational-information analysis before large-scale model training to optimize compute allocation",
      "description": "Demonstrated gains motivate adopting VoCI analysis in practice.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Light inference from example to intervention.",
      "edge_rationale": "Illustration shows practical benefit."
    },
    {
      "type": "mitigated_by",
      "source_node": "Conversation computation overhead outweighs informational benefit in autonomous agents",
      "target_node": "Zero-knowledge proof value bounded by computational speedup in decision frameworks",
      "description": "Bounding conversation utility via ZK proofs addresses overhead concern.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Theorem 3.6 explicitly connects the two.",
      "edge_rationale": "Formally resolves problem."
    },
    {
      "type": "enabled_by",
      "source_node": "Zero-knowledge proof value bounded by computational speedup in decision frameworks",
      "target_node": "Use zero-knowledge proof interactions to bound informational conversations and computation expenditure",
      "description": "Design adopts ZK interaction to limit conversation value to acceptable bounds.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Direct design step from theoretical result.",
      "edge_rationale": "Logical design fallout."
    },
    {
      "type": "implemented_by",
      "source_node": "Use zero-knowledge proof interactions to bound informational conversations and computation expenditure",
      "target_node": "Precision-bounded simulator construction in zero-knowledge proofs linking conversation to speedup",
      "description": "Precision-bounded simulators are required for the ZK protocol to satisfy the bound.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 3.4 details simulator role.",
      "edge_rationale": "Mechanism realises design."
    },
    {
      "type": "validated_by",
      "source_node": "Precision-bounded simulator construction in zero-knowledge proofs linking conversation to speedup",
      "target_node": "Guess-the-number factoring example demonstrates minimal conversation value under hard computation",
      "description": "Factoring example shows that when computation is hard, bounded conversation indeed yields near-zero extra utility.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Example 3.5 compared to ZK theorem.",
      "edge_rationale": "Provides illustrative validation."
    },
    {
      "type": "motivates",
      "source_node": "Guess-the-number factoring example demonstrates minimal conversation value under hard computation",
      "target_node": "Deploy zero-knowledge proof-based interaction protocols in safety evaluations to limit unnecessary computation",
      "description": "Low demonstrated utility motivates switching to ZK-based protocols in safety testing.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Inference from example to intervention.",
      "edge_rationale": "Example suggests practical benefit."
    }
  ],
  "meta": [
    {
      "key": "date_published",
      "value": "2011-06-14T00:00:00Z"
    },
    {
      "key": "source",
      "value": "arxiv"
    },
    {
      "key": "title",
      "value": "I Don't Want to Think About it Now:Decision Theory With Costly Computation"
    },
    {
      "key": "authors",
      "value": [
        "Joseph Y. Halpern",
        "Rafael Pass"
      ]
    },
    {
      "key": "url",
      "value": "https://arxiv.org/abs/1106.2657"
    }
  ]
}