{
  "nodes": [
    {
      "name": "algorithmic discrimination in decision-making systems",
      "aliases": [
        "algorithmic bias",
        "unfair ML predictions"
      ],
      "type": "concept",
      "description": "Machine-learning models used for credit, crime, loans and other high-stakes tasks can systematically disadvantage protected demographic groups.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced in 1 Introduction as the primary societal risk motivating the work."
    },
    {
      "name": "amplification of historical biases through predictive models",
      "aliases": [
        "perpetuation of past prejudice",
        "historic bias amplification"
      ],
      "type": "concept",
      "description": "Models trained on historically biased data can reinforce or worsen existing social inequities over time.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 2 Fairness lists historically biased distributions and selection unfairness as core dangers."
    },
    {
      "name": "insufficient statistical fairness definitions leading to discrimination",
      "aliases": [
        "limitations of FTU/DP/EO",
        "fairness criteria conflict"
      ],
      "type": "concept",
      "description": "Definitions such as fairness-through-unawareness, demographic parity and equal opportunity can be mutually incompatible and sometimes increase discrimination.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Discussed in Section 2 and illustrated by Kleinberg et al. (2016) impossibility result."
    },
    {
      "name": "causal dependence of features on protected attributes causing bias",
      "aliases": [
        "descendants of A bias",
        "feature-causal pathways from A"
      ],
      "type": "concept",
      "description": "Observed features often lie downstream of protected attributes; using them without causal correction transmits unfair influence to predictions.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Explained with the red-car, high-crime, university scenarios in Section 4.2."
    },
    {
      "name": "selection bias in training data for protected groups",
      "aliases": [
        "sampling unfairness",
        "training data selection bias"
      ],
      "type": "concept",
      "description": "Historical decisions (e.g., who received loans) limit observable outcomes, skewing datasets and inducing biased models.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Outlined under 'Selection unfairness' in Section 2."
    },
    {
      "name": "counterfactual fairness via causal invariance across protected attribute",
      "aliases": [
        "counterfactual fairness criterion",
        "invariance under A-intervention"
      ],
      "type": "concept",
      "description": "A predictor is fair if its distribution for an individual remains unchanged under a counterfactual where the protected attribute had always been different.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Formal Definition 5 in Section 4 introduces this key insight."
    },
    {
      "name": "fair predictors depend only on latent background variables non-descendant of protected attribute",
      "aliases": [
        "use U not descendants of A",
        "fair feature criterion"
      ],
      "type": "concept",
      "description": "To satisfy counterfactual fairness, predictors should be functions of latent causes and observed features that are not causally influenced by protected attributes.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 4.1 shows any g(U) is fair; Section 5 generalises."
    },
    {
      "name": "causal latent variable modeling enables extraction of fair information",
      "aliases": [
        "latent variable fairness modeling",
        "U-based modeling"
      ],
      "type": "concept",
      "description": "Introducing domain-informed latent variables allows use of information encoded in biased observables while blocking unfair causal paths.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Levels 1-3 strategy in Section 5.1 motivates latent-variable approach."
    },
    {
      "name": "construct predictor function of latent variables and protected attribute adjustments to cancel unfair paths",
      "aliases": [
        "design of adjusted predictor",
        "A-adjusted regression for fairness"
      ],
      "type": "concept",
      "description": "Design regression or other predictors that explicitly use protected attribute values to negate their unfair influence (e.g., λ_A term in red-car lemma).",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Demonstrated by Lemma 1 analytic construction in Section 4.2."
    },
    {
      "name": "multi-level causal modeling methodology balancing assumptions and accuracy",
      "aliases": [
        "levels 1-3 model building guide",
        "assumption-accuracy trade-off"
      ],
      "type": "concept",
      "description": "Three increasing-assumption levels (non-descendants only, latent parents, additive-noise decomposition) offer practitioners a spectrum between fairness guarantees and predictive power.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Outlined in Section 5.1 Limitations and Guide."
    },
    {
      "name": "twin network causal graph for counterfactual fairness testing",
      "aliases": [
        "twin network audit",
        "counterfactual twin DAG"
      ],
      "type": "concept",
      "description": "Duplicate all descendants of protected attribute under an alternate attribute value to empirically compare factual vs. counterfactual predictions.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Figure 1(c) and Section 4 use twin networks to illustrate fairness assessments."
    },
    {
      "name": "least-squares regression incorporating protected attribute to neutralize causal path",
      "aliases": [
        "A-aware LS regression",
        "λ_A cancellation mechanism"
      ],
      "type": "concept",
      "description": "Including protected attribute alongside biased feature in linear regression yields coefficients that cancel unfair influence, satisfying counterfactual fairness under certain DAGs.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Explicitly derived in equations (2) of Lemma 1, Section 4.2."
    },
    {
      "name": "bayesian inference of latent variables using probabilistic programming",
      "aliases": [
        "Stan latent variable estimation",
        "posterior K estimation"
      ],
      "type": "concept",
      "description": "Fit causal models with latent variables (e.g., student knowledge K) via probabilistic programming (Stan) and use inferred U for fair prediction.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Implemented in Section 6.1 experiments (Fair K model)."
    },
    {
      "name": "residual additive noise extraction from biased features",
      "aliases": [
        "additive error residualization",
        "Fair Add residuals"
      ],
      "type": "concept",
      "description": "Model biased observables with race/sex predictors, treat residual errors (ϵ terms) as fair features independent of protected attributes.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Level 3 Fair Add model in Section 6.1."
    },
    {
      "name": "sampling twin networks for empirical counterfactual fairness evaluation",
      "aliases": [
        "counterfactual sampling audit",
        "empirical fairness test"
      ],
      "type": "concept",
      "description": "Generate datasets under factual and counterfactual protected attributes via the fitted causal model to compare prediction distributions.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Used in Section 6.1 Counterfactual fairness evaluation with density plots."
    },
    {
      "name": "lemma 1 analytic proof of unfairness of unaware model and fairness of adjusted model",
      "aliases": [
        "red-car lemma evidence",
        "analytical validation"
      ],
      "type": "concept",
      "description": "Mathematical demonstration that FTU model is unfair while A-adjusted regression is fair under specified DAG.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Presented in Section 4.2 Scenario 1."
    },
    {
      "name": "law school dataset experiment showing fair models approach parity with slight accuracy loss",
      "aliases": [
        "law school empirical evidence",
        "FYA fairness experiment"
      ],
      "type": "concept",
      "description": "Fair K and Fair Add models satisfy counterfactual fairness with small RMSE increase compared to unfair baselines; density plots show invariance.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Results in Section 6.1, Table 1 and Figure 4."
    },
    {
      "name": "stop-and-frisk latent criminality near demographic parity",
      "aliases": [
        "NYPD experiment evidence",
        "criminality vs perception evidence"
      ],
      "type": "concept",
      "description": "Fitted model shows latent criminality distributions almost identical across races while perceived criminality varies, validating causal separation.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Presented in Section 6.2, Figure 7 and accompanying text."
    },
    {
      "name": "design and train models using counterfactually fair causal modeling with latent variable inference",
      "aliases": [
        "counterfactual fairness training",
        "causal-fair model development"
      ],
      "type": "intervention",
      "description": "During model-training, build a causal DAG, infer latent variables (e.g., via Stan) and train predictors solely on those and non-descendant observables, optionally including protected attributes to cancel unfair paths.",
      "concept_category": null,
      "intervention_lifecycle": "3",
      "intervention_lifecycle_rationale": "Applies at Fine-Tuning/Training phase where model parameters are learned (Section 5 Methods).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Demonstrated only in proof-of-concept experiments on two datasets (Section 6).",
      "node_rationale": "Proposed as main practical takeaway in Sections 5 and 7."
    },
    {
      "name": "audit trained models via twin network counterfactual fairness evaluation before deployment",
      "aliases": [
        "counterfactual fairness audit",
        "twin network testing"
      ],
      "type": "intervention",
      "description": "Before deployment, construct twin network for protected attributes, sample factual vs. counterfactual scenarios from fitted causal model and statistically compare prediction distributions to detect violations.",
      "concept_category": null,
      "intervention_lifecycle": "4",
      "intervention_lifecycle_rationale": "Performed after training but prior to deployment to validate fairness (Section 6.1 Counterfactual fairness check).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Used experimentally; not yet standardized in production pipelines.",
      "node_rationale": "Section 6 demonstrates this audit; Section 7 recommends causal regulation."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "algorithmic discrimination in decision-making systems",
      "target_node": "causal dependence of features on protected attributes causing bias",
      "description": "Discrimination arises when features downstream of protected attributes are used directly in prediction.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Explicit causal explanations in Section 4 scenarios.",
      "edge_rationale": "Section 4.2 shows A→X→Y pathways producing unfair outcomes."
    },
    {
      "type": "caused_by",
      "source_node": "algorithmic discrimination in decision-making systems",
      "target_node": "selection bias in training data for protected groups",
      "description": "Unrepresentative training data leads to discriminatory model behaviour.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Qualitative explanation in Section 2.",
      "edge_rationale": "‘Selection unfairness’ paragraph in Section 2."
    },
    {
      "type": "caused_by",
      "source_node": "amplification of historical biases through predictive models",
      "target_node": "selection bias in training data for protected groups",
      "description": "Historical lending or policing decisions restrict observed outcomes, embedding bias.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Discussed conceptually in Section 2.",
      "edge_rationale": "Historical bias examples preceding Definition 1."
    },
    {
      "type": "caused_by",
      "source_node": "amplification of historical biases through predictive models",
      "target_node": "insufficient statistical fairness definitions leading to discrimination",
      "description": "Relying on incompatible or weak fairness metrics allows historical bias to persist.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Paper argues EO/DP can conflict and fail (Section 2).",
      "edge_rationale": "Section 2 last paragraph before Section 3."
    },
    {
      "type": "addressed_by",
      "source_node": "causal dependence of features on protected attributes causing bias",
      "target_node": "counterfactual fairness via causal invariance across protected attribute",
      "description": "Counterfactual fairness removes influence of protected-attribute causal descendants.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Formal definition explicitly targets this pathway.",
      "edge_rationale": "Definition 5 and subsequent discussion."
    },
    {
      "type": "mitigated_by",
      "source_node": "insufficient statistical fairness definitions leading to discrimination",
      "target_node": "counterfactual fairness via causal invariance across protected attribute",
      "description": "Counterfactual fairness overcomes shortcomings of purely statistical definitions.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Comparative analysis in Sections 2 and 4.",
      "edge_rationale": "Section 4.1 implications discuss superiority."
    },
    {
      "type": "refined_by",
      "source_node": "counterfactual fairness via causal invariance across protected attribute",
      "target_node": "fair predictors depend only on latent background variables non-descendant of protected attribute",
      "description": "Theoretical criterion specifies allowable functional form for fair predictors.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Direct logical derivation in Section 4.1.",
      "edge_rationale": "Paragraph starting ‘In contrast, any function of variables not descendants of A…’"
    },
    {
      "type": "refined_by",
      "source_node": "causal latent variable modeling enables extraction of fair information",
      "target_node": "multi-level causal modeling methodology balancing assumptions and accuracy",
      "description": "Latent variable insight is operationalised through a three-level design guide.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Section 5.1 elaborates levels based on latent constructs.",
      "edge_rationale": "‘Guide to Model Building’ subsection."
    },
    {
      "type": "enables",
      "source_node": "fair predictors depend only on latent background variables non-descendant of protected attribute",
      "target_node": "construct predictor function of latent variables and protected attribute adjustments to cancel unfair paths",
      "description": "Knowledge of allowed variables guides construction of adjusted predictors.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Design step follows theoretical restriction (Section 4.2).",
      "edge_rationale": "Lemma 1 shows how U and A are combined."
    },
    {
      "type": "implemented_by",
      "source_node": "construct predictor function of latent variables and protected attribute adjustments to cancel unfair paths",
      "target_node": "least-squares regression incorporating protected attribute to neutralize causal path",
      "description": "Linear regression with both X and A realises the design in Scenario 1.",
      "edge_confidence": "5",
      "edge_confidence_rationale": "Exact mathematical derivation in Lemma 1.",
      "edge_rationale": "Equations (2) in Section 4.2."
    },
    {
      "type": "implemented_by",
      "source_node": "construct predictor function of latent variables and protected attribute adjustments to cancel unfair paths",
      "target_node": "bayesian inference of latent variables using probabilistic programming",
      "description": "Latent variable inference realises predictor using inferred fair features.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Applied concretely in Section 6.1 Fair K.",
      "edge_rationale": "Experiment description under ‘Fair K’."
    },
    {
      "type": "implemented_by",
      "source_node": "construct predictor function of latent variables and protected attribute adjustments to cancel unfair paths",
      "target_node": "residual additive noise extraction from biased features",
      "description": "Additive noise residualisation operationalises Level 3 design.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Method introduced with weaker assumptions (Section 6.1).",
      "edge_rationale": "Fair Add model equations."
    },
    {
      "type": "implemented_by",
      "source_node": "twin network causal graph for counterfactual fairness testing",
      "target_node": "sampling twin networks for empirical counterfactual fairness evaluation",
      "description": "Sampling twin networks is the concrete mechanism for the audit design.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Direct methodological connection in Section 6.1.",
      "edge_rationale": "Paragraph on generating counterfactual samples."
    },
    {
      "type": "validated_by",
      "source_node": "least-squares regression incorporating protected attribute to neutralize causal path",
      "target_node": "lemma 1 analytic proof of unfairness of unaware model and fairness of adjusted model",
      "description": "Lemma 1 analytically proves the fairness of the LS mechanism.",
      "edge_confidence": "5",
      "edge_confidence_rationale": "Formal proof contained in the lemma.",
      "edge_rationale": "Section 4.2 Scenario 1 proof."
    },
    {
      "type": "validated_by",
      "source_node": "bayesian inference of latent variables using probabilistic programming",
      "target_node": "law school dataset experiment showing fair models approach parity with slight accuracy loss",
      "description": "Empirical results confirm fairness and acceptable accuracy of latent variable model.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Real dataset evaluation (Table 1, Figure 4).",
      "edge_rationale": "Section 6.1 results discussion."
    },
    {
      "type": "validated_by",
      "source_node": "residual additive noise extraction from biased features",
      "target_node": "law school dataset experiment showing fair models approach parity with slight accuracy loss",
      "description": "Fair Add residual model validated on same experiment.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Results in Table 1 show performance.",
      "edge_rationale": "Section 6.1 Fair Add discussion."
    },
    {
      "type": "validated_by",
      "source_node": "sampling twin networks for empirical counterfactual fairness evaluation",
      "target_node": "law school dataset experiment showing fair models approach parity with slight accuracy loss",
      "description": "Density plot comparisons demonstrate audit effectiveness.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Qualitative plot evidence (Figure 4).",
      "edge_rationale": "Counterfactual fairness evaluation subsection."
    },
    {
      "type": "validated_by",
      "source_node": "bayesian inference of latent variables using probabilistic programming",
      "target_node": "stop-and-frisk latent criminality near demographic parity",
      "description": "Latent modeling separates true vs perceived criminality across races.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Empirical boxplots in Figure 7.",
      "edge_rationale": "Section 6.2 results."
    },
    {
      "type": "motivates",
      "source_node": "lemma 1 analytic proof of unfairness of unaware model and fairness of adjusted model",
      "target_node": "design and train models using counterfactually fair causal modeling with latent variable inference",
      "description": "Analytical validation provides rationale to adopt causal-fair training.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Logical extrapolation from proof to practice.",
      "edge_rationale": "End of Section 4.2 suggests using causal design."
    },
    {
      "type": "motivates",
      "source_node": "law school dataset experiment showing fair models approach parity with slight accuracy loss",
      "target_node": "design and train models using counterfactually fair causal modeling with latent variable inference",
      "description": "Empirical evidence shows practical viability of causal-fair training.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Quantitative RMSE and fairness plots.",
      "edge_rationale": "Section 6.1 conclusion."
    },
    {
      "type": "motivates",
      "source_node": "stop-and-frisk latent criminality near demographic parity",
      "target_node": "design and train models using counterfactually fair causal modeling with latent variable inference",
      "description": "Second dataset demonstrates scalability and fairness, encouraging adoption.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Single-domain evidence yet indicative.",
      "edge_rationale": "Section 6.2 discussion."
    },
    {
      "type": "motivates",
      "source_node": "sampling twin networks for empirical counterfactual fairness evaluation",
      "target_node": "audit trained models via twin network counterfactual fairness evaluation before deployment",
      "description": "Sampling method forms the technical basis for a systematic audit intervention.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Direct implementation link shown in experiments.",
      "edge_rationale": "Section 6.1 audit procedure."
    }
  ],
  "meta": [
    {
      "key": "date_published",
      "value": "2017-03-20T00:00:00Z"
    },
    {
      "key": "title",
      "value": "Counterfactual Fairness"
    },
    {
      "key": "authors",
      "value": [
        "Matt J. Kusner",
        "Joshua R. Loftus",
        "Chris Russell",
        "Ricardo Silva"
      ]
    },
    {
      "key": "url",
      "value": "https://arxiv.org/abs/1703.06856"
    },
    {
      "key": "source",
      "value": "arxiv"
    }
  ]
}