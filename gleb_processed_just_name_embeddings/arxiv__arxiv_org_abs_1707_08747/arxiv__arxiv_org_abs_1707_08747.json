{
  "nodes": [
    {
      "name": "Logical non-omniscience in bounded AI reasoners",
      "aliases": [
        "logical uncertainty in limited agents",
        "deductive limitation risk"
      ],
      "type": "concept",
      "description": "AI systems with finite computation cannot know the truth value of all logical facts, creating epistemic gaps that may degrade planning or verification.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Highlighted in Introduction as the motivating problem."
    },
    {
      "name": "Exploitability via Dutch book strategies in AI belief systems",
      "aliases": [
        "Dutch book vulnerability",
        "logical betting exploitation"
      ],
      "type": "concept",
      "description": "If an AI’s credences about logical claims violate coherence in practice, an efficient adversary could construct trading strategies that extract unbounded value.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Discussed under Desideratum 12 and Logical Induction Criterion."
    },
    {
      "name": "Probability theory inability to model logical uncertainty under computational limits",
      "aliases": [
        "standard Bayesian limits on logical facts",
        "old evidence problem"
      ],
      "type": "concept",
      "description": "Classical probability requires Pr(A) ≤ Pr(B) when A⇒B, forcing near-certainty in unproven claims and thus fails for agents lacking proofs.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Outlined in Introduction and Desiderata section."
    },
    {
      "name": "Strict coherence constraints requiring logical omniscience",
      "aliases": [
        "logical omniscience requirement",
        "perfect Bayesian coherence issue"
      ],
      "type": "concept",
      "description": "Exact Dutch-book style coherence forces reasoners to instantaneously reflect all logical implications, impossible for bounded agents.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Motivating failure mode discussed around Desideratum 12."
    },
    {
      "name": "Relaxed Dutch book criterion via approximate inexploitability against polynomial-time traders",
      "aliases": [
        "efficient-trader inexploitability",
        "weak Dutch book standard"
      ],
      "type": "concept",
      "description": "Require that no polynomial-time algorithm can make unbounded profit by trading against the reasoner’s prices, weakening classical no-dutch-book to a computable standard.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Core theoretical move stated in §4 Logical Induction Criterion."
    },
    {
      "name": "Belief-as-market-price modelling for learning logical patterns",
      "aliases": [
        "market analogy for beliefs",
        "pricing interpretation of credences"
      ],
      "type": "concept",
      "description": "Treat each probability as a share-price; learning arises because mispriced statements invite trades that reveal patterns faster than proof search.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Explained in §4 overview as intuition for property guarantees."
    },
    {
      "name": "Logical induction criterion ensuring computable approximability and approximate inexploitability",
      "aliases": [
        "logical induction requirement",
        "LIC guarantee"
      ],
      "type": "concept",
      "description": "A sequence of computable pricings is a logical inductor if no efficient trader exploits it, directly encoding Desiderata 1 & 12.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Defined formally in Definition 4.0.5."
    },
    {
      "name": "Market-based belief updating to anticipate proofs",
      "aliases": [
        "pattern-learning via trading pressure",
        "pricing refinement over time"
      ],
      "type": "concept",
      "description": "The design pushes prices to converge earlier than brute-force deduction by rewarding recognition of computable patterns in theorems.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Illustrated by Provability Induction Theorem 5.3.1."
    },
    {
      "name": "Computable sequence of pricings resisting efficient traders",
      "aliases": [
        "evolving market prices",
        "belief sequence P_n"
      ],
      "type": "concept",
      "description": "Implementation object: the daily list of sentence-prices output by the logical inductor that cannot be exploited by any poly-time trader.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "See Definitions 4.0.1–4.0.4 describing pricing, market and trader."
    },
    {
      "name": "Construction algorithm for logical inductor over a deductive process",
      "aliases": [
        "logical inductor existence proof",
        "market maker algorithm"
      ],
      "type": "concept",
      "description": "An explicit computable procedure that, given any deductive process Γ, outputs a market sequence satisfying the logical induction criterion.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Promised by Theorem 4.0.6."
    },
    {
      "name": "Existence proof for logical inductors over any deductive process",
      "aliases": [
        "Theorem 4.0.6 existence",
        "feasibility proof"
      ],
      "type": "concept",
      "description": "Formal theorem guaranteeing that the construction works, underpinning feasibility of the mechanism.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Serves as primary validation in §4."
    },
    {
      "name": "Convergence, limit coherence, and non-dogmatism properties of logical inductors",
      "aliases": [
        "Theorems 5.2.x property set",
        "asymptotic guarantees"
      ],
      "type": "concept",
      "description": "Proved theorems show beliefs converge, respect logical consistency in the limit, stay non-extreme without proof, and dominate universal semimeasures.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Stated in §5.2."
    },
    {
      "name": "Learning of halting patterns before deduction",
      "aliases": [
        "Theorems 5.3.1–5.3.3",
        "outpacing deduction evidence"
      ],
      "type": "concept",
      "description": "Empirical-style theorems show logical inductors assign high probability to halting programs and low probability to non-halting ones earlier than proofs arrive.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Presented in §5.3."
    },
    {
      "name": "Implement logical induction reasoning module in AI systems",
      "aliases": [
        "integrate logical inductor",
        "logical-uncertainty engine"
      ],
      "type": "intervention",
      "description": "At model-design time, embed an internal logical-induction–based subsystem to generate probabilistic beliefs over mathematical and code-level statements, replacing brittle heuristics.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Module is architected during Model Design phase (Sections 4 & 6 discussion).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Only theoretical and proof-of-concept algorithms exist; no large-scale deployment reported (Section 6 Discussion).",
      "node_rationale": "Natural downstream application for AI safety drawn from properties proven."
    },
    {
      "name": "Apply logical inductor-based program behaviour evaluation during pre-deployment testing",
      "aliases": [
        "logical-uncertainty audits",
        "halting-pattern predictor for safety"
      ],
      "type": "intervention",
      "description": "Before deploying an ML system, run a logical-inductor heuristic to estimate probabilities of critical program behaviours (e.g., halting, compliance) to catch anomalies not provable within resource bounds.",
      "concept_category": null,
      "intervention_lifecycle": "4",
      "intervention_lifecycle_rationale": "Used in Pre-Deployment Testing to evaluate model or code artefacts (link to §5.3 halting tests).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Conceptual safety tooling; only theoretical backing provided (Section 6 Discussion).",
      "node_rationale": "Directly motivated by Evidence of learning halting patterns."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Logical non-omniscience in bounded AI reasoners",
      "target_node": "Probability theory inability to model logical uncertainty under computational limits",
      "description": "Classical probability’s rigid constraints create the logical non-omniscience failure mode in bounded agents.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Explicit argument in Introduction.",
      "edge_rationale": "Section 1 shows how Pr(A)≤Pr(B) forces certainty on unproven facts."
    },
    {
      "type": "caused_by",
      "source_node": "Logical non-omniscience in bounded AI reasoners",
      "target_node": "Strict coherence constraints requiring logical omniscience",
      "description": "Dutch-book coherence enforces impossible omniscience, thereby producing logical non-omniscience risk when unmet.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Discussed around Desideratum 12.",
      "edge_rationale": "Risk stems from inability to meet these constraints."
    },
    {
      "type": "caused_by",
      "source_node": "Exploitability via Dutch book strategies in AI belief systems",
      "target_node": "Strict coherence constraints requiring logical omniscience",
      "description": "If agents cannot maintain full coherence, efficient traders can exploit belief inconsistencies.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Dutch-book literature cited in §2.",
      "edge_rationale": "Exploitability is a direct consequence of unmet coherence."
    },
    {
      "type": "mitigated_by",
      "source_node": "Probability theory inability to model logical uncertainty under computational limits",
      "target_node": "Relaxed Dutch book criterion via approximate inexploitability against polynomial-time traders",
      "description": "Relaxing the Dutch book standard removes the need for perfect logical consistency while retaining protection.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Stated but relies on theoretical proposal.",
      "edge_rationale": "§4 introduces criterion as response."
    },
    {
      "type": "mitigated_by",
      "source_node": "Strict coherence constraints requiring logical omniscience",
      "target_node": "Relaxed Dutch book criterion via approximate inexploitability against polynomial-time traders",
      "description": "Approximate inexploitability replaces impossible strict coherence.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Same as above.",
      "edge_rationale": "Logical induction criterion weakens requirement."
    },
    {
      "type": "enabled_by",
      "source_node": "Relaxed Dutch book criterion via approximate inexploitability against polynomial-time traders",
      "target_node": "Belief-as-market-price modelling for learning logical patterns",
      "description": "The market analogy operationalises the relaxed criterion.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Conceptual link made in §4 overview.",
      "edge_rationale": "Prices invite trades that test exploitability."
    },
    {
      "type": "refined_by",
      "source_node": "Belief-as-market-price modelling for learning logical patterns",
      "target_node": "Market-based belief updating to anticipate proofs",
      "description": "Design rationale applies the market model to update prices ahead of deduction.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Demonstrated by Provability Induction theorem.",
      "edge_rationale": "Shows concrete design."
    },
    {
      "type": "refined_by",
      "source_node": "Relaxed Dutch book criterion via approximate inexploitability against polynomial-time traders",
      "target_node": "Logical induction criterion ensuring computable approximability and approximate inexploitability",
      "description": "Logical induction criterion formalises the relaxed requirement.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Definition 4.0.5 explicitly does this.",
      "edge_rationale": "Criterion = formal refinement."
    },
    {
      "type": "implemented_by",
      "source_node": "Logical induction criterion ensuring computable approximability and approximate inexploitability",
      "target_node": "Computable sequence of pricings resisting efficient traders",
      "description": "The belief sequence P_n is the artifact satisfying the criterion.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Definitions 4.0.1–4.0.2.",
      "edge_rationale": "Implementation object."
    },
    {
      "type": "refined_by",
      "source_node": "Computable sequence of pricings resisting efficient traders",
      "target_node": "Construction algorithm for logical inductor over a deductive process",
      "description": "Algorithm produces such price sequences for any deductive process.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Theorem 4.0.6.",
      "edge_rationale": "Algorithmic refinement."
    },
    {
      "type": "validated_by",
      "source_node": "Computable sequence of pricings resisting efficient traders",
      "target_node": "Existence proof for logical inductors over any deductive process",
      "description": "Existence theorem shows the mechanism can always be built.",
      "edge_confidence": "5",
      "edge_confidence_rationale": "Formal proof claim.",
      "edge_rationale": "Direct validation."
    },
    {
      "type": "validated_by",
      "source_node": "Construction algorithm for logical inductor over a deductive process",
      "target_node": "Convergence, limit coherence, and non-dogmatism properties of logical inductors",
      "description": "Proved properties demonstrate algorithm’s performance.",
      "edge_confidence": "5",
      "edge_confidence_rationale": "Theorems in §5.2.",
      "edge_rationale": "Shows resulting beliefs behave well."
    },
    {
      "type": "validated_by",
      "source_node": "Market-based belief updating to anticipate proofs",
      "target_node": "Learning of halting patterns before deduction",
      "description": "Halting-pattern theorems confirm timely learning claim.",
      "edge_confidence": "5",
      "edge_confidence_rationale": "Theorems 5.3.1–5.3.3.",
      "edge_rationale": "Empirical-style validation."
    },
    {
      "type": "motivates",
      "source_node": "Convergence, limit coherence, and non-dogmatism properties of logical inductors",
      "target_node": "Implement logical induction reasoning module in AI systems",
      "description": "These guarantees justify integrating the module for safer reasoning.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Application inference not explicit.",
      "edge_rationale": "Logical next step for AI safety engineer."
    },
    {
      "type": "motivates",
      "source_node": "Learning of halting patterns before deduction",
      "target_node": "Apply logical inductor-based program behaviour evaluation during pre-deployment testing",
      "description": "Demonstrated early detection of halting-related behaviours suggests use for safety testing.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Moderate inference from property to practice.",
      "edge_rationale": "Section 5.3 shows capability; Section 6 calls for practical tools."
    }
  ],
  "meta": [
    {
      "key": "url",
      "value": "https://arxiv.org/abs/1707.08747"
    },
    {
      "key": "title",
      "value": "A Formal Approach to the Problem of Logical Non-Omniscience"
    },
    {
      "key": "authors",
      "value": [
        "Scott Garrabrant",
        "Tsvi Benson-Tilsen",
        "Andrew Critch",
        "Nate Soares",
        "Jessica Taylor"
      ]
    },
    {
      "key": "date_published",
      "value": "2017-07-27T00:00:00Z"
    },
    {
      "key": "source",
      "value": "arxiv"
    }
  ]
}