{
  "nodes": [
    {
      "name": "Overconfident incorrect predictions in neural network deployments",
      "aliases": [
        "overly confident wrong predictions",
        "high-confidence errors in DNNs"
      ],
      "type": "concept",
      "description": "Deep neural networks often assign very high probabilities to wrong outputs, which can cause harmful or offensive outcomes in practical systems.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced in 1 Introduction as a central safety concern."
    },
    {
      "name": "Miscalibration of predictive probabilities in deep neural networks",
      "aliases": [
        "poor calibration in DNNs",
        "mis-aligned confidence levels"
      ],
      "type": "concept",
      "description": "The predicted probabilities of standard neural networks do not match empirical frequencies, violating calibration and risking misuse of confidence values.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 1 frames calibration as a core goal for uncertainty estimation."
    },
    {
      "name": "Uncertainty failure under domain shift in neural networks",
      "aliases": [
        "OOD over-confidence",
        "poor uncertainty generalisation"
      ],
      "type": "concept",
      "description": "When inputs come from distributions different from training data, standard networks produce low uncertainty instead of recognising the shift.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Highlighted in 1 Introduction and 3.5 OOD experiments."
    },
    {
      "name": "Deterministic point prediction training in standard neural networks",
      "aliases": [
        "single-point loss optimisation",
        "MSE/Cross-entropy only training"
      ],
      "type": "concept",
      "description": "Most DNNs are trained to output a single value or class with losses that do not explicitly model predictive distributions, leading to over-confidence.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Discussed in Introduction as mechanism behind risks."
    },
    {
      "name": "Approximate Bayesian inference dependence on incorrect priors in Bayesian neural networks",
      "aliases": [
        "prior mis-specification in BNNs",
        "Bayesian NN prior issues"
      ],
      "type": "concept",
      "description": "Bayesian neural networks rely on user-chosen priors; if these priors are poor, resulting uncertainty estimates become unreliable.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 1 critiques existing Bayesian methods."
    },
    {
      "name": "Lack of robustness to unseen classes due to narrow training data support",
      "aliases": [
        "training-data support limitation",
        "class-space coverage gap"
      ],
      "type": "concept",
      "description": "Because training data rarely covers all possible inputs, models fail to recognise unfamiliar classes, producing confident but wrong predictions.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Motivates OOD tests in 3.5."
    },
    {
      "name": "Proper scoring rule optimization promotes probabilistic calibration",
      "aliases": [
        "scoring-rule training improves calibration",
        "NLL/Brier as proper scores"
      ],
      "type": "concept",
      "description": "Training with losses that are proper scoring rules (e.g. negative log-likelihood, Brier score) incentivises networks to align predicted probabilities with true frequencies.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 2.2 derives calibration benefits of proper scoring rules."
    },
    {
      "name": "Model averaging across diverse networks captures model uncertainty",
      "aliases": [
        "ensembling for model uncertainty",
        "deep ensembles as averaging"
      ],
      "type": "concept",
      "description": "Combining predictions from independently trained networks reduces variance and reflects uncertainty about the model parameters.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 2.4 and Discussion explain ensemble rationale."
    },
    {
      "name": "Adversarial training encourages local smoothness in predictive distributions",
      "aliases": [
        "adversarial data augmentation for smoothness",
        "FGSM smoothing effect"
      ],
      "type": "concept",
      "description": "Including adversarially perturbed examples during training forces the network to assign similar probabilities within an ε-ball, reducing sharp confidence spikes.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 2.3 interprets adversarial training as distributional smoothing."
    },
    {
      "name": "Train probabilistic neural networks with predictive mean and variance outputs",
      "aliases": [
        "heteroscedastic output heads",
        "predictive distribution parameterisation"
      ],
      "type": "concept",
      "description": "Networks output both mean and variance (or full class probability vector), enabling direct modelling of aleatoric uncertainty.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Design step in 2.2.1 regression and general classification setup."
    },
    {
      "name": "Independently train ensemble of NNs on full data with random initialization",
      "aliases": [
        "independent deep ensemble training",
        "random-seed diversity"
      ],
      "type": "concept",
      "description": "Each ensemble member is trained on the entire dataset with a different random seed, leveraging multiple local optima for diversity without bagging.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Algorithm 1 lines 1-6 and 2.4 observations."
    },
    {
      "name": "Augment training with adversarial examples using fast gradient sign method",
      "aliases": [
        "FGSM adversarial augmentation",
        "adversarial training step"
      ],
      "type": "concept",
      "description": "During each training step, an ε-bounded FGSM perturbation is added to inputs and the loss is optimised on both clean and perturbed data.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Described in Section 2.3 and Algorithm 1."
    },
    {
      "name": "Negative log-likelihood loss for heteroscedastic Gaussian outputs",
      "aliases": [
        "NLL loss with softplus variance",
        "proper scoring rule implementation"
      ],
      "type": "concept",
      "description": "Implements proper scoring-rule training by minimising NLL of a Gaussian with network-predicted mean and variance, enforcing variance positivity via softplus.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Equation (1) in 2.2.1 shows exact form used in experiments."
    },
    {
      "name": "Uniform averaging of ensemble predictive distributions",
      "aliases": [
        "simple mixture ensembling",
        "equal-weight model averaging"
      ],
      "type": "concept",
      "description": "Final predictive distribution is the arithmetic mean of member distributions; for regression, mixture moments are used for Gaussian approximation.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Equation in 2.4 under ‘prediction’ step."
    },
    {
      "name": "Fast gradient sign generation of adversarial perturbations with epsilon 1% input range",
      "aliases": [
        "FGSM ε=0.01*range",
        "scaled FGSM perturbations"
      ],
      "type": "concept",
      "description": "Perturbations are computed as ε·sign(∇x ℓ) with ε set to 1 % of per-dimension data range, generalising FGSM to heterogeneous features.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Parameter choice explained in 2.3 and 3.1."
    },
    {
      "name": "Deep ensemble NLL and Brier improvements over MC-dropout across benchmarks",
      "aliases": [
        "empirical calibration gains",
        "ensemble outperforms MC-dropout"
      ],
      "type": "concept",
      "description": "Experiments in Sections 3.2–3.4 show lower NLL and Brier scores for deep ensembles versus MC-dropout on regression, MNIST, SVHN and ImageNet.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Summarises quantitative results in Tables 1 & Figure 2."
    },
    {
      "name": "Higher predictive entropy on out-of-distribution datasets with ensembles",
      "aliases": [
        "OOD uncertainty increase",
        "entropy separation experiments"
      ],
      "type": "concept",
      "description": "Histograms in Figure 3 show ensemble entropy rises sharply for NotMNIST and CIFAR-10 when trained on MNIST or SVHN, unlike MC-dropout.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Validates robustness claim in 3.5."
    },
    {
      "name": "Improved accuracy vs confidence curves showing reduced overconfidence",
      "aliases": [
        "confidence-filtered accuracy gains",
        "robust calibration curve"
      ],
      "type": "concept",
      "description": "Figure 6 demonstrates that, at any confidence threshold, ensemble accuracy exceeds MC-dropout and monotonically increases with confidence.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Confirms practical decision-making utility in 3.6."
    },
    {
      "name": "Train deep probabilistic neural network ensembles with adversarial training and proper scoring rule",
      "aliases": [
        "deep ensemble uncertainty training pipeline",
        "scoring-rule-based ensemble training"
      ],
      "type": "intervention",
      "description": "During initial model training, independently initialise M≥5 neural networks, optimise NLL (or Brier) on both clean and FGSM-perturbed data, and average outputs at inference.",
      "concept_category": null,
      "intervention_lifecycle": "2",
      "intervention_lifecycle_rationale": "Implemented during Pre-Training stage as per Algorithm 1 (2 Deep Ensembles).",
      "intervention_maturity": "3",
      "intervention_maturity_rationale": "Validated across many public benchmarks but not yet ubiquitous in safety-critical deployment (Sections 3.2–3.5).",
      "node_rationale": "Primary actionable technique proposed by the paper."
    },
    {
      "name": "Apply ensemble predictive entropy thresholding during deployment to defer uncertain predictions",
      "aliases": [
        "confidence gating with entropy",
        "selective prediction using deep ensembles"
      ],
      "type": "intervention",
      "description": "At run-time, compute predictive entropy (or max probability) from the ensemble; only act on inputs where confidence exceeds a preset threshold, otherwise route to fallback (e.g. human-in-loop).",
      "concept_category": null,
      "intervention_lifecycle": "5",
      "intervention_lifecycle_rationale": "Used at Deployment time to filter or defer outputs (Section 3.6).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Demonstrated experimentally but not yet systematically deployed.",
      "node_rationale": "Provides a direct safety control that leverages improved uncertainty estimates."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Overconfident incorrect predictions in neural network deployments",
      "target_node": "Deterministic point prediction training in standard neural networks",
      "description": "Training that ignores uncertainty leads to high-confidence errors.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Stated relationship in 1 Introduction; widely observed though not experimentally isolated here.",
      "edge_rationale": "Connects primary risk to identified mechanism."
    },
    {
      "type": "caused_by",
      "source_node": "Miscalibration of predictive probabilities in deep neural networks",
      "target_node": "Deterministic point prediction training in standard neural networks",
      "description": "Point-estimate training fails to align predicted probabilities with frequencies.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Discussed in 1 Introduction and 2.2.",
      "edge_rationale": "Links calibration risk to training paradigm."
    },
    {
      "type": "caused_by",
      "source_node": "Miscalibration of predictive probabilities in deep neural networks",
      "target_node": "Approximate Bayesian inference dependence on incorrect priors in Bayesian neural networks",
      "description": "Incorrect priors in Bayesian NNs propagate miscalibration.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Argumentative link in Introduction, limited direct evidence.",
      "edge_rationale": "Adds second failure mode for calibration risk."
    },
    {
      "type": "caused_by",
      "source_node": "Uncertainty failure under domain shift in neural networks",
      "target_node": "Lack of robustness to unseen classes due to narrow training data support",
      "description": "Unseen classes fall outside training support causing uncertainty collapse.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicitly described when motivating OOD tests (1 Introduction).",
      "edge_rationale": "Explains domain-shift risk."
    },
    {
      "type": "mitigated_by",
      "source_node": "Deterministic point prediction training in standard neural networks",
      "target_node": "Proper scoring rule optimization promotes probabilistic calibration",
      "description": "Using proper scoring rules directly addresses over-confidence from point training.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Theoretical proof in 2.2 with Gibbs inequality support.",
      "edge_rationale": "Transitions to theoretical insight."
    },
    {
      "type": "mitigated_by",
      "source_node": "Approximate Bayesian inference dependence on incorrect priors in Bayesian neural networks",
      "target_node": "Model averaging across diverse networks captures model uncertainty",
      "description": "Ensembling removes need for subjective priors, reducing mis-specification effects.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Argument in 2.4 comparing ensembles with Bayesian methods.",
      "edge_rationale": "Shows alternative path to handle prior problems."
    },
    {
      "type": "mitigated_by",
      "source_node": "Lack of robustness to unseen classes due to narrow training data support",
      "target_node": "Model averaging across diverse networks captures model uncertainty",
      "description": "Diverse models express higher uncertainty on unfamiliar inputs.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Validated by OOD entropy results (3.5).",
      "edge_rationale": "Links robustness problem to ensemble theory."
    },
    {
      "type": "mitigated_by",
      "source_node": "Lack of robustness to unseen classes due to narrow training data support",
      "target_node": "Adversarial training encourages local smoothness in predictive distributions",
      "description": "Adversarial training smooths predictions around training data, improving OOD behaviour.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Conceptual argument in 2.3; partial empirical support.",
      "edge_rationale": "Adds second theoretical mitigation."
    },
    {
      "type": "enabled_by",
      "source_node": "Proper scoring rule optimization promotes probabilistic calibration",
      "target_node": "Train probabilistic neural networks with predictive mean and variance outputs",
      "description": "Implementing scoring-rule training requires networks to output full distributions.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Implementation described in 2.2.1.",
      "edge_rationale": "Moves to design rationale."
    },
    {
      "type": "enabled_by",
      "source_node": "Model averaging across diverse networks captures model uncertainty",
      "target_node": "Independently train ensemble of NNs on full data with random initialization",
      "description": "Random initialisation provides the required diversity for effective averaging.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Empirically evaluated in 2.4 and Figure 2.",
      "edge_rationale": "Design rationale for ensembles."
    },
    {
      "type": "enabled_by",
      "source_node": "Adversarial training encourages local smoothness in predictive distributions",
      "target_node": "Augment training with adversarial examples using fast gradient sign method",
      "description": "FGSM perturbations operationalise adversarial smoothing.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Algorithm 1 lines 4-6.",
      "edge_rationale": "Bridges theoretical idea to concrete step."
    },
    {
      "type": "implemented_by",
      "source_node": "Train probabilistic neural networks with predictive mean and variance outputs",
      "target_node": "Negative log-likelihood loss for heteroscedastic Gaussian outputs",
      "description": "NLL on Gaussian outputs realises proper scoring-rule training in regression.",
      "edge_confidence": "5",
      "edge_confidence_rationale": "Equation (1) gives exact form; widely accepted.",
      "edge_rationale": "Implementation mechanism detail."
    },
    {
      "type": "implemented_by",
      "source_node": "Independently train ensemble of NNs on full data with random initialization",
      "target_node": "Uniform averaging of ensemble predictive distributions",
      "description": "Equal-weight averaging composes individual models into final ensemble.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Prediction formula in 2.4.",
      "edge_rationale": "Implementation of ensemble output."
    },
    {
      "type": "implemented_by",
      "source_node": "Augment training with adversarial examples using fast gradient sign method",
      "target_node": "Fast gradient sign generation of adversarial perturbations with epsilon 1% input range",
      "description": "Specifies perturbation rule and ε scaling used in experiments.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Detailed in 2.3 and 3.1.",
      "edge_rationale": "Concrete mechanism."
    },
    {
      "type": "validated_by",
      "source_node": "Negative log-likelihood loss for heteroscedastic Gaussian outputs",
      "target_node": "Deep ensemble NLL and Brier improvements over MC-dropout across benchmarks",
      "description": "Empirical results show NLL-trained models outperform MSE-trained baselines.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Supported by Figure 1 and Table 1.",
      "edge_rationale": "Evidence for implementation efficacy."
    },
    {
      "type": "validated_by",
      "source_node": "Uniform averaging of ensemble predictive distributions",
      "target_node": "Deep ensemble NLL and Brier improvements over MC-dropout across benchmarks",
      "description": "Ensembling contributes to overall uncertainty quality gains.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Ablation results in Figure 2 and Table 1.",
      "edge_rationale": "Evidence link."
    },
    {
      "type": "validated_by",
      "source_node": "Fast gradient sign generation of adversarial perturbations with epsilon 1% input range",
      "target_node": "Higher predictive entropy on out-of-distribution datasets with ensembles",
      "description": "Variants with adversarial training produce slightly higher entropy on unseen classes.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Observed difference in Figure 3(a) modes.",
      "edge_rationale": "Validates smoothing effect."
    },
    {
      "type": "validated_by",
      "source_node": "Uniform averaging of ensemble predictive distributions",
      "target_node": "Improved accuracy vs confidence curves showing reduced overconfidence",
      "description": "Accuracy-confidence curves benefit from ensemble averaging.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Figure 6 shows ensemble superiority.",
      "edge_rationale": "Connects mechanism to practical decision making."
    },
    {
      "type": "motivates",
      "source_node": "Deep ensemble NLL and Brier improvements over MC-dropout across benchmarks",
      "target_node": "Train deep probabilistic neural network ensembles with adversarial training and proper scoring rule",
      "description": "Empirical gains justify adopting the full training pipeline.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Consistent performance improvements across tasks (3.2-3.4).",
      "edge_rationale": "Drives intervention implementation."
    },
    {
      "type": "motivates",
      "source_node": "Higher predictive entropy on out-of-distribution datasets with ensembles",
      "target_node": "Train deep probabilistic neural network ensembles with adversarial training and proper scoring rule",
      "description": "OOD robustness evidence further supports ensemble training adoption.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Figure 3.",
      "edge_rationale": "Adds robustness motivation."
    },
    {
      "type": "motivates",
      "source_node": "Improved accuracy vs confidence curves showing reduced overconfidence",
      "target_node": "Apply ensemble predictive entropy thresholding during deployment to defer uncertain predictions",
      "description": "Demonstrates that confidence values can safely gate decisions.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Section 3.6 and Figure 6 provide direct evidence.",
      "edge_rationale": "Enables deployment-phase safety control."
    }
  ],
  "meta": [
    {
      "key": "date_published",
      "value": "2016-12-05T00:00:00Z"
    },
    {
      "key": "title",
      "value": "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles"
    },
    {
      "key": "authors",
      "value": [
        "Balaji Lakshminarayanan",
        "Alexander Pritzel",
        "Charles Blundell"
      ]
    },
    {
      "key": "url",
      "value": "https://arxiv.org/abs/1612.01474"
    },
    {
      "key": "source",
      "value": "arxiv"
    }
  ]
}