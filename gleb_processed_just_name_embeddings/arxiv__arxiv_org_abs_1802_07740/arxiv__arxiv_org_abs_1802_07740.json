{
  "nodes": [
    {
      "name": "Opaque decision-making in deep learning agents",
      "aliases": [
        "black-box behaviour in neural networks",
        "uninterpretable deep RL policies"
      ],
      "type": "concept",
      "description": "Modern deep learning and deep reinforcement-learning agents expose weights but not the reasoning behind actions, hampering oversight and safety.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced under '1 Introduction' as the motivating safety concern."
    },
    {
      "name": "Absence of predictive models of agent behavior in multi-agent environments",
      "aliases": [
        "no forward model of other agents",
        "lack of behaviour prediction tools"
      ],
      "type": "concept",
      "description": "Without a learned model that forecasts how an arbitrary agent will act, humans cannot anticipate failures or coordinate.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Problem framed in '1 Introduction'—difficulty of understanding others' latent policies."
    },
    {
      "name": "High-level theory-of-mind abstractions enable behavior prediction without internal weight access",
      "aliases": [
        "cognitive ToM abstractions",
        "belief-desire modelling insight"
      ],
      "type": "concept",
      "description": "Humans rely on abstract beliefs/desires rather than neural details; analogous abstractions can let machines predict agents while remaining agnostic to internal parameters.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Discussed in '1 Introduction' and Theory-of-Mind background."
    },
    {
      "name": "Meta-learning observer infers agent priors and posteriors from limited behavioral data",
      "aliases": [
        "observer meta-learning approach",
        "learning-to-learn agent models"
      ],
      "type": "concept",
      "description": "Formulating ToM as a meta-learning task lets an observer rapidly build a prior and update it online for each new agent.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Outlined in '1.1 Our approach'."
    },
    {
      "name": "ToMnet architecture with character net, mental state net, and prediction net",
      "aliases": [
        "character-mental-prediction tri-module",
        "ToMnet core architecture"
      ],
      "type": "concept",
      "description": "Implementation splits inference into: (i) character embeddings from past episodes, (ii) mental-state embeddings from current trajectory, and (iii) a shared prediction net for behaviour queries.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Detailed in '2.2 The architecture'."
    },
    {
      "name": "Bayes-optimal action prediction on random agent species tasks",
      "aliases": [
        "random agents experiment results",
        "Section 3.1 validation"
      ],
      "type": "concept",
      "description": "When trained on Dirichlet-distributed random agents, ToMnet reproduced Bayes-optimal posteriors and out-performed naive baselines.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Empirical evidence reported in '3.1 Random agents'."
    },
    {
      "name": "Deploy ToMnet observers for pre-deployment behavior prediction of novel AI systems",
      "aliases": [
        "pre-deployment ToMnet analysis",
        "behaviour forecasting via ToMnet"
      ],
      "type": "intervention",
      "description": "Before releasing a new agent, run a trained ToMnet on simulated or recorded trajectories to forecast actions, detect anomalies, and inform safety audits.",
      "concept_category": null,
      "intervention_lifecycle": "4",
      "intervention_lifecycle_rationale": "Applies after training but before real-world release—aligns with '4 Pre-Deployment Testing' phase described in Discussion.",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Only demonstrated in controlled grid-worlds; categorised as Experimental/Proof-of-Concept (Discussion section).",
      "node_rationale": "Logical safety use-case derived from findings in 'Discussion'."
    },
    {
      "name": "Misinterpretation of agents' hidden beliefs leading to unsafe interactions",
      "aliases": [
        "false belief misunderstanding risk",
        "belief attribution failures"
      ],
      "type": "concept",
      "description": "If observers cannot tell when an agent is acting on outdated or false information, coordination and safety measures may fail.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Motivated in '3.4 Acting based on false beliefs'."
    },
    {
      "name": "Observer models ignore distinction between world state and agent belief state",
      "aliases": [
        "world-belief conflation",
        "no belief modelling"
      ],
      "type": "concept",
      "description": "Traditional observers assume agents act on true state, failing when agents possess limited observations or misconceptions.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "'3.4' describes this shortcoming via swap events."
    },
    {
      "name": "Behavioral discrepancies reveal agents can hold false beliefs",
      "aliases": [
        "false-belief inference insight",
        "swap-event theoretical insight"
      ],
      "type": "concept",
      "description": "Seeing policies diverge after unseen environment changes suggests agents rely on internal belief states separate from reality.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Insight gained in '3.4 Acting based on false beliefs'."
    },
    {
      "name": "Augment ToMnet with belief prediction heads to infer internal beliefs",
      "aliases": [
        "belief-state design rationale",
        "explicit belief modelling in ToMnet"
      ],
      "type": "concept",
      "description": "Design adjustment: add a supervised output that predicts where the agent believes objects are, enabling declarative belief estimates.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Presented in '3.5 Explicitly inferring belief states'."
    },
    {
      "name": "Supervised training of ToMnet on agent self-reported belief states",
      "aliases": [
        "belief-state implementation mechanism",
        "belief supervision pipeline"
      ],
      "type": "concept",
      "description": "Agents output posterior distributions over object locations; these labels let ToMnet learn to map observed trajectories to latent belief estimates.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Implementation specifics in '3.5'."
    },
    {
      "name": "Accurate belief-state prediction in Sally-Anne swap experiments",
      "aliases": [
        "belief validation evidence",
        "Sally-Anne ToMnet results"
      ],
      "type": "concept",
      "description": "ToMnet correctly predicted that agents would persist with or revise plans depending on whether swaps were within their field of view, matching ground truth.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Quantified in 'Figures 11-13' of section 3.5."
    },
    {
      "name": "Use belief-predicting ToMnet to detect agent false beliefs before deployment",
      "aliases": [
        "false-belief safety audit",
        "belief-aware deployment test"
      ],
      "type": "intervention",
      "description": "Run the enhanced ToMnet on candidate policies; flag situations where predicted beliefs diverge from reality, indicating possible unsafe behaviour.",
      "concept_category": null,
      "intervention_lifecycle": "4",
      "intervention_lifecycle_rationale": "Tool is applied in test environments pre-deployment, per '4 Discussion' future work on safety use-cases.",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Demonstrated only in controlled experiments; labelled Experimental.",
      "node_rationale": "Translates validation in 3.5 into a concrete safety process."
    },
    {
      "name": "Entangled latent representations reduce interpretability of agent characteristics",
      "aliases": [
        "opaque character embeddings",
        "latent entanglement risk"
      ],
      "type": "concept",
      "description": "When embeddings mix multiple behavioural factors, humans cannot easily reason about species, preferences or other traits.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Identified in '3.3 Learning to model deep RL agents' before adding bottleneck."
    },
    {
      "name": "High-dimensional character embeddings mix species and preferences",
      "aliases": [
        "embedding dimensionality problem",
        "mixed factors in R8 space"
      ],
      "type": "concept",
      "description": "Without constraints, ToMnet required >2D embeddings that obscured structure, making analysis difficult.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Problem statement in 3.3 prior to information-bottleneck experiment."
    },
    {
      "name": "Information bottleneck regularization can disentangle latent dimensions",
      "aliases": [
        "IB theoretical insight",
        "compression-based disentanglement"
      ],
      "type": "concept",
      "description": "Penalising mutual information between embeddings and prior encourages compact, factorised representations that align with distinct behavioural causes.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Insight adopted from Alemi et al. and applied in '3.3'."
    },
    {
      "name": "Variational Gaussian embeddings with KL penalty in ToMnet training",
      "aliases": [
        "variational information bottleneck implementation",
        "Gaussian character posterior"
      ],
      "type": "concept",
      "description": "Replace deterministic character vectors with Gaussian posteriors q(e) and add β·KL(q||p) to loss, gradually annealing β.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Mechanism described in 'Figure 8' of section 3.3."
    },
    {
      "name": "Separated embedding dimensions for species and preference observed",
      "aliases": [
        "disentangled embedding validation",
        "Figure 8 evidence"
      ],
      "type": "concept",
      "description": "After bottleneck training, first two dimensions encoded species, next two encoded object preference, confirming successful disentanglement.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Validation in '3.3 Learning to model deep RL agents' Figure 8."
    },
    {
      "name": "Regularize observer embeddings with variational information bottleneck during analysis",
      "aliases": [
        "apply IB to observer training",
        "disentangled ToMnet embedding intervention"
      ],
      "type": "intervention",
      "description": "When training observer networks, include a KL-penalised Gaussian embedding layer to yield human-interpretable, disentangled factors for safety auditing.",
      "concept_category": null,
      "intervention_lifecycle": "2",
      "intervention_lifecycle_rationale": "Implemented during ToMnet pre-training phase before it is used for analysis.",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Currently validated only in grid-world experiments—classified as Experimental.",
      "node_rationale": "Actionable training recommendation drawn from successful disentanglement results."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Opaque decision-making in deep learning agents",
      "target_node": "Absence of predictive models of agent behavior in multi-agent environments",
      "description": "Without forward models, agent behaviour remains opaque to observers.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Qualitative argument from '1 Introduction'.",
      "edge_rationale": "Paper states opacity stems from lack of understanding/prediction tools."
    },
    {
      "type": "mitigated_by",
      "source_node": "Absence of predictive models of agent behavior in multi-agent environments",
      "target_node": "High-level theory-of-mind abstractions enable behavior prediction without internal weight access",
      "description": "Using ToM abstractions offers a route to build predictive models.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Conceptual claim; supported but not rigorously measured.",
      "edge_rationale": "Section 1 argues abstractions alleviate need for mechanistic access."
    },
    {
      "type": "enabled_by",
      "source_node": "High-level theory-of-mind abstractions enable behavior prediction without internal weight access",
      "target_node": "Meta-learning observer infers agent priors and posteriors from limited behavioral data",
      "description": "Abstraction premise motivates meta-learning design.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicit reasoning in '1.1 Our approach'.",
      "edge_rationale": "Meta-learning leverages abstraction to learn priors."
    },
    {
      "type": "implemented_by",
      "source_node": "Meta-learning observer infers agent priors and posteriors from limited behavioral data",
      "target_node": "ToMnet architecture with character net, mental state net, and prediction net",
      "description": "ToMnet realises the meta-learning observer concept.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Detailed architectural description in Section 2.2.",
      "edge_rationale": "Direct mapping of design to implementation."
    },
    {
      "type": "validated_by",
      "source_node": "ToMnet architecture with character net, mental state net, and prediction net",
      "target_node": "Bayes-optimal action prediction on random agent species tasks",
      "description": "Random-agent experiment demonstrates correctness of implementation.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Controlled experiment results with quantitative fit (Figure 3).",
      "edge_rationale": "Validation node summarises empirical findings."
    },
    {
      "type": "motivates",
      "source_node": "Bayes-optimal action prediction on random agent species tasks",
      "target_node": "Deploy ToMnet observers for pre-deployment behavior prediction of novel AI systems",
      "description": "Successful prediction capability suggests safety application.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Application logic drawn from Discussion; not yet field-tested.",
      "edge_rationale": "Discussion proposes using ToMnet to aid interpretability."
    },
    {
      "type": "caused_by",
      "source_node": "Misinterpretation of agents' hidden beliefs leading to unsafe interactions",
      "target_node": "Observer models ignore distinction between world state and agent belief state",
      "description": "If models conflate world and belief, false-belief scenarios go undetected.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Presented in '3.4' with illustrative failures.",
      "edge_rationale": "Mechanism explanation."
    },
    {
      "type": "mitigated_by",
      "source_node": "Observer models ignore distinction between world state and agent belief state",
      "target_node": "Behavioral discrepancies reveal agents can hold false beliefs",
      "description": "Recognising behavioural anomalies offers a theoretical mitigation route.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Conceptual but inferred from swap-event analysis.",
      "edge_rationale": "Insight enables a solution."
    },
    {
      "type": "enabled_by",
      "source_node": "Behavioral discrepancies reveal agents can hold false beliefs",
      "target_node": "Augment ToMnet with belief prediction heads to infer internal beliefs",
      "description": "Insight drives design change to predict beliefs explicitly.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "'3.5' explicitly motivated by previous section.",
      "edge_rationale": "Design responds to theoretical observation."
    },
    {
      "type": "implemented_by",
      "source_node": "Augment ToMnet with belief prediction heads to infer internal beliefs",
      "target_node": "Supervised training of ToMnet on agent self-reported belief states",
      "description": "Belief heads are trained via supervised labels.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Implementation details and training procedure in '3.5'.",
      "edge_rationale": "Direct implementation mapping."
    },
    {
      "type": "validated_by",
      "source_node": "Supervised training of ToMnet on agent self-reported belief states",
      "target_node": "Accurate belief-state prediction in Sally-Anne swap experiments",
      "description": "Sally-Anne style tests confirm effectiveness.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Figure 13 quantitative match between predictions and ground truth.",
      "edge_rationale": "Empirical support."
    },
    {
      "type": "motivates",
      "source_node": "Accurate belief-state prediction in Sally-Anne swap experiments",
      "target_node": "Use belief-predicting ToMnet to detect agent false beliefs before deployment",
      "description": "Validated capability suggests practical safety audit.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Application extrapolation from experimental success.",
      "edge_rationale": "Logical next step proposed in Discussion."
    },
    {
      "type": "enabled_by",
      "source_node": "ToMnet architecture with character net, mental state net, and prediction net",
      "target_node": "Supervised training of ToMnet on agent self-reported belief states",
      "description": "Belief-prediction module extends the core architecture.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Architecture reused with added heads ('3.5').",
      "edge_rationale": "Core architecture prerequisite."
    },
    {
      "type": "caused_by",
      "source_node": "Entangled latent representations reduce interpretability of agent characteristics",
      "target_node": "High-dimensional character embeddings mix species and preferences",
      "description": "Mixing factors inside high-dimensional embeddings leads to entanglement risk.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Observed empirically before bottleneck was added.",
      "edge_rationale": "Problem diagnosis."
    },
    {
      "type": "mitigated_by",
      "source_node": "High-dimensional character embeddings mix species and preferences",
      "target_node": "Information bottleneck regularization can disentangle latent dimensions",
      "description": "Theory proposes compression to separate factors.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Adopts known IB theory, referenced in section 3.3.",
      "edge_rationale": "IB offers mitigation."
    },
    {
      "type": "implemented_by",
      "source_node": "Information bottleneck regularization can disentangle latent dimensions",
      "target_node": "Variational Gaussian embeddings with KL penalty in ToMnet training",
      "description": "KL-penalised Gaussian embeddings instantiate the IB idea.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Implementation explicitly specified (Figure 8).",
      "edge_rationale": "Mechanism realises theoretical insight."
    },
    {
      "type": "validated_by",
      "source_node": "Variational Gaussian embeddings with KL penalty in ToMnet training",
      "target_node": "Separated embedding dimensions for species and preference observed",
      "description": "Post-training visualisation confirms disentanglement.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Clear qualitative and quantitative evidence in Figure 8.",
      "edge_rationale": "Validation node summarises evidence."
    },
    {
      "type": "motivates",
      "source_node": "Separated embedding dimensions for species and preference observed",
      "target_node": "Regularize observer embeddings with variational information bottleneck during analysis",
      "description": "Successful disentanglement motivates routine use of IB in observer training.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Suggestion extrapolated from experiment; not yet broadly adopted.",
      "edge_rationale": "Leverages positive result for future practice."
    },
    {
      "type": "preceded_by",
      "source_node": "ToMnet architecture with character net, mental state net, and prediction net",
      "target_node": "Variational Gaussian embeddings with KL penalty in ToMnet training",
      "description": "IB implementation builds on the existing architecture.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Architecture retained with minor modification (section 3.3).",
      "edge_rationale": "Temporal/structural dependency."
    }
  ],
  "meta": [
    {
      "key": "title",
      "value": "Machine Theory of Mind"
    },
    {
      "key": "url",
      "value": "https://arxiv.org/abs/1802.07740"
    },
    {
      "key": "date_published",
      "value": "2018-02-21T00:00:00Z"
    },
    {
      "key": "authors",
      "value": [
        "Neil C. Rabinowitz",
        "Frank Perbet",
        "H. Francis Song",
        "Chiyuan Zhang",
        "S. M. Ali Eslami",
        "Matthew Botvinick"
      ]
    },
    {
      "key": "source",
      "value": "arxiv"
    }
  ]
}