{
  "nodes": [
    {
      "name": "Unexpected robot behavior in human-robot interaction",
      "aliases": [
        "surprising robot actions",
        "unanticipated robot movements"
      ],
      "type": "concept",
      "description": "Robots (e.g., self-driving cars) can brake or merge suddenly, causing user surprise, discomfort or safety hazards when their actions are not anticipated.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Scenario in I Introduction where passengers are frightened by sudden braking."
    },
    {
      "name": "Opacity of robot objective functions to end-users",
      "aliases": [
        "lack of transparency of robot goals",
        "users cannot infer robot objective"
      ],
      "type": "concept",
      "description": "End-users often lack a clear mental model of the reward function that drives a robot’s behaviour, hindering their ability to anticipate future actions.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Motivating problem stated in I Introduction."
    },
    {
      "name": "Underdetermined optimal behavior in low-interaction environments",
      "aliases": [
        "non-informative environments",
        "objective under-determination"
      ],
      "type": "concept",
      "description": "In simple settings (e.g., an empty lane) many different reward functions yield identical optimal trajectories, so users cannot tell which objective the robot truly follows.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Discussed in I Introduction: highway driving with no other cars does not reveal the trade-offs encoded in θ."
    },
    {
      "name": "Human approximate inference over robot objectives",
      "aliases": [
        "approximate inverse reinforcement learning by humans",
        "imperfect human inference"
      ],
      "type": "concept",
      "description": "People update beliefs about a robot’s reward parameters only approximately, using noisy distance judgements rather than exact Bayesian elimination of objectives.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced in II-D Approximate-Inference Models."
    },
    {
      "name": "Informative demonstrations accelerate mental model formation",
      "aliases": [
        "example behaviours as teaching signals",
        "algorithmic teaching hypothesis"
      ],
      "type": "concept",
      "description": "Showing purposefully chosen trajectories that differentiate between competing objectives can quickly align the user’s mental model with the true reward function.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Central claim in I Introduction and II-B Teaching Framework."
    },
    {
      "name": "Algorithmic teaching for informative behavior selection",
      "aliases": [
        "objective-function teaching algorithm",
        "informative example selection"
      ],
      "type": "concept",
      "description": "Formulates environment/trajectory selection as maximising the posterior probability that users assign to the true reward parameters after observing the examples.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Detailed in II-B and II-E."
    },
    {
      "name": "Deterministic Euclidean-based user model for teaching",
      "aliases": [
        "Euclidean deterministic approximation",
        "distance-threshold learner model"
      ],
      "type": "concept",
      "description": "Assumes users keep reward hypotheses whose optimal trajectories lie within a Euclidean distance τ of the observed trajectory, eliminating others.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Identified as best-performing model in IV Analysis & V-B User Study."
    },
    {
      "name": "Strategy coverage in teaching examples",
      "aliases": [
        "coverage over trajectory clusters",
        "balanced demonstration coverage"
      ],
      "type": "concept",
      "description": "Ensuring at least one example from each major trajectory-strategy cluster prevents users from over-generalising from partial information.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Derived from correlation analysis in V-B and formalised in VI-B Coverage-Augmented Algorithm."
    },
    {
      "name": "Greedy environment selection maximizing posterior over objectives",
      "aliases": [
        "greedy informative environment search",
        "posterior-maximising example chooser"
      ],
      "type": "concept",
      "description": "Selects environments one-by-one that yield the greatest increase in the user-model posterior probability of the true θ*, leveraging sub-modularity.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Algorithm described in II-E Example Selection."
    },
    {
      "name": "Deterministic Euclidean distance metric in learner model",
      "aliases": [
        "Euclidean τ-threshold",
        "distance metric implementation"
      ],
      "type": "concept",
      "description": "Computes the average positional Euclidean distance between optimal and observed trajectories; eliminates hypotheses if the distance exceeds τ.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Mathematically defined in II-D; τ tuned in II-F."
    },
    {
      "name": "Coverage augmentation after posterior convergence",
      "aliases": [
        "post-posterior coverage heuristic",
        "coverage term λ"
      ],
      "type": "concept",
      "description": "Adds extra examples once additional posterior gain falls below ε, selecting one per uncovered strategy cluster to maximise user-model benefit.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Equation 9 and VI-B Coverage-Augmented Algorithm."
    },
    {
      "name": "User study: Euclidean model improves trajectory identification",
      "aliases": [
        "MTurk study result 1",
        "approx* user study"
      ],
      "type": "concept",
      "description": "161 participants trained with Euclidean-model examples achieved significantly higher confidence and accuracy than with exact-inference examples (p=0.025).",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Results shown in Fig. 5 (left) of V-B Analysis."
    },
    {
      "name": "User study: coverage-augmented teaching outperforms random baseline",
      "aliases": [
        "MTurk study result 2",
        "coverage-approx* result"
      ],
      "type": "concept",
      "description": "Coverage-augmented Euclidean teaching significantly outperformed a random-example baseline (p=0.049) with 53 new participants.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "VI-C User Study on Coverage and Fig. 5 (right)."
    },
    {
      "name": "Deploy coverage-augmented algorithmic teaching of robot objectives to end-users",
      "aliases": [
        "coverage-based teaching deployment",
        "end-user objective demonstration with coverage"
      ],
      "type": "intervention",
      "description": "Before real operation, show users a curated set of robot behaviours that both maximise the Euclidean-model posterior on θ* and cover every trajectory-strategy cluster, teaching the robot’s objective.",
      "concept_category": null,
      "intervention_lifecycle": "5",
      "intervention_lifecycle_rationale": "Occurs during user-facing training immediately prior to real deployment (VI Utility of Algorithmic Teaching).",
      "intervention_maturity": "3",
      "intervention_maturity_rationale": "Validated via controlled Mechanical-Turk studies but not yet deployed at scale (V & VI sections).",
      "node_rationale": "Proposed practical takeaway in VI Discussion."
    },
    {
      "name": "Generate teaching examples using deterministic Euclidean-based inference model during user training",
      "aliases": [
        "Euclidean-model example selection",
        "approx* example generation"
      ],
      "type": "intervention",
      "description": "Utilise the deterministic Euclidean user model to select informative driving environments/trajectories that best teach the true reward parameters.",
      "concept_category": null,
      "intervention_lifecycle": "5",
      "intervention_lifecycle_rationale": "Executed in the same user-training phase as above (II-E Example Selection and V User Study).",
      "intervention_maturity": "3",
      "intervention_maturity_rationale": "Supported by user-study evidence but not yet industrially deployed (V-B Analysis).",
      "node_rationale": "Directly supported by the best-performing condition (*approx*)."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Unexpected robot behavior in human-robot interaction",
      "target_node": "Opacity of robot objective functions to end-users",
      "description": "Unexpected behaviour arises because users cannot see the trade-offs encoded in the hidden reward function.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicit reasoning in I Introduction; no quantitative proof (qualitative evidence).",
      "edge_rationale": "Paper claims anticipation depends on understanding objective; lack thereof causes surprise."
    },
    {
      "type": "caused_by",
      "source_node": "Opacity of robot objective functions to end-users",
      "target_node": "Underdetermined optimal behavior in low-interaction environments",
      "description": "When multiple objectives yield identical behaviour, observing such environments gives no information, keeping the objective opaque.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Direct textual explanation in I Introduction with highway example.",
      "edge_rationale": "Authors highlight these environments as a root cause for slow mental-model formation."
    },
    {
      "type": "caused_by",
      "source_node": "Opacity of robot objective functions to end-users",
      "target_node": "Human approximate inference over robot objectives",
      "description": "Even when informative data exist, users’ approximate inference limits their ability to deduce the objective, sustaining opacity.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Discussed conceptually in II-D; no quantitative measure.",
      "edge_rationale": "Approximate inference prevents perfect elimination of wrong θ."
    },
    {
      "type": "mitigated_by",
      "source_node": "Opacity of robot objective functions to end-users",
      "target_node": "Informative demonstrations accelerate mental model formation",
      "description": "Providing carefully chosen examples helps users overcome opacity and understand objectives.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Central hypothesis repeatedly asserted; supported by subsequent user studies.",
      "edge_rationale": "Teaching examples are proposed solution to opacity."
    },
    {
      "type": "implemented_by",
      "source_node": "Informative demonstrations accelerate mental model formation",
      "target_node": "Algorithmic teaching for informative behavior selection",
      "description": "Algorithmic teaching operationalises the idea of informative demonstrations.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Formalised in II-B with optimisation framework.",
      "edge_rationale": "Design turns theoretical insight into a concrete approach."
    },
    {
      "type": "required_by",
      "source_node": "Algorithmic teaching for informative behavior selection",
      "target_node": "Human approximate inference over robot objectives",
      "description": "Teaching algorithm must model how humans (approximately) update beliefs to select effective examples.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Algorithm explicitly incorporates a learner model (II-B, II-D).",
      "edge_rationale": "Prerequisite for calculating P(θ|examples)."
    },
    {
      "type": "refined_by",
      "source_node": "Algorithmic teaching for informative behavior selection",
      "target_node": "Deterministic Euclidean-based user model for teaching",
      "description": "Selecting this specific learner model refines the generic teaching approach.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Model chosen after comparing six variants (IV, V).",
      "edge_rationale": "Refinement narrows design to best-fit user model."
    },
    {
      "type": "refined_by",
      "source_node": "Algorithmic teaching for informative behavior selection",
      "target_node": "Strategy coverage in teaching examples",
      "description": "Adding coverage addresses users’ over-generalisation, refining the teaching strategy.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Motivated by strong r=0.83 correlation (V-B).",
      "edge_rationale": "Coverage augments original algorithm."
    },
    {
      "type": "implemented_by",
      "source_node": "Algorithmic teaching for informative behavior selection",
      "target_node": "Greedy environment selection maximizing posterior over objectives",
      "description": "Greedy selection realises the algorithm due to sub-modularity properties.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Formal proof sketch in II-E.",
      "edge_rationale": "Implementation mechanism for design rationale."
    },
    {
      "type": "implemented_by",
      "source_node": "Deterministic Euclidean-based user model for teaching",
      "target_node": "Deterministic Euclidean distance metric in learner model",
      "description": "Metric operationalises the deterministic Euclidean learner model.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Metric formula provided in II-D.",
      "edge_rationale": "Distance function instantiates the model."
    },
    {
      "type": "implemented_by",
      "source_node": "Strategy coverage in teaching examples",
      "target_node": "Coverage augmentation after posterior convergence",
      "description": "Coverage augmentation algorithm realises the coverage design principle.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Equation 9 and implementation details in VI-B.",
      "edge_rationale": "Concrete mechanism to achieve coverage."
    },
    {
      "type": "validated_by",
      "source_node": "Deterministic Euclidean distance metric in learner model",
      "target_node": "User study: Euclidean model improves trajectory identification",
      "description": "User study shows metric-based teaching increases accuracy and confidence.",
      "edge_confidence": "5",
      "edge_confidence_rationale": "Controlled experiment with statistical significance (p=0.025).",
      "edge_rationale": "Empirical validation of the mechanism."
    },
    {
      "type": "validated_by",
      "source_node": "Coverage augmentation after posterior convergence",
      "target_node": "User study: coverage-augmented teaching outperforms random baseline",
      "description": "Study confirms added coverage yields significant performance gains over baseline.",
      "edge_confidence": "5",
      "edge_confidence_rationale": "Statistical result p=0.049 in VI-C.",
      "edge_rationale": "Direct empirical evidence."
    },
    {
      "type": "motivates",
      "source_node": "User study: Euclidean model improves trajectory identification",
      "target_node": "Generate teaching examples using deterministic Euclidean-based inference model during user training",
      "description": "Positive results motivate adopting this example-generation method in practice.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Strong experimental support; practical recommendation in Discussion.",
      "edge_rationale": "Findings justify intervention."
    },
    {
      "type": "motivates",
      "source_node": "User study: coverage-augmented teaching outperforms random baseline",
      "target_node": "Deploy coverage-augmented algorithmic teaching of robot objectives to end-users",
      "description": "Demonstrated benefit motivates full deployment of coverage-augmented teaching.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Significant superiority over baseline (p=0.049).",
      "edge_rationale": "Evidence supports scaling the intervention."
    },
    {
      "type": "enabled_by",
      "source_node": "Greedy environment selection maximizing posterior over objectives",
      "target_node": "Deterministic Euclidean distance metric in learner model",
      "description": "Greedy selection’s posterior computations rely on the Euclidean distance metric to evaluate candidate trajectories.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Implicit in II-E; moderate inference.",
      "edge_rationale": "Metric necessary to compute P(ξ|θ)."
    },
    {
      "type": "enabled_by",
      "source_node": "Coverage augmentation after posterior convergence",
      "target_node": "Strategy coverage in teaching examples",
      "description": "Augmentation mechanism specifically realises the coverage design goal.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Section VI-B explicitly states this relationship.",
      "edge_rationale": "Mechanism operationalises the design principle."
    },
    {
      "type": "validated_by",
      "source_node": "Greedy environment selection maximizing posterior over objectives",
      "target_node": "User study: Euclidean model improves trajectory identification",
      "description": "User performance confirms that greedy-selected examples are effective.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Selection was part of the approx* condition tested; effect separated less directly.",
      "edge_rationale": "Greedy selection contributed to observed improvement."
    }
  ],
  "meta": [
    {
      "key": "authors",
      "value": [
        "Sandy H. Huang",
        "David Held",
        "Pieter Abbeel",
        "Anca D. Dragan"
      ]
    },
    {
      "key": "date_published",
      "value": "2017-02-11T00:00:00Z"
    },
    {
      "key": "title",
      "value": "Enabling Robots to Communicate their Objectives"
    },
    {
      "key": "source",
      "value": "arxiv"
    },
    {
      "key": "url",
      "value": "https://arxiv.org/abs/1702.03465"
    }
  ]
}