{
  "nodes": [
    {
      "name": "Incorrect human preference inference in AI value learning",
      "aliases": [
        "preference misidentification",
        "value learning misalignment"
      ],
      "type": "concept",
      "description": "Risk that AI systems learn an inaccurate model of human preferences from observed behaviour, leading to actions that conflict with human values and safety goals.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced in Introduction and Conclusion as the overarching problem the work tries to solve."
    },
    {
      "name": "Assuming optimal rational choice in inverse reinforcement learning",
      "aliases": [
        "perfect rationality assumption",
        "optimality assumption in IRL"
      ],
      "type": "concept",
      "description": "Standard IRL models invert a perfectly rational planner, treating deviations as random noise, which misattributes systematic human errors to preferences.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Problem highlighted in Introduction and Deviations from Optimality sections."
    },
    {
      "name": "Modeling systematic human biases as unstructured noise in choice modelling",
      "aliases": [
        "biases treated as noise",
        "unstructured error assumption"
      ],
      "type": "concept",
      "description": "Treating false beliefs and time-inconsistency as generic noise hides their structure, leading to wrong preference inference.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Discussed in Introduction with smoking example; motivates structured modelling."
    },
    {
      "name": "Modeling structured deviations from optimality improves preference identification",
      "aliases": [
        "structure-aware preference inference",
        "bias-model integration benefit"
      ],
      "type": "concept",
      "description": "The key theoretical claim that explicitly representing systematic deviations (false beliefs, hyperbolic discounting) enables more accurate recovery of underlying utilities.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Central thesis stated in Abstract and Deviations from Optimality."
    },
    {
      "name": "Bayesian joint inference over preferences, beliefs, and biases captures uncertainty",
      "aliases": [
        "joint posterior over agent properties",
        "Bayesian preference-bias inference"
      ],
      "type": "concept",
      "description": "Maintaining a posterior over utilities, beliefs, bias type, discount rate and noise mitigates ambiguity when limited behavioural data is available.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Formalised in Equation (1) in Inferring Preferences section."
    },
    {
      "name": "Extend agent model with false belief distributions and time inconsistency types",
      "aliases": [
        "belief & bias augmented agent model",
        "extended generative agent model"
      ],
      "type": "concept",
      "description": "Design decision to parameterise agents by belief distributions, hyperbolic discount rate k, Naive vs Sophisticated type, and soft-max noise.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Derived from Formal Model Definition section."
    },
    {
      "name": "Distinguish Naive vs Sophisticated hyperbolic discounting in planning models",
      "aliases": [
        "Naive-Sophisticated distinction",
        "self-prediction of discounting"
      ],
      "type": "concept",
      "description": "Design refinement: Naive agents mispredict their future discounting whereas Sophisticated agents forecast it, leading to different observable trajectories.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Explained in Temporal Inconsistency subsection with Fig 1."
    },
    {
      "name": "Represent agent decision-making as recursive probabilistic program",
      "aliases": [
        "probabilistic programming agent model",
        "recursive WebPPL agent"
      ],
      "type": "concept",
      "description": "Using WebPPL to encode mutually recursive expected-utility and action-choice functions allows easy modification of biases and automated Bayesian inversion.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Shown in Agents as Probabilistic Programs section and Figure 2."
    },
    {
      "name": "Softmax action choice with hyperbolic discount factor in WebPPL",
      "aliases": [
        "hyperbolic soft-max policy",
        "discount-aware softmax"
      ],
      "type": "concept",
      "description": "Implementation mechanism combining soft-max stochasticity (α) with 1/(1+k·d) hyperbolic discounting inside the probabilistic program.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Equation definitions and code in Formal Model Definition & Figure 2."
    },
    {
      "name": "Exact inference via enumeration over discretized parameters",
      "aliases": [
        "grid enumeration inference",
        "exact Bayesian enumeration"
      ],
      "type": "concept",
      "description": "Inference mechanism enumerates a discrete grid for continuous parameters (utilities, beliefs, k, α) enabling exact posterior calculation with dynamic programming.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Described in Agents as Probabilistic Programs section."
    },
    {
      "name": "Model recovers correct preferences in Gridworld case studies",
      "aliases": [
        "Gridworld posterior accuracy",
        "case-study validation"
      ],
      "type": "concept",
      "description": "Validation evidence showing the algorithm infers that Vegetarian Cafe is preferred despite majority donut choices when discounting explains behaviour (Example 3, Figure 4).",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Reported in Model Inferences section."
    },
    {
      "name": "Human subject experiments show algorithm's inferences match human judgments",
      "aliases": [
        "MTurk validation",
        "human alignment with model"
      ],
      "type": "concept",
      "description": "Across three experiments, participants’ explanations and preference attributions agree with the model’s posterior distributions, supporting face validity.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Covered in Experiments with Human Subjects section."
    },
    {
      "name": "Design preference inference algorithms incorporating structured bias models using probabilistic programming",
      "aliases": [
        "bias-aware preference inference design",
        "structured IRL algorithm development"
      ],
      "type": "intervention",
      "description": "At model-design time, build IRL modules that jointly infer utilities, beliefs and biases by encoding agent causal models (false beliefs, Naive/Sophisticated hyperbolic discounting) in probabilistic programming frameworks like WebPPL or Pyro.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Targets the Model Design phase where the causal structure of preference inference is specified (Formal Model Definition & Agents as Probabilistic Programs).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Demonstrated only in proof-of-concept simulations and small user studies; no large-scale deployment (Experiments with Human Subjects).",
      "node_rationale": "Proposed explicitly in Conclusion as next steps for AI systems to better learn human values."
    },
    {
      "name": "Deploy Bayesian inverse planning with bias-aware generative models in AI value learning modules",
      "aliases": [
        "bias-aware inverse planning deployment",
        "structured IRL integration"
      ],
      "type": "intervention",
      "description": "Integrate the above probabilistic preference-inference components into training or deployment pipelines of recommender, assistant or planning AI systems to reduce misalignment caused by human sub-optimal behaviour.",
      "concept_category": null,
      "intervention_lifecycle": "5",
      "intervention_lifecycle_rationale": "Applies during Deployment when the AI system must infer live user preferences (Conclusion).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Only proposed; real-world deployments not yet documented, making it experimental.",
      "node_rationale": "Logical application step discussed in Conclusion: using the model to support humans in complex domains."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Incorrect human preference inference in AI value learning",
      "target_node": "Assuming optimal rational choice in inverse reinforcement learning",
      "description": "Misalignment arises because standard IRL assumes perfect rationality, mis-explaining systematic human deviations.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicitly stated in Introduction; medium empirical support.",
      "edge_rationale": "Introduction links rationality assumption to incorrect inference risk."
    },
    {
      "type": "caused_by",
      "source_node": "Incorrect human preference inference in AI value learning",
      "target_node": "Modeling systematic human biases as unstructured noise in choice modelling",
      "description": "Treating biases as random error rather than structured causes leads AI to learn wrong utilities.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Illustrated by smoking example in Introduction.",
      "edge_rationale": "Paper argues unstructured-noise models mis-identify preferences."
    },
    {
      "type": "mitigated_by",
      "source_node": "Assuming optimal rational choice in inverse reinforcement learning",
      "target_node": "Modeling structured deviations from optimality improves preference identification",
      "description": "Introducing structured bias models removes the faulty optimality assumption.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Central claim developed in Deviations from Optimality.",
      "edge_rationale": "Structured modelling directly addresses the assumption flaw."
    },
    {
      "type": "mitigated_by",
      "source_node": "Modeling systematic human biases as unstructured noise in choice modelling",
      "target_node": "Modeling structured deviations from optimality improves preference identification",
      "description": "Replacing unstructured-noise treatment with structured bias models mitigates this problem.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Same sections provide argument.",
      "edge_rationale": "Structured deviations explicitly encode biases, solving the unstructured-noise issue."
    },
    {
      "type": "refined_by",
      "source_node": "Modeling structured deviations from optimality improves preference identification",
      "target_node": "Bayesian joint inference over preferences, beliefs, and biases captures uncertainty",
      "description": "Bayesian joint inference refines the general concept by quantifying uncertainty over multiple explanations.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Equation (1) formalises this refinement.",
      "edge_rationale": "Joint posterior is a refinement implementing the theoretical insight."
    },
    {
      "type": "implemented_by",
      "source_node": "Modeling structured deviations from optimality improves preference identification",
      "target_node": "Extend agent model with false belief distributions and time inconsistency types",
      "description": "Concrete agent parametrisation realises the theoretical approach.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Formal Model Definition precisely maps theory to model parameters.",
      "edge_rationale": "Parameter extension is the implementation step."
    },
    {
      "type": "refined_by",
      "source_node": "Extend agent model with false belief distributions and time inconsistency types",
      "target_node": "Distinguish Naive vs Sophisticated hyperbolic discounting in planning models",
      "description": "Adds finer granularity on how time-inconsistency manifests.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Temporal Inconsistency subsection provides detailed refinement.",
      "edge_rationale": "Naive/Sophisticated split refines the generic time-inconsistency component."
    },
    {
      "type": "enabled_by",
      "source_node": "Extend agent model with false belief distributions and time inconsistency types",
      "target_node": "Represent agent decision-making as recursive probabilistic program",
      "description": "Recursive probabilistic programming enables straightforward encoding of the extended agent model.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Agents as Probabilistic Programs explains how recursion supports the model.",
      "edge_rationale": "Programming paradigm makes the design feasible."
    },
    {
      "type": "implemented_by",
      "source_node": "Extend agent model with false belief distributions and time inconsistency types",
      "target_node": "Softmax action choice with hyperbolic discount factor in WebPPL",
      "description": "Soft-max with discounting operationalises the extended model in code.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Equations and code snippet are explicit.",
      "edge_rationale": "Action-choice function is the concrete implementation."
    },
    {
      "type": "refined_by",
      "source_node": "Softmax action choice with hyperbolic discount factor in WebPPL",
      "target_node": "Exact inference via enumeration over discretized parameters",
      "description": "Enumeration provides a precise inference method for the implemented policy model.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Inference method specified right after code listing.",
      "edge_rationale": "Inference mechanism refines runtime implementation details."
    },
    {
      "type": "validated_by",
      "source_node": "Softmax action choice with hyperbolic discount factor in WebPPL",
      "target_node": "Model recovers correct preferences in Gridworld case studies",
      "description": "Case studies confirm that the implemented model produces correct posteriors.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Example 3 results reported with statistics.",
      "edge_rationale": "Empirical evidence validates mechanism performance."
    },
    {
      "type": "validated_by",
      "source_node": "Softmax action choice with hyperbolic discount factor in WebPPL",
      "target_node": "Human subject experiments show algorithm's inferences match human judgments",
      "description": "User studies confirm the model’s inferences align with human reasoning.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Experiments with Human Subjects present detailed agreement.",
      "edge_rationale": "Human data provides additional validation."
    },
    {
      "type": "validated_by",
      "source_node": "Exact inference via enumeration over discretized parameters",
      "target_node": "Model recovers correct preferences in Gridworld case studies",
      "description": "Exact inference contributes to correct posterior recovery in toy domains.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Indirect evidence; enumeration mentioned but not isolatedly tested.",
      "edge_rationale": "Inference accuracy supports validation results."
    },
    {
      "type": "motivates",
      "source_node": "Model recovers correct preferences in Gridworld case studies",
      "target_node": "Design preference inference algorithms incorporating structured bias models using probabilistic programming",
      "description": "Successful toy-domain results motivate algorithm design adoption.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Model Inferences discussion draws the connection.",
      "edge_rationale": "Positive evidence encourages designing such algorithms."
    },
    {
      "type": "motivates",
      "source_node": "Human subject experiments show algorithm's inferences match human judgments",
      "target_node": "Design preference inference algorithms incorporating structured bias models using probabilistic programming",
      "description": "Agreement with human judgments further motivates structured bias models.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Conclusion cites human-study success as justification.",
      "edge_rationale": "Human alignment demonstrates feasibility."
    },
    {
      "type": "refined_by",
      "source_node": "Design preference inference algorithms incorporating structured bias models using probabilistic programming",
      "target_node": "Deploy Bayesian inverse planning with bias-aware generative models in AI value learning modules",
      "description": "Deployment in operational systems refines the initial design-phase intervention.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Speculative extension suggested in Conclusion.",
      "edge_rationale": "Design must be realised in deployment to impact safety."
    }
  ],
  "meta": [
    {
      "key": "date_published",
      "value": "2015-12-18T00:00:00Z"
    },
    {
      "key": "source",
      "value": "arxiv"
    },
    {
      "key": "title",
      "value": "Learning the Preferences of Ignorant, Inconsistent Agents"
    },
    {
      "key": "authors",
      "value": [
        "Owain Evans",
        "Andreas Stuhlmueller",
        "Noah D. Goodman"
      ]
    },
    {
      "key": "url",
      "value": "https://arxiv.org/abs/1512.05832"
    }
  ]
}