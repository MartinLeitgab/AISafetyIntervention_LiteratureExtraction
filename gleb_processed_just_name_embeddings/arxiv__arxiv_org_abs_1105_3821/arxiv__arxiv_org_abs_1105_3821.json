{
  "nodes": [
    {
      "name": "Value misalignment from ontological crises in AI agents",
      "aliases": [
        "ontological crisis value misalignment",
        "goal corruption from ontology upgrade"
      ],
      "type": "concept",
      "description": "Risk that an agent’s original utility function loses its intended meaning after the agent upgrades or replaces its ontology, potentially leading to actions misaligned with designer goals.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced in Abstract & Introduction as the top-level safety concern motivating the paper."
    },
    {
      "name": "Ontology replacement makes predefined utility functions ill-defined",
      "aliases": [
        "utility undefined in new ontology",
        "goal specification breakdown on model change"
      ],
      "type": "concept",
      "description": "When an agent adopts a more accurate or learned ontology, the states or objects referenced by its original utility function may not exist or map cleanly, preventing evaluation of utility in the new model.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Detailed in Introduction (classical-to-quantum example) as the concrete mechanism causing the risk."
    },
    {
      "name": "Utility function translation via stochastic ontology mapping",
      "aliases": [
        "probabilistic state mapping",
        "stochastic function ϕ between ontologies"
      ],
      "type": "concept",
      "description": "Proposes resolving the crisis by composing the original utility with a stochastic mapping ϕ that converts states of the new ontology into probability distributions over states of the old ontology.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Outlined in ‘Maps between Ontologies’ as the core theoretical solution."
    },
    {
      "name": "Optimizing ontology mappings to approximate isomorphism using bisimulation and KL divergence",
      "aliases": [
        "approximate isomorphism criterion",
        "bisimulation-KL optimisation"
      ],
      "type": "concept",
      "description": "Design choice to jointly optimise ϕ and its pseudo-inverse ϕ⁻¹ so that each ontology can simulate the other, minimising KL divergence across transition and output matrices, thereby making ϕ as close to an isomorphism as possible.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Presented in ‘Maps between Ontologies’ as the reasoning that justifies the chosen optimisation objective."
    },
    {
      "name": "Hill-climbing optimization of mapping functions in finite state models",
      "aliases": [
        "finite-state hill-climb mapping search",
        "ϕ/ϕ⁻¹ hill-climbing algorithm"
      ],
      "type": "concept",
      "description": "Implements the design by representing ontologies as finite-state hidden-Markov models (transition and output matrices) and employing a simple hill-climbing algorithm to search for ϕ and ϕ⁻¹ that minimise the objective.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Described in ‘Finite State Models’ and used operationally in the corridor experiment."
    },
    {
      "name": "Long corridor example demonstrates mapping preserves right-end goal",
      "aliases": [
        "five-state corridor validation",
        "ϕ corridor experiment outcome"
      ],
      "type": "concept",
      "description": "Toy scenario where a four-state corridor utility (‘stand at right end’) is translated to a five-state ontology; resulting mapping assigns highest utility to the new rightmost square, confirming intuitive goal preservation.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section ‘Example: the long corridor’ supplies empirical support for the method."
    },
    {
      "name": "Integrate ontology mapping algorithm into agent design to translate utility during model upgrades",
      "aliases": [
        "implement ontological crisis resolution module",
        "apply ϕ-based utility translation at deployment"
      ],
      "type": "intervention",
      "description": "During model design, include a module that computes and applies the bisimulation-KL optimised stochastic mapping between successive ontologies, composing it with the original utility so that the agent preserves intended goals after upgrades.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Outlined in ‘Our Approach’ where translation is performed before the agent is turned on, fitting lifecycle stage 1 (Model Design).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Only demonstrated on a toy example; classified as Experimental/Proof-of-Concept per ‘Example’ section.",
      "node_rationale": "Represents the actionable step an AI developer would take based on the paper’s method."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Value misalignment from ontological crises in AI agents",
      "target_node": "Ontology replacement makes predefined utility functions ill-defined",
      "description": "The misalignment risk arises because replacing the ontology breaks the original utility reference.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicit linkage in Introduction; qualitative but clear argument.",
      "edge_rationale": "Introduction paragraphs on ontology upgrade leading to undefined goals."
    },
    {
      "type": "mitigated_by",
      "source_node": "Ontology replacement makes predefined utility functions ill-defined",
      "target_node": "Utility function translation via stochastic ontology mapping",
      "description": "Translating the utility through a mapping addresses the undefinedness problem.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Direct proposal in ‘Maps between Ontologies’.",
      "edge_rationale": "Section states the mapping is intended to resolve the crisis."
    },
    {
      "type": "refined_by",
      "source_node": "Utility function translation via stochastic ontology mapping",
      "target_node": "Optimizing ontology mappings to approximate isomorphism using bisimulation and KL divergence",
      "description": "The general idea of translation is refined by specifying optimisation criteria that make the mapping near-isomorphic.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Paper explicitly derives optimisation objective.",
      "edge_rationale": "‘Maps between Ontologies’ explains rationale for bisimulation & KL."
    },
    {
      "type": "implemented_by",
      "source_node": "Optimizing ontology mappings to approximate isomorphism using bisimulation and KL divergence",
      "target_node": "Hill-climbing optimization of mapping functions in finite state models",
      "description": "The optimisation rationale is operationalised via a hill-climbing search over finite-state model parameters.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Concrete algorithm and matrices provided.",
      "edge_rationale": "‘Finite State Models’ details hill-climbing implementation."
    },
    {
      "type": "validated_by",
      "source_node": "Hill-climbing optimization of mapping functions in finite state models",
      "target_node": "Long corridor example demonstrates mapping preserves right-end goal",
      "description": "The corridor experiment empirically tests and supports the implementation.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Explicit empirical demonstration with matrices and outcome.",
      "edge_rationale": "‘Example: the long corridor’ section."
    },
    {
      "type": "motivates",
      "source_node": "Long corridor example demonstrates mapping preserves right-end goal",
      "target_node": "Integrate ontology mapping algorithm into agent design to translate utility during model upgrades",
      "description": "Positive experimental result motivates adopting the algorithm as a practical design intervention.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Inference that successful toy example motivates deployment; not explicitly a deployment recommendation.",
      "edge_rationale": "Derived from Outlook and conclusion urging further work."
    }
  ],
  "meta": [
    {
      "key": "date_published",
      "value": "2011-05-19T00:00:00Z"
    },
    {
      "key": "source",
      "value": "arxiv"
    },
    {
      "key": "title",
      "value": "Ontological Crises in Artificial Agents' Value Systems"
    },
    {
      "key": "authors",
      "value": [
        "Peter de Blanc"
      ]
    },
    {
      "key": "url",
      "value": "https://arxiv.org/abs/1105.3821"
    }
  ]
}