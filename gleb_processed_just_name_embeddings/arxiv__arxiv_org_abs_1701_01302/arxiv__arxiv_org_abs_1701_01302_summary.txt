Data source overview:
The paper “Toward negotiable reinforcement learning: shifting priorities in Pareto-optimal sequential decision-making” formalises how an AI system jointly owned by multiple principals should choose its policy. It proves that naïve linear utility aggregation fails when principals have different priors and derives a Pareto-optimal recursion that dynamically re-weights principals’ utilities in proportion to how well their beliefs predict observations.

EXTRACTION CONFIDENCE[83]

Inference strategy justification:
All nodes are drawn directly from explicit arguments (risks, theoretical results, algorithms, proofs, example) except for two intervention nodes, which are reasonable AI-safety actions implied by the proposed framework (confidence marked 2).

Extraction completeness explanation:
Both top-level risks discussed (arms race / unfair value representation) are traced through problems, theoretical insights, design rationale, implementation mechanisms, validation evidence and to actionable interventions, forming one connected fabric with no isolated nodes.

Key limitations:
• Interventions are early-stage ideas without engineering detail.
• Paper provides proofs but no empirical data; validation evidence nodes capture this limitation.
• Some implementation mechanism decomposition (e.g. code-level specifics) is not available in source.

Suggested prompt improvements:
Allow explicit flags for “purely theoretical proof” validation evidence; provide canonical naming registry to ensure global consistency (e.g. “negotiable RL priority-shifting recursion”).