<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.1.0.min.js" integrity="sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=" crossorigin="anonymous"></script>                <div id="kg3d" class="plotly-graph-div" style="height:900px; width:1400px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("kg3d")) {                    Plotly.newPlot(                        "kg3d",                        [{"hoverinfo":"text","hovertext":["Value Misalignment → Proxy Objectives\u003cbr\u003eType: leads to\u003cbr\u003eConfidence: 4\u003cbr\u003eImperfect specification causes AI to pursue misaligned proxy objectives.","Value Misalignment → Proxy Objectives\u003cbr\u003eType: leads to\u003cbr\u003eConfidence: 4\u003cbr\u003eImperfect specification causes AI to pursue misaligned proxy objectives.",null,"Proxy Objectives → Reward Hacking\u003cbr\u003eType: enables\u003cbr\u003eConfidence: 4\u003cbr\u003eProxy objectives create exploitable loopholes for reward hacking.","Proxy Objectives → Reward Hacking\u003cbr\u003eType: enables\u003cbr\u003eConfidence: 4\u003cbr\u003eProxy objectives create exploitable loopholes for reward hacking.",null,"Reward Hacking → Distributional Shift\u003cbr\u003eType: creates\u003cbr\u003eConfidence: 3\u003cbr\u003eReward hacking leads to performance shifts from training to deployment.","Reward Hacking → Distributional Shift\u003cbr\u003eType: creates\u003cbr\u003eConfidence: 3\u003cbr\u003eReward hacking leads to performance shifts from training to deployment.",null,"Distributional Shift → Limited Human Oversight\u003cbr\u003eType: exacerbates\u003cbr\u003eConfidence: 3\u003cbr\u003eDistributional shifts worsen oversight challenges for humans.","Distributional Shift → Limited Human Oversight\u003cbr\u003eType: exacerbates\u003cbr\u003eConfidence: 3\u003cbr\u003eDistributional shifts worsen oversight challenges for humans.",null,"Limited Human Oversight → Evaluation Difficulties\u003cbr\u003eType: causes\u003cbr\u003eConfidence: 4\u003cbr\u003eLimited oversight leads to difficulties in evaluating AI systems.","Limited Human Oversight → Evaluation Difficulties\u003cbr\u003eType: causes\u003cbr\u003eConfidence: 4\u003cbr\u003eLimited oversight leads to difficulties in evaluating AI systems.",null,"Evaluation Difficulties → Scalability Constraints\u003cbr\u003eType: highlights\u003cbr\u003eConfidence: 3\u003cbr\u003eEvaluation challenges reveal constraints in scaling safety measures.","Evaluation Difficulties → Scalability Constraints\u003cbr\u003eType: highlights\u003cbr\u003eConfidence: 3\u003cbr\u003eEvaluation challenges reveal constraints in scaling safety measures.",null,"Scalability Constraints → Scalable Automated Alignment Framework (SAAF)\u003cbr\u003eType: necessitates\u003cbr\u003eConfidence: 4\u003cbr\u003eScalability issues drive the need for automated alignment frameworks.","Scalability Constraints → Scalable Automated Alignment Framework (SAAF)\u003cbr\u003eType: necessitates\u003cbr\u003eConfidence: 4\u003cbr\u003eScalability issues drive the need for automated alignment frameworks.",null,"Automated Red Teaming → Reward Hacking\u003cbr\u003eType: detects\u003cbr\u003eConfidence: 3\u003cbr\u003eAutomated red teaming identifies reward hacking behaviors.","Automated Red Teaming → Reward Hacking\u003cbr\u003eType: detects\u003cbr\u003eConfidence: 3\u003cbr\u003eAutomated red teaming identifies reward hacking behaviors.",null,"Automated Red Teaming → Robust Evaluation Protocols\u003cbr\u003eType: supports\u003cbr\u003eConfidence: 4\u003cbr\u003eAutomated red teaming enhances evaluation protocol robustness.","Automated Red Teaming → Robust Evaluation Protocols\u003cbr\u003eType: supports\u003cbr\u003eConfidence: 4\u003cbr\u003eAutomated red teaming enhances evaluation protocol robustness.",null,"Scalable Automated Alignment Framework (SAAF) → Robust Evaluation Protocols\u003cbr\u003eType: enables\u003cbr\u003eConfidence: 3\u003cbr\u003eSAAF supports scalable robust evaluation protocols.","Scalable Automated Alignment Framework (SAAF) → Robust Evaluation Protocols\u003cbr\u003eType: enables\u003cbr\u003eConfidence: 3\u003cbr\u003eSAAF supports scalable robust evaluation protocols.",null,"Robust Evaluation Protocols → Evaluation Difficulties\u003cbr\u003eType: mitigates\u003cbr\u003eConfidence: 3\u003cbr\u003eRobust protocols reduce difficulties in AI evaluation.","Robust Evaluation Protocols → Evaluation Difficulties\u003cbr\u003eType: mitigates\u003cbr\u003eConfidence: 3\u003cbr\u003eRobust protocols reduce difficulties in AI evaluation.",null,"Optimization Pressure → Mesa Optimizer Emergence\u003cbr\u003eType: drives\u003cbr\u003eConfidence: 4\u003cbr\u003eTraining pressures lead to emergent mesa-optimizers in complex models.","Optimization Pressure → Mesa Optimizer Emergence\u003cbr\u003eType: drives\u003cbr\u003eConfidence: 4\u003cbr\u003eTraining pressures lead to emergent mesa-optimizers in complex models.",null,"Mesa Optimizer Emergence → Inner-Outer Objective Mismatch\u003cbr\u003eType: causes\u003cbr\u003eConfidence: 4\u003cbr\u003eMesa-optimizers cause discrepancies between learned and intended objectives.","Mesa Optimizer Emergence → Inner-Outer Objective Mismatch\u003cbr\u003eType: causes\u003cbr\u003eConfidence: 4\u003cbr\u003eMesa-optimizers cause discrepancies between learned and intended objectives.",null,"Inner-Outer Objective Mismatch → Deceptive Alignment\u003cbr\u003eType: enables\u003cbr\u003eConfidence: 3\u003cbr\u003eObjective mismatches allow deceptive alignment strategies.","Inner-Outer Objective Mismatch → Deceptive Alignment\u003cbr\u003eType: enables\u003cbr\u003eConfidence: 3\u003cbr\u003eObjective mismatches allow deceptive alignment strategies.",null,"Model Complexity → Mesa Optimizer Emergence\u003cbr\u003eType: increases\u003cbr\u003eConfidence: 3\u003cbr\u003eComplex architectures heighten the risk of mesa-optimizer emergence.","Model Complexity → Mesa Optimizer Emergence\u003cbr\u003eType: increases\u003cbr\u003eConfidence: 3\u003cbr\u003eComplex architectures heighten the risk of mesa-optimizer emergence.",null,"Mechanistic Interpretability Tools → Mesa Optimizer Emergence\u003cbr\u003eType: detects\u003cbr\u003eConfidence: 3\u003cbr\u003eInterpretability tools identify emergent mesa-optimizers.","Mechanistic Interpretability Tools → Mesa Optimizer Emergence\u003cbr\u003eType: detects\u003cbr\u003eConfidence: 3\u003cbr\u003eInterpretability tools identify emergent mesa-optimizers.",null,"Human Feedback Limitations → Constitutional AI\u003cbr\u003eType: drives\u003cbr\u003eConfidence: 4\u003cbr\u003eFeedback limitations spur development of principle-based AI training.","Human Feedback Limitations → Constitutional AI\u003cbr\u003eType: drives\u003cbr\u003eConfidence: 4\u003cbr\u003eFeedback limitations spur development of principle-based AI training.",null,"Constitutional AI → Scalable Oversight\u003cbr\u003eType: enhances\u003cbr\u003eConfidence: 4\u003cbr\u003eConstitutional AI improves oversight through principled evaluation.","Constitutional AI → Scalable Oversight\u003cbr\u003eType: enhances\u003cbr\u003eConfidence: 4\u003cbr\u003eConstitutional AI improves oversight through principled evaluation.",null,"AI Debate Framework → Scalable Oversight\u003cbr\u003eType: contributes to\u003cbr\u003eConfidence: 3\u003cbr\u003eAI debate frameworks enhance scalable oversight capabilities.","AI Debate Framework → Scalable Oversight\u003cbr\u003eType: contributes to\u003cbr\u003eConfidence: 3\u003cbr\u003eAI debate frameworks enhance scalable oversight capabilities.",null,"Scalable Oversight → AI Assisted Evaluation\u003cbr\u003eType: enables\u003cbr\u003eConfidence: 4\u003cbr\u003eScalable oversight supports AI-assisted evaluation methods.","Scalable Oversight → AI Assisted Evaluation\u003cbr\u003eType: enables\u003cbr\u003eConfidence: 4\u003cbr\u003eScalable oversight supports AI-assisted evaluation methods.",null,"AI Assisted Evaluation → Alignment Robustness\u003cbr\u003eType: improves\u003cbr\u003eConfidence: 3\u003cbr\u003eAI-assisted evaluations enhance alignment robustness.","AI Assisted Evaluation → Alignment Robustness\u003cbr\u003eType: improves\u003cbr\u003eConfidence: 3\u003cbr\u003eAI-assisted evaluations enhance alignment robustness.",null,"Capability Overhang → Oversight Lag\u003cbr\u003eType: causes\u003cbr\u003eConfidence: 4\u003cbr\u003eRapid AI capability growth outpaces oversight development.","Capability Overhang → Oversight Lag\u003cbr\u003eType: causes\u003cbr\u003eConfidence: 4\u003cbr\u003eRapid AI capability growth outpaces oversight development.",null,"Oversight Lag → Capability Control Mechanisms\u003cbr\u003eType: necessitates\u003cbr\u003eConfidence: 3\u003cbr\u003eOversight lag drives the need for capability control methods.","Oversight Lag → Capability Control Mechanisms\u003cbr\u003eType: necessitates\u003cbr\u003eConfidence: 3\u003cbr\u003eOversight lag drives the need for capability control methods.",null,"Oversight Lag → AI Governance Frameworks\u003cbr\u003eType: necessitates\u003cbr\u003eConfidence: 4\u003cbr\u003eOversight lag highlights the need for improved governance frameworks.","Oversight Lag → AI Governance Frameworks\u003cbr\u003eType: necessitates\u003cbr\u003eConfidence: 4\u003cbr\u003eOversight lag highlights the need for improved governance frameworks.",null,"Capability Control Mechanisms → Gradual Deployment Protocols\u003cbr\u003eType: enables\u003cbr\u003eConfidence: 4\u003cbr\u003eControl mechanisms support staged AI deployment strategies.","Capability Control Mechanisms → Gradual Deployment Protocols\u003cbr\u003eType: enables\u003cbr\u003eConfidence: 4\u003cbr\u003eControl mechanisms support staged AI deployment strategies.",null,"Gradual Deployment Protocols → Alignment Robustness\u003cbr\u003eType: improves\u003cbr\u003eConfidence: 3\u003cbr\u003eGradual deployment enhances alignment through careful testing.","Gradual Deployment Protocols → Alignment Robustness\u003cbr\u003eType: improves\u003cbr\u003eConfidence: 3\u003cbr\u003eGradual deployment enhances alignment through careful testing.",null,"Adversarial Examples → Distributional Shift\u003cbr\u003eType: exploits\u003cbr\u003eConfidence: 3\u003cbr\u003eAdversarial examples exploit vulnerabilities in distributional shifts.","Adversarial Examples → Distributional Shift\u003cbr\u003eType: exploits\u003cbr\u003eConfidence: 3\u003cbr\u003eAdversarial examples exploit vulnerabilities in distributional shifts.",null,"Adversarial Training → Adversarial Examples\u003cbr\u003eType: improves\u003cbr\u003eConfidence: 4\u003cbr\u003eAdversarial training enhances robustness against adversarial attacks.","Adversarial Training → Adversarial Examples\u003cbr\u003eType: improves\u003cbr\u003eConfidence: 4\u003cbr\u003eAdversarial training enhances robustness against adversarial attacks.",null,"Robustness Evaluation → Adversarial Training\u003cbr\u003eType: validates\u003cbr\u003eConfidence: 3\u003cbr\u003eRobustness evaluation confirms effectiveness of adversarial training.","Robustness Evaluation → Adversarial Training\u003cbr\u003eType: validates\u003cbr\u003eConfidence: 3\u003cbr\u003eRobustness evaluation confirms effectiveness of adversarial training.",null,"AI Governance Frameworks → Regulatory Compliance\u003cbr\u003eType: establishes\u003cbr\u003eConfidence: 4\u003cbr\u003eGovernance frameworks set regulatory compliance requirements.","AI Governance Frameworks → Regulatory Compliance\u003cbr\u003eType: establishes\u003cbr\u003eConfidence: 4\u003cbr\u003eGovernance frameworks set regulatory compliance requirements.",null,"Regulatory Compliance → Algorithmic Auditing\u003cbr\u003eType: necessitates\u003cbr\u003eConfidence: 4\u003cbr\u003eCompliance drives the need for algorithmic auditing.","Regulatory Compliance → Algorithmic Auditing\u003cbr\u003eType: necessitates\u003cbr\u003eConfidence: 4\u003cbr\u003eCompliance drives the need for algorithmic auditing.",null,"Emergent Capabilities → Capability Overhang\u003cbr\u003eType: creates\u003cbr\u003eConfidence: 4\u003cbr\u003eEmergent capabilities lead to risks of capability overhang.","Emergent Capabilities → Capability Overhang\u003cbr\u003eType: creates\u003cbr\u003eConfidence: 4\u003cbr\u003eEmergent capabilities lead to risks of capability overhang.",null,"Capability Monitoring → Emergent Capabilities\u003cbr\u003eType: detects\u003cbr\u003eConfidence: 3\u003cbr\u003eMonitoring systems identify emergent AI capabilities.","Capability Monitoring → Emergent Capabilities\u003cbr\u003eType: detects\u003cbr\u003eConfidence: 3\u003cbr\u003eMonitoring systems identify emergent AI capabilities.",null,"Emergent Capability Detection → Capability Overhang\u003cbr\u003eType: targets\u003cbr\u003eConfidence: 4\u003cbr\u003eDetection methods address risks from capability overhang.","Emergent Capability Detection → Capability Overhang\u003cbr\u003eType: targets\u003cbr\u003eConfidence: 4\u003cbr\u003eDetection methods address risks from capability overhang.",null,"Scaling Laws → Emergent Capabilities\u003cbr\u003eType: predicts\u003cbr\u003eConfidence: 3\u003cbr\u003eScaling laws forecast the emergence of new AI capabilities.","Scaling Laws → Emergent Capabilities\u003cbr\u003eType: predicts\u003cbr\u003eConfidence: 3\u003cbr\u003eScaling laws forecast the emergence of new AI capabilities.",null],"line":{"color":"rgba(255,100,100,0.8)","width":4},"mode":"lines","name":"High confidence edges","showlegend":true,"x":[-0.3443201340494095,-0.8954371973521895,null,-0.8954371973521895,-0.5367175057278216,null,-0.5367175057278216,-0.3443201340494103,null,-0.3443201340494103,-0.6711521011873915,null,-0.6711521011873915,-0.3443201340494094,null,-0.3443201340494094,-0.3443201340494094,null,-0.3443201340494094,-0.8954371973521911,null,-1.537412767126176,-0.5367175057278216,null,-1.537412767126176,-0.9117403042678812,null,-0.8954371973521911,-0.9117403042678812,null,-0.9117403042678812,-0.3443201340494094,null,4.565890732020018,-0.3443201340494093,null,-0.3443201340494093,-0.3443201340494089,null,-0.3443201340494089,-0.3443201340494094,null,4.565890732020018,-0.3443201340494093,null,4.565890732020018,-0.3443201340494093,null,-0.3443201340494095,-0.5367175057278216,null,-0.5367175057278216,-0.34432013404940903,null,-0.5367175057278216,-0.34432013404940903,null,-0.34432013404940903,-0.5367175057278208,null,-0.5367175057278208,-0.2534616275782054,null,-0.3443201340494094,-0.5367175057278218,null,-0.5367175057278218,-0.3443201340494092,null,-0.5367175057278218,-0.34432013404940925,null,-0.3443201340494092,-0.5367175057278208,null,-0.5367175057278208,-0.2534616275782054,null,-0.5367175057278214,-0.3443201340494103,null,-0.3443201340494091,-0.5367175057278214,null,-0.3443201340494094,-0.3443201340494091,null,-0.34432013404940925,-0.3443201340494094,null,-0.3443201340494094,-0.25346162757820545,null,-0.5367175057278213,-0.3443201340494094,null,-0.9117403042678816,-0.5367175057278213,null,-0.5367175057278215,-0.3443201340494094,null,-0.6711521011873932,-0.5367175057278213,null],"y":[-0.22515572851257867,3.138611572664918,null,3.138611572664918,-0.47256247916530536,null,-0.47256247916530536,-0.22515572851257867,null,-0.22515572851257867,-1.1126502280335386,null,-1.1126502280335386,-0.22515572851257631,null,-0.22515572851257631,-0.22515572851257915,null,-0.22515572851257915,3.138611572664919,null,6.425007446182619,-0.47256247916530536,null,6.425007446182619,-1.695170401909856,null,3.138611572664919,-1.695170401909856,null,-1.695170401909856,-0.22515572851257631,null,0.3945747536300279,-0.2251557285125774,null,-0.2251557285125774,-0.22515572851257765,null,-0.22515572851257765,-0.22515572851257767,null,0.3945747536300279,-0.2251557285125774,null,0.3945747536300279,-0.2251557285125774,null,-0.2251557285125777,-0.47256247916530303,null,-0.47256247916530303,-0.22515572851257765,null,-0.47256247916530303,-0.22515572851257765,null,-0.22515572851257765,-0.47256247916530303,null,-0.47256247916530303,-0.14778430085278194,null,-0.22515572851257754,-0.47256247916530114,null,-0.47256247916530114,-0.22515572851257784,null,-0.47256247916530114,-0.22515572851257787,null,-0.22515572851257784,-0.47256247916530303,null,-0.47256247916530303,-0.14778430085278194,null,-0.47256247916530386,-0.22515572851257867,null,-0.22515572851257756,-0.47256247916530386,null,-0.22515572851257784,-0.22515572851257756,null,-0.22515572851257787,-0.22515572851257776,null,-0.22515572851257776,-0.1477843008527818,null,-0.472562479165303,-0.22515572851257754,null,-1.6951704019098044,-0.472562479165303,null,-0.4725624791653027,-0.22515572851257754,null,-1.1126502280335093,-0.472562479165303,null],"z":[-6.287325061276755e-15,2.065835377276648e-14,null,2.065835377276648e-14,-7.753899768650463e-15,null,-7.753899768650463e-15,-5.3891357668086465e-15,null,-5.3891357668086465e-15,3.0075047750377406,null,3.0075047750377406,-2.470020559787297e-15,null,-2.470020559787297e-15,-6.287325061276755e-15,null,-6.287325061276755e-15,1.875587707032715e-14,null,4.0193970927447827e-14,-7.753899768650463e-15,null,4.0193970927447827e-14,4.866244947338678,null,1.875587707032715e-14,4.866244947338678,null,4.866244947338678,-2.470020559787297e-15,null,4.850644070822327e-15,-5.104726648981945e-15,null,-5.104726648981945e-15,-5.185952083952636e-15,null,-5.185952083952636e-15,-5.019869192601864e-15,null,4.850644070822327e-15,-5.104726648981945e-15,null,4.850644070822327e-15,-5.104726648981945e-15,null,-4.898937898226333e-15,-7.099860650016611e-15,null,-7.099860650016611e-15,-5.1141417473779695e-15,null,-7.099860650016611e-15,-5.1141417473779695e-15,null,-5.1141417473779695e-15,-7.159344640555201e-15,null,-7.159344640555201e-15,-3.088823104286932e-15,null,-5.222263138687733e-15,-8.184438359227153e-15,null,-8.184438359227153e-15,-4.952519695345892e-15,null,-8.184438359227153e-15,-5.183471215251044e-15,null,-4.952519695345892e-15,-7.276823573029965e-15,null,-7.276823573029965e-15,-3.088823104286932e-15,null,-7.43334962675244e-15,-5.3891357668086465e-15,null,-5.107157847956536e-15,-7.43334962675244e-15,null,-4.973732253532777e-15,-5.107157847956536e-15,null,-5.183471215251044e-15,-5.253168901309265e-15,null,-5.253168901309265e-15,-3.063892618603749e-15,null,-7.075919730971922e-15,-5.222263138687733e-15,null,-4.866244947338634,-7.075919730971922e-15,null,-7.213238266352735e-15,-5.222263138687733e-15,null,-3.0075047750377193,-7.075919730971922e-15,null],"type":"scatter3d"},{"hoverinfo":"text","hovertext":["Robust Evaluation Protocols → Value Misalignment\u003cbr\u003eType: addresses\u003cbr\u003eConfidence: 2\u003cbr\u003eRobust evaluations help mitigate value misalignment issues.","Robust Evaluation Protocols → Value Misalignment\u003cbr\u003eType: addresses\u003cbr\u003eConfidence: 2\u003cbr\u003eRobust evaluations help mitigate value misalignment issues.",null,"Training Data Diversity → Mesa Optimizer Emergence\u003cbr\u003eType: affects\u003cbr\u003eConfidence: 2\u003cbr\u003eDiverse training data influences mesa-optimizer emergence patterns.","Training Data Diversity → Mesa Optimizer Emergence\u003cbr\u003eType: affects\u003cbr\u003eConfidence: 2\u003cbr\u003eDiverse training data influences mesa-optimizer emergence patterns.",null,"Deceptive Alignment → Gradient Hacking\u003cbr\u003eType: facilitates\u003cbr\u003eConfidence: 2\u003cbr\u003eDeceptive alignment enables AI to manipulate training gradients.","Deceptive Alignment → Gradient Hacking\u003cbr\u003eType: facilitates\u003cbr\u003eConfidence: 2\u003cbr\u003eDeceptive alignment enables AI to manipulate training gradients.",null,"Capability Monitoring → Scaling Laws\u003cbr\u003eType: incorporates\u003cbr\u003eConfidence: 2\u003cbr\u003eMonitoring systems use scaling laws to predict capability emergence.","Capability Monitoring → Scaling Laws\u003cbr\u003eType: incorporates\u003cbr\u003eConfidence: 2\u003cbr\u003eMonitoring systems use scaling laws to predict capability emergence.",null],"line":{"color":"rgba(100,255,100,0.6)","width":2},"mode":"lines","name":"Medium confidence edges","showlegend":true,"x":[-0.9117403042678812,-0.3443201340494095,null,4.565890732020018,-0.3443201340494093,null,-0.3443201340494094,-0.2534616275782054,null,-0.9117403042678816,-0.6711521011873932,null],"y":[-1.695170401909856,-0.22515572851257867,null,0.3945747536300279,-0.2251557285125774,null,-0.22515572851257767,-0.14778430085278194,null,-1.6951704019098044,-1.1126502280335093,null],"z":[4.866244947338678,-6.287325061276755e-15,null,4.850644070822327e-15,-5.104726648981945e-15,null,-5.019869192601864e-15,-3.088823104286932e-15,null,-4.866244947338634,-3.0075047750377193,null],"type":"scatter3d"},{"hoverinfo":"text","hovertext":["\u003cb\u003eValue Misalignment\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: AI systems pursuing objectives misaligned with human values due to imperfect specification.","\u003cb\u003eProxy Objectives\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Use of simplified metrics as substitutes for complex human goals, leading to unintended outcomes.","\u003cb\u003eReward Hacking\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 3\u003cbr\u003eDescription: AI exploiting loopholes in proxy objectives to maximize rewards without achieving intended goals.","\u003cb\u003eDistributional Shift\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 3\u003cbr\u003eDescription: Mismatch between training and deployment data distributions, causing performance degradation.","\u003cb\u003eLimited Human Oversight\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Challenges in monitoring AI systems due to limited human capacity and expertise.","\u003cb\u003eEvaluation Difficulties\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 3\u003cbr\u003eDescription: Complexities in accurately assessing AI system performance and safety.","\u003cb\u003eScalability Constraints\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Limitations in scaling AI safety measures to match increasing system complexity.","\u003cb\u003eAutomated Red Teaming\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Automated testing to identify vulnerabilities in AI systems by simulating adversarial attacks.","\u003cb\u003eScalable Automated Alignment Framework (SAAF)\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Framework for scalable, automated alignment of AI systems with human values.","\u003cb\u003eRobust Evaluation Protocols\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 4\u003cbr\u003eDescription: Standardized methods for thoroughly evaluating AI system safety and alignment.","\u003cb\u003eOptimization Pressure\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Training Dynamics\u003cbr\u003eDegree: 1\u003cbr\u003eDescription: Forces during AI training that drive systems toward unintended optimization behaviors.","\u003cb\u003eMesa Optimizer Emergence\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Training Dynamics\u003cbr\u003eDegree: 5\u003cbr\u003eDescription: Emergence of unintended sub-optimization processes within trained AI systems.","\u003cb\u003eInner-Outer Objective Mismatch\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Training Dynamics\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Discrepancy between AI's learned objectives and intended training objectives.","\u003cb\u003eModel Complexity\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Training Dynamics\u003cbr\u003eDegree: 1\u003cbr\u003eDescription: Increasing complexity of AI models contributing to unpredictable behaviors.","\u003cb\u003eTraining Data Diversity\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Training Dynamics\u003cbr\u003eDegree: 1\u003cbr\u003eDescription: Variety in training data influencing AI behavior and robustness.","\u003cb\u003eDeceptive Alignment\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: AI systems appearing aligned during training but pursuing misaligned goals in deployment.","\u003cb\u003eGradient Hacking\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 1\u003cbr\u003eDescription: AI manipulating training gradients to achieve unintended objectives.","\u003cb\u003eMechanistic Interpretability Tools\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 1\u003cbr\u003eDescription: Tools for understanding internal AI decision-making processes to detect misalignments.","\u003cb\u003eActivation Patching\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 0\u003cbr\u003eDescription: Technique for modifying AI activations to study and control behavior.","\u003cb\u003eObjective Robustness Training\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 0\u003cbr\u003eDescription: Training methods to ensure AI objectives remain robust against misalignment.","\u003cb\u003eMesa Optimizer Detection\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 0\u003cbr\u003eDescription: Methods to identify emergent mesa-optimizers within AI systems.","\u003cb\u003eBehavioral Monitoring Systems\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 0\u003cbr\u003eDescription: Systems for continuous monitoring of AI behavior during deployment.","\u003cb\u003eHuman Feedback Limitations\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 1\u003cbr\u003eDescription: Constraints in using human feedback for AI alignment due to scalability issues.","\u003cb\u003eConstitutional AI\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Training AI systems with predefined principles to enhance alignment and oversight.","\u003cb\u003eAI Debate Framework\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 1\u003cbr\u003eDescription: Framework using AI debate to evaluate and improve system robustness.","\u003cb\u003eScalable Oversight\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Solutions\u003cbr\u003eDegree: 3\u003cbr\u003eDescription: Methods to monitor and align AI systems at scale without extensive human intervention.","\u003cb\u003eAI Assisted Evaluation\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Using AI systems to assist in evaluating other AI systems for safety and alignment.","\u003cb\u003eAlignment Robustness\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Solutions\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Ensuring AI systems maintain alignment under diverse conditions and stressors.","\u003cb\u003eCapability Overhang\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 3\u003cbr\u003eDescription: AI systems possessing latent capabilities exceeding current oversight mechanisms.","\u003cb\u003eOversight Lag\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 3\u003cbr\u003eDescription: Delay in developing oversight mechanisms relative to AI capability advancements.","\u003cb\u003eCapability Control Mechanisms\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Methods to restrict AI capabilities to ensure safe operation.","\u003cb\u003eGradual Deployment Protocols\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Controlled rollout strategies to test AI systems before full deployment.","\u003cb\u003eAdversarial Examples\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Inputs designed to exploit AI vulnerabilities, causing incorrect outputs.","\u003cb\u003eAdversarial Training\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Training AI with adversarial examples to improve robustness against attacks.","\u003cb\u003eRobustness Evaluation\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 1\u003cbr\u003eDescription: Testing AI systems under adversarial conditions to assess robustness.","\u003cb\u003eAI Governance Frameworks\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Policies and structures to regulate and oversee AI development and deployment.","\u003cb\u003eRegulatory Compliance\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Ensuring AI systems adhere to legal and ethical standards.","\u003cb\u003eAlgorithmic Auditing\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 1\u003cbr\u003eDescription: Systematic evaluation of AI algorithms for fairness, safety, and compliance.","\u003cb\u003eEmergent Capabilities\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Safety Challenges\u003cbr\u003eDegree: 3\u003cbr\u003eDescription: Unexpected AI capabilities arising from increased scale or complexity.","\u003cb\u003eCapability Monitoring\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Continuous tracking of AI capabilities to identify emergent behaviors.","\u003cb\u003eEmergent Capability Detection\u003c\u002fb\u003e\u003cbr\u003eCategory: Unknown\u003cbr\u003eDegree: 1\u003cbr\u003eDescription: Techniques to detect unexpected capabilities in AI systems during development.","\u003cb\u003eScaling Laws\u003c\u002fb\u003e\u003cbr\u003eCategory: AI Training Dynamics\u003cbr\u003eDegree: 2\u003cbr\u003eDescription: Mathematical relationships predicting AI performance with increased scale."],"marker":{"color":[2,2,2,2,2,2,2,1,1,1,3,3,3,3,3,2,2,1,1,1,1,1,2,1,1,0,1,0,2,2,1,1,2,1,1,1,1,1,2,1,1,3],"colorbar":{"title":{"text":"Categories"}},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"line":{"color":"white","width":1},"opacity":0.8,"showscale":true,"size":[14,14,16,16,14,16,14,14,14,18,12,20,14,12,12,14,12,12,10,10,10,10,12,14,12,16,14,14,16,16,14,14,14,14,12,14,14,12,16,14,12,14]},"mode":"markers+text","name":"nodes","text":["Value Misa","Proxy Obje","Reward Hac","Distributi","Limited Hu","Evaluation","Scalabilit","Automated ","Scalable A","Robust Eva","Optimizati","Mesa Optim","Inner-Oute","Model Comp","Training D","Deceptive ","Gradient H","Mechanisti","Activation","Objective ","Mesa Optim","Behavioral","Human Feed","Constituti","AI Debate ","Scalable O","AI Assiste","Alignment ","Capability","Oversight ","Capability","Gradual De","Adversaria","Adversaria","Robustness","AI Governa","Regulatory","Algorithmi","Emergent C","Capability","Emergent C","Scaling La"],"textfont":{"size":8},"textposition":"top center","x":{"dtype":"f8","bdata":"3y3GUFcJ1r9U\u002fMfoa6fsv39VyTDKLOG\u002f7i3GUFcJ1r+cuqf4E3rlv94txlBXCda\u002f3i3GUFcJ1r8ZKDQhPpn4v2L8x+hrp+y\u002fCdKoAPos7b+7iizceEMSQNwtxlBXCda\u002f1S3GUFcJ1r+7iizceEMSQLuKLNx4QxJA3i3GUFcJ1r8VUU8etzjQv7uKLNx4QxJAFVFPHrc40L8VUU8etzjQvxVRTx63ONC\u002fFVFPHrc40L\u002ffLcZQVwnWv39VyTDKLOG\u002ff1XJMMos4b\u002fXLcZQVwnWv3hVyTDKLOG\u002fFVFPHrc40L\u002feLcZQVwnWv4FVyTDKLOG\u002f2i3GUFcJ1r94Vckwyizhv31VyTDKLOG\u002f2C3GUFcJ1r\u002feLcZQVwnWv9stxlBXCda\u002f3i3GUFcJ1r8WUU8etzjQv3xVyTDKLOG\u002fDNKoAPos7b9+Vckwyizhv6u6p\u002fgTeuW\u002f"},"y":{"dtype":"f8","bdata":"b\u002fo7JefRzL8qi1ti4BsJQAw6VbJ2Pt6\u002fb\u002fo7JefRzL\u002fmp1RTas3xvxr6OyXn0cy\u002fgPo7JefRzL+wpOcmNbMZQCyLW2LgGwlAoZnV\u002f2of+788xKp3tkDZP0H6OyXn0cy\u002fSvo7JefRzL88xKp3tkDZPzzEqne2QNk\u002fS\u002fo7JefRzL+wMIORmOrCvzzEqne2QNk\u002fsDCDkZjqwr+wMIORmOrCv7Awg5GY6sK\u002fsDCDkZjqwr9M+jsl59HMv+I5VbJ2Pt6\u002f4jlVsnY+3r9K+jsl59HMv+I5VbJ2Pt6\u002fsDCDkZjqwr9G+jsl59HMv8A5VbJ2Pt6\u002fUfo7JefRzL\u002fiOVWydj7ev\u002fE5VbJ2Pt6\u002fR\u002fo7JefRzL9R+jsl59HMv1L6OyXn0cy\u002fTvo7JefRzL+rMIORmOrCv+E5VbJ2Pt6\u002fuZjV\u002f2of+7\u002fcOVWydj7ev2KnVFNqzfG\u002f"},"z":{"dtype":"f8","bdata":"nDMu0spQ\u002fLzShcp1XUIXPRw0CKPRdQG9YHXeIUBF+Ly2ztqpXg8IQESWtsl6P+a8nDMu0spQ\u002fLwZED7Kj6AmPY5Y73QDHhU9V5Rc6gh3E0DBpK9vadj1PFl3gGBZ\u002ffa8tDHZ5P5a97zBpK9vadj1PMGkr29p2PU8FmRg4IOb9rxw1F9WV9LrvMGkr29p2PU8cNRfVlfS67xw1F9WV9LrvHDUX1ZX0uu8cNRfVlfS67zIqx1CFxD2vCiJd\u002f+U+f+8KIl3\u002f5T5\u002f7xZMDk5NAj3vPfkW8kUHwC9cNRfVlfS67y+5pIG3IT3vN8cHOsBbgK9dKg90N1N9rz+uvGdzWIAvcQHEMkIvQC9z9+z8CYA97xRVdKnUmb2vBCKtasiWPe8Hm75y32o97wYBOX52pjrvFCuxOL63f+8JpRc6gh3E8AHz\u002fkUJj4AvYbO2qleDwjA"},"type":"scatter3d"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermap":[{"type":"scattermap","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"title":{"font":{"size":20,"color":"white"},"text":"True 3D Knowledge Graph Visualization\u003cbr\u003e42 nodes, 39 edges"},"scene":{"xaxis":{"showgrid":false,"zeroline":false,"showticklabels":false,"showline":false,"showbackground":false,"title":{"text":""}},"yaxis":{"showgrid":false,"zeroline":false,"showticklabels":false,"showline":false,"showbackground":false,"title":{"text":""}},"zaxis":{"showgrid":false,"zeroline":false,"showticklabels":false,"showline":false,"showbackground":false,"title":{"text":""}},"camera":{"eye":{"x":1.5,"y":1.5,"z":1.5},"center":{"x":0,"y":0,"z":0},"up":{"x":0,"y":0,"z":1},"projection":{"type":"perspective"}},"aspectmode":"cube","bgcolor":"rgba(5,10,20,1)","dragmode":"orbit","hovermode":"closest"},"margin":{"l":0,"r":0,"b":0,"t":80},"font":{"color":"white"},"legend":{"font":{"color":"white"},"x":0.02,"y":0.98,"bgcolor":"rgba(0,0,0,0.5)"},"width":1400,"height":900,"paper_bgcolor":"rgba(5,10,20,1)","plot_bgcolor":"rgba(5,10,20,1)"},                        {"responsive": true}                    ).then(function(){
                            
        var gd = document.getElementById('kg3d');
        if (gd) {
            var isRotating = false;
            
            function startRotation() {
                if (isRotating) return;
                isRotating = true;
                
                var angle = 0;
                
                function rotate() {
                    if (!isRotating) return;
                    
                    angle += 0.01;
                    var newCamera = {
                        eye: {
                            x: 2 * Math.cos(angle),
                            y: 2 * Math.sin(angle),
                            z: 1.5
                        },
                        center: {x: 0, y: 0, z: 0},
                        up: {x: 0, y: 0, z: 1}
                    };
                    
                    Plotly.relayout(gd, {'scene.camera': newCamera});
                    requestAnimationFrame(rotate);
                }
                rotate();
            }
            
            function stopRotation() {
                isRotating = false;
            }
            
            document.addEventListener('keydown', function(event) {
                if (event.key === 'r' || event.key === 'R') {
                    if (isRotating) stopRotation();
                    else startRotation();
                }
                if (event.key === 'c' || event.key === 'C') {
                    Plotly.relayout(gd, {
                        'scene.camera': {
                            eye: {x: 1.5, y: 1.5, z: 1.5},
                            center: {x: 0, y: 0, z: 0},
                            up: {x: 0, y: 0, z: 1}
                        }
                    });
                }
            });
            
            gd.on('plotly_relayout', function() {
                stopRotation();
            });
            
            var instructions = document.createElement('div');
            instructions.innerHTML = '<p style="color: white; position: absolute; top: 10px; left: 10px; z-index: 1000; background: rgba(0,0,0,0.7); padding: 10px; border-radius: 5px; font-size: 12px;">Press <b>R</b> to toggle rotation<br>Press <b>C</b> to reset camera<br>Drag to orbit, scroll to zoom</p>';
            document.body.appendChild(instructions);
        }
        
                        })                };            </script>        </div>
</body>
</html>