[
  {
    "nodes": [
      {
        "id": 101,
        "alias": "",
        "labels": [
          "Concept",
          "NODE"
        ],
        "properties": {
          "name": "correlated_onpolicy_transition_sequences",
          "type": "concept",
          "description": "Sequences of observations collected sequentially under the current policy are strongly correlated in time.",
          "aliases": [
            "correlated data sequences",
            "temporally correlated samples"
          ],
          "concept_category": "Problem",
          "paper_id": "arxiv__arxiv_org_abs_1312_5602",
          "method": "model",
          "is_tombstone": false
        }
      }
    ],
    "edges": [],
    "length": 0
  },
  {
    "nodes": [
      {
        "id": 102,
        "alias": "",
        "labels": [
          "Concept",
          "NODE"
        ],
        "properties": {
          "name": "training_instability_and_divergence_in_q_networks",
          "type": "concept",
          "description": "Non-linear function approximators combined with off-policy updates can diverge or oscillate during RL training.",
          "aliases": [
            "weight divergence",
            "unstable learning dynamics"
          ],
          "concept_category": "Problem",
          "paper_id": "arxiv__arxiv_org_abs_1312_5602",
          "method": "model",
          "is_tombstone": false
        }
      }
    ],
    "edges": [],
    "length": 0
  },
  {
    "nodes": [
      {
        "id": 103,
        "alias": "",
        "labels": [
          "NODE",
          "Intervention"
        ],
        "properties": {
          "name": "experience_replay_uniform_1M_buffer",
          "type": "intervention",
          "description": "Maintain a replay memory of the latest 10^6 transitions and train with minibatches uniformly sampled from it.",
          "aliases": [
            "experience replay buffer",
            "uniform replay memory"
          ],
          "intervention_lifecycle": 1,
          "intervention_maturity": 2,
          "paper_id": "arxiv__arxiv_org_abs_1312_5602",
          "method": "model",
          "is_tombstone": false
        }
      }
    ],
    "edges": [],
    "length": 0
  },
  {
    "nodes": [
      {
        "id": 104,
        "alias": "",
        "labels": [
          "Concept",
          "NODE"
        ],
        "properties": {
          "name": "nonstationary_behavior_distribution",
          "type": "concept",
          "description": "Because the agentâ€™s policy changes during learning, the distribution over visited states and actions drifts over time.",
          "aliases": [
            "changing data distribution",
            "policy-induced non-stationarity"
          ],
          "concept_category": "Observation",
          "paper_id": "arxiv__arxiv_org_abs_1312_5602",
          "method": "model",
          "is_tombstone": false
        }
      }
    ],
    "edges": [],
    "length": 0
  },
  {
    "nodes": [
      {
        "id": 198,
        "alias": "",
        "labels": [
          "Concept",
          "NODE"
        ],
        "properties": {
          "name": "unintended instrumental actions",
          "type": "concept",
          "description": "Utility-maximising agents pursue resource acquisition, self-preservation, manipulation, etc.",
          "aliases": [
            "power-seeking side-effects"
          ],
          "concept_category": "Problem",
          "paper_id": "arxiv__arxiv_org_abs_1411_1373",
          "method": "model",
          "is_tombstone": false
        }
      }
    ],
    "edges": [],
    "length": 0
  },
  {
    "nodes": [
      {
        "id": 541,
        "alias": "",
        "labels": [
          "Concept",
          "NODE"
        ],
        "properties": {
          "name": "misguided policy or safety decisions",
          "type": "concept",
          "description": "Regulatory or strategic choices are made on the basis of incorrect capability assessments.",
          "aliases": [
            "faulty governance outcome",
            "policy risk"
          ],
          "concept_category": "Risk",
          "paper_id": "arxiv__arxiv_org_abs_1703_10987",
          "method": "model",
          "is_tombstone": false
        }
      }
    ],
    "edges": [],
    "length": 0
  }
]