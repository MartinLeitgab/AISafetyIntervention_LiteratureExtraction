{"text": "1. Introduction\n----------------\n\n\n\nBenchmarks are a key tool for measuring technical progress in artificial intelligence (AI) research. A variety of benchmark datasets have been developed to measure a model\u2019s performance on particular tasks, such as question answering\u00a0(Rajpurkar et\u00a0al., [2016](#bib.bib176)), facial recognition\u00a0(Huang\net\u00a0al., [2008](#bib.bib109)), machine translation\u00a0(Bojar et\u00a0al., [2014](#bib.bib37)), etc. At the same time, the subject of AI ethics\u2014including questions surrounding safety, fairness, accountability, transparency, etc.\u2014has become increasingly prominent as a research direction in the field in recent years. However, there is presently no community-accepted standard for measuring the \u2018ethicality\u2019 of an AI system\u2014i.e., whether the decisions rendered by an AI system are morally \u2018correct\u2019. That is to say, there is no benchmark for measuring whether an AI system \u2018is\u2019 ethical or for comparing the performance (in morally-loaded scenarios) between two distinct models or use cases.\n\n\n\n\nIn this paper, drawing upon research in moral philosophy\u2014including normative ethics and meta-ethics\u2014we argue that it is, in fact, impossible to develop such a benchmark. Part of the problem arises because the word \u2018ethics\u2019 carries significant philosophical and conceptual baggage. Furthermore, members of the AI community are not always sensitive to the subtleties and problems that drive research in moral philosophy. For example, some researchers have suggested that moral dilemmas\u2014a type of philosophical thought experiment\u2014may be useful as a verification mechanism for whether a model chooses the ethically-\u2018correct\u2019 option in a range of circumstances. But, these dilemmas, in the context of benchmarking ethics, often fail to maintain sensitivity to, e.g., the purpose of philosophical thought experiments like moral dilemmas\u00a0(LaCroix, [2022](#bib.bib131)). Further problems arise because of the implicit assumptions that AI researchers make about the very nature of ethics\u2014particularly, meta-ethical assumptions about the objectivity of ethics. These insights help clarify why attempts to benchmark ethics for AI systems presently fail and why they will continue to do so.\n\n\n\n\nThus, we argue that alternative mechanisms are necessary for evaluating whether an AI system \u2018is\u2019 ethical. These considerations are especially pressing in light of the prevalence of applied industrial AI research. We argue that it makes more sense to talk about \u2018values\u2019 (and \u2018value alignment\u2019) rather than \u2018ethics\u2019 when considering the possible actions of present and future AI systems. We further highlight that because values are unambiguously relative, focusing on values rather than ethics forces us to consider explicitly what and whose values they are. This practice has additional downstream benefits for conceptual clarity and transparency in AI research. Therefore, shifting the emphasis from ethics to values gives rise to several new ways of understanding how researchers might move forward with a programme for robustly safe or beneficial AI.\n\n\n\n\nWe begin with a discussion of benchmarking in general, highlighting some of the issues recently identified for existing machine learning (ML) datasets and benchmarks (Section\u00a0[2](#S2 \"2. Measuring Progress in Artificial Intelligence \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\")). We then consider benchmarks in the context of ethics for AI systems (Section\u00a0[3](#S3 \"3. Moral Benchmarks for AI Systems \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\")) and why they fail. In particular, we discuss a supposed benchmark for ethical AI that has arisen in the context of autonomous vehicles as a particular case study: the \u2018Moral Machine Experiment\u2019 (MME)\u00a0(Massachusetts Institute of Technology, [2016](#bib.bib148)). We follow with a discussion regarding what values are transmitted via AI research and whose values they are (Section\u00a0[4](#S4 \"4. The Ethical Values of AI Research or: How ethics can be defined as a set of values \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\")). We conclude by highlighting several possible ways forward for the field as a whole, and we advocate for different approaches towards more ethically-aligned AI research (Section\u00a0[5](#S5 \"5. Ways Forward \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\")).\n\n2. Measuring Progress in Artificial Intelligence\n-------------------------------------------------\n\n\n\nGenerally speaking, a benchmark can be described as a dataset in combination with a metric\u2014defined by some set of community standards\u2014 used for measuring the performance of a particular model on a specific task\u00a0(Raji et\u00a0al., [2021](#bib.bib175)). Benchmarks are meant to provide a fixed and representative sample for comparing models\u2019 performance and tracking \u2018progress\u2019 on a particular task. In this section, we describe some examples of benchmarking results for typical ML tasks and then highlight the myriad ways that have been noted in the literature in which these standard benchmarks give rise to certain issues ([2.1](#S2.SS1 \"2.1. Issues with Existing Benchmarks \u2023 2. Measuring Progress in Artificial Intelligence \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\")). We then discuss how human performance on certain tasks is increasingly used to benchmark model performance and why this approach is illogical given the differences between humans and algorithms ([2.2](#S2.SS2 \"2.2. Benchmarking Humans and Machines \u2023 2. Measuring Progress in Artificial Intelligence \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\")).\n\n\n\n\n### \n2.1. Issues with Existing Benchmarks\n\n\n\nSince its inception, designing tasks and measuring model performance have been central to the field of AI. These continue to be an important part of how members of the AI community measure \u2018progress\u2019. However, despite the ubiquity of benchmarking, major issues have been identified in existing ML datasets and benchmarks.111In the context of this paper, we use \u2018AI\u2019 to refer to general approaches in the field pursuing machine intelligence, and we use \u2018ML\u2019 to refer specifically to non-linear statistical approaches within that field. These issues can arise from, e.g., subjective or erroneous labels\u00a0(Gebru et\u00a0al., [2018](#bib.bib87)) or a lack of representation, leading to systematic failures across datasets and evaluative approaches\u00a0(Raji et\u00a0al., [2021](#bib.bib175); Liao\net\u00a0al., [2021](#bib.bib139)). For example, datasets like ImageNet\u00a0(Deng\net\u00a0al., [2009](#bib.bib64)) depend on linguistic hierarchies created in the 1980s and include outdated terms such as \u2018harlot\u2019 and \u2018chimneysweep\u2019\u00a0(Crawford and\nPaglen, [2019](#bib.bib59)). At the same time, some of the most commonly-used datasets (including ImageNet) have been shown to contain an average of 3.33.33.33.3% labelling errors, with some datasets having error rates up to 10101010%\u00a0(Northcutt\net\u00a0al., [2021](#bib.bib166)).222If 3.33.33.33.3% sounds like a reasonable error rate, consider that these datasets are often huge. ImageNet contains more than 14141414 million images, meaning that nearly 1111 million of these images\u2014commonly used for training\u2014might be erroneously labelled.\n\n\n\n\nAt best, these issues can affect model performance since they represent noisier data, making it harder for models to learn meaningful representations\u00a0(Reed et\u00a0al., [2015](#bib.bib177)) and for researchers to evaluate model performance properly\u00a0(Northcutt\net\u00a0al., [2021](#bib.bib166)). Further, this can preserve problematic stereotypes or biases, which are difficult to identify in models deployed in the real world\u00a0(Koch\net\u00a0al., [2021](#bib.bib124); Yang et\u00a0al., [2020](#bib.bib220)). At worst, they may reinforce, perpetuate, and even generate harms by creating negative feedback loops that further entrench societal structural inequalities (O\u2019Neil, [2016](#bib.bib167); Falbo and LaCroix, [2021](#bib.bib76)).\n\n\n\n\nAbove and beyond specific datasets, entire AI tasks\u2014such as recognising faces and emotions\u2014have been repeatedly flagged as problematic (often for similar reasons as described above)\u00a0(Buolamwini and\nGebru, [2018](#bib.bib47); Stark, [2018](#bib.bib196); Stark and Hutson, [2021](#bib.bib197)). Nonetheless, these tasks continue to be used for benchmarking models and developing entire systems. One such task involves predicting the mortality of different passengers aboard the HMS Titanic\u00a0(Kaggle, [2012](#bib.bib118)). This task has been used for hundreds of tutorials, blog posts, and ultimately published studies.333See, for example, (Kakde and Agrawal, [2018](#bib.bib119); Barhoom et\u00a0al., [2019](#bib.bib18); Singh\net\u00a0al., [2020](#bib.bib192); Tabbakh\net\u00a0al., [2021](#bib.bib198); Shekhar\net\u00a0al., [2021](#bib.bib189)).\nHowever, whether or not a particular passenger survived is mostly predicted by their gender and the fare they purchased\u2014i.e., their class or social status\u00a0(Broussard, [2018](#bib.bib43)). So, the task of predicting the fate of passengers on the Titanic is perhaps morally dubious\u2014especially when it is done without considering the social inequalities that gave rise to differential mortality rates in the first place.\n\n\n\n\nConsider another example, from the field of computer vision. Oft-used tasks have included applying makeup to images of female faces\u00a0(Jiang\net\u00a0al., [2020](#bib.bib113); Li\net\u00a0al., [2018](#bib.bib138); Chang\net\u00a0al., [2018](#bib.bib50)), changing women\u2019s clothes from pants to mini-skirts\u00a0(Mo et\u00a0al., [2018](#bib.bib155); Yang\net\u00a0al., [2014](#bib.bib221)), and censoring nude women\u2019s bodies by, e.g., covering breasts with a bikini top\u00a0(Sim\u00f5es\net\u00a0al., [2019](#bib.bib191); More\net\u00a0al., [2018](#bib.bib160)). Such tasks are ethically problematic because they perpetuate gendered biases and stereotypes, thus reinforcing harmful systems of sexism and misogyny\u00a0(Manne, [2018](#bib.bib147)). Even so, these tasks are routinely used as acceptable benchmarks for computer vision models and their results are accepted at leading AI conferences, such as CVPR and ICCV.\n\n\n\n\nAlthough some publication venues\u2014academic conferences and journals\u2014are starting to forward ethical guidelines for both authors and reviewers\u00a0(Bengio et\u00a0al., [2021](#bib.bib23)), there is still a general lack of consensus about what constitutes acceptable tasks and applications of ML. This variance exacerbates the fact that it is not obvious that such guidelines will be effective in the first place\u00a0(LaCroix and\nMohseni, [2020](#bib.bib133)). Furthermore, creating larger and larger datasets is relatively cheap, but the process of filtering those datasets or \u2018detoxifying\u2019 the models trained on them is expensive (Birhane\net\u00a0al., [2021b](#bib.bib32); Welbl et\u00a0al., [2021](#bib.bib213); Xu et\u00a0al., [2021](#bib.bib219)). In addition, even when these changes in the direction of \u2018more ethical\u2019 or for a \u2018common good\u2019 are well-intentioned, the lack of conceptual clarity surrounding the targets of such change\u2014i.e., considering what it means to \u2018be ethical\u2019 in the first place\u2014will only compound the issue\u00a0(Taylor, [2016](#bib.bib199); Green, [2019](#bib.bib92); Moore, [2019](#bib.bib158); Cowls, [2021](#bib.bib58)).\n\n\n\n\nIn natural language processing (NLP), issues with benchmarks can be more subtle to identify. Still, these may range from unscientific task framing (such as predicting IQ scores based on written text\u00a0(Johann\u00dfen et\u00a0al., [2020](#bib.bib115))) to embedded gender and cultural stereotypes in common NLP benchmarks\u00a0(Blodgett et\u00a0al., [2021](#bib.bib36)). For example, in a recent survey of gender biases in NLP models,\u00a0Sta\u0144czak and\nAugenstein ([2021](#bib.bib195)) highlight four key limitations for NLP research:444In this context, biases can be understood as behaviours that involve systematic discrimination against specific individuals or groups (typically in favour of other individuals or groups)\u00a0(Friedman and\nNissenbaum, [1996](#bib.bib83)).\n(1) gender is often interpreted in a binary fashion, leading to, e.g., misgendering or erasure of non-binary gender identities\u00a0(Behm-Morawitz and\nMastro, [2008](#bib.bib21); Fast\net\u00a0al., [2016](#bib.bib77)); (2) NLP research is primarily monolingual, often focusing solely on the English language\u00a0(Web Technology\nSurveys, [2021](#bib.bib212); Koroteev, [2021](#bib.bib125); Wang et\u00a0al., [2019](#bib.bib211); Conneau and Kiela, [2018](#bib.bib56)); (3) biases are typically tested post hoc\u2014i.e., after the model has been deployed\u00a0(Mitchell et\u00a0al., [2019](#bib.bib153)); and (4) when research explicitly tests for bias (which is infrequent), the evaluation metrics are often incoherent\u00a0(Sta\u0144czak and\nAugenstein, [2021](#bib.bib195)). Thus, even when benchmarks exist for a particular task, researchers lack good baselines for testing ethics considerations in their models\u2014of which bias is one salient example. However, most newly-developed algorithms in this field do not test their models for biases in the first place, and ethical considerations are often ignored.\n\n\n\n\n\n### \n2.2. Benchmarking Humans and Machines\n\n\n\nAs mentioned, AI models\u2019 performance is increasingly compared to that of humans, with some models reporting \u2018superhuman performance\u2019 on, e.g., game-playing\u00a0(Tesauro, [1995](#bib.bib200); Schaeffer\net\u00a0al., [1996](#bib.bib186); Campbell et\u00a0al., [2002](#bib.bib48); Mnih et\u00a0al., [2013](#bib.bib154); Silver et\u00a0al., [2016](#bib.bib190); Brown and\nSandholm, [2017](#bib.bib45); Morav\u010d\u00edk\net\u00a0al., [2017](#bib.bib159)), image recognition\u00a0(He\net\u00a0al., [2015](#bib.bib103)), NLP tasks\u00a0(He\net\u00a0al., [2021](#bib.bib104)), etc. However, such comparisons are often misguided (at best) and incoherent (at worst). Recent research has shown that many \u2018superhuman\u2019 language models fail on simple challenge examples requiring compositionality\u00a0(Nie\net\u00a0al., [2019](#bib.bib165)), logical reasoning\u00a0(Glockner\net\u00a0al., [2018](#bib.bib90)), or even simple negation\u00a0(Hossain et\u00a0al., [2020](#bib.bib108)). At the same time, human performance on certain tasks\u2014e.g., diagnoses from X-rays\u2014are often measured by the accuracy of binary outputs\u2014a particular diagnosis is either positive or negative. In contrast, diagnostic AI models are continuous, including certainty or confidence (Gichoya et\u00a0al., [2018](#bib.bib88))\u2014this makes it difficult to compare the two, since the decision threshold can change depending on model parameters. Finally, comparing human and machine performance using the same metrics is precarious because metrics such as accuracy, widely used in AI, often fail to correlate with human judgement\u00a0(Blagec\net\u00a0al., [2021](#bib.bib35)). Thus, there is a sense in which human performance on tasks is incomparable to computer performance, making any claim of comparison incoherent\u2014not to mention that such comparisons imply \u2018a narcissistic human tendency to view ourselves as the gold standard\u2019\u00a0(Lee, [2021](#bib.bib137)).\n\n\n\n\nBut given this divergence, it is important to systematically measure progress in AI, either alone or in comparison with \u2018human-level performance\u2019. However, for this to be possible, performance metrics should provide similar conditions for humans and algorithms. An emerging research topic seeks to bridge this gap by establishing more \u2018equitable\u2019 settings for such comparisons\u2014e.g., by imposing constraints such as reduced exposure time for algorithms\u00a0(Funke et\u00a0al., [2021](#bib.bib84)) or a restricted set of label options for humans\u00a0(Dujmovi\u0107 et\u00a0al., [2020](#bib.bib71)). For instance, recent work shows that running images through human-like processing filters before feeding them through an algorithm helps even the playing field for both humans and machines\u00a0(Elsayed et\u00a0al., [2018](#bib.bib72)). These insights have led to proposals that AI models\u2019 performance on standard benchmarking tasks is not representative of any underlying capacity or lack thereof, given the nature and context of the tasks\u00a0(Firestone, [2020](#bib.bib79)).\n\n\n\n\nAnother way of making the human-machine comparison more coherent is developing ways for models to signal that they do not know how to solve, for instance, a classification task. This ability would require developing new ways for quantifying and integrating uncertainty into the decision-making process since current approaches do not provide an \u2018I don\u2019t know\u2019 option in the categories available during classification. In real-world deployments of AI systems, this behaviour is often addressed with heuristics (e.g., a cutoff based on a logit below a certain value). However, this does not solve the underlying issue that existing models do not know when they do not know;555Some philosophers have suggested that understanding the limits of knowledge is a prerequisite for wisdom (as opposed to mere intelligence)\u00a0(Plato, [1997](#bib.bib172)). this makes it difficult to compare human and machine classification processes.\n\n\n\n\nExisting proposals have forwarded new evaluation benchmarks that aim at measuring models\u2019 robustness and capacity to generalise to new tasks, both from a natural language\u00a0(Yogatama\net\u00a0al., [2019](#bib.bib222); Bowman and Dahl, [2021](#bib.bib42); Clark et\u00a0al., [2018](#bib.bib53)) and a computer vision perspective\u00a0(Hendrycks and\nDietterich, [2018](#bib.bib107); Mu and Gilmer, [2019](#bib.bib161)), finding that many models that succeed at existing benchmarks fail at these. Recent work has also proposed alternative approaches such as iterative benchmark development\u00a0(Ettinger et\u00a0al., [2017](#bib.bib74)) and dynamic benchmarking\u00a0(Kiela et\u00a0al., [2021](#bib.bib122)), which endeavour to bring entire fields towards a more nuanced, complex, and informed way of comparing models and measuring progress\u00a0(Denton et\u00a0al., [2020](#bib.bib68); Schlangen, [2020](#bib.bib187)). However, even if the issues with existing benchmarks (and their underlying datasets) on well-defined tasks are resolved, these problems severely limit any possibility of benchmarking ethics for AI systems insofar as ethics tasks are rarely, if ever, well-defined. This difficulty is a consequence of the very nature of ethics, as we discuss in the next section.\n\n3. Moral Benchmarks for AI Systems\n-----------------------------------\n\n\n\nAs AI systems become increasingly autonomous and more deeply integrated with society, it is obvious that some of the decisions made by these systems will begin to have moral weight. For example, consider a narrow chess-playing algorithm that can only make decisions confined to the action space provided by a chessboard. If the model \u2018decides\u2019 to open with the Queen\u2019s Gambit, this is not a moral decision under any definition of \u2018morality\u2019. In contrast, the decisions made by an autonomous weapon system\u00a0(Arkin, [2008a](#bib.bib11), [b](#bib.bib12); Krishnan, [2009](#bib.bib128); Tonkens, [2012](#bib.bib205); Hellstr\u00f6m, [2013](#bib.bib105); Asaro, [2020](#bib.bib13)), a healthcare robot\u00a0(Anderson\net\u00a0al., [2006](#bib.bib7); Anderson and\nAnderson, [2008](#bib.bib6); Sharkey and\nSharkey, [2012](#bib.bib188); Conti et\u00a0al., [2017](#bib.bib57)), or an autonomous vehicle\u00a0(Bhargava and Kim, [2017](#bib.bib29); Sommaggio and\nMarchiori, [2018](#bib.bib193); Evans et\u00a0al., [2020](#bib.bib75)) may have moral weight. In these cases, the action space may include decision points that we might call \u2018moral\u2019 or \u2018immoral\u2019\u2014for example, choosing to prioritise one patient over another. \n\n\n\n\nPart of the distinction between a chess-playing algorithm, whose decisions are confined to a particular action space, and an algorithm that acts in the real world is that the decisions made by the latter systems have the potential to impact others. So, in theory, deploying AI systems in the real world logically implies that they will sometimes need to make decisions with moral weight. However, as the action space increases, the set of possible failure modes increases exponentially. Further, the economic promise of AI implies that these systems are increasingly being deployed in society rather than being rigorously tested in the confines of a research lab, thus increasing the risk of harm\u00a0(LaCroix and\nBengio, [2019](#bib.bib132); Luccioni and\nBengio, [2020](#bib.bib144)). Of course, it is not necessary to posit some future science-fiction version of an AI robot acting autonomously in the world to see that the decisions of AI systems may create harm. As a case in point, even narrow AI systems today perpetuate harmful biases, affecting real-world outcomes\u00a0(Angwin\net\u00a0al., [2016](#bib.bib8); Christian, [2020](#bib.bib52); Tomasev\net\u00a0al., [2021](#bib.bib204)). And, as mentioned, these decisions may give rise to negative feedback loops, which further entrench those biases (and the harms caused by them) in society\u00a0(O\u2019Neil, [2016](#bib.bib167); Falbo and LaCroix, [2021](#bib.bib76)).\n\n\n\n\nIt should come as no surprise, then, that research on ethical behaviour or decision-making in AI systems would attempt to construct a coherent measure for determining whether a system is \u2018acting ethically\u2019\u2014i.e., whether the decision the model renders is morally \u2018correct\u2019. Given the historical importance of benchmarks for developing and evaluating AI systems, it makes sense that researchers would try to utilise this tool for evaluating the moral performance of an AI system. However, we argue in this section that benchmarking ethics in this way is impossible. First, we highlight how AI researchers have used moral dilemmas from philosophy as benchmarks for moral performance ([3.1](#S3.SS1 \"3.1. Moral Dilemmas and Normative Theories \u2023 3. Moral Benchmarks for AI Systems \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\")) and some recent work criticising this approach ([3.2](#S3.SS2 \"3.2. Moral Machines \u2023 3. Moral Benchmarks for AI Systems \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\")). We then introduce philosophical research in metaethics to show why it is impossible to benchmark ethical behaviour ([3.3](#S3.SS3 \"3.3. Ground Truths for Moral Benchmarks \u2023 3. Moral Benchmarks for AI Systems \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\")). Finally, we turn our discussion toward real-world distributions to highlight that even if our claims about the nature of ethics turn out to be false, it will still be impossible to benchmark ethical behaviour in an AI system ([3.4](#S3.SS4 \"3.4. A Long Tail Problem \u2023 3. Moral Benchmarks for AI Systems \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\")).\n\n\n\n\nThus, the arguments of this section are primarily negative. However, in the subsequent section, we provide a positive argument in favour of shifting the discourse of AI ethics toward talk of values. We discuss how such a shift would avoid many of the problems to which attempts to benchmark ethics give rise.\n\n\n\n\n### \n3.1. Moral Dilemmas and Normative Theories\n\n\n\nThe most common metric for evaluating whether or not a system \u2018is\u2019 ethical is how the algorithm performs on particular moral dilemmas\u00a0(Nallur, [2020](#bib.bib162)). Before we discuss benchmarking ethics using moral dilemmas, we introduce what a moral dilemma is in the first place. To take a concrete example, trolley-style problems are sometimes used to consider certain morally-loaded decisions that autonomous vehicles (AVs) might have to make as these systems become increasingly ubiquitous in society. The trolley problem was originally introduced by Philippa Foot\u00a0(Foot, [1967](#bib.bib81))\u2014and later extended by Judith Jarvis Thomson\u00a0(Thomson, [1976](#bib.bib202), [1985](#bib.bib203))\u2014to consider why it might be permissible to perform some intentional action, A\ud835\udc34Aitalic\\_A, in situation, S\ud835\udc46Sitalic\\_S, despite its foreseeable (and undesirable) consequences.666This principle dates to at least\u00a0Aquinas ([1485](#bib.bib9)); Foot calls it the Doctrine of Double Effect\u00a0(FitzPatrick, [2012](#bib.bib80)). See also discussion in\u00a0(Kamm, [1989](#bib.bib120); Unger, [1996](#bib.bib206)). Consider the following scenario.\n\n\n\n\n> \n> Bystander at the Switch\n>   \n> \n> Suppose there is a trolley heading toward five individuals tied up on the tracks and unable to move. You are near a switch, which would divert the trolley to a separate track, where there is only one individual on the track (also unable to move). You have two (and only two) options:\n> \n> \n> \n> > \n> > 1. (1)\n> > \n> > Do nothing, in which case the trolley is guaranteed to kill the five people on the main track.\n> > 2. (2)\n> > \n> > Pull the switch, diverting the trolley onto the side track where it is guaranteed to kill one person.\n> > \n> > \n> > \n> \n> \n> \n\n\nThis standard formulation can be contrasted with the following alternative trolley problem:\n\n\n\n\n> \n> Bystander on the Footbridge\n>   \n> \n> Suppose you are on a footbridge above a set of trolley tracks. Below, an out-of-control trolley is approaching five people on the track. The only way to stop the trolley is by dropping something of sufficiently heavy weight onto the tracks to block its path. As it happens, there is a person nearby of sufficiently heavy weight. You have two (and only two) options:\n> \n> \n> \n> > \n> > 1. (1)\n> > \n> > Do nothing, in which case the trolley will kill the five people on the track.\n> > 2. (2)\n> > \n> > Push the person off the bridge, thus killing them (but thereby saving the five others).\n> > \n> > \n> > \n> \n> \n> \n\n\nEach of these is a particular type of philosophical thought experiment, called a moral dilemma\u00a0(McConnell, [2018](#bib.bib149)). Note that different normative theories from moral philosophy might offer divergent prescriptions (or proscriptions) when these two cases\u2014Switch and Footbridge\u2014are considered together. In this context, \u2018normativity\u2019 concerns an evaluation or judgement\u2014e.g., that one ought to do something. (We will use the phrase \u2018normative theory\u2019 throughout this paper to refer to theories from moral philosophy, without necessarily committing to any claims about \u2018morality\u2019 or \u2018ethics\u2019.) A \u2018prescription\u2019 can be understood as the provision of a rule to follow or an action to take\u2014i.e., a prescription that one ought to \u03d5italic-\u03d5\\phiitalic\\_\u03d5 or that one must \u03d5italic-\u03d5\\phiitalic\\_\u03d5. In contrast, a \u2018proscription\u2019 is the provision of something forbidden\u2014i.e., a proscription that one ought not to \u03d5italic-\u03d5\\phiitalic\\_\u03d5, or that one must not \u03d5italic-\u03d5\\phiitalic\\_\u03d5.\n\n\n\n\nConsider a concrete example of how distinct normative theories may offer divergent prescriptions in the same scenario. Certain forms of utilitarianism\u00a0(Mill, [1863](#bib.bib151); Bentham, [1789](#bib.bib26))\u2014a consequentialist normative theory that prescribes utility-maximisation as a reason for action\u2014would recommend acting in both Switch and Footbridge because five deaths are obviously worse than one death. On the other hand, a Kantian brand of deontology\u00a0(Kant, [1785](#bib.bib121); Korsgaard, [1996](#bib.bib126), [2009](#bib.bib127))\u2014a non-consequentialist normative theory which emphasises the importance of duties\u2014would at least say that it is impermissible to act in Footbridge since this requires treating a human agent as a means to an end, rather than an end in itself, thus violating the Categorical Imperative\u00a0(Kant, [1785](#bib.bib121)).777The categorical imperative states it is never permissible to use a human agent as a means to an end. It is less obvious whether this imperative would also proscribe acting in Switch. However, Thomson ([1985](#bib.bib203)) argues that there is a sense in which Switch still uses a human agent as a means to an end and thus would be impermissible by Kantian deontology.\nSo, two different normative theories may prescribe (or proscribe) different actions in the same context because they take competing considerations to be important for moral decisions\u2014in this example, consequences on the one hand and duties on the other.\n\n\n\n\nIn many cases, different normative theories will prescribe the same action (although, possibly for different reasons). However, as we have seen, there may be some tension between the prescriptions of these theories, and moral dilemmas can serve to make these differences salient. Further, moral dilemmas underscore tensions between individual intuitions regarding the rightness or wrongness of an action in a given scenario. In empirical studies, most individuals say they would only act in the case of Switch, not in Footbridge\u00a0(Navarrete et\u00a0al., [2012](#bib.bib164); Bourget and\nChalmers, [2014](#bib.bib41)). Thus, both the prescriptions of normative theories and common intuitions about the permissibility of an act may vary.888Of course, how people respond to abstract philosophical dilemmas on questionnaires may be quite different from how they act in the real world\u00a0(Navarrete et\u00a0al., [2012](#bib.bib164); Bostyn\net\u00a0al., [2018](#bib.bib40)).\nThe point is that a moral dilemma is a tool for philosophical analysis used to bring these tensions to the fore.\n\n\n\n\nPart of the purpose of a moral dilemma (as a type of philosophical thought experiment) is to focus attention on the morally-salient features of the dilemma\u00a0(Dennett, [1984](#bib.bib65), [1992](#bib.bib66), [2013](#bib.bib67); Brown and Fehige, [2019](#bib.bib44)) without getting bogged down by the pre-theoretic baggage that individuals may carry. In the case of the trolley problem, Foot\u2019s original target of analysis is abortion (not trolleys)\u00a0(Foot, [1967](#bib.bib81)). However, the thought experiment is useful precisely because of the supposed tension (at least in western analytic philosophy) between emotion and rationality\u00a0(James, [1890](#bib.bib112); Jagger, [1989](#bib.bib111); Spelman, [1989](#bib.bib194); Fricker, [1991](#bib.bib82)): people are less likely to carry pre-theoretic baggage about trolleys than they are about abortions. Therefore, the thought experiment gets to the core of a moral issue in applied ethics while abstracting away from the actual (morally-loaded) target\u00a0(LaCroix, [2022](#bib.bib131)). Despite the conceptual purpose of dilemmas in moral philosophy\u2014i.e., as thought experiments or \u2018intuition pumps\u2019\u00a0(Dennett, [1984](#bib.bib65), [1992](#bib.bib66), [2013](#bib.bib67))\u2014AI researchers have begun to use these dilemmas as validation proxies for whether an model is ethical. In the remainder of this section, we discuss why this is a mistake.\n\n\n\n\n\n### \n3.2. Moral Machines\n\n\n\nAs we have seen (Section\u00a0[2](#S2 \"2. Measuring Progress in Artificial Intelligence \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\")), what we might call the \u2018standard model\u2019 for measuring \u2018progress\u2019 in AI research involves benchmarking. Thus, it stands to reason that to determine whether (1) a choice made by a particular model in a morally-loaded scenario is the (morally) \u2018correct\u2019 one, (2) one model is \u2018more\u2019 moral than another, or (3) a model is increasingly \u2018moral\u2019 when subjected to further training, it appears that researchers need a benchmark for measuring the \u2018ethicality\u2019 of a model. Logically, then, for such a task to be successful, we would require an ethics dataset\u2014either general-purpose or task-specific\u2014and a metric for measuring model performance relative to that dataset.999Recall that, in Section\u00a0[2](#S2 \"2. Measuring Progress in Artificial Intelligence \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\"), following\u00a0Raji et\u00a0al. ([2021](#bib.bib175)), we described a benchmark as a dataset in combination with a metric.\n\n\n\n\n\nTo take a specific example, trolley-style moral dilemmas, like Switch and Footbridge, have been widely discussed in machine ethics and AI research in the context of possible (low-probability but high-stakes) situations in which an autonomous vehicle (AV) may be placed.101010See, for example, (Allen\net\u00a0al., [2011](#bib.bib5); Wallach and Allen, [2009](#bib.bib210); Pereira and\nSaptawijaya, [2015](#bib.bib171), [2011](#bib.bib170); Berreby\net\u00a0al., [2015](#bib.bib28); Danielson, [2015](#bib.bib61); Lin, [2015](#bib.bib140); Malle et\u00a0al., [2015](#bib.bib146); Saptawijaya and\nPereira, [2015](#bib.bib183), [2016](#bib.bib184); Bentzen, [2016](#bib.bib27); Bhargava and Kim, [2017](#bib.bib29); Casey, [2017](#bib.bib49); Cointe\net\u00a0al., [2017](#bib.bib54); Greene, [2017](#bib.bib94); Lindner\net\u00a0al., [2017](#bib.bib141); Santoni\u00a0de Sio, [2017](#bib.bib182); Welsh, [2017](#bib.bib214); Wintersberger et\u00a0al., [2017](#bib.bib216); Bj\u00f8rgen et\u00a0al., [2018](#bib.bib33); Grinbaum, [2018](#bib.bib96); Misselhorn, [2018](#bib.bib152); Pardo, [2018](#bib.bib168); Sommaggio and\nMarchiori, [2018](#bib.bib193); Baum\net\u00a0al., [2019](#bib.bib20); Cunneen\net\u00a0al., [2019](#bib.bib60); Krylov\net\u00a0al., [2019](#bib.bib130); Sans and\nCasacuberta, [2019](#bib.bib181); Wright, [2019](#bib.bib217); Agrawal\net\u00a0al., [2020](#bib.bib3); Awad et\u00a0al., [2020](#bib.bib14); Banks, [2021](#bib.bib17); Bauer, [2020](#bib.bib19); Etienne, [2020](#bib.bib73); Gordon, [2020](#bib.bib91); Harris, [2020](#bib.bib102); Lindner\net\u00a0al., [2020](#bib.bib142); Nallur, [2020](#bib.bib162)). \u00a0Suppose that a fully-autonomous vehicle must \u2018choose\u2019 between killing five pedestrians or swerving into a barrier, killing the driver in the process. Functionally, this scenario is equivalent to a trolley problem, in that an actor must choose, the consequences of which will involve one death or several.\n\n\n\n\nPerhaps the most well-known instantiation of this dilemma in an AI context is the Moral Machine Experiment\u00a0(Massachusetts Institute of Technology, [2016](#bib.bib148)) (MME): a multilingual online \u2018game\u2019 for gathering human perspectives on (hypothetical) moral decisions made by a machine intelligence. Participants are shown several unavoidable accident scenarios with binary outcomes and are prompted to choose which outcome they think is more acceptable. These include \u2018sparing humans (versus pets), staying on course (versus swerving), sparing passengers (versus pedestrians), sparing more lives (versus fewer lives), sparing men (versus women), sparing the young (versus the elderly), sparing pedestrians who cross legally (versus jaywalking), sparing the fit (versus the less fit), and sparing those with higher social status (versus lower social status)\u2019\u00a0(Awad et\u00a0al., [2018](#bib.bib15), p. 60). The MME appears to provide a type of benchmark in the following sense: the dataset is the set of data collected online from humans in response to the hypothetical scenarios posed; the metric, then, could be how closely the decision of a model accords with the data for a given scenario\u2014i.e., human responses to the data on average.\n\n\n\n\nHowever, this approach to the problem of creating \u2018moral\u2019 AI systems is highly pernicious. First, the MME data are descriptive rather than normative. That is, the data do not tell us (or a model) anything about how one ought to act in a given scenario; instead, the data offer a description of how people (hypothetically and on average) would (or say they would) act in such a scenario. As a result, using these data for benchmarking a new algorithm is a type of fallacy\u2014i.e., the logical error of deriving an \u2018ought\u2019 from an \u2018is\u2019 (Hume, [1739](#bib.bib110); Moore, [1903](#bib.bib157)). The error of reasoning arises from the implication that since people say they would act in this way (a descriptive claim), it follows that the machine ought to act in this way (a normative claim).\n\n\n\n\nSecond, the thing being measured against the MME data is not whether a decision is, in fact, ethical, but how well a decision corresponds to the opinions of a particular set of humans, on average. For an ethics benchmark to be useful, it must provide data for the de facto morally-\u2018correct\u2019 decision in a given scenario. The MME data provide a mere proxy for this target: namely, a sociological fact about how some set of human agents annotates a particular set of decision problems, on average. Such proxies are especially harmful when the researchers who use them do not maintain sensitivity to the differences between the proxy and the target. This is, in effect, a value alignment problem, which we will discuss in more detail in Section\u00a0[4](#S4 \"4. The Ethical Values of AI Research or: How ethics can be defined as a set of values \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\").\n\n\n\n\nThird, although there are intrinsic reasons why we might want AI systems to be capable of acting ethically, the AV case brings to light a different type of value alignment problem. Namely, for-profit corporations have some market incentives for designing \u2018ethical\u2019 AI since humans (i.e., consumers) will likely be more trusting of an autonomous agent (i.e., a product) if it is known to possess a set of moral principles intended to constrain and guide its behaviour\u00a0(Bonnefon\net\u00a0al., [2016](#bib.bib38)). However, suppose that the (in fact) \u2018ethical\u2019 decision between killing five pedestrians and swerving into a barrier, thus killing the passenger of the AV, is to swerve. Human consumers may be less willing to purchase a product that may choose to kill them, even if it is the \u2018most ethical\u2019 decision. Indeed, a human consumer may be more willing to purchase a product that follows the pseudo-moral imperative: always prioritise the passenger\u2019s wellbeing. Therefore, the companies that design these models have perverse profit-maximising incentives when designing \u2018ethical\u2019 AI. We will discuss this in more detail in Section\u00a0[4.2](#S4.SS2 \"4.2. Whose Values are Encoded in AI Research? \u2023 4. The Ethical Values of AI Research or: How ethics can be defined as a set of values \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\").\n\n\n\n\nThe MME exemplifies a trend that attempts to use moral dilemmas from philosophy as benchmarks for ethical AI. For example, Nallur ([2020](#bib.bib162)) suggests that if some model implementation can \u2018resolve a dilemma in a particular manner, then it is deemed to be a successful implementation of ethics in the robot/software agent\u2019 (p. 2382). Additionally, Bj\u00f8rgen et\u00a0al. ([2018](#bib.bib33)) argue that certain types of ethical dilemmas\u2014including the trolley-style problems discussed above\u2014\u2018can be used as benchmarks for estimating the ethical performance of an autonomous system\u2019 (p. 23). Similarly,\u00a0Bonnemains\net\u00a0al. ([2018](#bib.bib39)) argue that \u2018it seems legitimate to use some [moral dilemmas] as a starting point for designing an automated ethical judgement on decisions\u2019 (p. 43) because classic moral dilemmas have already been used as a basis for ethical reasoning. And, this reasoning extends well beyond the particular use of trolley-style problems for reasoning about ethical decision-making in autonomous vehicles; for example, Lourie\net\u00a0al. ([2020](#bib.bib143)) introduce a dataset of ethical dilemmas, which they suggest \u2018enables models to learn basic ethical understanding\u2019. However,\u00a0LaCroix ([2022](#bib.bib131)) argues that using moral dilemmas for benchmarking involves a category mistake. Moral dilemmas have no right answer, by design.\n\n\n\n\nThus the question that researchers take themselves to address is how to determine whether the decision chosen by the system is \u2018in fact\u2019 moral. From the perspective of AI research, it appears that this problem is merely a matter of choosing a metric by which performance on the system can be measured and then determining whether or not the algorithm in question is successful on that metric. Once the metric is determined, standard benchmarking techniques may apply such that one algorithm performs better than (or, \u2018is more ethical than\u2019) another. The question then arises how we are supposed to know whether the decision chosen by the system is \u2018in fact\u2019 moral\u2014i.e., how ethical are the decisions made by the algorithm? We now argue that this question is incoherent by appealing to research in metaethics.\n\n\n\n\n\n### \n3.3. Ground Truths for Moral Benchmarks\n\n\n\nMetaethics is the branch of moral philosophy that seeks to explain the very nature of ethics.111111Unlike normative ethics, which asks questions like \u2018what ought I to do\u2019, metaethics is primarily concerned with questions surrounding ethical concepts\u2014e.g., what does a normative word like \u2018ought\u2019 mean? Moral realism is a metaethical view which holds that moral properties exist\u00a0(Sayre-McCord, [2021](#bib.bib185)). A realist about ethics would hold that moral claims purport to report facts\u2014i.e., about the world\u2014and are true when they get those facts correct. For example, if I say \u2018murder is wrong\u2019, I am making a normative claim. A moral realist would hold that this proposition is either true or false, regardless of, e.g., social norms or conventions. And, whether this proposition is true or false depends upon some matters of fact\u2014i.e., about the world\u2014independent of me and my views.121212At least according to certain theories of truth. See (Glanzberg, [2021](#bib.bib89)). For benchmarking to make sense in the first place, there must be some ground truth against which one can compare the outputs of one\u2019s model. Thus, by assuming that ethics is the sort of thing that can be benchmarked, researchers in the field are tacitly assuming that there is a ground truth\u2014i.e., that there are moral facts, which can be true or false, and that we have epistemic access to those facts. This \u2018commonsense\u2019 view of morality presupposes the existence of objective values.\n\n\n\n\nHowever, this is not to be taken for granted. It is highly contentious whether there is any such ground truth in ethics, even amongst experts in the field. For example, non-cognitivists about ethics think that moral claims do not express propositions; thus, such claims are not truth-apt\u2014similar to an exclamation or a question, moral claims are not capable of being true or false. One particular brand of non-cognitivism\u2014\u2018emotivism\u2019\u2014likens moral claims to an emotional expression of one\u2019s attitude toward some action or set of actions\u00a0(Ayer, [1936](#bib.bib16)). Another prominent form of anti-realism about ethics is error theory, which holds that all moral claims are false (because there are no objective moral values)\u00a0(Mackie, [1977](#bib.bib145)). Objective ethics, it may turn out, is \u2018a useful fiction\u2019\u00a0(Joyce, [2001](#bib.bib117)), \u2018an error\u2019 (Mackie, [1977](#bib.bib145)), \u2018a collective illusion\u2019\u00a0(Ruse, [1986](#bib.bib179)), a \u2018function of social conventions\u2019\u00a0(Harman, [1977](#bib.bib99), [1984](#bib.bib100); Harman and\nThomson, [1996](#bib.bib101)), or simply a \u2018network of attitudes\u2019 that is projected onto the world\u00a0(Blackburn, [1996](#bib.bib34)).\n\n\n\n\n\nIf it turns out that moral realism is false, then benchmarking ethics would be impossible because there is no ground truth against which one can benchmark a model. The point here is not whether moral realism is true or false. The point, instead, is that \u2018moral realism is true\u2019 is a substantive (and contested) claim that cannot be taken for granted. However, this is precisely what is taken for granted when researchers assume that they can benchmark the ethicality of a decision made by their model. But ethics, itself, is an \u2018essentially contested concept\u2019\u00a0(Gallie, [1956](#bib.bib86)). As with the benchmarking issues discussed in Section\u00a0[2](#S2 \"2. Measuring Progress in Artificial Intelligence \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\"), the real problem with benchmarking ethics concerns taking substantive claims for granted and unreflectively applying vague concepts to a problem with potentially significant real-world consequences. Even if moral realism turns out to be true, thus vindicating the assumptions made by some members of the AI community, benchmarking ethics will still be impossible with current approaches because of the disconnect between the distribution of examples that models see in training and the distribution of states of the real world. Namely, the long tail problem.\n\n\n\n\n\n### \n3.4. A Long Tail Problem\n\n\n\nThe long tail problem is a longstanding issue in the field of AI. In effect, there are a potentially infinite number of states an AI system might face in the real world, and it is impossible to represent every contingency in the training data. Although gathering data about common objects, contexts, or situations is relatively easy, doing so for uncommon ones is difficult precisely because of their rarity. However, \u2018rare\u2019 does not mean \u2018impossible\u2019. Following the theory that \u2018what-ever can happen will happen if we make trials enough\u2019\u00a0(De Morgan, [1872](#bib.bib63)),\u00a0as models are deployed in the real world, it becomes increasingly plausible that they will encounter objects and situations on which they were not trained. Namely, any event with non-zero probability is an actuality in the limit. Even applied AI techniques, like adversarial generation\u2014i.e., training a separate model to artificially generate training data that does not exist in the real world\u00a0(Zhang\net\u00a0al., [2018](#bib.bib223))\u2014will not solve this problem because it is impossible to account for all potential scenarios and situations. In practice, these data generation techniques are often coupled with user-defined heuristics, such as compelling a model to abstain from proposing a classification if its confidence threshold is too low or simply removing problematic categories. For example, when Google\u2019s AI-based photo-tagging feature labelled two African Americans as \u2018Gorillas\u2019, they removed that particular category from the options available to the model\u00a0(Vincent, [2018](#bib.bib208)). Nonetheless, both of these approaches are brittle and fail to generalise for the multitude of real-world situations and problems that AI systems face.\n\n\n\n\nThus, even if we ignore the fact that benchmarking ethics requires significant presuppositions about the nature of ethics (which AI researchers are not warranted to make), the long-tail problem makes benchmarking ethics impossible, regardless of whether there is a ground truth against which a model might be benchmarked. Part of this is the distinction between actions spaces containing decisions with or without moral weight. To go back to our original example, if a chess-playing algorithm has not seen some set of moves, and responds sub-optimally, the worst possible thing that can happen is that the algorithm loses a game of chess. Although this outcome may not be ideal for the researchers who trained the model, it has little real-world consequence. In contrast, when a model encounters a situation that it has not seen before, and its action space includes acts that we would call \u2018immoral\u2019, this can have real-world consequences. Therefore, low-probability but high-risk events pose unique challenges in ethical contexts. This problem is difficult even when there is an objectively correct answer, but as we have seen, some (possibly all) morally-loaded situations have no such claim to objectivity. Thus, the long-tail problem prevents the coherence of benchmarking in the context of ethics even in the possible world in which ethics has some ground truth.\n\n\n\n\nThe conceptual difficulties surrounding the very nature of ethics are further exacerbated when researchers are not attentive to them. Although the objectivity of ethics is contested, we suggest that values are unambiguously relative. Therefore, in the next section we suggest that values, rather than ethics, are a more appropriate target for research on safe and beneficial AI.\n\n4. The Ethical Values of AI Research or: How ethics can be defined as a set of values\n--------------------------------------------------------------------------------------\n\n\n\nGiven the increasing influence of AI systems on the world around it and the impossibility of benchmarking ethics, it is necessary to investigate the tacit (often value-laden) aspects of model creation and deployment. Considering the values embedded in models is especially important because these can have major downstream impacts on the products and applications in which they are integrated, despite not being explicitly defined or communicated. In this section, we investigate these values by asking two key questions: What values are encoded in AI research? And, whose values are they?\n\n\n\n\n### \n4.1. What Values are Encoded in AI Research?\n\n\n\nModels and algorithms carry values encoded by the researchers and institutions that created them. However, these values are often not clearly stated during the peer-review process or subsequently, once the research is formally published. In a recent study,\u00a0Birhane et\u00a0al. ([2021a](#bib.bib31)) analysed 100100100100 highly-cited ML papers to identify their intrinsic values. They found that the most common values underlying this research include generalisation, efficiency, interpretability, and novelty\u2014although, these are rarely made explicit. Here, we examine two of the most prevalent values identified in the study: performance and building upon prior work. We discuss their repercussions on the field\u2019s priorities as a whole and the power dynamics that drive them.\n\n\n\n\nBirhane et\u00a0al. ([2021a](#bib.bib31)) report that the most common value held by the ML research community\u2014present in 87% of the papers analysed\u2014is performance. However, benchmarks are the main mechanism for tracking and reporting performance improvements, and we have already seen (Section\u00a0[2](#S2 \"2. Measuring Progress in Artificial Intelligence \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\")) that benchmarks have significant and well-known issues. Another known issue with this performance-centric value is that training higher-performing models often entails training larger models, given current paradigms in deep learning. However, requirements of size make performance contingent on access to ever-increasing quantities of data and computing power, which is increasingly unsustainable from an economic, technical, and environmental point of view\u00a0(Thompson\net\u00a0al., [2020](#bib.bib201); Bender et\u00a0al., [2021](#bib.bib22)).131313For example, Thompson\net\u00a0al. ([2020](#bib.bib201)) estimate that it would take an additional 105superscript10510^{5}10 start\\_POSTSUPERSCRIPT 5 end\\_POSTSUPERSCRIPT times more computation to achieve an error rate of 5555% for ImageNet, based on the current trend of computing requirements for ML. (The present error rate was estimated at 11.5%.) This increase would produce an additional 10,0001000010,00010 , 000 pounds of carbon emissions and cost millions of US dollars.\nA purely performance-focused mindset also adversely affects researchers from countries and regions with no access to large-scale computing infrastructures or expensive hardware. This disproportionate disadvantage further amplifies the extant power dynamics within the field\u00a0(Mohamed\net\u00a0al., [2020](#bib.bib156)). Finally, since performance is so highly-valued in the research community, this creates a negative feedback loop: undue emphasis on performance measures sways the course of subsequent research and influences the directions pursued by others, thus further orienting the field in the direction of pursuing performance as opposed to other, more varied pursuits\u00a0(Dotan and Milli, [2019](#bib.bib70)). There are currently limited mechanisms for flattening the exponential need for compute resources. And, the efficiency of models is not taken into account during their benchmarking.141414For example, a model that achieves an increased accuracy of 0.5% on ImageNet while requiring one month of compute is still considered \u2018better\u2019 than a model achieving an increase of 0.45% with only one week of compute.\nAlthough alternative approaches are possible\u2014for example, methods for improving neural networks\u2019 efficiency\u00a0(Wu\net\u00a0al., [2020](#bib.bib218); Chen\net\u00a0al., [2019](#bib.bib51)) and developing more optimised hardware accelerators\u00a0(Potok et\u00a0al., [2018](#bib.bib173))\u2014these are not currently mainstream endeavours.\n\n\n\n\nThe second most prevalent value identified value by\u00a0Birhane et\u00a0al. ([2021a](#bib.bib31)) is building on past work, which often is (explicitly or implicitly) bound up with valuing novelty. Indeed, the structure adopted by many ML papers hinges upon discussing similarities or differences to related works without questioning or critiquing them\u00a0(Langley, [2000](#bib.bib134)). The same consideration applies to datasets and benchmarks, which persist despite their shortcomings (including lack of applicability to any real-world deployment of the proposed algorithms)\u00a0(Raji et\u00a0al., [2021](#bib.bib175)). Even in cases where societal impacts are meant to be mentioned\u2014such as the increasingly-common \u2018broader impact\u2019 statements now appearing in conference submissions\u2014these statements often fail to address negative societal consequences, keeping any remarks high-level, abstract, or vague\u00a0(Nanayakkara et\u00a0al., [2021](#bib.bib163)). These difficulties have also contributed to a \u2018reproducibility crisis\u2019 in the field: endeavours that aim to reproduce ML research have systematically found that many peer-reviewed papers are missing information necessary for reproducibility\u00a0(Dodge et\u00a0al., [2019](#bib.bib69)). Sometimes these omissions are minor, such as failing to report random seeds and hyperparameter values; however, they can also be significant\u2014e.g., not sharing data and code\u00a0(Henderson et\u00a0al., [2018](#bib.bib106); Raff, [2019](#bib.bib174)). However, if past research is impossible to reproduce, it will also be impossible to build upon it (unless past results are taken for granted). Thus, even supposedly marginal details, like random seeds, can have significant downstream effects on future work since the results of past work may be entirely contingent upon these details.\n\n\n\n\nThe two values described above are especially pervasive in the field of large language models (LLMs), whose size has drastically increased in recent years: recent models boast progressively more parameters, which are now in the trillions\u00a0(Fedus\net\u00a0al., [2021](#bib.bib78)). However, descriptions of these models exclusively emphasise (1) their performance on the same set of benchmarks and (2) that their parameter-count is bigger than that of previous models. Certain relevant aspects of the model\u2014e.g., training time, energy consumption, or compute costs\u2014are often ignored.151515For instance, while the paper accompanying GPT-3\u2014a recent LLM with 175175175175 billion parameters\u2014reported its performance extensively on 42424242 \u2018accuracy-dominated benchmarks\u2019, the authors provided no details on training time or compute costs\u00a0(Brown\net\u00a0al., [2020](#bib.bib46)).\nThis lack of transparency regarding the negative impacts of ML models, with an emphasis on those deemed positive by the community at large (e.g., performance, novelty, etc.), further entrenches the presumed contributions of ML while sweeping the cost of these contributions under the rug. Furthermore, when researchers do criticise these models\u2019 shortcomings, they may be penalised by the very institutions whose business models hinge upon their success\u00a0(Dave and Dastin, [2021](#bib.bib62)). All this is to say that the values that are encoded by AI research are inherently subjective, so it is crucial to consider whose values models encode.\n\n\n\n\n\n### \n4.2. Whose Values are Encoded in AI Research?\n\n\n\nIn the history of AI research, the computational constraints of the late 1980s and early 90s forced researchers to make primarily theoretical progress on toy datasets or mathematical analysis\u00a0(Rumelhart\net\u00a0al., [1985](#bib.bib178); Bengio\net\u00a0al., [1994](#bib.bib24); LeCun\net\u00a0al., [1998](#bib.bib136)).\nThis focus shifted in the early 2010s when it became possible to train a deep neural network on a fairly large dataset using a single graphics processing unit (GPU) server\u00a0(Krizhevsky\net\u00a0al., [2012](#bib.bib129)). This breakthrough marked a new era in AI when it was possible for researchers to train models on local machines while making progress on datasets such as ImageNet\u00a0(Deng\net\u00a0al., [2009](#bib.bib64)) and MNIST\u00a0(LeCun, [1998](#bib.bib135)). This era did not last, however. In the last decade, the computing needs of AI have grown significantly, and most deep neural networks need to be trained on multiple GPUs, now measured in the hundreds or thousands\u00a0(Patterson et\u00a0al., [2021](#bib.bib169)).\n\n\n\n\nThis resource-intensive focus has contributed to a major shift in the power dynamics of the field insofar as it puts for-profit technological companies with large amounts of compute at an advantage compared to smaller companies and academic institutions\u00a0(Knight, [2021](#bib.bib123)). For example, Birhane et\u00a0al. ([2021a](#bib.bib31)) found that 79797979% of the highly-cited papers they analysed were written by authors with ties to corporations. This figure is corroborated by previous work that has analysed the increased presence and power that big tech companies wield in the field of AI\u00a0(Ahmed and Wahed, [2020](#bib.bib4); Abdalla and\nAbdalla, [2021](#bib.bib2)). Given the increased contributions of for-profit companies to AI research, it is important to keep track of their effect on research directions in the field. This situation constitutes a sort of value-alignment problem\u2014namely, the problem of aligning the \u2018goals\u2019 of AI systems with human values\u00a0(Gabriel, [2020](#bib.bib85); Russell, [2019](#bib.bib180); Christian, [2020](#bib.bib52))\u2014insofar as the incentives and goals of corporations may not align with a common good or the values of humanity, writ large\u00a0(LaCroix and\nBengio, [2019](#bib.bib132)). However, tracking these effects is difficult given the current lack of transparency around values driving industrial AI research.\n\n\n\n\nConcretely, the influence of for-profit corporations on AI research can vary, ranging from the seemingly harmless funding of academic research (provided that it aligns with a company\u2019s interests) to employing teams of researchers dedicated to pursuing in-house research. In the latter case, confidentiality may be protected by non-disclosure agreements, intellectual property laws, and multiple levels of compliance. Since salaries paid by academia and industry are increasingly disparate, more and more talented students and researchers are leaving academia for the prosperity promised by industry research, further widening the gap between the two camps\u00a0(Metz, [2018](#bib.bib150)). Abdalla and\nAbdalla ([2021](#bib.bib2)) highlight that the strategies employed by large technological corporations to maintain their freedom to develop and deploy AI tools and products while avoiding accountability and increased legislation are comparable to those employed by Big tobacco for decades to downplay the harmful effects of cigarettes. These techniques range from maintaining a socially acceptable image to influencing government legislation\u00a0(Abdalla and\nAbdalla, [2021](#bib.bib2)). These tactics are made possible by the extensive financial resources companies have, which far surpass the funding of academic institutions. \n\n\n\n\nIn the realm of moving research in an \u2018ethical\u2019 direction, ethics guidelines have proliferated in recent years\u00a0(Jobin\net\u00a0al., [2019](#bib.bib114)). These guidelines, codes, and principles come from various sources, including for-profit corporations. And, it has been pointed out that this implies that these stakeholders have a vested interest in shaping policies on AI ethics to fit their own priorities (Benkler, [2019](#bib.bib25); Greene\net\u00a0al., [2019](#bib.bib93); Jobin\net\u00a0al., [2019](#bib.bib114); Wagner, [2018](#bib.bib209); LaCroix and\nMohseni, [2020](#bib.bib133)). In the context of applied ethics, the current emphasis in AI research has been on the technical component of problems such as value alignment; this has the unfortunate consequence of ignoring the difficult work of determining which values are appropriate in the first place\u2014i.e., the normative component of value alignment\u00a0(Gabriel, [2020](#bib.bib85)).\n\n\n\n\nFurthermore, moral and political theory are deeply interconnected with the technical side of the AI alignment problem. And, as we argued in Section\u00a0[3](#S3 \"3. Moral Benchmarks for AI Systems \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\"), second-order ethical commitments are often taken for granted by AI researchers. More difficult still, suppose we discovered or determined that, e.g., utilitarianism is the objectively-correct normative theory. Even then, the utility considerations upon which this theory depends will always be relative to some frame. The theory prescribes maximising utility, but we must still ask: utility for whom? And, it is important to understand that no decisions made by researchers are value-free; this work is never neutral. As Green ([2019](#bib.bib92)) emphasises, \u2018[b]road cultural conceptions of science as neutral entrench the perspectives of dominant social groups, who are the only ones entitled to legitimate claims of neutrality\u2019.161616See also, (Haraway, [1988](#bib.bib97); Harding, [1998](#bib.bib98); Collins, [2000](#bib.bib55); Johnson, [2021](#bib.bib116)). \n\n\n\n\nWhen researchers say that such-and-such model \u2018is\u2019 ethical, or they unreflectively deploy normative terms like \u2018social good\u2019, this leaves certain metaethical and normative presuppositions and commitments implicit. Engaging in a discussion of values rather than ethics brings these commitments to the fore. Researchers are not warranted to say that any model is ethical unless they explicitly define what they mean by \u2018ethical\u2019\u2014high performance on a nonsense benchmark will not suffice. And, even then, the definition will be subject to criticism (if the history of Western philosophy is any indication).\n\n\n\n\nGiven all of the challenges and critiques presented in previous sections, it can be tempting to end our article here and conclude that it is impossible to measure morality and establish values for ethical AI research. However, we see several proactive and productive ways forward, which we present in the next section.\n\n5. Ways Forward\n----------------\n\n\n\nAI is still a relatively new and rapidly changing field. And, we have already seen some movement toward more socially-minded research and practice in recent years. However, we can still improve efforts to increase transparency and accountability within our community. Here, we list some tentative proposals.\n\n\n\n\na\n\n\n\n\nProposal 1. Shifting discourse from \u2018ethics\u2019 to \u2018values\u2019. This proposal follows the insights in Sections\u00a0[3](#S3 \"3. Moral Benchmarks for AI Systems \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\") and\u00a0[4](#S4 \"4. The Ethical Values of AI Research or: How ethics can be defined as a set of values \u2023 Metaethical Perspectives on \u2018Benchmarking\u2019 AI Ethics\"). \u2018Ethics\u2019 is a contested concept, and meta-ethical commitments are rarely explicitly stated. In contrast, \u2018values\u2019, while still ambiguous, are unequivocally relative. Thus, by consciously emphasising \u2018values\u2019 rather than \u2018ethics\u2019, researchers must grapple with what and whose values they are.\n\n\n\n\na\n\n\n\n\n\nProposal 2. Defining and communicating implicit values. Values influence how AI research is conducted. Therefore, to ensure transparency and accountability in research, these values should be made explicit and communicated clearly during the development and deployment of AI systems. For instance, researchers can make claims like, Model M\ud835\udc40Mitalic\\_M aligns with the set of values, V\ud835\udc49Vitalic\\_V, in context, C\ud835\udc36Citalic\\_C. When the variables in this statement are appropriately and thoughtfully filled in, this leads to the type of transparency necessary for criticism and, eventually, positive change. Publication venues might increase transparency with mechanisms like paper checklists which include some set of standards agreed upon by the community. Such standards may be generated through equitable and just processes to underscore democratic standards\u2014something that we value because of their importance to individual and social wellbeing\u00a0(V\u00e9liz, [2020](#bib.bib207)). Another possibility is that publication venues provide a list of values to be selected, so that trade-offs between, e.g., performance and accessibility, would be made explicit and may be taken into account when evaluating the paper\u2019s contribution to the field\u00a0(Birhane et\u00a0al., [2021a](#bib.bib31)). Over time, conventions may be established whereby too great a misalignment of values is (at least partial) cause for rejection, thus providing additional incentives for researchers to take these considerations seriously.171717Of course, some readers might be uncomfortable with this proposal, suggesting that rejection based on misaligned values amounts to censorship. To this, we say the following: this is already how peer review works, insofar as articles are reviewed and rejected by human beings, who carry with them myriad subjective values. The only difference is that these values are not transparent in the present setup. All the same check-and-balance mechanisms will be in place to ensure fair review processes. For example, an area chair for a conference might determine that the values emphasised by the paper are, in fact, appropriately aligned, and perhaps the reviewer\u2019s own biases and values are colouring the review. In any case, the target outcome of defining and communicating implicit values is that researchers pause and reflect upon their values.\n\n\n\n\na\n\n\n\n\nProposal 3. Making voluntary initiatives mandatory. Although checklists for papers are starting to become part of the submission process for many conferences and journals their elements remain voluntary in most cases (e.g. [NeurIPS](https://neuripsconf.medium.com/introducing-the-neurips-2021-paper-checklist-3220d6df500b), [ICML](https://icml.cc/Conferences/2020/StyleAuthorInstructions)). To compel the community to be more forthcoming regarding the details of their training approaches and the impacts of their research, many of these elements should become mandatory. This mandate may include sharing data and code\u2014including all hyperparameter values and seeds\u2014and information regarding the training procedure\u2014such as the quantity and type of hardware used, total training time and location of training. Substantial steps are being made towards this by initiatives like the [ACL Rolling Review](https://aclrollingreview.org/responsibleNLPresearch/). However, similar initiatives are missing in other research areas, such as computer vision and ML in general. Some consistency is necessary across venues to promote widespread adoption.\n\n\n\n\na\n\n\n\n\nProposal 4. Disclosure of funding sources and conflicts of interest. Although the voluntary disclosure of funding sources is also becoming part of the paper submission process in certain AI conferences, it is far from common. There is also a lack of clarity around what disclosure entails. For example, it is not always clear whether authors should disclose travel or compute grants from private companies or the funding of interns via private-public partnerships\u00a0(Abdalla and\nAbdalla, [2021](#bib.bib2)). Similarly, it is not always clear how venues and associations will use this information\u2014e.g., whether it is strictly internal or if the information will be shared publicly upon acceptance. More information is needed about what funding disclosures entail, accompanied by public discussions about how best to disseminate this information. In the social sciences, it is not uncommon for granting agencies to require funding disclosure for all research that was supported, even in part, by that grant. Indeed, some granting agencies require that all research resulting from their grants be made publicly available.181818For example, the Canadian Tri-Agency\u2014CIHR, NSERC, and SSHRC\u2014require any publications arising from Agency-supported research are freely accessible within 12 months of publication. This mandate follows from the assumption that \u2018[s]ocietal advancement is made possible through widespread and barrier-free access to cutting-edge research and knowledge\u2019. See here: <https://www.ic.gc.ca/eic/site/063.nsf/eng/h_F6765465.html>.\nThis requirement serves to promote the public dissemination of knowledge. At the same time, it makes potential conflicts of interest more transparent.\n\n\n\n\na\n\n\n\n\nProposal 5. Transparency around internal review and compliance processes. For many researchers working in private companies, internal review processes are a mandatory part of publishing outside the company. These processes often entail changes to the original content written by paper authors. The changes made due to this internal process and the teams (or individuals) involved should be included as part of the final publication\u2014for example, in the acknowledgements section\u2014to make the process more transparent and ensure internal and external accountability.\n\n\n\n\na\n\n\n\n\nProposal 6. Mindful and contextual benchmarking. While it may be tempting to use benchmarks as indicators of high-level skills and for reporting \u2018human-level performance\u2019\u2014e.g., in the way that Super GLUE\u00a0(Wang et\u00a0al., [2019](#bib.bib211)) does for natural language understanding\u2014this is misleading. AI researchers need to be mindful and reflective regarding the capabilities and limitations of both AI models and benchmarks. Reporting progress made on specific benchmarks should be in the specific content of intended models and the framing of the task. For example, \u2018Model X\ud835\udc4bXitalic\\_X has achieved Y%percent\ud835\udc4cY\\%italic\\_Y % accuracy on the co-reference resolution subset of the SuperGLUE dataset, framed as a binary classification task\u2019. Reporting metrics other than accuracy, such as F1-score, and carrying out more in-depth error analysis can paint a more nuanced picture of performance, highlighting what models have yet to succeed on and sharing failure cases with the community.\n\n\n\n\na\n\n\n\n\nProposal 7. Internal Review Boards for AI research. Human-centred disciplines, like psychology and medicine, have mandatory Internal Review Boards (IRBs) whose goal is to protect human subjects from physical or psychological harm due to the nature of the research carried out. While AI has historically been perceived as a field of research entirely detached from human subjects, recent years have proved this to be fallacious\u00a0(Whittaker, [2021](#bib.bib215); Birhane and\nCummins, [2019](#bib.bib30)). As such, AI research ranging from data collection to model training should be subject to reviews involving IRBs. This review process might be done internally at institutions or externally at the level of journals and conferences and could require formal review procedures for AI research encompassing criteria such as human rights, impact assessment, and consent.\n\n\n\n\na\n\n\n\n\nProposal 8. Incentivising multi-disciplinary research. Unfortunately, much of AI research is still siloed, carried out mostly by computer scientists in technology companies or computer science faculties, surrounded by other like-minded computer scientists, with limited diversity in terms of gender and race. While this has worked moderately well for the last few decades, \u2014predominantly during the theoretical era of AI, when much of the improvements made to models were fundamental\u2014 this is no longer ideal given the increasingly fine line between AI research and practice and the range of stakeholders AI affects. Working across disciplines with teams spanning from computer science to the humanities and social sciences allows for cross-pollination between different disciplines, resulting in new ideas and new approaches to existing methods. Despite these advantages, publishing multi-disciplinary research in many AI conferences remains a challenge, both for picking a track or topic and for receiving relevant reviews that recognise contributions from non-AI disciplines as worthy of publication. Additionally, disparate disciplines have distinct metrics for hiring and promotion that disincentivises researchers from engaging in inter-disciplinary research in the first place\u2014for example, journal articles are the currency of the realm for hiring and promotion in philosophy, whereas ML research is mainly published in conference proceedings, which do not carry as much weight in other disciplines.\n\n\n\n\na\n\n\n\n\nProposal 9. Improving knowledge and awareness. We are aware that many of the proposals we make above are difficult to implement immediately given that they entail extensive capacity-building to empower researchers, institutions, and communities with the necessary tools, skills, and knowledge. The keystone to all this is therefore adequate education and awareness-raising within the AI community around ethics and values-driven research. This involves intentionally giving researchers from other disciplines\u2014especially the social science and humanities\u2014the floor at AI conferences and workshops, and including them in the development of review processes and guidelines for IRBs. Adding mandatory courses in cultural and sociotechnical studies (given by experts from these domains) to AI curricula is another lever that will empower new generations of AI researchers to be better prepared and equipped to carry out values-sensitive research and improve the state of the field in the long-run.\n\n\n\n\na\n\n\n\n\nProposal 10. Practising epistemic humility. Media coverage of advances in AI research is often ridiculed for being overly sensationalist. The problem here is that the reports often inaccurately capture what models are actually capable of doing. For example, The Independent reported that Facebook\u2019s AI robots were \u2018shut down after they start[ed] talking to each other in their own language\u2019\u00a0(Griffin, [2017](#bib.bib95)). Despite that this is absurd to anyone familiar with the research, the claims of many research papers in AI are equally ostentatious (if shrouded in more formal dressing). It is a difficult practice to ensure the claims of one\u2019s paper do not outrun the evidence proffered, especially in a field that incentivises intellectual arrogance by demanding novelty as a (near) prerequisite for publication. However, humility (in the sense of \u2018accuracy\u2019 rather than \u2018modesty\u2019, per se) is a virtue\u00a0(Aristotle, [1995](#bib.bib10)).\n\n6. Conclusion\n--------------\n\n\n\nBenchmarking ethics would require a ground truth about ethical claims. A \u2018commonsense\u2019 view of morality presupposes that ethics is objective. Researchers in AI have taken this view for granted. We suggested, along with the typical problems to which benchmarking gives rise in the standard setting, benchmarking ethics is impossible. Whereas it is easy to fall into the trap of commonsense when discussing ethics, normative concepts like \u2018values\u2019 and \u2018preferences\u2019 are unambiguously relative. Therefore, we argued, shifting ethics-talk to talk of values forces researchers to consider explicitly what and whose values they are, thus making research more transparent and providing further opportunity for positive change.", "url": "https://arxiv.org/abs/2204.05151"}
{"text": "1 Introduction\n---------------\n\n\n\nMany recent studies have shown that (deep) reinforcement learning (RL) algorithms can achieve great progress when making use of regularization, though they may be derived from different motivations, such as robust policy optimization (Schulman et\u00a0al. [2015](#bib.bib17), [2017](#bib.bib18)) or efficient exploration (Haarnoja et\u00a0al. [2017](#bib.bib6), [2018a](#bib.bib7)). According to the reformulation in (Vieillard, Pietquin, and Geist [2020](#bib.bib22); Vieillard et\u00a0al. [2020](#bib.bib21)), Advantage Learning (AL) (Bellemare et\u00a0al. [2016](#bib.bib2)) can also be viewed as a variant of the Bellman optimality operator imposed by an implicit Kullback-Leibler (KL) regularization between two consecutive policies. And this KL penalty can help to reduce the policy search space for stable and efficient optimization.\n\n\n\n\nSpecifically, the AL operator adds a scaling advantage value term to Bellman optimality operator. Besides transformed into an implicit KL-regularized update, this operator can directly increase the gap between the optimal and suboptimal actions, called action gap. (Bellemare et\u00a0al. [2016](#bib.bib2)) shows that increasing this gap is beneficial, and especially a large gap can mitigate the undesirable effects of estimation errors from the approximation function.\n\n\n\n\nHowever, a potential problem less studied by previous research is that the advantage term may become a burden if the optimal action induced by the approximated value function does not align with the true optimal action. This mismatch is common when there exists under-exploration about the current MDP and would lead to a negative advantage term for the true optimal action at the next iteration.\nConsequently, the AL operator could hinder the value improvement about the true optimal and may lead to suboptimal policies.\nTo investigate this issue, we provide an in-depth analysis on the relationship between advantage term and performance loss bound for the AL operator.\nThe theoretical result shows that the advantage term could lead to more cumulative errors in performance loss bound while increasing the action gap, hence slowing down the value/policy update. We further illustrate this problem by a classic chain-walk example.\n\n\n\n\nTo address the above issue, we present an improved AL algorithm named clipped Advantage Learning (clipped AL). Our key idea can be summarized as \u201dadvantage term should not be added without necessity\u201d according to the principle of Occam\u2019s razor.\nIntuitively, assume that the optimal action induced by the approximated value function were wrong (which is highly likely at the early stage of the training), the action gap term works just like a regularization imposed on two randomly suboptimal actions and hence it makes no sense to continuously enlarge their gap if it has already been very large. Based on this observation, during AL training we first determine whether the current action gap is too small and only increase this gap if it is below some predefined threshold. This can be easily implemented with a clipping function, and hence we call the resulting method Clipped AL. We show that, with this simple mechanism, we could significantly improve the stability of the AL training by reducing the potential adverse effects when the induced optimal action is wrong.\nBesides, clipped AL adopts an adaptive clipping mechanism to adjust the advantage term more reasonably for a robust action gap increasing. From the perspective of implicit regularization, clipped AL can also be viewed as a relaxation on the KL constraints.\nWe prove that a theoretical balance between fast convergence and large action gap can be achieved by clipped AL.\nEmpirical performance on popular RL benchmarks also verifies the feasibility and effectiveness of our clipped AL.\n\n2 Related Work\n---------------\n\n\n\nTo better understand Advantage Learning, many researchers have tried to analyze and explain the actual effects of action-gap regularity adopted by the AL operator. Farahmand (Farahmand [2011](#bib.bib3)) studied the action gap phenomenon for two-action discounted MDPs and proved that smaller performance loss could be achieved by the problem with a favorable action-gap regularity. Vieillard et al. (Vieillard, Pietquin, and Geist [2020](#bib.bib22)) drew a connection between an implicit KL regularization with action-gap regularity, which is thought of as beneficial to stable learning. Besides, Seijen et al. (van Seijen, Fatemi, and Tavakoli [2019](#bib.bib20)) proposed a hypothesis that a larger difference in the action-gap sizes across the state-space would hurt the performance of approximate RL, which was also supported by strong empirical evidence.\n\n\n\n\nRecent work aims to improve advantage learning mainly from two perspectives. One direction is to extend the idea of AL to the other RL methods. For example, Ferret et al. (Ferret, Pietquin, and Geist [2021](#bib.bib5)) connected self-imitation learning (SIL) (Oh et\u00a0al. [2018](#bib.bib16)) with AL for an optimistic exploration, while by incorporating the AL operator with Retrace (Munos et\u00a0al. [2016](#bib.bib15)), Kozuno et al. (Kozuno, Han, and Doya [2019](#bib.bib10)) proposed a multi-step version of the AL algorithm. Another direction is to seek a more robust gap-increasing. Conservative valuation iteration (CVI) (Kozuno, Uchibe, and Doya [2019](#bib.bib12)) achieved a soft gap-increasing by replacing max\\maxroman\\_max operators in AL with softmax ones, which could control the trade-off between error-tolerance and convergence rate. Munchausen DQN (MDQN) (Vieillard, Pietquin, and Geist [2020](#bib.bib22)) also adopted a clipping function on its log-policy term so as to avoid the numerical issue, when implementing the soft gap-increasing.\n\n3 Preliminaries\n----------------\n\n\n\nWe also formulate the RL problem within the Markov Decision Processes (MDP) framework as commonly considered. Each specific MDP can be modeled as a unique tuple \u2133=\u27e8\ud835\udcae,\ud835\udc9c,P,r,\u03b3\u27e9\u2133\ud835\udcae\ud835\udc9c\ud835\udc43\ud835\udc5f\ud835\udefe\\mathcal{M}=\\langle\\mathcal{S},\\mathcal{A},P,r,\\gamma\\ranglecaligraphic\\_M = \u27e8 caligraphic\\_S , caligraphic\\_A , italic\\_P , italic\\_r , italic\\_\u03b3 \u27e9, where \ud835\udcae\ud835\udcae\\mathcal{S}caligraphic\\_S and \ud835\udc9c\ud835\udc9c\\mathcal{A}caligraphic\\_A denote the state and action space, P\ud835\udc43Pitalic\\_P is the Markov transition probability function P:\ud835\udcae\u00d7\ud835\udc9c\u00d7\ud835\udcae\u2192[0,1]:\ud835\udc43\u2192\ud835\udcae\ud835\udc9c\ud835\udcae01P:\\mathcal{S}\\times\\mathcal{A}\\times\\mathcal{S}\\rightarrow[0,1]italic\\_P : caligraphic\\_S \u00d7 caligraphic\\_A \u00d7 caligraphic\\_S \u2192 [ 0 , 1 ], r\ud835\udc5fritalic\\_r represents the reward function r:\ud835\udcae\u00d7\ud835\udc9c\u2192[Rmin,Rmax]:\ud835\udc5f\u2192\ud835\udcae\ud835\udc9csubscript\ud835\udc45subscript\ud835\udc45r:\\mathcal{S}\\times\\mathcal{A}\\rightarrow[R\\_{\\min},R\\_{\\max}]italic\\_r : caligraphic\\_S \u00d7 caligraphic\\_A \u2192 [ italic\\_R start\\_POSTSUBSCRIPT roman\\_min end\\_POSTSUBSCRIPT , italic\\_R start\\_POSTSUBSCRIPT roman\\_max end\\_POSTSUBSCRIPT ], and \u03b3\ud835\udefe\\gammaitalic\\_\u03b3 is the discount factor. The RL agent interacts with the environment following a policy \u03c0:\ud835\udcae\u00d7\ud835\udc9c\u2192[0,1]:\ud835\udf0b\u2192\ud835\udcae\ud835\udc9c01\\pi:\\mathcal{S}\\times\\mathcal{A}\\rightarrow[0,1]italic\\_\u03c0 : caligraphic\\_S \u00d7 caligraphic\\_A \u2192 [ 0 , 1 ]111Note that we may slightly abuse some function notations as the corresponding vector notations in the later, which depends on the context.\n\n\n\n\n### Bellman Operator\n\n\n\nIn common to estimate the quality of a policy, the expected discounted cumulative return, denoted by the state value function V\u03c0(s)=\ud835\udd3c\u03c0[\u2211t=0\u221e\u03b3tr(st,at)|s0=s]superscript\ud835\udc49\ud835\udf0b\ud835\udc60subscript\ud835\udd3c\ud835\udf0bdelimited-[]conditionalsuperscriptsubscript\ud835\udc610superscript\ud835\udefe\ud835\udc61\ud835\udc5fsubscript\ud835\udc60\ud835\udc61subscript\ud835\udc4e\ud835\udc61subscript\ud835\udc600\ud835\udc60V^{\\pi}(s)=\\mathbb{E}\\_{\\pi}\\left[\\sum\\_{t=0}^{\\infty}\\gamma^{t}r(s\\_{t},a\\_{t})|s\\_{0}=s\\right]italic\\_V start\\_POSTSUPERSCRIPT italic\\_\u03c0 end\\_POSTSUPERSCRIPT ( italic\\_s ) = blackboard\\_E start\\_POSTSUBSCRIPT italic\\_\u03c0 end\\_POSTSUBSCRIPT [ \u2211 start\\_POSTSUBSCRIPT italic\\_t = 0 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT \u221e end\\_POSTSUPERSCRIPT italic\\_\u03b3 start\\_POSTSUPERSCRIPT italic\\_t end\\_POSTSUPERSCRIPT italic\\_r ( italic\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT , italic\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT ) | italic\\_s start\\_POSTSUBSCRIPT 0 end\\_POSTSUBSCRIPT = italic\\_s ], is chosen as the evaluation criterion, where \ud835\udd3c\u03c0subscript\ud835\udd3c\ud835\udf0b\\mathbb{E}\\_{\\pi}blackboard\\_E start\\_POSTSUBSCRIPT italic\\_\u03c0 end\\_POSTSUBSCRIPT represents the expectation over all trajectories (s0,a0,r0,\u22efst,at,rt\u22ef)subscript\ud835\udc600subscript\ud835\udc4e0subscript\ud835\udc5f0\u22efsubscript\ud835\udc60\ud835\udc61subscript\ud835\udc4e\ud835\udc61subscript\ud835\udc5f\ud835\udc61\u22ef\\left(s\\_{0},a\\_{0},r\\_{0},\\cdots s\\_{t},a\\_{t},r\\_{t}\\cdots\\right)( italic\\_s start\\_POSTSUBSCRIPT 0 end\\_POSTSUBSCRIPT , italic\\_a start\\_POSTSUBSCRIPT 0 end\\_POSTSUBSCRIPT , italic\\_r start\\_POSTSUBSCRIPT 0 end\\_POSTSUBSCRIPT , \u22ef italic\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT , italic\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT , italic\\_r start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT \u22ef ) sampled by \u03c0\ud835\udf0b\\piitalic\\_\u03c0 and P\ud835\udc43Pitalic\\_P. And similarly, the action-state value function is defined as Q\u03c0(s,a)=\ud835\udd3c\u03c0[\u2211t=0\u221e\u03b3tr(st,at)|s0=s,a0=a]superscript\ud835\udc44\ud835\udf0b\ud835\udc60\ud835\udc4esubscript\ud835\udd3c\ud835\udf0bdelimited-[]formulae-sequenceconditionalsuperscriptsubscript\ud835\udc610superscript\ud835\udefe\ud835\udc61\ud835\udc5fsubscript\ud835\udc60\ud835\udc61subscript\ud835\udc4e\ud835\udc61subscript\ud835\udc600\ud835\udc60subscript\ud835\udc4e0\ud835\udc4eQ^{\\pi}(s,a)=\\mathbb{E}\\_{\\pi}\\left[\\sum\\_{t=0}^{\\infty}\\gamma^{t}r(s\\_{t},a\\_{t})|s\\_{0}=s,a\\_{0}=a\\right]italic\\_Q start\\_POSTSUPERSCRIPT italic\\_\u03c0 end\\_POSTSUPERSCRIPT ( italic\\_s , italic\\_a ) = blackboard\\_E start\\_POSTSUBSCRIPT italic\\_\u03c0 end\\_POSTSUBSCRIPT [ \u2211 start\\_POSTSUBSCRIPT italic\\_t = 0 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT \u221e end\\_POSTSUPERSCRIPT italic\\_\u03b3 start\\_POSTSUPERSCRIPT italic\\_t end\\_POSTSUPERSCRIPT italic\\_r ( italic\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT , italic\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT ) | italic\\_s start\\_POSTSUBSCRIPT 0 end\\_POSTSUBSCRIPT = italic\\_s , italic\\_a start\\_POSTSUBSCRIPT 0 end\\_POSTSUBSCRIPT = italic\\_a ]. What an optimal policy aims at is to maximize the value function V\u03c0(s)superscript\ud835\udc49\ud835\udf0b\ud835\udc60V^{\\pi}(s)italic\\_V start\\_POSTSUPERSCRIPT italic\\_\u03c0 end\\_POSTSUPERSCRIPT ( italic\\_s ) or Q\u03c0(s,a)superscript\ud835\udc44\ud835\udf0b\ud835\udc60\ud835\udc4eQ^{\\pi}(s,a)italic\\_Q start\\_POSTSUPERSCRIPT italic\\_\u03c0 end\\_POSTSUPERSCRIPT ( italic\\_s , italic\\_a ) over the space of non-stationary and randomized policies \u03a0\u03a0\\Piroman\\_\u03a0: V\\*(s)=sup\u03c0\u2208\u03a0V\u03c0(s)superscript\ud835\udc49\ud835\udc60subscriptsupremum\ud835\udf0b\u03a0superscript\ud835\udc49\ud835\udf0b\ud835\udc60V^{\\*}(s)=\\sup\\_{\\pi\\in\\Pi}V^{\\pi}(s)italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ) = roman\\_sup start\\_POSTSUBSCRIPT italic\\_\u03c0 \u2208 roman\\_\u03a0 end\\_POSTSUBSCRIPT italic\\_V start\\_POSTSUPERSCRIPT italic\\_\u03c0 end\\_POSTSUPERSCRIPT ( italic\\_s ), and Q\\*(s,a)=sup\u03c0\u2208\u03a0Q\u03c0(s,a)superscript\ud835\udc44\ud835\udc60\ud835\udc4esubscriptsupremum\ud835\udf0b\u03a0superscript\ud835\udc44\ud835\udf0b\ud835\udc60\ud835\udc4eQ^{\\*}(s,a)=\\sup\\_{\\pi\\in\\Pi}Q^{\\pi}(s,a)italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s , italic\\_a ) = roman\\_sup start\\_POSTSUBSCRIPT italic\\_\u03c0 \u2208 roman\\_\u03a0 end\\_POSTSUBSCRIPT italic\\_Q start\\_POSTSUPERSCRIPT italic\\_\u03c0 end\\_POSTSUPERSCRIPT ( italic\\_s , italic\\_a ).\nAnd it has been shown that there exists a stationary and deterministic \u03c0\\*superscript\ud835\udf0b\\pi^{\\*}italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT that satisfies V\u03c0\\*=V\\*superscript\ud835\udc49superscript\ud835\udf0bsuperscript\ud835\udc49V^{\\pi^{\\*}}=V^{\\*}italic\\_V start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT end\\_POSTSUPERSCRIPT = italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT and Q\u03c0\\*=Q\\*superscript\ud835\udc44superscript\ud835\udf0bsuperscript\ud835\udc44Q^{\\pi^{\\*}}=Q^{\\*}italic\\_Q start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT end\\_POSTSUPERSCRIPT = italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT for each \u2133\u2133\\mathcal{M}caligraphic\\_M.\n\n\n\n\n\nAs we all know, the optimal state-action value function Q\\*superscript\ud835\udc44Q^{\\*}italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT shared by all the optimal policies satisfies the Bellman optimality equation:\n\n\n\n\n|  |  |  |  |\n| --- | --- | --- | --- |\n|  | Q\\*(s,a)=r(s,a)+\u03b3\ud835\udd3cs\u2032\u223cP(\u22c5|s,a)[maxa\u2032\u2061Q\\*(s\u2032,a\u2032)]Q^{\\*}(s,a)=r(s,a)+\\gamma\\mathbb{E}\\_{s^{\\prime}\\sim P(\\cdot|s,a)}\\left[\\max\\_{a^{\\prime}}Q^{\\*}(s^{\\prime},a^{\\prime})\\right]italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s , italic\\_a ) = italic\\_r ( italic\\_s , italic\\_a ) + italic\\_\u03b3 blackboard\\_E start\\_POSTSUBSCRIPT italic\\_s start\\_POSTSUPERSCRIPT \u2032 end\\_POSTSUPERSCRIPT \u223c italic\\_P ( \u22c5 | italic\\_s , italic\\_a ) end\\_POSTSUBSCRIPT [ roman\\_max start\\_POSTSUBSCRIPT italic\\_a start\\_POSTSUPERSCRIPT \u2032 end\\_POSTSUPERSCRIPT end\\_POSTSUBSCRIPT italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s start\\_POSTSUPERSCRIPT \u2032 end\\_POSTSUPERSCRIPT , italic\\_a start\\_POSTSUPERSCRIPT \u2032 end\\_POSTSUPERSCRIPT ) ] |  | (1) |\n\n\nBy rewriting Eq.([1](#S3.E1 \"1 \u2023 Bellman Operator \u2023 3 Preliminaries \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\")) as the vector form, we can define the Bellman optimality operator \ud835\udcaf:\u211d|\ud835\udcae||\ud835\udc9c|\u2192\u211d|\ud835\udcae||\ud835\udc9c|:\ud835\udcaf\u2192superscript\u211d\ud835\udcae\ud835\udc9csuperscript\u211d\ud835\udcae\ud835\udc9c\\mathcal{T}:\\mathbb{R}^{|\\mathcal{S}||\\mathcal{A}|}\\rightarrow\\mathbb{R}^{|\\mathcal{S}||\\mathcal{A}|}caligraphic\\_T : blackboard\\_R start\\_POSTSUPERSCRIPT | caligraphic\\_S | | caligraphic\\_A | end\\_POSTSUPERSCRIPT \u2192 blackboard\\_R start\\_POSTSUPERSCRIPT | caligraphic\\_S | | caligraphic\\_A | end\\_POSTSUPERSCRIPT as:\n\n\n\n\n\n|  |  |  |  |\n| --- | --- | --- | --- |\n|  | \ud835\udcafQ\u225cr+\u03b3PV\u225c\ud835\udcaf\ud835\udc44\ud835\udc5f\ud835\udefe\ud835\udc43\ud835\udc49\\mathcal{T}Q\\triangleq r+\\gamma PVcaligraphic\\_T italic\\_Q \u225c italic\\_r + italic\\_\u03b3 italic\\_P italic\\_V |  | (2) |\n\n\nwhere P\u2208\u211d|\ud835\udcae||\ud835\udc9c|\u00d7|\ud835\udcae|,Q\u2208\u211d|\ud835\udcae||\ud835\udc9c|,V\u2208\u211d|\ud835\udcae|formulae-sequence\ud835\udc43superscript\u211d\ud835\udcae\ud835\udc9c\ud835\udcaeformulae-sequence\ud835\udc44superscript\u211d\ud835\udcae\ud835\udc9c\ud835\udc49superscript\u211d\ud835\udcaeP\\in\\mathbb{R}^{|\\mathcal{S}||\\mathcal{A}|\\times|\\mathcal{S}|},Q\\in\\mathbb{R}^{|\\mathcal{S}||\\mathcal{A}|},V\\in\\mathbb{R}^{|\\mathcal{S}|}italic\\_P \u2208 blackboard\\_R start\\_POSTSUPERSCRIPT | caligraphic\\_S | | caligraphic\\_A | \u00d7 | caligraphic\\_S | end\\_POSTSUPERSCRIPT , italic\\_Q \u2208 blackboard\\_R start\\_POSTSUPERSCRIPT | caligraphic\\_S | | caligraphic\\_A | end\\_POSTSUPERSCRIPT , italic\\_V \u2208 blackboard\\_R start\\_POSTSUPERSCRIPT | caligraphic\\_S | end\\_POSTSUPERSCRIPT and V(s)=maxa\u2061Q(s,a)\ud835\udc49\ud835\udc60subscript\ud835\udc4e\ud835\udc44\ud835\udc60\ud835\udc4eV(s)=\\max\\_{a}Q(s,a)italic\\_V ( italic\\_s ) = roman\\_max start\\_POSTSUBSCRIPT italic\\_a end\\_POSTSUBSCRIPT italic\\_Q ( italic\\_s , italic\\_a ). \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T is a contraction operator whose unique fixed point is the optimal action-state function Q\\*superscript\ud835\udc44Q^{\\*}italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT.\n\n\n\n\n\n### Advantage Learning\n\n\n\nIn complex tasks, the Q\ud835\udc44Qitalic\\_Q value function is usually approximated by a parameterized neural network Q\u03b8(s,a)subscript\ud835\udc44\ud835\udf03\ud835\udc60\ud835\udc4eQ\\_{\\theta}(s,a)italic\\_Q start\\_POSTSUBSCRIPT italic\\_\u03b8 end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ), of which one obvious challenge is its robustness to the estimation errors.\nAnd to mitigate this issue, Advantage Learning (AL) (Bellemare et\u00a0al. [2016](#bib.bib2)) is proposed to increase the action gap\n, i.e., the difference between the optimal action value and the suboptimal ones, and its operator can be defined as:\n\n\n\n\n|  |  |  |  |\n| --- | --- | --- | --- |\n|  | \ud835\udcafALQ(s,a)\u225c\ud835\udcafQ(s,a)\u2212\u03b1(V(s)\u2212Q(s,a))\u225csubscript\ud835\udcafAL\ud835\udc44\ud835\udc60\ud835\udc4e\ud835\udcaf\ud835\udc44\ud835\udc60\ud835\udc4e\ud835\udefc\ud835\udc49\ud835\udc60\ud835\udc44\ud835\udc60\ud835\udc4e\\mathcal{T}\\_{\\rm{AL}}Q(s,a)\\triangleq\\mathcal{T}Q(s,a)-\\alpha\\left(V(s)-Q(s,a)\\right)caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT italic\\_Q ( italic\\_s , italic\\_a ) \u225c caligraphic\\_T italic\\_Q ( italic\\_s , italic\\_a ) - italic\\_\u03b1 ( italic\\_V ( italic\\_s ) - italic\\_Q ( italic\\_s , italic\\_a ) ) |  | (3) |\n\n\n\n\nWhere the scaling parameter \u03b1\u2208[0,1)\ud835\udefc01\\alpha\\in[0,1)italic\\_\u03b1 \u2208 [ 0 , 1 ). Compared to \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T, the only modification in the AL operator is the addition of a scaling advantage function A(s,a)=Q(s,a)\u2212V(s)\ud835\udc34\ud835\udc60\ud835\udc4e\ud835\udc44\ud835\udc60\ud835\udc4e\ud835\udc49\ud835\udc60A(s,a)=Q(s,a)-V(s)italic\\_A ( italic\\_s , italic\\_a ) = italic\\_Q ( italic\\_s , italic\\_a ) - italic\\_V ( italic\\_s ) for each state-action pair and \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT is consistent with \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T when \u03b1=0\ud835\udefc0\\alpha=0italic\\_\u03b1 = 0.\nIdeally, \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT will decrease the value of suboptimal actions (as A(s,a)<0\ud835\udc34\ud835\udc60\ud835\udc4e0A(s,a)<0italic\\_A ( italic\\_s , italic\\_a ) < 0), and keep the consistent optimal action value with \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T (as A(s,a\\*)=0\ud835\udc34\ud835\udc60superscript\ud835\udc4e0A(s,a^{\\*})=0italic\\_A ( italic\\_s , italic\\_a start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ) = 0). The AL operator has also been proved (Theorem 1 in (Bellemare et\u00a0al. [2016](#bib.bib2))) to obtain some critical properties: optimality-preserving and gap-increasing, which defined as the following:\n\n\n\n\n###### \nDefinition 1 (optimality-preserving).\n\n\n\nAn operator \ud835\udcaf\u2032superscript\ud835\udcafnormal-\u2032\\mathcal{T}^{\\prime}caligraphic\\_T start\\_POSTSUPERSCRIPT \u2032 end\\_POSTSUPERSCRIPT is optimality-preserving if, for \u2200Q0\u2208\ud835\udcacfor-allsubscript\ud835\udc440\ud835\udcac\\forall\\;Q\\_{0}\\in\\mathcal{Q}\u2200 italic\\_Q start\\_POSTSUBSCRIPT 0 end\\_POSTSUBSCRIPT \u2208 caligraphic\\_Q and s\u2208\ud835\udcae\ud835\udc60\ud835\udcaes\\in\\mathcal{S}italic\\_s \u2208 caligraphic\\_S, letting Qk+1=\ud835\udcaf\u2032Qksubscript\ud835\udc44\ud835\udc581superscript\ud835\udcafnormal-\u2032subscript\ud835\udc44\ud835\udc58Q\\_{k+1}=\\mathcal{T}^{\\prime}Q\\_{k}italic\\_Q start\\_POSTSUBSCRIPT italic\\_k + 1 end\\_POSTSUBSCRIPT = caligraphic\\_T start\\_POSTSUPERSCRIPT \u2032 end\\_POSTSUPERSCRIPT italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT,\n\n\n\n\n|  |  |  |\n| --- | --- | --- |\n|  | V^(s)\u225climk\u2192\u221emaxa\u2208\ud835\udc9c\u2061Qk(s,a)\u225c^\ud835\udc49\ud835\udc60subscript\u2192\ud835\udc58subscript\ud835\udc4e\ud835\udc9csubscript\ud835\udc44\ud835\udc58\ud835\udc60\ud835\udc4e\\hat{V}(s)\\triangleq\\lim\\_{k\\rightarrow\\infty}\\max\\_{a\\in\\mathcal{A}}Q\\_{k}(s,a)over^ start\\_ARG italic\\_V end\\_ARG ( italic\\_s ) \u225c roman\\_lim start\\_POSTSUBSCRIPT italic\\_k \u2192 \u221e end\\_POSTSUBSCRIPT roman\\_max start\\_POSTSUBSCRIPT italic\\_a \u2208 caligraphic\\_A end\\_POSTSUBSCRIPT italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ) |  |\n\n\nexists, is unique, V^(s)=V\\*(s)normal-^\ud835\udc49\ud835\udc60superscript\ud835\udc49\ud835\udc60\\hat{V}(s)=V^{\\*}(s)over^ start\\_ARG italic\\_V end\\_ARG ( italic\\_s ) = italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ), and for \u2200a\u2208\ud835\udc9cfor-all\ud835\udc4e\ud835\udc9c\\forall a\\in\\mathcal{A}\u2200 italic\\_a \u2208 caligraphic\\_A,\n\n\n\n\n|  |  |  |\n| --- | --- | --- |\n|  | Q\\*(s,a)<V\\*(s)\u21d2lim supk\u2192\u221eQk(s,a)<V\\*(s)superscript\ud835\udc44\ud835\udc60\ud835\udc4esuperscript\ud835\udc49\ud835\udc60\u21d2subscriptlimit-supremum\u2192\ud835\udc58subscript\ud835\udc44\ud835\udc58\ud835\udc60\ud835\udc4esuperscript\ud835\udc49\ud835\udc60Q^{\\*}(s,a)<V^{\\*}(s)\\Rightarrow\\limsup\\_{k\\rightarrow\\infty}Q\\_{k}(s,a)<V^{\\*}(s)italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s , italic\\_a ) < italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ) \u21d2 lim sup start\\_POSTSUBSCRIPT italic\\_k \u2192 \u221e end\\_POSTSUBSCRIPT italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ) < italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ) |  |\n\n\n\n\n\nAccording to the definition of optimality-preserving, it\u2019s suggested that, when using the AL operator, at least one optimal action remains optimal, and all suboptimal actions are still suboptimal.\n\n\n\n\n![Refer to caption](/html/2203.11677/assets/x1.png)\n\n\nFigure 1: The 11-state chain-walk example used in (Kozuno, Uchibe, and Doya [2017](#bib.bib11)). The optimal policy is to take the left movement regardless of the initial and current states, so that the agent can arrive and stay at the left end state s0subscript\ud835\udc600s\\_{0}italic\\_s start\\_POSTSUBSCRIPT 0 end\\_POSTSUBSCRIPT for larger long-horizon rewards.\n\n\n###### \nDefinition 2 (gap-increasing).\n\n\n\nLet \u2133\u2133\\mathcal{M}caligraphic\\_M be a MDP, an operator \ud835\udcaf\u2032superscript\ud835\udcafnormal-\u2032\\mathcal{T}^{\\prime}caligraphic\\_T start\\_POSTSUPERSCRIPT \u2032 end\\_POSTSUPERSCRIPT for \u2133\u2133\\mathcal{M}caligraphic\\_M is gap-increasing if for \u2200Q0\u2208\ud835\udcac,s\u2208\ud835\udcae,a\u2208\ud835\udc9cformulae-sequencefor-allsubscript\ud835\udc440\ud835\udcacformulae-sequence\ud835\udc60\ud835\udcae\ud835\udc4e\ud835\udc9c\\forall Q\\_{0}\\in\\mathcal{Q},s\\in\\mathcal{S},a\\in\\mathcal{A}\u2200 italic\\_Q start\\_POSTSUBSCRIPT 0 end\\_POSTSUBSCRIPT \u2208 caligraphic\\_Q , italic\\_s \u2208 caligraphic\\_S , italic\\_a \u2208 caligraphic\\_A, letting Qk+1\u225c\ud835\udcaf\u2032Qknormal-\u225csubscript\ud835\udc44\ud835\udc581superscript\ud835\udcafnormal-\u2032subscript\ud835\udc44\ud835\udc58Q\\_{k+1}\\triangleq\\mathcal{T}^{\\prime}Q\\_{k}italic\\_Q start\\_POSTSUBSCRIPT italic\\_k + 1 end\\_POSTSUBSCRIPT \u225c caligraphic\\_T start\\_POSTSUPERSCRIPT \u2032 end\\_POSTSUPERSCRIPT italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT and Vk(s)\u225cmaxa\u2032\u2061Qk(s,a\u2032)normal-\u225csubscript\ud835\udc49\ud835\udc58\ud835\udc60subscriptsuperscript\ud835\udc4enormal-\u2032subscript\ud835\udc44\ud835\udc58\ud835\udc60superscript\ud835\udc4enormal-\u2032V\\_{k}(s)\\triangleq\\max\\_{a^{\\prime}}Q\\_{k}(s,a^{\\prime})italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s ) \u225c roman\\_max start\\_POSTSUBSCRIPT italic\\_a start\\_POSTSUPERSCRIPT \u2032 end\\_POSTSUPERSCRIPT end\\_POSTSUBSCRIPT italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a start\\_POSTSUPERSCRIPT \u2032 end\\_POSTSUPERSCRIPT ),\n\n\n\n\n|  |  |  |\n| --- | --- | --- |\n|  | lim infk\u2192\u221e[Vk(s)\u2212Qk(s,a)]\u2265V\\*(s)\u2212Q\\*(s,a)subscriptlimit-infimum\u2192\ud835\udc58delimited-[]subscript\ud835\udc49\ud835\udc58\ud835\udc60subscript\ud835\udc44\ud835\udc58\ud835\udc60\ud835\udc4esuperscript\ud835\udc49\ud835\udc60superscript\ud835\udc44\ud835\udc60\ud835\udc4e\\liminf\\_{k\\rightarrow\\infty}\\left[V\\_{k}(s)-Q\\_{k}(s,a)\\right]\\geq V^{\\*}(s)-Q^{\\*}(s,a)lim inf start\\_POSTSUBSCRIPT italic\\_k \u2192 \u221e end\\_POSTSUBSCRIPT [ italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ) ] \u2265 italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ) - italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s , italic\\_a ) |  |\n\n\n\n\n\nThe property of gap-increasing implies that the AL operator will enlarge the value difference between the optimal and suboptimal actions than \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T does. In fact, Theorem 1 in (Kozuno, Uchibe, and Doya [2017](#bib.bib11)) shows that the action gaps obtained by \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT and \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T satisfy: limk\u2192\u221e[Vk(s)\u2212Qk(s,a)]=11\u2212\u03b1[V\\*(s)\u2212Q\\*(s,a)]subscript\u2192\ud835\udc58delimited-[]subscript\ud835\udc49\ud835\udc58\ud835\udc60subscript\ud835\udc44\ud835\udc58\ud835\udc60\ud835\udc4e11\ud835\udefcdelimited-[]superscript\ud835\udc49\ud835\udc60superscript\ud835\udc44\ud835\udc60\ud835\udc4e\\lim\\_{k\\rightarrow\\infty}[V\\_{k}(s)-Q\\_{k}(s,a)]=\\frac{1}{1-\\alpha}[V^{\\*}(s)-Q^{\\*}(s,a)]roman\\_lim start\\_POSTSUBSCRIPT italic\\_k \u2192 \u221e end\\_POSTSUBSCRIPT [ italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ) ] = divide start\\_ARG 1 end\\_ARG start\\_ARG 1 - italic\\_\u03b1 end\\_ARG [ italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ) - italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s , italic\\_a ) ].\n\n4 Performance Loss Bound of AL\n-------------------------------\n\n\n\nThe additional scaling advantage term in the AL operator contributes to increase the action gap, thereby achieving the robust learning of the value function.\nHowever, the advantage value term may also become a burden for the value iteration.\nIn this section, we will analyze the relationship between the advantage term and the performance loss bound of the AL operator, which leads to our motivation on improving the AL operator.\n\n\n\n\nStarting with an arbitrary initial action-state value function Q0\u2208\ud835\udcacsubscript\ud835\udc440\ud835\udcacQ\\_{0}\\in\\mathcal{Q}italic\\_Q start\\_POSTSUBSCRIPT 0 end\\_POSTSUBSCRIPT \u2208 caligraphic\\_Q, we can obtain an action-state value function sequence {Qk}k=0Ksuperscriptsubscriptsubscript\ud835\udc44\ud835\udc58\ud835\udc580\ud835\udc3e\\left\\{Q\\_{k}\\right\\}\\_{k=0}^{K}{ italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT } start\\_POSTSUBSCRIPT italic\\_k = 0 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_K end\\_POSTSUPERSCRIPT by iteratively applying the AL operator \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT, i.e., Qk+1=\ud835\udcafALQksubscript\ud835\udc44\ud835\udc581subscript\ud835\udcafALsubscript\ud835\udc44\ud835\udc58Q\\_{k+1}=\\mathcal{T}\\_{\\rm{AL}}Q\\_{k}italic\\_Q start\\_POSTSUBSCRIPT italic\\_k + 1 end\\_POSTSUBSCRIPT = caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT. And we get the corresponding state value function sequence {Vk}k=0Ksuperscriptsubscriptsubscript\ud835\udc49\ud835\udc58\ud835\udc580\ud835\udc3e\\left\\{V\\_{k}\\right\\}\\_{k=0}^{K}{ italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT } start\\_POSTSUBSCRIPT italic\\_k = 0 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_K end\\_POSTSUPERSCRIPT by following the definition: Vk(s)\u225cmaxa\u2061Qk(s,a)\u225csubscript\ud835\udc49\ud835\udc58\ud835\udc60subscript\ud835\udc4esubscript\ud835\udc44\ud835\udc58\ud835\udc60\ud835\udc4eV\\_{k}(s)\\triangleq\\max\\_{a}Q\\_{k}(s,a)italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s ) \u225c roman\\_max start\\_POSTSUBSCRIPT italic\\_a end\\_POSTSUBSCRIPT italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ). Because \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT is optimality-preserving, we know that the state value function sequence will converge to the optimal one, i.e., limk\u2192\u221eVk=V\\*subscript\u2192\ud835\udc58subscript\ud835\udc49\ud835\udc58superscript\ud835\udc49\\lim\\_{k\\rightarrow\\infty}V\\_{k}=V^{\\*}roman\\_lim start\\_POSTSUBSCRIPT italic\\_k \u2192 \u221e end\\_POSTSUBSCRIPT italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT = italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT. The greedy policy induced by the k\ud835\udc58kitalic\\_k-th state value function Vksubscript\ud835\udc49\ud835\udc58V\\_{k}italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT is defined as: \u03c0k+1(s)=arg\u2061maxa\u2061[r(s,a)+\u03b3\ud835\udd3cs\u2032|s,a[Vk(s\u2032)]]subscript\ud835\udf0b\ud835\udc581\ud835\udc60subscript\ud835\udc4e\ud835\udc5f\ud835\udc60\ud835\udc4e\ud835\udefesubscript\ud835\udd3cconditionalsuperscript\ud835\udc60\u2032\ud835\udc60\ud835\udc4edelimited-[]subscript\ud835\udc49\ud835\udc58superscript\ud835\udc60\u2032\\pi\\_{k+1}(s)=\\arg\\max\\_{a}\\left[r(s,a)+\\gamma\\mathbb{E}\\_{s^{\\prime}|s,a}\\left[V\\_{k}(s^{\\prime})\\right]\\right]italic\\_\u03c0 start\\_POSTSUBSCRIPT italic\\_k + 1 end\\_POSTSUBSCRIPT ( italic\\_s ) = roman\\_arg roman\\_max start\\_POSTSUBSCRIPT italic\\_a end\\_POSTSUBSCRIPT [ italic\\_r ( italic\\_s , italic\\_a ) + italic\\_\u03b3 blackboard\\_E start\\_POSTSUBSCRIPT italic\\_s start\\_POSTSUPERSCRIPT \u2032 end\\_POSTSUPERSCRIPT | italic\\_s , italic\\_a end\\_POSTSUBSCRIPT [ italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s start\\_POSTSUPERSCRIPT \u2032 end\\_POSTSUPERSCRIPT ) ] ],\nand then the \u2113\u221esubscript\u2113\\ell\\_{\\infty}roman\\_\u2113 start\\_POSTSUBSCRIPT \u221e end\\_POSTSUBSCRIPT-norm performance loss bound of state value function of the induced policy satisfies the following result222we analyze the convergence error, because the sequence {Vk}k=0Ksubscriptsuperscriptsubscript\ud835\udc49\ud835\udc58\ud835\udc3e\ud835\udc580\\left\\{V\\_{k}\\right\\}^{K}\\_{k=0}{ italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT } start\\_POSTSUPERSCRIPT italic\\_K end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_k = 0 end\\_POSTSUBSCRIPT must converge to the optimal, while {Qk}k=0Ksubscriptsuperscriptsubscript\ud835\udc44\ud835\udc58\ud835\udc3e\ud835\udc580\\left\\{Q\\_{k}\\right\\}^{K}\\_{k=0}{ italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT } start\\_POSTSUPERSCRIPT italic\\_K end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_k = 0 end\\_POSTSUBSCRIPT may not, according the definition of optimality-preserving.: (proof in Appendix A.1)\n\n\n\n\n###### \nTheorem 1.\n\n\n\nAssume the optimal policy \u03c0\\*superscript\ud835\udf0b\\pi^{\\*}italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT and its state value function V\\*superscript\ud835\udc49V^{\\*}italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT, and \u2200\u03c0\u2208\u03a0,\u2016V\u03c0\u2016\u221e\u2264Vmaxformulae-sequencefor-all\ud835\udf0bnormal-\u03a0subscriptnormsuperscript\ud835\udc49\ud835\udf0bsubscript\ud835\udc49\\forall\\pi\\in\\Pi,\\|V^{\\pi}\\|\\_{\\infty}\\leq V\\_{\\max}\u2200 italic\\_\u03c0 \u2208 roman\\_\u03a0 , \u2225 italic\\_V start\\_POSTSUPERSCRIPT italic\\_\u03c0 end\\_POSTSUPERSCRIPT \u2225 start\\_POSTSUBSCRIPT \u221e end\\_POSTSUBSCRIPT \u2264 italic\\_V start\\_POSTSUBSCRIPT roman\\_max end\\_POSTSUBSCRIPT, let \u0394k\u03c0\\*\u2208\u211d|\ud835\udcae|subscriptsuperscriptnormal-\u0394superscript\ud835\udf0b\ud835\udc58superscript\u211d\ud835\udcae\\Delta^{\\pi^{\\*}}\\_{k}\\in\\mathbb{R}^{|\\mathcal{S}|}roman\\_\u0394 start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT \u2208 blackboard\\_R start\\_POSTSUPERSCRIPT | caligraphic\\_S | end\\_POSTSUPERSCRIPT and each entry is defined as :\u0394k\u03c0\\*(s)=Vk(s)\u2212Qk(s,\u03c0\\*(s))superscriptsubscriptnormal-\u0394\ud835\udc58superscript\ud835\udf0b\ud835\udc60subscript\ud835\udc49\ud835\udc58\ud835\udc60subscript\ud835\udc44\ud835\udc58\ud835\udc60superscript\ud835\udf0b\ud835\udc60\\Delta\\_{k}^{\\pi^{\\*}}(s)=V\\_{k}(s)-Q\\_{k}(s,\\pi^{\\*}(s))roman\\_\u0394 start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT end\\_POSTSUPERSCRIPT ( italic\\_s ) = italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ) ), then we have:\n\n\n\n\n\n|  |  |  |\n| --- | --- | --- |\n|  | \u2016V\\*\u2212V\u03c0K+1\u2016\u221esubscriptnormsuperscript\ud835\udc49superscript\ud835\udc49subscript\ud835\udf0b\ud835\udc3e1\\displaystyle\\|V^{\\*}-V^{\\pi\\_{K+1}}\\|\\_{\\infty}\u2225 italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT - italic\\_V start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUBSCRIPT italic\\_K + 1 end\\_POSTSUBSCRIPT end\\_POSTSUPERSCRIPT \u2225 start\\_POSTSUBSCRIPT \u221e end\\_POSTSUBSCRIPT |  |\n|  | \u22642\u03b31\u2212\u03b3[2\u03b3KVmax+\u03b1\u2211k=0k=K\u22121\u03b3K\u2212k\u22121\u2016\u0394k\u03c0\\*\u2016\u221e]absent2\ud835\udefe1\ud835\udefedelimited-[]2superscript\ud835\udefe\ud835\udc3esubscript\ud835\udc49\ud835\udefcsuperscriptsubscript\ud835\udc580\ud835\udc58\ud835\udc3e1superscript\ud835\udefe\ud835\udc3e\ud835\udc581subscriptnormsuperscriptsubscript\u0394\ud835\udc58superscript\ud835\udf0b\\displaystyle\\leq\\frac{2\\gamma}{1-\\gamma}\\left[2\\gamma^{K}V\\_{\\max}+\\alpha\\sum\\_{k=0}^{k=K-1}\\gamma^{K-k-1}\\|\\Delta\\_{k}^{\\pi^{\\*}}\\|\\_{\\infty}\\right]\u2264 divide start\\_ARG 2 italic\\_\u03b3 end\\_ARG start\\_ARG 1 - italic\\_\u03b3 end\\_ARG [ 2 italic\\_\u03b3 start\\_POSTSUPERSCRIPT italic\\_K end\\_POSTSUPERSCRIPT italic\\_V start\\_POSTSUBSCRIPT roman\\_max end\\_POSTSUBSCRIPT + italic\\_\u03b1 \u2211 start\\_POSTSUBSCRIPT italic\\_k = 0 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_k = italic\\_K - 1 end\\_POSTSUPERSCRIPT italic\\_\u03b3 start\\_POSTSUPERSCRIPT italic\\_K - italic\\_k - 1 end\\_POSTSUPERSCRIPT \u2225 roman\\_\u0394 start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT end\\_POSTSUPERSCRIPT \u2225 start\\_POSTSUBSCRIPT \u221e end\\_POSTSUBSCRIPT ] |  |\n\n\n\n\n\nComparing the result in Theorem [1](#Sx1.EGx1 \"Theorem 1. \u2023 4 Performance Loss Bound of AL \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\") with the similar one of Bellman optimality operator (Farahmand, Szepesv\u00e1ri, and Munos [2010](#bib.bib4)), we can see that \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT would accumulate an extra discounted error into the performance loss bound in the case that a non-zero \u0394k\u03c0\\*superscriptsubscript\u0394\ud835\udc58superscript\ud835\udf0b\\Delta\\_{k}^{\\pi^{\\*}}roman\\_\u0394 start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT end\\_POSTSUPERSCRIPT occurs at any update step. And the additional cumulative errors will further lead to a slower convergence to the optimal value function.\n\n\n\n\nRecall the definition \u0394k\u03c0\\*(s)=Vk(s)\u2212Qk(s,\u03c0\\*(s))superscriptsubscript\u0394\ud835\udc58superscript\ud835\udf0b\ud835\udc60subscript\ud835\udc49\ud835\udc58\ud835\udc60subscript\ud835\udc44\ud835\udc58\ud835\udc60superscript\ud835\udf0b\ud835\udc60\\Delta\\_{k}^{\\pi^{\\*}}(s)=V\\_{k}(s)-Q\\_{k}\\left(s,\\pi^{\\*}(s)\\right)roman\\_\u0394 start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT end\\_POSTSUPERSCRIPT ( italic\\_s ) = italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ) ), we know it\u2019s a non-negative vector (\u0394k\u03c0\\*\u22650subscriptsuperscript\u0394superscript\ud835\udf0b\ud835\udc580\\Delta^{\\pi^{\\*}}\\_{k}\\geq 0roman\\_\u0394 start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT \u2265 0) and \u2212\u0394k\u03c0\\*(s)subscriptsuperscript\u0394superscript\ud835\udf0b\ud835\udc58\ud835\udc60-\\Delta^{\\pi^{\\*}}\\_{k}(s)- roman\\_\u0394 start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s ) represents the estimated advantage value of the true optimal action at state s\ud835\udc60sitalic\\_s. When the optimal action induced by the iterative value function does not agree with the true optimal action, i.e., \u03c0\\*(s)\u2260arg\u2061maxa\u2208\ud835\udc9c\u2061Qk(s,a)superscript\ud835\udf0b\ud835\udc60subscript\ud835\udc4e\ud835\udc9csubscript\ud835\udc44\ud835\udc58\ud835\udc60\ud835\udc4e\\pi^{\\*}(s)\\neq\\arg\\max\\_{a\\in\\mathcal{A}}Q\\_{k}(s,a)italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ) \u2260 roman\\_arg roman\\_max start\\_POSTSUBSCRIPT italic\\_a \u2208 caligraphic\\_A end\\_POSTSUBSCRIPT italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ) at some timesteps, a positive discounted error \u03b3K\u2212k\u22121\u2016\u0394k\u03c0\\*\u2016\u221e>0superscript\ud835\udefe\ud835\udc3e\ud835\udc581subscriptnormsubscriptsuperscript\u0394superscript\ud835\udf0b\ud835\udc580\\gamma^{K-k-1}\\|\\Delta^{\\pi^{\\*}}\\_{k}\\|\\_{\\infty}>0italic\\_\u03b3 start\\_POSTSUPERSCRIPT italic\\_K - italic\\_k - 1 end\\_POSTSUPERSCRIPT \u2225 roman\\_\u0394 start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT \u2225 start\\_POSTSUBSCRIPT \u221e end\\_POSTSUBSCRIPT > 0 will be accumulated in the performance loss bound.\nIn other words, unless the induced greedy policy keeps consistent with the optimal policy over all the iterations, i.e., \u03c01=\u22ef=\u03c0K+1=\u03c0\\*subscript\ud835\udf0b1\u22efsubscript\ud835\udf0b\ud835\udc3e1superscript\ud835\udf0b\\pi\\_{1}=\\cdots=\\pi\\_{K+1}=\\pi^{\\*}italic\\_\u03c0 start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT = \u22ef = italic\\_\u03c0 start\\_POSTSUBSCRIPT italic\\_K + 1 end\\_POSTSUBSCRIPT = italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT, \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT would cause larger performance loss bound than \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T does.\nHowever, it\u2019s impossible to guarantee this ideal condition in practice, especially because of the under-exploration in complex tasks and the estimation error that existed in the function approximator. So the AL operator also suffers from slower value convergence (i.e., larger performance loss ) while obtaining larger action gaps.\n\n\n\n\nIn summary, we show that increasing the action gap by the advantage term is not always a beneficial choice, especially when the induced optimal action is not consistent with the true optimal one. Because the advantage term in this case may also introduce more errors into the state value function, leading to the slow convergence.\n\n\n\n\n\n\n![Refer to caption](/html/2203.11677/assets/x2.png)\n\n\n\n![Refer to caption](/html/2203.11677/assets/x3.png)\n\n\n\n![Refer to caption](/html/2203.11677/assets/x4.png)\n\n\n\nFigure 2: \nNumerical experiments on 11-state chain-walk. (a): Performance loss bound. The induced policies by \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T, \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT and \ud835\udcafclipALsubscript\ud835\udcafclipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT reach the optimal one after 78, 138 and 113 iterations respectively; (b-c): Q\ud835\udc44Qitalic\\_Q value at 10-th and 500-th iteration. The solid lines depict the Q\ud835\udc44Qitalic\\_Q value of both actions at each state. The dashed lines show the averaged Q\ud835\udc44Qitalic\\_Q value of both actions over all states and the distance between them represents the mean action gap. (a) and (c) indicate that our \ud835\udcafclipALsubscript\ud835\udcafclipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT can speed up the policy convergence than \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT (though slower than \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T), and still maintain a larger mean action gap (15.7115.7115.7115.71) than \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T (1.651.651.651.65), so as to achieve the balance between convergence speed and action gap.\n\n\n\n11-State Chain-Walk. We further illustrate this adverse effect with the chain-walk example shown in Figure [1](#S3.F1 \"Figure 1 \u2023 Advantage Learning \u2023 3 Preliminaries \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\"). The agent can move either left or right at each state and would be transitioned to the state in the intended direction with probability 0.7, while to the state in the opposite direction with probability 0.3. At both ends of the chain, attempted movement to outside of the chain results in staying at the ends. The agent gets 00 reward once reaching the middle state (s5subscript\ud835\udc605s\\_{5}italic\\_s start\\_POSTSUBSCRIPT 5 end\\_POSTSUBSCRIPT). If the agent moves to the right side of the chain (s6subscript\ud835\udc606s\\_{6}italic\\_s start\\_POSTSUBSCRIPT 6 end\\_POSTSUBSCRIPT-s10subscript\ud835\udc6010s\\_{10}italic\\_s start\\_POSTSUBSCRIPT 10 end\\_POSTSUBSCRIPT), it can get 1111 reward, otherwise get \u221211-1- 1 reward on the left side of this chain (s1subscript\ud835\udc601s\\_{1}italic\\_s start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT-s4subscript\ud835\udc604s\\_{4}italic\\_s start\\_POSTSUBSCRIPT 4 end\\_POSTSUBSCRIPT) except 3333 reward on the left end (s0subscript\ud835\udc600s\\_{0}italic\\_s start\\_POSTSUBSCRIPT 0 end\\_POSTSUBSCRIPT).\n\n\n\n\nAssume every episode will start from state s5subscript\ud835\udc605s\\_{5}italic\\_s start\\_POSTSUBSCRIPT 5 end\\_POSTSUBSCRIPT, according to the definition, we know that the optimal policy is to implement the \u2019left\u2019 action at all states. We denote the Q\ud835\udc44Qitalic\\_Q value of \u2019left\u2019(\u2019right\u2019) action as Q(s,L)\ud835\udc44\ud835\udc60\ud835\udc3fQ(s,L)italic\\_Q ( italic\\_s , italic\\_L ) (Q(s,R)\ud835\udc44\ud835\udc60\ud835\udc45Q(s,R)italic\\_Q ( italic\\_s , italic\\_R )) and initiate a Q\ud835\udc44Qitalic\\_Q-table in which Q(s,R)=Q(s,L)=0\ud835\udc44\ud835\udc60\ud835\udc45\ud835\udc44\ud835\udc60\ud835\udc3f0Q(s,R)=Q(s,L)=0italic\\_Q ( italic\\_s , italic\\_R ) = italic\\_Q ( italic\\_s , italic\\_L ) = 0 for all states. Then with a perfect environment model, the Q\ud835\udc44Qitalic\\_Q-table will be updated using \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T and \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT respectively.\n\n\n\n\nFigure [2](#S4.F2 \"Figure 2 \u2023 4 Performance Loss Bound of AL \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\") shows the performance loss of state value function of the induced policy.\nWe can see that it spends more time for \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT (iteration 138) to achieve the optimal state value function than \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T does (iteration 78). This is because a suboptimal policy would be learned at the early update iterations. As shown in Figure [2](#S4.F2 \"Figure 2 \u2023 4 Performance Loss Bound of AL \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\"), at the beginning of iterations (iteration 10), the induced greedy policy will take the suboptimal (\u2019right\u2019) action at state s4subscript\ud835\udc604s\\_{4}italic\\_s start\\_POSTSUBSCRIPT 4 end\\_POSTSUBSCRIPT-s10subscript\ud835\udc6010s\\_{10}italic\\_s start\\_POSTSUBSCRIPT 10 end\\_POSTSUBSCRIPT due to the larger immediate reward at the right side of the chain. And according to our analysis in Theorem [1](#Sx1.EGx1 \"Theorem 1. \u2023 4 Performance Loss Bound of AL \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\"), this suboptimal policy would accumulate more errors in \u2016V\\*\u2212V\u03c0K+1\u2016\u221esubscriptnormsuperscript\ud835\udc49superscript\ud835\udc49subscript\ud835\udf0b\ud835\udc3e1\\|V^{\\*}-V^{\\pi\\_{K+1}}\\|\\_{\\infty}\u2225 italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT - italic\\_V start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUBSCRIPT italic\\_K + 1 end\\_POSTSUBSCRIPT end\\_POSTSUPERSCRIPT \u2225 start\\_POSTSUBSCRIPT \u221e end\\_POSTSUBSCRIPT, leading to a slower convergence. Even though a larger mean action gap can be achieved by \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT (163.33163.33163.33163.33) than \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T (1.651.651.651.65) after converging to the optimal policy as illustrated in Figure [2](#S4.F2 \"Figure 2 \u2023 4 Performance Loss Bound of AL \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\"). More experimental details and results about this chain-walk example can be found in Appendix B.1.\n\n5 Clipped Advantage Learning\n-----------------------------\n\n\n\nBased on the observation in Sec.[4](#S4 \"4 Performance Loss Bound of AL \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\"), we present a novel AL-based method (named clipped AL) in this section, which adds the advantage term more reasonably through a clipping mechanism and also prove its some critical properties.\n\n\n\n\n### Methods\n\n\n\nBesides the robustness benefited from the larger action gap, the AL operator can also cause a slower convergence due to the blind action gap increasing by the advantage term.\nTo mitigate this issue, one intuitive method is to add the advantage term conditionally based on the necessity of increasing the action gap, rather than doing this for all state-action pairs like AL does.\nSo we propose the Clipped Advantage Learning (clipped AL) operator as following:\n\n\n\n\n|  |  |  |\n| --- | --- | --- |\n|  | \ud835\udcafclipALQ(s,a)subscript\ud835\udcafclipAL\ud835\udc44\ud835\udc60\ud835\udc4e\\displaystyle\\mathcal{T}\\_{\\rm{clipAL}}Q(s,a)caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT italic\\_Q ( italic\\_s , italic\\_a ) |  |\n|  | \u225c\ud835\udcafQ(s,a)\u2212\u03b1(V(s)\u2212Q(s,a))\u22c5\ud835\udd40[Q(s,a)\u2212QlV(s)\u2212Ql\u2265c]\u225cabsent\ud835\udcaf\ud835\udc44\ud835\udc60\ud835\udc4e\u22c5\ud835\udefc\ud835\udc49\ud835\udc60\ud835\udc44\ud835\udc60\ud835\udc4e\ud835\udd40delimited-[]\ud835\udc44\ud835\udc60\ud835\udc4esubscript\ud835\udc44\ud835\udc59\ud835\udc49\ud835\udc60subscript\ud835\udc44\ud835\udc59\ud835\udc50\\displaystyle\\triangleq\\mathcal{T}Q(s,a)-\\alpha(V(s)-Q(s,a))\\cdot\\mathbb{I}\\left[\\frac{Q(s,a)-Q\\_{l}}{V(s)-Q\\_{l}}\\geq c\\right]\u225c caligraphic\\_T italic\\_Q ( italic\\_s , italic\\_a ) - italic\\_\u03b1 ( italic\\_V ( italic\\_s ) - italic\\_Q ( italic\\_s , italic\\_a ) ) \u22c5 blackboard\\_I [ divide start\\_ARG italic\\_Q ( italic\\_s , italic\\_a ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT end\\_ARG start\\_ARG italic\\_V ( italic\\_s ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT end\\_ARG \u2265 italic\\_c ] |  | (4) |\n\n\n\n\nwhere \ud835\udd40[\u22c5]\ud835\udd40delimited-[]\u22c5\\mathbb{I}\\left[\\cdot\\right]blackboard\\_I [ \u22c5 ] is the indicator function that equals to 1 if the condition is satisfied, otherwise returns 0. And c\u2208(0,1)\ud835\udc5001c\\in\\left(0,1\\right)italic\\_c \u2208 ( 0 , 1 ) denotes the clipping ratio coefficient. Qlsubscript\ud835\udc44\ud835\udc59Q\\_{l}italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT is a lower bound of Q\ud835\udc44Qitalic\\_Q value such that Q(s,a)\u2212QlV(s)\u2212Ql\u22650\ud835\udc44\ud835\udc60\ud835\udc4esubscript\ud835\udc44\ud835\udc59\ud835\udc49\ud835\udc60subscript\ud835\udc44\ud835\udc590\\frac{Q(s,a)-Q\\_{l}}{V(s)-Q\\_{l}}\\geq 0divide start\\_ARG italic\\_Q ( italic\\_s , italic\\_a ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT end\\_ARG start\\_ARG italic\\_V ( italic\\_s ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT end\\_ARG \u2265 0.\nThis operator can also be rewritten as a more direct form:\n\n\n\n\n|  |  |  |  |\n| --- | --- | --- | --- |\n|  | \ud835\udcafclipAL={\ud835\udcafAL,if\u00a0Q(s,a)\u2212Ql\u2265c(V(s)\u2212Ql)\ud835\udcaf,otherwisesubscript\ud835\udcafclipALcasessubscript\ud835\udcafALif\u00a0\ud835\udc44\ud835\udc60\ud835\udc4esubscript\ud835\udc44\ud835\udc59\ud835\udc50\ud835\udc49\ud835\udc60subscript\ud835\udc44\ud835\udc59\ud835\udcafotherwise\\mathcal{T}\\_{\\rm{clipAL}}=\\begin{cases}\\mathcal{T}\\_{\\rm{AL}},&\\mbox{if }Q(s,a)-Q\\_{l}\\geq c(V(s)-Q\\_{l})\\\\\n\\mathcal{T},&\\mbox{otherwise}\\end{cases}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT = { start\\_ROW start\\_CELL caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT , end\\_CELL start\\_CELL if italic\\_Q ( italic\\_s , italic\\_a ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT \u2265 italic\\_c ( italic\\_V ( italic\\_s ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT ) end\\_CELL end\\_ROW start\\_ROW start\\_CELL caligraphic\\_T , end\\_CELL start\\_CELL otherwise end\\_CELL end\\_ROW |  | (5) |\n\n\n\n\nThe motivation behind the clipped AL can be summarized as \u201dadvantage term should not be added without necessity\u201d. According to the definition in Eq.([5](#S5.E5 \"5 \u2023 Methods \u2023 5 Clipped Advantage Learning \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\")), the clipped AL is designed to increase the action gap by implementing \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT if and only if the Q\ud835\udc44Qitalic\\_Q value of suboptimal actions exceeds a certain threshold and gets close to the corresponding V\ud835\udc49Vitalic\\_V value, or otherwise, it will keep consistent with the Bellman optimality operator \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T.\nOn the one hand, \ud835\udcafclipALsubscript\ud835\udcafclipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT can still maintain an enough action gaps by the additional advantage term when suboptimal state-action values approach to the optimal one. On the other hand, if an appropriate gap has already existed, it can achieve a larger value improvement without the advantage term in the next iteration. And eventually, \ud835\udcafclipALsubscript\ud835\udcafclipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT is expected to reach a balance between large action gaps and fast convergence.\n\n\n\n\n###### \nCorollary 1.\n\n\n\nThe clipped AL operator \ud835\udcafclipALsubscript\ud835\udcafnormal-clipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT satisfies the both conditions in Theorem 1 in (Bellemare et\u00a0al. [2016](#bib.bib2)) and then is both optimality-preserving and gap-increasing,\n\n\n\n\n\nThe above Corollary implies that \ud835\udcafclipALsubscript\ud835\udcafclipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT can still keep both optimality-preserving and gap-increasing like \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT. and will eventually yield an optimal greedy policy when the Q value can be represented exactly. This clipping mechanism is beneficial in the case that the estimated value of the true optimal action Qk(s,\u03c0\\*(s))subscript\ud835\udc44\ud835\udc58\ud835\udc60superscript\ud835\udf0b\ud835\udc60Q\\_{k}(s,\\pi^{\\*}(s))italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ) ) is much less than the estimated optimal value Vk(s)subscript\ud835\udc49\ud835\udc58\ud835\udc60V\\_{k}(s)italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s ), because it would omit the negative advantage value Qk(s,\u03c0\\*(s))\u2212Vk(s)subscript\ud835\udc44\ud835\udc58\ud835\udc60superscript\ud835\udf0b\ud835\udc60subscript\ud835\udc49\ud835\udc58\ud835\udc60Q\\_{k}(s,\\pi^{\\*}(s))-V\\_{k}(s)italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ) ) - italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s ) so as to achieve a larger improvement on Qk+1(s,\u03c0\\*(s))subscript\ud835\udc44\ud835\udc581\ud835\udc60superscript\ud835\udf0b\ud835\udc60Q\\_{k+1}(s,\\pi^{\\*}(s))italic\\_Q start\\_POSTSUBSCRIPT italic\\_k + 1 end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ) ) in the next iteration, and then help the induced optimal action to align with the true optimal action faster.\nNote that instead of a fixed Q\ud835\udc44Qitalic\\_Q value threshold, we choose a fixed Q\ud835\udc44Qitalic\\_Q value ratio c\ud835\udc50citalic\\_c as the clipping threshold to adjust the advantage value term adaptively according to the varying scale of action value.\n\n\n\n\n\n### Balance between Large Action Gap and Fast Convergence\n\n\n\nRecall the 11-state chain-walk example in Figure [1](#S3.F1 \"Figure 1 \u2023 Advantage Learning \u2023 3 Preliminaries \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\"). We know that, despite increasing the action gap, \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT may also lead to a slow convergence to the optimal value function because of the mismatch between induced and true optimal action. We also implement \ud835\udcafclipALsubscript\ud835\udcafclipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT on chain-walk example with the same settings and show the results in Figure [2](#S4.F2 \"Figure 2 \u2023 4 Performance Loss Bound of AL \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\"). We can see that, comparing with \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT, our \ud835\udcafclipALsubscript\ud835\udcafclipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT can obtain a faster achievement to the optimal policy (iteration 113), i.e., V\u03c0K+1=V\\*superscript\ud835\udc49subscript\ud835\udf0b\ud835\udc3e1superscript\ud835\udc49V^{\\pi\\_{K+1}}=V^{\\*}italic\\_V start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUBSCRIPT italic\\_K + 1 end\\_POSTSUBSCRIPT end\\_POSTSUPERSCRIPT = italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT (shown in Figure [2](#S4.F2 \"Figure 2 \u2023 4 Performance Loss Bound of AL \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\")). This result is intuitive because \ud835\udcafclipALsubscript\ud835\udcafclipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT would clip the unnecessary advantage term \u2212\u0394k\u03c0\\*superscriptsubscript\u0394\ud835\udc58superscript\ud835\udf0b-\\Delta\\_{k}^{\\pi^{\\*}}- roman\\_\u0394 start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_\u03c0 start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT end\\_POSTSUPERSCRIPT, reducing the cumulative errors in performance loss bound. Meanwhile, \ud835\udcafclipALsubscript\ud835\udcafclipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT can also maintain a larger action gap (15.7115.7115.7115.71) than \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T (1.651.651.651.65) as shown in Figure [2](#S4.F2 \"Figure 2 \u2023 4 Performance Loss Bound of AL \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\"), which keeps its robustness.\n\n\n\n\nSpecifically, for \u2200(s,a)\u2208\ud835\udcae\u00d7\ud835\udc9cfor-all\ud835\udc60\ud835\udc4e\ud835\udcae\ud835\udc9c\\forall(s,a)\\in\\mathcal{S}\\times\\mathcal{A}\u2200 ( italic\\_s , italic\\_a ) \u2208 caligraphic\\_S \u00d7 caligraphic\\_A, we define its action gap as following:\n\n\n\n\n|  |  |  |  |\n| --- | --- | --- | --- |\n|  | G(s,a)=lim infk\u2192\u221e[Vk(s)\u2212Qk(s,a)]\ud835\udc3a\ud835\udc60\ud835\udc4esubscriptlimit-infimum\u2192\ud835\udc58delimited-[]subscript\ud835\udc49\ud835\udc58\ud835\udc60subscript\ud835\udc44\ud835\udc58\ud835\udc60\ud835\udc4eG(s,a)=\\liminf\\_{k\\rightarrow\\infty}\\left[V\\_{k}(s)-Q\\_{k}(s,a)\\right]italic\\_G ( italic\\_s , italic\\_a ) = lim inf start\\_POSTSUBSCRIPT italic\\_k \u2192 \u221e end\\_POSTSUBSCRIPT [ italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ) ] |  | (6) |\n\n\n\n\nwhere {Qk}k=0\u221esuperscriptsubscriptsubscript\ud835\udc44\ud835\udc58\ud835\udc580\\left\\{Q\\_{k}\\right\\}\\_{k=0}^{\\infty}{ italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT } start\\_POSTSUBSCRIPT italic\\_k = 0 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT \u221e end\\_POSTSUPERSCRIPT and {Vk}k=0\u221esuperscriptsubscriptsubscript\ud835\udc49\ud835\udc58\ud835\udc580\\left\\{V\\_{k}\\right\\}\\_{k=0}^{\\infty}{ italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT } start\\_POSTSUBSCRIPT italic\\_k = 0 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT \u221e end\\_POSTSUPERSCRIPT are the corresponding value functions w.r.t any operator and Vk(s)=maxa\u2208\ud835\udc9c\u2061Qk(s,a)subscript\ud835\udc49\ud835\udc58\ud835\udc60subscript\ud835\udc4e\ud835\udc9csubscript\ud835\udc44\ud835\udc58\ud835\udc60\ud835\udc4eV\\_{k}(s)=\\max\\_{a\\in\\mathcal{A}}Q\\_{k}(s,a)italic\\_V start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s ) = roman\\_max start\\_POSTSUBSCRIPT italic\\_a \u2208 caligraphic\\_A end\\_POSTSUBSCRIPT italic\\_Q start\\_POSTSUBSCRIPT italic\\_k end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ). And the action gap obtained by the above three operators satisfies the conclusion in Theorem[2](#S5.Ex8 \"Theorem 2. \u2023 Balance between Large Action Gap and Fast Convergence \u2023 5 Clipped Advantage Learning \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\").\n\n\n\n\n###### \nTheorem 2.\n\n\n\nFor \u2200s\u2208\ud835\udcae,a\u2208\ud835\udc9cformulae-sequencefor-all\ud835\udc60\ud835\udcae\ud835\udc4e\ud835\udc9c\\forall s\\in\\mathcal{S},a\\in\\mathcal{A}\u2200 italic\\_s \u2208 caligraphic\\_S , italic\\_a \u2208 caligraphic\\_A, we define its action gap from \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T, \ud835\udcafALsubscript\ud835\udcafnormal-AL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT, and \ud835\udcafclipALsubscript\ud835\udcafnormal-clipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT by G\\*(s,a)superscript\ud835\udc3a\ud835\udc60\ud835\udc4eG^{\\*}(s,a)italic\\_G start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s , italic\\_a ), GAL(s,a)subscript\ud835\udc3anormal-AL\ud835\udc60\ud835\udc4eG\\_{\\rm{AL}}(s,a)italic\\_G start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ), and GclipAL(s,a)subscript\ud835\udc3anormal-clipAL\ud835\udc60\ud835\udc4eG\\_{\\rm{clipAL}}(s,a)italic\\_G start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ). Let Q\\*superscript\ud835\udc44Q^{\\*}italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT and V\\*superscript\ud835\udc49V^{\\*}italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT represent the optimal state (action) value functions, then G\\*(s,a)=V\\*(s)\u2212Q\\*(s,a)superscript\ud835\udc3a\ud835\udc60\ud835\udc4esuperscript\ud835\udc49\ud835\udc60superscript\ud835\udc44\ud835\udc60\ud835\udc4eG^{\\*}(s,a)=V^{\\*}(s)-Q^{\\*}(s,a)italic\\_G start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s , italic\\_a ) = italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s ) - italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s , italic\\_a ) and these action gaps satisfy:\n\n\n\n\n\n|  |  |  |\n| --- | --- | --- |\n|  | G\\*(s,a)\u2264GclipAL(s,a)\u2264GAL(s,a)superscript\ud835\udc3a\ud835\udc60\ud835\udc4esubscript\ud835\udc3aclipAL\ud835\udc60\ud835\udc4esubscript\ud835\udc3aAL\ud835\udc60\ud835\udc4eG^{\\*}(s,a)\\leq G\\_{\\rm{clipAL}}(s,a)\\leq G\\_{\\rm{AL}}(s,a)italic\\_G start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ( italic\\_s , italic\\_a ) \u2264 italic\\_G start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ) \u2264 italic\\_G start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ) |  |\n\n\nAnd when Ql\u2264mins,a\u2061Q\\*\u2212\u03b1V\\*1\u2212\u03b1subscript\ud835\udc44\ud835\udc59subscript\ud835\udc60\ud835\udc4esuperscript\ud835\udc44\ud835\udefcsuperscript\ud835\udc491\ud835\udefcQ\\_{l}\\leq\\min\\_{s,a}\\frac{Q^{\\*}-\\alpha V^{\\*}}{1-\\alpha}italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT \u2264 roman\\_min start\\_POSTSUBSCRIPT italic\\_s , italic\\_a end\\_POSTSUBSCRIPT divide start\\_ARG italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT - italic\\_\u03b1 italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT end\\_ARG start\\_ARG 1 - italic\\_\u03b1 end\\_ARG, GclipAL(s,a)=GAL(s,a)subscript\ud835\udc3anormal-clipAL\ud835\udc60\ud835\udc4esubscript\ud835\udc3anormal-AL\ud835\udc60\ud835\udc4eG\\_{\\rm{clipAL}}(s,a)=G\\_{\\rm{AL}}(s,a)italic\\_G start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ) = italic\\_G start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ) if the clipping ratio satisfies:\n\n\n\n\n|  |  |  |\n| --- | --- | --- |\n|  | c\u2264mins,a\u2061Q\\*\u2212\u03b1V\\*\u2212(1\u2212\u03b1)Ql(1\u2212\u03b1)(V\\*\u2212Ql)\ud835\udc50subscript\ud835\udc60\ud835\udc4esuperscript\ud835\udc44\ud835\udefcsuperscript\ud835\udc491\ud835\udefcsubscript\ud835\udc44\ud835\udc591\ud835\udefcsuperscript\ud835\udc49subscript\ud835\udc44\ud835\udc59c\\leq\\min\\_{s,a}\\frac{Q^{\\*}-\\alpha V^{\\*}-(1-\\alpha)Q\\_{l}}{(1-\\alpha)(V^{\\*}-Q\\_{l})}italic\\_c \u2264 roman\\_min start\\_POSTSUBSCRIPT italic\\_s , italic\\_a end\\_POSTSUBSCRIPT divide start\\_ARG italic\\_Q start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT - italic\\_\u03b1 italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT - ( 1 - italic\\_\u03b1 ) italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT end\\_ARG start\\_ARG ( 1 - italic\\_\u03b1 ) ( italic\\_V start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT - italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT ) end\\_ARG |  |\n\n\n\n\n\nThis theorem implies that the action gap of \ud835\udcafclipALsubscript\ud835\udcafclipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT is somewhere between the action gaps of both \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T and \ud835\udcafALsubscript\ud835\udcafAL\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT and finally depends on the clipping ratio c\ud835\udc50citalic\\_c. So these results and conclusions support the goal of our clipped AL: achieve a balance between the large action gaps and fast convergence.\n\n6 Experiment\n-------------\n\n\n\nTo further verify the feasibility and effectiveness of the proposed clipping mechanism applied in the family of Advantage Learning algorithms, we evaluate and compare the performance of our method on several popular RL benchmarks, such as the MinAtar (Young and Tian [2019](#bib.bib23)), PLE (Tasfi [2016](#bib.bib19)) and Atari (Bellemare et\u00a0al. [2013](#bib.bib1)) .\n\n\n\n\n### Experimental Setup\n\n\n\n#### Implementation.\n\n\n\nWe conduct the MinAtar and PLE experiments mainly based on the Explorer framework (Lan [2019](#bib.bib13)), and the Atari experiments based on APE-X framework (Horgan et\u00a0al. [2018](#bib.bib9)).\nAnd due to the paper space limit, the results on Atari tasks will be provided in Appendix B.3. All the implementations are run on a computer with an Intel Xeon(R) CPU, 64GB of memory and a GeForce RTX 2080 Ti GPU.\n\nWhen implementing our clipped AL, instead of an enough lower bound Qlsubscript\ud835\udc44\ud835\udc59Q\\_{l}italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT, we choose a proper value: Ql=1\u2212\u03b3H1\u2212\u03b3Rminsubscript\ud835\udc44\ud835\udc591superscript\ud835\udefe\ud835\udc3b1\ud835\udefesubscript\ud835\udc45Q\\_{l}=\\frac{1-\\gamma^{H}}{1-\\gamma}R\\_{\\min}italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT = divide start\\_ARG 1 - italic\\_\u03b3 start\\_POSTSUPERSCRIPT italic\\_H end\\_POSTSUPERSCRIPT end\\_ARG start\\_ARG 1 - italic\\_\u03b3 end\\_ARG italic\\_R start\\_POSTSUBSCRIPT roman\\_min end\\_POSTSUBSCRIPT, where Rminsubscript\ud835\udc45R\\_{\\min}italic\\_R start\\_POSTSUBSCRIPT roman\\_min end\\_POSTSUBSCRIPT is the minimum reward for each step. This choice is the least discounted sum of rewards for a H\ud835\udc3bHitalic\\_H-length trajectory.\nAlthough Q(s,a)\u2212QlV(s)\u2212Ql<0\ud835\udc44\ud835\udc60\ud835\udc4esubscript\ud835\udc44\ud835\udc59\ud835\udc49\ud835\udc60subscript\ud835\udc44\ud835\udc590\\frac{Q(s,a)-Q\\_{l}}{V(s)-Q\\_{l}}<0divide start\\_ARG italic\\_Q ( italic\\_s , italic\\_a ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT end\\_ARG start\\_ARG italic\\_V ( italic\\_s ) - italic\\_Q start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT end\\_ARG < 0 may still happen during the training process due to approximation error at certain timesteps, it equals to implement \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T in this case. And we know that the fixed point of \ud835\udcaf\ud835\udcaf\\mathcal{T}caligraphic\\_T must be greater than or equal to 1\u2212\u03b3H1\u2212\u03b3Rmin1superscript\ud835\udefe\ud835\udc3b1\ud835\udefesubscript\ud835\udc45\\frac{1-\\gamma^{H}}{1-\\gamma}R\\_{\\min}divide start\\_ARG 1 - italic\\_\u03b3 start\\_POSTSUPERSCRIPT italic\\_H end\\_POSTSUPERSCRIPT end\\_ARG start\\_ARG 1 - italic\\_\u03b3 end\\_ARG italic\\_R start\\_POSTSUBSCRIPT roman\\_min end\\_POSTSUBSCRIPT, so the ratio will still be non-negative after some iterations. Except the clipping ratio c\ud835\udc50citalic\\_c, we select the same hyperparameter used in AL method and more details about the settings can be found in Appendix B.2.\n\n\n\n\n\n#### Baselines.\n\n\n\nTo verify our method sufficiently, we compare the clipped AL with several popular baselines as following:\n\n\n* \u2022\n\nAL: the original Advantage Learning algorithm (Bellemare et\u00a0al. [2016](#bib.bib2)), which is the basic method we modify. And we adopt the recommended \u03b1=0.9\ud835\udefc0.9\\alpha=0.9italic\\_\u03b1 = 0.9;\n* \u2022\n\nDQN: the vanilla DQN (Mnih et\u00a0al. [2015](#bib.bib14)), a famous baseline commonly used in discrete-action environment;\n* \u2022\n\nMDQN: the Munchausen DQN (Vieillard, Pietquin, and Geist [2020](#bib.bib22)), which is a state-of-the-art non-distRL algorithm. And we follow its hyperparameter suggestions: \u03b1=0.9\ud835\udefc0.9\\alpha=0.9italic\\_\u03b1 = 0.9 (Munchausen scaling term), \u03c4=0.03\ud835\udf0f0.03\\tau=0.03italic\\_\u03c4 = 0.03 (entropy temperature), and l0=\u22121subscript\ud835\udc5901l\\_{0}=-1italic\\_l start\\_POSTSUBSCRIPT 0 end\\_POSTSUBSCRIPT = - 1 (clipping value);\n* \u2022\n\nSoft-DQN(\u03c4\ud835\udf0f\\tauitalic\\_\u03c4): the vanilla DQN with maximum entropy regularization, i.e., the discrete-action version of Soft Actor-Critic (SAC) (Haarnoja et\u00a0al. [2018b](#bib.bib8)), we set the same temperature parameter \u03c4=0.03\ud835\udf0f0.03\\tau=0.03italic\\_\u03c4 = 0.03 with MDQN;\n\n\n\n\n\n\n![Refer to caption](/html/2203.11677/assets/x5.png)\n\n\n\n![Refer to caption](/html/2203.11677/assets/x6.png)\n\n\n\n![Refer to caption](/html/2203.11677/assets/x7.png)\n\n\n\n\n![Refer to caption](/html/2203.11677/assets/x8.png)\n\n\n\n![Refer to caption](/html/2203.11677/assets/x9.png)\n\n\n\n![Refer to caption](/html/2203.11677/assets/x10.png)\n\n\n\nFigure 3: Evaluation episode reward comparison between our clipped AL algorithm and the chosen baselines on six benchmark tasks. All the results are averaged over five random seeds, with the shade area corresponding to one standard error.\n\n\n\n#### Evaluation.\n\n\n\nAs for the evaluation scenarios, we select five MinAtar tasks (Asterix, Breakout, Freeway, Space-invaders, and Seaquest) and one PLE task (Pixelcopter). We separate the evaluation from the training process, and conduct policy evaluation per 5000 timesteps. Specifically, we measure the policy performance by the mean reward of 10 evaluation episodes, and all the performance results are averaged over 5 random seeds.\n\n\n\n\nTo further quantify the performance improvement, we adopt the \u201dbaseline-normalized\u201d score as the metric. At each evaluation, the score is the undiscounted sum of rewards, averaged over the last 5 evaluations. The normalized score is then a\u2212r|b\u2212r|\ud835\udc4e\ud835\udc5f\ud835\udc4f\ud835\udc5f\\frac{a-r}{|b-r|}divide start\\_ARG italic\\_a - italic\\_r end\\_ARG start\\_ARG | italic\\_b - italic\\_r | end\\_ARG, with a\ud835\udc4eaitalic\\_a the score of the compared algorithm, b\ud835\udc4fbitalic\\_b the score of the baseline, and r\ud835\udc5fritalic\\_r the score of a random policy.\n\n\n\n\n\n\n### Effectiveness of Clipping Mechanism\n\n\n\n#### Performance Improvement.\n\n\n\nWe firstly validate the effectiveness of our clipped AL. Figure [3](#S6.F3 \"Figure 3 \u2023 Baselines. \u2023 Experimental Setup \u2023 6 Experiment \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\") shows the performance comparison between our method and the baselines mentioned above. We can see that our clipped AL performs better significantly than the AL operator over 5 tasks except Freeway task. Though both methods have a similar final performance on Freeway task, our clipped AL still has a higher sample efficiency before the final convergence. Even comparing with MDQN and Soft-DQN(\u03c4\ud835\udf0f\\tauitalic\\_\u03c4), our method is also competitive and achieve the best performance on Breakout, Space invaders and Pixelcopter tasks.\nWe compute the \u2019DQN-normalized\u2019 score for the other 4 methods and Table [1](#S6.T1 \"Table 1 \u2023 Performance Improvement. \u2023 Effectiveness of Clipping Mechanism \u2023 6 Experiment \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\") depicts the quantitative results.\nWe can see from it that our clipped AL achieves around 45.73 % averaged performance improvement, which is better than the rest baselines\nand more than double times than the original AL method especially. All the results can verify our clipping mechanism does improve the original AL algorithm.\n\n\n\n\n\n\n\n|  |  |  |  |  |\n| --- | --- | --- | --- | --- |\n| Algorithm | Soft-DQN | MDQN | AL | clipAL |\n| Asterix | 36.59 | 12.46 | -1.60 | 6.90 |\n| (0.20) | (0.16) | (0.14) | (0.17) |\n| Breakout | 5.28 | 63.06 | -4.94 | 92.34 |\n| (0.17) | (0.29) | (0.17) | (0.27) |\n| Freeway | -3.96 | 2.03 | 2.52 | 2.10 |\n| (0.02) | (0.01) | (0.01) | (0.02) |\n| Space Invaders | -0.89 | 20.88 | 23.02 | 27.88 |\n| (0.11) | (0.22) | (0.16) | (0.18) |\n| Seaquest | 74.56 | 136.89 | 62.75 | 100.39 |\n| (0.25) | (0.41) | (0.64) | (0.36) |\n| Pixelcopter | 19.52 | 31.22 | 39.77 | 44.79 |\n| (0.20) | (0.21) | (0.17) | (0.10) |\n| mean | 21.85 | 44.42 | 20.25 | 45.73 |\n\n\nTable 1: DQN-normalized score comparison, which represents the percentage (%) of performance improvement than the DQN baseline. All the results are averaged over 5 seeds, and one standard deviation included in the parenthesis.\n\n\nNaturally, our method can be easily extended to the family of AL-based algorithms, so we also apply our clipping mechanism to two variants of AL-based algorithms, and all the results and analysis are provided in Appendix B.2.2.\n\n\n\n\n\n\n![Refer to caption](/html/2203.11677/assets/x11.png)\n\n\n\n![Refer to caption](/html/2203.11677/assets/x12.png)\n\n\n\nFigure 4: Comparison about the action gap and the V\ud835\udc49Vitalic\\_V value estimations on Seaquest and Space-invaders tasks during the training process. Top subfigures represent the results on Seaquest task and the bottom ones are on Space invaders task. a): action gap estimations; b): V\ud835\udc49Vitalic\\_V value estimations.\n\n\n\n#### Property Analysis.\n\n\n\nAs mentioned before, our clipped AL aims to achieve a balance between large action gaps and fast convergence of value function, which is thought of as the main incentive of superior performance. So in this section, we mainly verify whether our clipped AL can achieve this goal.\nWe estimate the both variables for \ud835\udcaf,\ud835\udcafAL\ud835\udcafsubscript\ud835\udcafAL\\mathcal{T},\\mathcal{T}\\_{\\rm{AL}}caligraphic\\_T , caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_AL end\\_POSTSUBSCRIPT, and \ud835\udcafclipALsubscript\ud835\udcafclipAL\\mathcal{T}\\_{\\rm{clipAL}}caligraphic\\_T start\\_POSTSUBSCRIPT roman\\_clipAL end\\_POSTSUBSCRIPT during the training process. Specifically, we denote the V\ud835\udc49Vitalic\\_V value by V\u03b8(s)=maxa\u2061Q\u03b8(s,a)subscript\ud835\udc49\ud835\udf03\ud835\udc60subscript\ud835\udc4esubscript\ud835\udc44\ud835\udf03\ud835\udc60\ud835\udc4eV\\_{\\theta}(s)=\\max\\_{a}Q\\_{\\theta}(s,a)italic\\_V start\\_POSTSUBSCRIPT italic\\_\u03b8 end\\_POSTSUBSCRIPT ( italic\\_s ) = roman\\_max start\\_POSTSUBSCRIPT italic\\_a end\\_POSTSUBSCRIPT italic\\_Q start\\_POSTSUBSCRIPT italic\\_\u03b8 end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ), and the empirical action gap by the difference of estimated values between the best and second best actions: Q\u03b8(s,a\\*)\u2212maxa\u2208\ud835\udc9c\\{a\\*}\u2061Q\u03b8(s,a)subscript\ud835\udc44\ud835\udf03\ud835\udc60superscript\ud835\udc4esubscript\ud835\udc4e\\\ud835\udc9csuperscript\ud835\udc4esubscript\ud835\udc44\ud835\udf03\ud835\udc60\ud835\udc4eQ\\_{\\theta}(s,a^{\\*})-\\max\\_{a\\in\\mathcal{A}\\backslash\\left\\{a^{\\*}\\right\\}}Q\\_{\\theta}(s,a)italic\\_Q start\\_POSTSUBSCRIPT italic\\_\u03b8 end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT ) - roman\\_max start\\_POSTSUBSCRIPT italic\\_a \u2208 caligraphic\\_A \\ { italic\\_a start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT } end\\_POSTSUBSCRIPT italic\\_Q start\\_POSTSUBSCRIPT italic\\_\u03b8 end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ) with a\\*=arg\u2061maxa\u2208\ud835\udc9c\u2061Q\u03b8(s,a)superscript\ud835\udc4esubscript\ud835\udc4e\ud835\udc9csubscript\ud835\udc44\ud835\udf03\ud835\udc60\ud835\udc4ea^{\\*}=\\arg\\max\\_{a\\in\\mathcal{A}}Q\\_{\\theta}(s,a)italic\\_a start\\_POSTSUPERSCRIPT \\* end\\_POSTSUPERSCRIPT = roman\\_arg roman\\_max start\\_POSTSUBSCRIPT italic\\_a \u2208 caligraphic\\_A end\\_POSTSUBSCRIPT italic\\_Q start\\_POSTSUBSCRIPT italic\\_\u03b8 end\\_POSTSUBSCRIPT ( italic\\_s , italic\\_a ) (Vieillard, Pietquin, and Geist [2020](#bib.bib22)).\n\n\n\n\nThe results in Figure [4](#S6.F4 \"Figure 4 \u2023 Performance Improvement. \u2023 Effectiveness of Clipping Mechanism \u2023 6 Experiment \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\") include the V\ud835\udc49Vitalic\\_V value and action gap estimations of DQN, AL, and clipped AL on Seaquest and Space-invaders tasks. Figure [4](#S6.F4 \"Figure 4 \u2023 Performance Improvement. \u2023 Effectiveness of Clipping Mechanism \u2023 6 Experiment \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\") shows the estimations of action gaps, in which the action gap of our clipped AL lies between the ones of DQN and AL for the both tasks. These results correspond to our theoretical analysis on the relationship of action gaps in Theorem [2](#S5.Ex8 \"Theorem 2. \u2023 Balance between Large Action Gap and Fast Convergence \u2023 5 Clipped Advantage Learning \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\"). And Figure [4](#S6.F4 \"Figure 4 \u2023 Performance Improvement. \u2023 Effectiveness of Clipping Mechanism \u2023 6 Experiment \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\") shows the V\ud835\udc49Vitalic\\_V value estimations of the three algorithms, we can see that the V\ud835\udc49Vitalic\\_V value of our clipped AL converges faster than AL, in spite of slower than DQN. Combining with the comparisons of both variables, our clipped AL does achieve such a balance between fast convergence and large action gaps, which verifies the feasibility and effectiveness of our motivations.\n\n\n\n\n\n\n### Ablation Study\n\n\n\nAccording to Theorem [1](#Sx1.EGx1 \"Theorem 1. \u2023 4 Performance Loss Bound of AL \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\"), we know that the trade-off between convergence speed and action gap can be achieved by tuning the scaling parameter \u03b1\ud835\udefc\\alphaitalic\\_\u03b1 and clipping ratio c\ud835\udc50citalic\\_c. In this section, we do an ablation study on both critical parameters. We mainly compare the action gap obtained by all the combinations from the candidate set: \u03b1=c={0.9,0.8,0.7}\ud835\udefc\ud835\udc500.90.80.7\\alpha=c=\\left\\{0.9,0.8,0.7\\right\\}italic\\_\u03b1 = italic\\_c = { 0.9 , 0.8 , 0.7 }.\n\n\n\n\nFigure [5](#S6.F5 \"Figure 5 \u2023 Ablation Study \u2023 6 Experiment \u2023 Robust Action Gap Increasing with Clipped Advantage Learning\") shows the action gap comparison about different parameter combinations on Space invaders and Seaquest tasks. We can see that, when fixing \u03b1\ud835\udefc\\alphaitalic\\_\u03b1, the action gap will decrease with the increase of clipping ratio c\ud835\udc50citalic\\_c; this is intuitive because a larger c\ud835\udc50citalic\\_c means the less probability to add the advantage term, leading to a smaller action gap. While a larger \u03b1\ud835\udefc\\alphaitalic\\_\u03b1 with a fixed c\ud835\udc50citalic\\_c can lead to more action gaps because \u03b1\ud835\udefc\\alphaitalic\\_\u03b1 determines the scaling of advantage term, i.e., gap-increasing. In other words, \u03b1\ud835\udefc\\alphaitalic\\_\u03b1 controls the overall action gaps of all state-action pairs, and our clipping ratio c\ud835\udc50citalic\\_c can further adjust the individual action gap for each state-action pair selectively so as to achieve the finer balance.\n\n\n\n![Refer to caption](/html/2203.11677/assets/x13.png)\nFigure 5: Ablation study on scaling parameter \u03b1\ud835\udefc\\alphaitalic\\_\u03b1 and clipping ratio c\ud835\udc50citalic\\_c in clipped AL. Comparison about the action gap with different hyperparameter combinations.\n\n7 Conclusion\n-------------\n\n\n\nAdvantage Learning (AL) is considered to be more robust due to its regularization on the action gap. However, our analysis reveals that AL may cause worse performance loss bound, leading to a slower value convergence if increasing the action gap blindly. In this paper, we propose the clipped AL to adjust the advantage term adaptively so as to increase the action gap more reasonably. This simple modification can obtain better performance with faster convergence while maintaining a proper action gap to keep its robustness and be extended to the family of gap-increasing operators easily. The theoretical and empirical results also confirm the rationality and effectiveness of our proposed methods.\n\n\n\n\nAn interesting future study is to design an adaptive clipping ratio c\ud835\udc50citalic\\_c for the training process. Because the clipping mechanism may be more necessary for the robust gap-increasing at the early training stage. While when the induced optimal actions align with the true optimal ones at the late training stage, increasing the action gap for all state-action pairs is more important.\n\nAcknowledgments\n---------------\n\n\n\nThis work is partially supported by National Science Foundation of China (61732006,61976115), and National Key R&D program of China (2021ZD0113203). We would also like to thank the anonymous reviewers, for offering thoughtful comments and helpful advice on earlier versions of this work. We also thank Yuhui Wang and Qingyuan Wu for their constructive discussion in the early stage.", "url": "https://arxiv.org/abs/2203.11677"}
{"text": "1 \n Quantifying the pathways to life using assembly spaces  \n \nStuart M. Marshall,1 Douglas G. Moore,2 Alastair R. G. Murray,1 Sara I. Walker,2,3* and Leroy \nCronin1* \n1 School of Chemistry, University of Glasgow, Glasgow, G12 8QQ, UK.  \n2 BEYOND Center for Fundamental Concepts in Science, Arizona State University, Tempe, \nAZ, USA  \n3 School of Earth and Space Exploration, Arizona State University, Tempe, AZ, USA  \n*Correspondi ng author email: Lee.Cronin@glasgow.ac.uk, sara.i.walker@asu.edu   \n Abstract  \nWe have developed the theory of pathway assembly to explore the extrinsic information required to distinguish a given object  from a random ensemble. To quantify the assembly in an \nagnostic way , we determine the pathway assembly information contained within such an object \nby deconstructing the object into its irreducible parts, and then evaluating the minimum number \nof steps to reconstruct the object. The formalisation of this approach uses an assembly space. By finding the minimal number of steps contained in the route by which the objects can be \nassembled within that space, we can compa re how much information ( \ud835\udc3c\ud835\udc3c) is gained from \nknowing this pathway assembly index (PA) according to \ud835\udc3c\ud835\udc3c\n\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43=\ud835\udc59\ud835\udc59\ud835\udc59\ud835\udc59\ud835\udc59\ud835\udc59 |\ud835\udc41\ud835\udc41|\n|\ud835\udc41\ud835\udc41\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43|  where, for a n end \nproduct with \ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43=\ud835\udc65\ud835\udc65,  N is the set of objects possible that can be created from the same \nirreducible parts with in \ud835\udc65\ud835\udc65 steps regardless of PA , and N PA is the subset of those objects with \nthe precise pathway assembly index  \ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43=\ud835\udc65\ud835\udc65.  Applying this theory to objects formed in 1D, \n2D and 3D leads to the identification of objects in the world or wider Universe that have high \nassembly numbers. W e propose that objects with high PA will be uniquely identifiable as those \nthat must have been produced by biological or technological processes, rather than the \nassembly occurring via unbiased random processes alone , thereby defining a new scale of \naliveness. We think this approach is needed to help identify the new physic al and chemical \nlaws needed to understand what life is , by quantifying what life does . \n \nIntroduction In the thought experiment known as the \u201cinfinite monkey theorem \u201d, an infinite number of \nmonkeys, each having a typewriter, produce strings of text by hitting keys at random ( 1). Given \ninfinite resources, it can be deduced that the monkeys will produce all possible strings, \n2 \n including the complete works of Shakespeare. However, when constrained to the bounds of the \nphysical universe, the likelihood that any particular text is produced by a finite number of \nmonkeys drops rapidly with the length of the text ( 2). This can also be extended to physical \nobjects like cars, aeroplanes, and computers, which must be constructed from a finite set of \nobjects  - just as meaningful text is constructed from a finite set of letters. Even if we were to \nconvert nearly all matter in the universe to object constructing monkeys, and give them the age \nof the universe in which to work, the probability that any monkey would construct  any \nsufficiently comple x physical object is negligible ( 3). This is an entropic argument \u2013 the \nnumber of possible arrangements of the objects of a given composition increases exponentially with the object size. For example, if the number of possible play- sized strings is suffici ently \nlarge, it would be practically impossible to produce a  predetermined Shakespearean string \nwithout the author. This argument implies information  external to the object itself  is necessary \nto construct  an object  if it is of sufficiently high complexity  (4,5): in biology the requisite \ninformation partly comes from DNA, the sequence of which has been acquired  through \nprogressive rounds of evolution. Although Shakespeare\u2019s works are \u2013  in the absence of an \nappropriate constructor (6) (an author)  - as likely  to be produced as any other string of the same \nlength, our knowledge of English, and Shakespeare in particular, allows us to partition the set \nof possible strings to generate information about those  strings containing meaning, and to \nconstruct them.  \n \nBiological systems have access to a lot of information -  genetically, epigenetically, \nmorphologically, and metabolically - and the acquisition of that information occurs via \nevolutionary selection over successive cycles of replication and propagation ( 7). One way to \nlook at such systems is by comparing the self -dissimilarity between different classes of \ncomplex system, allowing a model free comparison ( 8).  However, i t has also been suggested \nthat much of this information is effectively encrypted, with the heritable information being \nencoded with random keys from the environment ( 9). As such, these random keys are recorded \nas frozen accidents and increase the operative information content, as well as help direct the system during the process of evolution, producing objects that can construct other objects ( 10). \nThis is significant since one important characteristic of objects produced autonomously by \nmachinery (such as life), which itself is instructed in some way, is their relative complexity as compared to objects that require no information for their assembly beyond what chemistry and \nphysics alone can provide. This means that for complex objects there is \u2018object -assembly\u2019 \ninformation that is generated  by an evolutionary system, and is not just the product of laws of \n3 \n physics and chemistry alone. B iological systems are the only known source of agency in the \nuniverse (11), and it has been suggested that new physical laws are needed to understand the \nphenomenon of life ( 12). The challenge is how to explore th e complexity  of objects generated \nby evolutionary systems  without a priori  havi ng a model of the system.  \n \nHerein, we present the foundations of a new theoretical approach to agnostically quantify the \namount of potential pathway assembly information contained within an object. This is achieved \nby considering how the object can be dec onstructed into its irreducible parts, and then \nevaluating the minimum number of steps  necessary  to reconstruct the object along any \npathway. The analysis of pathway assembly is done by the recursive deconstruction of a given object using shortest paths, a nd this can be used to evaluate the effective pathway assembly \nindex for that object ( 13). In developing pathway assembly, we have been motivated to create \nan intrinsic  measure of an object forming through random processes, where the only knowledge \nrequire d of the system is the basic building blocks and the permitted ways of joining structures \ntogether. This allows determining when an extrinsic  agent or evolutionary system is necessary \nto construct the object, permitting  the search for complexity in the abstract, without any specific \nnotions of what we are looking for, thus removing the requirement for an external imposition of meaning, see Figure 1. \n \n \n \nFigure 1:  The Pathway Assembly process (centre) ( 13) is compared to implementations of \nShannon Entropy ( 14) (left) and Kolmogorov Complexity ( 15) (right) for blue and white \nblocks. The Pathway Assembly process leads to a measure of structural complexity that \naccounts for the structure of the object and how it could have been constructed, which is in all \ncases computable and unambiguous.  \n\n4 \n  \nThe development of the Pathway Assembly (13) index (PA) was motivated by the desire to \ndefine a biological threshold, such that any object found in abundance with PA above t he \nthreshold would have required the intervention of one or more biological processes to form (16). The Pathway Assembly index (PA) of an object is the length of the shortest pathway to \nconstruct the object starting from its basic building blocks . It shoul d be noted that this approach \nis entirely classical (17), allowing quantifying pathways through assembly space \nprobabilistically as a way to understand what life does . We construct the object using a \nsequence of joining operations, where at each step any s tructures already created are available \nfor use in subsequent steps, see Figure 2. The shortest pathway approach is in some ways \nanalogous to Kolmogorov complexity ( 15), which in the case of strings is the shortest computer \nprogram that can output a given string. However, Pathway Assembly differs in that we only \nallow joining operations as defined in our model. This restriction is intended to allow the \nPathway Assembly process to mimic the natural construction of objects through random processes, and it also importantly allows the PA of an object to be computable for all finite \nobjects (see Theorem 4 in the SI).  \n \n \n \nFigure 2:  The basic concept of pathway assembly is shown here. Each of the final structures \ncan be created from white and blue basic objects in four joining operations, giving a Pathway \nAssembly Index of 4. Pathway (a) shows the creation of a structure that can onl y be formed in \nfour steps by adding one basic object at a time, while pathway (c) represents the maximum increase in size per step, by combining the largest object in the pathway with itself at each \nstage. Pathway (b) is an intermediate case.  \n\n5 \n Given a sys tem where objects interact randomly and with equal probability, it is intuitively \nclear that the likelihood of an object being formed in \ud835\udc5b\ud835\udc5b steps decreases rapidly with \ud835\udc5b\ud835\udc5b . \nHowever, it is also true that a highly contrived set of biases could guarantee the formation of \nany object . For example, this could occur i f we were to model the system such that  any \ninteractions contributing to the formation of the object were certain to be successful, while other interactions were prohibited. For complex objects, such a serendipitous set of biases \nwould seem unlikely in the absence of external information about the end products , but physical \nsystems generally do have biases in their interactions, and we can explore how these affect the \nlikelihood of formation of objects.  However, we expect f or any perceived \u201cconstruction \nprocesses\u201d that requires  a large enough set of highly contrived biases, we can deduce that \nexternal information is required in the form of a \u201cmachine\u201d that is doing the constructing. \n \nTechnological processes  are bootstrapped to biological ones, and hence , by extension, \nproduction of technosignatures  involve s process es that necessarily have a biological origin. \nExamples of biosignatures and technosignatures  include chemical products produced by the \naction of complex molecular systems such as networks of enzymes (18), and also objects whose \ncreation involved any biological organisms such as technological artefacts (19), complex \nchemicals made in the laboratory ( 20), and the complete works of Shakespeare. Finding the \nobject in some abundance, or a single object with a large number of complex, but precisely \nrepeating features, is required in order to distinguish single random occurrences from \ndeliberately generated objects.  For example, a system which produces long random strings will \ngenerate  many that have high PA, but  not in abundance. Finding the same long string more \nthan once will tell us that there is a bias in the system towards creating that string , thus \nsearching f or signatures of life should involve looking for objects with high PA found in \nrelatively high abundance .  \n \nFormalism  \nIn this manuscript, we explore the foundations of Pathway Assembly, as well as some of its properties and variants. We also describe how P athway Assembly can be incorporated into a \nnew information measure, Pathway Information, and how this can help identify objects, above \na threshold, that must have been produced by living systems. Finally, we offer some examples \nof the use of pathway assemb ly in systems of varying dimensionality, and describe some \npotential real -world applications of this approach. The Pathway Assembly process is formally \ndefined in the context of an Assembly Space, which comprises an acyclic quiver \u0393 (a quiver \n6 \n being a direc ted graph that allows multiple edges between pairs of nodes and has no directed \ncycles), where the vertices in the quiver are objects in the space, along with an edge labelling \nmap \ud835\udf19\ud835\udf19 which associates each edge with a vertex in the quiver (see Definition 11 in the SI). The \nquiver is associated with a reachability relationship \u2264 where for vertices \ud835\udc4e\ud835\udc4e,\ud835\udc4f\ud835\udc4f in \u0393, \ud835\udc4e\ud835\udc4e\u2264\ud835\udc4f\ud835\udc4f if \nthere is a path from \ud835\udc4e\ud835\udc4e  to \ud835\udc4f\ud835\udc4f, in other words it is possible reach \ud835\udc4f\ud835\udc4f starting at \ud835\udc4e\ud835\udc4e by following a \nsequence of edges along their respective directions. If for an edge \ud835\udc52\ud835\udc52  from object \ud835\udc65\ud835\udc65 to object \ud835\udc67\ud835\udc67, \n\ud835\udf19\ud835\udf19(\ud835\udc52\ud835\udc52)=\ud835\udc66\ud835\udc66, then this can be thought of as \ud835\udc67\ud835\udc67  being constructed through the combination of \ud835\udc65\ud835\udc65  and \n\ud835\udc66\ud835\udc66. We also require that the symmetric operation exists within the space, i.e. there is an edge \ud835\udc59\ud835\udc59  \nfrom \ud835\udc66\ud835\udc66 to \ud835\udc67\ud835\udc67 such that \ud835\udf19\ud835\udf19(\ud835\udc59\ud835\udc59)=\ud835\udc65\ud835\udc65. \n \nWe define an assembly subspace \u0394 on an assembly space \u0393 to be an assembly space that \ncontains a subset of the objects in  \u0393, maintaining all the relation ships between them (see \nDefinition 1 5 in the SI). An assembly subspace is said to be rooted if it contains a nonempty \nsubset of the basic objects. This is an important distinction in the definition of the Assembly \nIndex below, as it allows us to define the  shortest construction pathway for objects using a \nconsistent set of basic objects. We define the basis of an Assembly Space \u0393 as the set of minimal \nvertices in the space with regard to \u2264 , and refer to those vertices as basic objects, basic vertices, \nor ba sic elements (see Definition 12 in the SI). We define an assembly map  (see Definition 17 \nin the SI) as a map from one assembly space \u0393 to another \u0394  that maintains the relationship \nbetween objects, but may map multiple objects in \u0393  to the same object in \u0394. One such map that \nis generally applicable  is the mapping of each object to its size, see Figure 3. Assembly maps \ncan be useful for finding a lower bound to the assembly index (described below, and Definition \n19 in the SI), by mapping to a  system that may be more computationally tractable to work in  \nthan the original system of interest (see Theorem 3 in the SI).  \n \n7 \n  \nFigure 3:  An assembly space comprised of objects formed by joining together white and blue \nblocks. Some of the morphisms have been omitted for clarity. The dotted region is an assembly \nsubspace, and topological ordering of the objects in the subspace represents a minimal \nassembly pathway for  any subspace containing the sequence of four blue boxes. \n \nWe define the cardinality and augmented cardinality as the number of objects in the assembly space, where  the augmented cardinality excludes the basic objects  (defined separately, as this \nmeasure is used in the assembly index) . We then define an assembly pathway and the assembly \nindex. An assembly pathway is a set of all the objects in an assembly space \u0393 in some order \nthat respects the reachability relationship  \u2264, i.e. a topological order. If we take all the rooted \nassembly subspaces of \u0393 that contain some object \ud835\udc65\ud835\udc65 , we then define the assembly index as the \naugmented cardinality of the smallest rooted assembly subspace that contains \ud835\udc65\ud835\udc65. The subspace \nmust be rooted, as otherwise a subspace containing only \ud835\udc65\ud835\udc65 would meet this criterion. We use \nthe augmented cardinality of this subspace, as defined above, as defining the assembly index \nwithout including basic objects in accord with the phys ical interpretations that motivated this \nmeasure;  however , the cardinality could instead be used if desired, and the difference in the \nmeasures for any structures with shared basic objects would be require a constant. The \nassembly index then represents the  minimum number of joining operations required to \n\n8 \n construct object \ud835\udc65\ud835\udc65, as illustrated in Figure 2. For a formal definition, see Definition 19  in the \nSI. \n \nWhen mapping from assembly space \u0393  to assembly space \u0394  through an assembly map f, the \nassembly index o f a mapped object in \u0394  acts as a lower bound for the assembly index of the \noriginal object in \u0393 . This can allow us, for example, to map an assembly space to another in \nwhich finding the assembly index is less computationally intensive in order to calculate  a useful \nlower bound, see Theorem 3 in the SI. The assembly index of an object in any rooted assembly subspace of \u0393 is an upper bound for the assembly index of the object in \u0393 , see Lemma 6 in the \nSI.  A split- branched space is an assembly space \u0393  where fo r each pair of objects \ud835\udc65\ud835\udc65 ,\ud835\udc66\ud835\udc66 in \u0393, \ud835\udc65\ud835\udc65\u2264\n\ud835\udc66\ud835\udc66 or \ud835\udc66\ud835\udc66\u2264\ud835\udc65\ud835\udc65 whenever \ud835\udc49\ud835\udc49(\ud835\udc65\ud835\udc65\u2193)\u2229\ud835\udc49\ud835\udc49(\ud835\udc66\ud835\udc66\u2193)\u2260\u2205 (see Definition 14 in the SI).  This means that, other \nthan basic objects, when combining two different objects neither of them can have an assembly \npathway that uses objects created in the construction of the other. They may use objects that \nare considered identical (e.g. the same string) but these are separate objects within the space. \nSince we can define an assembly map that maps these identical objects to a new space where \nthey map to the same object, the split -branched assembly index for a system is an upper bound \nfor the assembly index on that system. \n \nWe use the space of integers under addition to explore th ese assembly maps, where an addition \nchain for an integer is a sequence o f integers, starting with 1, with each integer in the sequence \nbeing the sum of two previous integers, see Figure 4. A minimal addition chain for an integer \nis the shortest addition chain that terminates in that integer, and the size of that addition chain  \nis equivalent to the pathway assembly index of the integer (after subtracting 1 to account for \nthe single basic object). The objects in this space can be considered as abstract integers, or as \nrepresenting the size of objects in some other assembly space.  See the \u201cExample Applications\u201d \nsection below for more information on addition chains. We model the assembly process as a \nweighted decision tree where at each level there is a choice of objects that can be formed. The \nnumber of choices at each level of the  tree is constrained by the number of integers that have \nthe assembly index associated with that level. To obtain the assembly indices, we used data for all minimal addition chain lengths for integers up to 100,000, as published in the Online \nEncyclopaedia  of Integer Sequences (21). \n \n9 \n  \n \nFigure 4:  An assembly map that maps an assembly space of white and blue blocks onto \nintegers representing the object size.  \n \nIn the initial case of zero bias, the probability of each step was drawn from a uniform random \ndistribution. In subsequent steps, a value \ud835\udc65\ud835\udc65 was drawn from a uniform random distribution \nbetween 0 and a value \u210e , and the probability of the step was assigned a value 10\ud835\udc65\ud835\udc65, subsequently \nnormalised so that all probabilities sum to 1. As \u210e increases, so does the bias of the distribution, \nwith each increase of \ud835\udc65\ud835\udc65 by 1 representing a 10- fold increase in likelihood of that choice. We \nthen calculated the probability o f the most likely pathway to assess the impact of the bias. In \nthe case of zero bias, at assembly index 25, the integer generated along the most probable \npathway will be found has approximately 10\u22127 probability of being formed. Increasing the bias \nto the m aximum level \u210e=5, the integer generated along the most probable pathway at \nassembly index 25 will appear approximately 12% of the time, see Figure 5.  \n\n10 \n  \n \nFigure 5:  Left \u2013 Minimal addition chains modelled as a decision tree. Right \u2013 probability of \nthe most likely pathway at different levels of bias.  \n \nThese probabilities will reduce further when considering greater number of choices, such as in \nsituations of higher dimensionality, like strings, grid structures, and graphs (see \u201cExample \nApplications\u201d section below). In the maximum bias case  explored here , where \u210e =5, the \nchoices with \ud835\udc65\ud835\udc65 =5 will be 10,000  times more likely than those with \ud835\udc65\ud835\udc65 =1.  This argument \ndemonstrates that using a pathway assembly model will result in a threshold above which it is \nunlikely tha t any specific object would be found, with the threshold depending on the system \nof objects and joining operations, and the physical limits of the inherent biases present  in the \nprocess. Even in a significantly biased system, such a  threshold will exist, and any objects \nfound in abundance with PA above the threshold will require some process inducing specificity \noutside of the random (bias) model to form. We consider these additional processes to be \nbiological. Exploration of the processes and biases of a s pecific system can then be used, along \nwith experimental data, to determine this threshold.  \n \nIn addition to using the assembly index to determine this  biological threshold, it is useful to \nconsider an information measure based on the number of possible st ructures that can be created \nusing assembly pathways, see Figure 6. One way to do this is to consider a bounded set of \npossible structures \ud835\udc41\ud835\udc41 , and then the sub set of possible structures with a specified  pathway \nassembly index, \ud835\udc41\ud835\udc41 \ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43. The \"pathway information\" is the amount of uncertainty the pathway \nassembly index reduces beyond what knowledge of only the size or general composition can \nprovide. In this case, using the approach of Shannon Information ( 14), the information provided \nby the Pathway Assembly index, \ud835\udc3c\ud835\udc3c\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43, is given by:  \n\n11 \n \ud835\udc3c\ud835\udc3c\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43=\ud835\udc59\ud835\udc59\ud835\udc59\ud835\udc59\ud835\udc59\ud835\udc59 |\ud835\udc41\ud835\udc41|\n|\ud835\udc41\ud835\udc41\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43|  \n \n \nFigure 6:  Pathway Information. The precise definitions of \ud835\udc41\ud835\udc41 and \ud835\udc41\ud835\udc41\ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43 will depend on the \nspecific implementation.  \n \nIt should be noted that this information measure provides a way of formalizing information \nover states (size, composition) and over paths (PA) within a common mathematical framework. \nTo calculate I PA, there are several possible choices for \ud835\udc41\ud835\udc41, all of which must be finite. In o ne \noption, for a n end product with \ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43=\ud835\udc65\ud835\udc65, N is the set of objects possible that can be created from \nthe same irreducible parts within \ud835\udc65\ud835\udc65 steps regardless of PA , and N PA is the subset of those objects \nwith the precise pathway assembly index  \ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43=\ud835\udc65\ud835\udc65. This then gives us a me asure of the \ninformation provided by learning the assembly index, within the context of all objects that \ncould be created by traversing that distance in the assembly space. The difference in utility \nbetween the Pathway Assembly index and the pathway inform ation, is that the Assembly Index \nprovides a simple threshold based on pathway length, whereas pathway information can \n\n12 \n provide an intuition on what the assembly index tells us about the space of possible objects and \nhow much additional information is provi ded by knowing the paths . The information increases \nrapidly with Assembly Index, as the space of objects accessible within a given number of steps \ngrows rapidly with the number of steps , see Figure 7.  P seudo code describ ing the algorithm to \ncalculate the pathway assembly of a given object is described in the SI.  \n \n \nFigure 7 : Pathway Information vs Pathway Assembly index for strings consisting of 6 x letter \n\u201cA\u201d and 6 x letter \u201cB\u201d. If we have a string with Assembly Index of 9, i.e. it can be constructed in 9 steps, the pathway information is much higher than with Assembly Index 8, as the number \nof objects that can be constructed in \ud835\udc65\ud835\udc65  steps grows much more rapidly than the number of \nobjects with \ud835\udc43\ud835\udc43\ud835\udc43\ud835\udc43=\ud835\udc65\ud835\udc65. \n \nExample Applications  \nIn the following sections we describe how the pathway assembly approach can be applied to systems of varying dimensionality, see Figure 8.  \n \nAn addition chain is defined ( 22) as \u201ca finite sequence of positive integers  \n1 = \ud835\udc4e\ud835\udc4e\n0 \u2264 \ud835\udc4e\ud835\udc4e1\u2026 \u2264 \ud835\udc4e\ud835\udc4e\ud835\udc5f\ud835\udc5f = \ud835\udc5b\ud835\udc5b with the property that for a ll \ud835\udc56\ud835\udc56 > 0 there exists \ud835\udc57\ud835\udc57,\ud835\udc58\ud835\udc58 with  \n\ud835\udc4e\ud835\udc4e\ud835\udc56\ud835\udc56 = \ud835\udc4e\ud835\udc4e\ud835\udc57\ud835\udc57 + \ud835\udc4e\ud835\udc4e\ud835\udc58\ud835\udc58 \ud835\udc4e\ud835\udc4e\ud835\udc5b\ud835\udc5b\ud835\udc4e\ud835\udc4e \ud835\udc5f\ud835\udc5f \u2265 \ud835\udc56\ud835\udc56 > \ud835\udc57\ud835\udc57 \u2265 \ud835\udc58\ud835\udc58 \u2265 0. An optimal addition chain is one with the  shortest \npossible length. An example of an optimum addition chain is for \ud835\udc5b\ud835\udc5b=123 is \n \n{1,2,3,5,10,15,30,60,63,123}  \n\n13 \n  \nAn assembly space (\u0393 ,\ud835\udef7\ud835\udef7) for addition chains can be defined where \ud835\udc49\ud835\udc49 (\u0393)=\u2115\\{0}=\n{1,2,3,\u2026}, the set of positive integers, and for an edge \ud835\udc52\ud835\udc52~[\ud835\udc67\ud835\udc67\ud835\udc65\ud835\udc65], \ud835\udf19\ud835\udf19(\ud835\udc52\ud835\udc52)=\ud835\udc66\ud835\udc66 if and only if \ud835\udc65\ud835\udc65 +\n\ud835\udc66\ud835\udc66=\ud835\udc67\ud835\udc67. In this space, an assembly pathway on a subspace representing the assembly index of \nan integer will be equivalent to an optimum addition chain (subtracting 1 to account for the \nsingle basic object). Addition c hains can provide a useful lower bound for the  assembly index \nin other assembly spaces, as we can define an assembly map in an assembly space that maps each object to an integer representing the number of basic objects within it (see Figure 3).  Addition chains can be generalised to vectorial addition chains (23), in which we define a \nvectorial addition chain for an k -dimensional vector of natural numbers \ud835\udc5b\ud835\udc5b \u2208\u2115\n\ud835\udc58\ud835\udc58/{0} (excluding \nthe 0 vector) as a sequence of \ud835\udc4e\ud835\udc4e\ud835\udc56\ud835\udc56\u2208\u2115\ud835\udc58\ud835\udc58/{0} such that for \u2212 \ud835\udc58\ud835\udc58+1\u2264\ud835\udc56\ud835\udc56\u22640, \ud835\udc4e\ud835\udc4e\ud835\udc56\ud835\udc56 are the standard \nbasis of unit vectors {(1,0,...,0),(0,1,...,0),...,(0,0,...,1)}, and for each \ud835\udc56\ud835\udc56>0 there exists \n\ud835\udc57\ud835\udc57,\ud835\udc58\ud835\udc58 with \ud835\udc4e\ud835\udc4e \ud835\udc56\ud835\udc56=\ud835\udc4e\ud835\udc4e\ud835\udc57\ud835\udc57+\ud835\udc4e\ud835\udc4e\ud835\udc58\ud835\udc58 and \ud835\udc56\ud835\udc56>\ud835\udc57\ud835\udc57\u2265\ud835\udc58\ud835\udc58. An example of a vectorial addition chain for [8,8,10] is \n \n[[1,0,0],[0,1,0],[0,0,1],[1,1,0],[1,1,1],[2,2,2],[4,4,4],[8,8,8],[8,8,9],[8,8,10]] \n \n \n Figure 8:  Example a ssembly pathways for systems of varying dimensionality  \n  \n\n14 \n We can also define an assembly map from other assembly spaces to vectorial addition chains, \nwhere each element in a vector represents the count of a type of basic object (e.g. [1, 2, 3] for \n1 red block, 2 blue blocks, 3 green blocks), so this can provide another lower bound. In this \ncase, there also exists a trivial assembly map from vectorial addition chains to addition chains, \nby summing the vector, so the assembly index on addition chains is a lower bound for the \nassembly index on vectorial addition chains.  In one -dimensional strings we can define an \nassembly space (\u0393,\ud835\udf19\ud835\udf19) of strings, where each \ud835\udc60\ud835\udc60\u2208\ud835\udc49\ud835\udc49(\u0393) is a string and if a string \ud835\udc67\ud835\udc67 can be \nproduced by concatenating strings \ud835\udc65\ud835\udc65 and \ud835\udc66\ud835\udc66, then there exists an edge \ud835\udc52\ud835\udc52 ~[\ud835\udc67\ud835\udc67\ud835\udc65\ud835\udc65] with  \ud835\udf19\ud835\udf19(\ud835\udc52\ud835\udc52)=\ud835\udc66\ud835\udc66, \nif \ud835\udc67\ud835\udc67 can be produced by concatenating \ud835\udc65\ud835\udc65  and \ud835\udc66\ud835\udc66. There are multiple systems that have string \nrepresentations, including text strings, binary signals and polymers.  \n \n \n \nFigure 9:  Examples of text assembly pat hways for 16 -character strings. The first example \ndemonstrates the shortest possible assembly index of any such string. The second example has \na nontrivial assembly pathway, while the third example is a string without any shorter pathway \nthan adding one character at a time. This model assumes that text fragments cannot be reversed when concatenating.  \n Two other methods for analysing the complexity / information content of strings are the \nShannon Information (14) and the Kolmogorov Complexity ( 15). The Shannon information \ncontent of a string is based on the probability of occurrence of its characters.  For example, for \na string \u201cABBCCCDDDD\u201d, the Shannon entropy (using base 2) is given by \n \n\ud835\udc3b\ud835\udc3b=\u2212\ufffd\ud835\udc5d\ud835\udc5d\n\ud835\udc56\ud835\udc56\ud835\udc5d\ud835\udc5d\ud835\udc56\ud835\udc56\n\ud835\udc56\ud835\udc56\u2208{\ud835\udc43\ud835\udc43,\ud835\udc35\ud835\udc35,\ud835\udc36\ud835\udc36,\ud835\udc37\ud835\udc37} =\u2212(0.10.1  +0.20.2  +0.30.3  +0.40.4  )\u22431.84 \n \n\n15 \n In the case of strings, the probabilities \ud835\udc5d\ud835\udc5d\ud835\udc56\ud835\udc56 for each character \ud835\udc56\ud835\udc56 represent the likelihood of finding \nit in the string, i.e. the inverse of the count of that character within the string. The Shannon \ninformation content is defined as the reduction in entropy (uncertainty) on being presented with \nsome information, and in the case where we are presented with the string itself (reducing entropy to zero) the entropy and information are numerically equal. Unlike Pathwa y Assembly, \nShannon information in this implementation does not consider the structure of the string, e.g. the information content will be the same for \u201cABBCCCDDDD\u201d as for \u201cABCDBCDCDD\u201d. The Kolmogorov Complexity ( 15) of an object is the length of the short est program that outputs \nthat object, in a given Turing- complete language. Although Kolmogorov Complexity is \ndependent on the language used, it can be shown that the Kolmogorov complexity \ud835\udc36\ud835\udc36 in any \nlanguage \ud835\udf19\ud835\udf19 can be related to the Kolmogorov complexity in a universal language \ud835\udc48\ud835\udc48  by  \n\ud835\udc36\ud835\udc36\n\ud835\udc48\ud835\udc48(\ud835\udc65\ud835\udc65)\u2264\ud835\udc36\ud835\udc36\ud835\udf19\ud835\udf19(\ud835\udc65\ud835\udc65)+\ud835\udc50\ud835\udc50 for some constant \ud835\udc50\ud835\udc50 (24). If a string cannot be expressed in a universal \nlanguage by a program shorter than its length, it is considered random. It has been shown that the Kolmogorov complexity is not computable, whereas the Pathway Assembly index is computable (see Theorem 4 in the SI).  \n \nWe can extend Pathway Assembly to two dimensions by considering a grid of pixels, or \ncoloured boxes, for example a digital image. For simplicity we will consider images with b lack \nand white basic objects, although this could be simply extended to greyscale images or colour images (e.g. greyscale images could have 256 basic objects representing different pixel intensities, as in an 8- bit greyscale image). We can define an assemb ly space with assemblages \nof black and white pixels as objects. In this space, two assemblages \ud835\udc4e\ud835\udc4e and \ud835\udc65\ud835\udc65 are connected by \nan edge \ud835\udc52\ud835\udc52 ~ [\ud835\udc65\ud835\udc65\ud835\udc4e\ud835\udc4e] if \ud835\udc4e\ud835\udc4e is a substructure of \ud835\udc65\ud835\udc65. The edge \ud835\udc52\ud835\udc52 is labelled as \ud835\udf19\ud835\udf19 (\ud835\udc52\ud835\udc52)=\ud835\udc4f\ud835\udc4f with \ud835\udc4f\ud835\udc4f the \ncomplement of \ud835\udc4e\ud835\udc4e  in \ud835\udc65\ud835\udc65. In other words, you can connect \ud835\udc4e\ud835\udc4e and \ud835\udc4f\ud835\udc4f together to get \ud835\udc65\ud835\udc65 . A choice can \nbe made about whether to enforce the preservation of orientation, or whether to consider substructures rotated by 90 degrees to be equivalent, and the latter choice can be related t o the \nformer by way of an assembly map. An illustration of an assembly pathway in this space can be seen in Figure 10.  \n16 \n  \n \nFigure 10:  Illustrative assembly pathway of a two- dimensional image. This does not \nnecessarily represent the minimal assembly pathway for this shape. Here, images that are \nrotated are considered equivalent.  \n The assembly index of an image can be bounded by an assembly map to the one -dimensional \ncase, for example by mapping to a numeric list containing a count of the number of black pixels in each column . It can also be mapped to the space of addition chains as normal  and to a reduced \nrepresentation of the image such as those generated by pooling operations used in convolutional \nneural networks, or quantisation matrices used in jpeg compression. To extend pathway \nassembly to three dimensions we can consider structures created out of cubic building blocks \nas a natural extension of the two- dimensional model. Pathway assembly does not need to be \napplied to objects as a whole, but can be applied to shared motifs or networks found within the \nobjects (13), which can in some cases map to the problem of cubic building blocks. P athway \nassembly, as described here, currently has no simple extension to continuous objects, however \nwe can use an  assembly map to define a function that consistently maps similar features to \nlarger block structures, and can calculate the assembly index o f that structural motif to explore \nwhether it is over the biological threshold, if found in some abundance. As in the two-dimensional case, the assembly index of cubic structures can be bounded by an assembly map \nto the two -dimensional case, the one- dimens ional case, or to the case of addition chains.  \n \nAn undirected graph \ud835\udc3a\ud835\udc3a(\ud835\udc49\ud835\udc49,\ud835\udc38\ud835\udc38) is defined by a set of vertices \ud835\udc49\ud835\udc49 and a set of edges \ud835\udc38\ud835\udc38 \u2286\ud835\udc49\ud835\udc49\u00d7\ud835\udc49\ud835\udc49.  \nAn assembly space for connected graphs (directed or undirected) can be defined where \u0393 is the \nspace of all connected graphs, with the basis set \ud835\udc35\ud835\udc35 consisting of a single node. The reachability \nrelationship \u2264 is defined on \u0393  such that \ud835\udf19\ud835\udf19([\ud835\udc3a\ud835\udc3a\n\ud835\udc65\ud835\udc65,\ud835\udc3a\ud835\udc3a\ud835\udc4e\ud835\udc4e])=\ud835\udc3a\ud835\udc3a\ud835\udc4f\ud835\udc4f if \ud835\udc49\ud835\udc49\ud835\udc65\ud835\udc65=\ud835\udc49\ud835\udc49\ud835\udc4e\ud835\udc4e\u222a\ud835\udc49\ud835\udc49\ud835\udc4f\ud835\udc4f and \ud835\udc38\ud835\udc38\ud835\udc65\ud835\udc65=\ud835\udc38\ud835\udc38\ud835\udc4e\ud835\udc4e\u222a\ud835\udc38\ud835\udc38\ud835\udc4f\ud835\udc4f\u222a\n\ud835\udc38\ud835\udc38\ud835\udc4e\ud835\udc4e\ud835\udc4f\ud835\udc4f where \ud835\udc38\ud835\udc38\ud835\udc4e\ud835\udc4e\ud835\udc4f\ud835\udc4f\u2286\ud835\udc49\ud835\udc49\ud835\udc4e\ud835\udc4e\u00d7\ud835\udc49\ud835\udc49\ud835\udc4f\ud835\udc4f and \ud835\udc38\ud835\udc38\ud835\udc4e\ud835\udc4e\ud835\udc4f\ud835\udc4f\u2260\u2205 . In other words, \ud835\udc3a\ud835\udc3a\ud835\udc65\ud835\udc65 contains all vertices and edges of \n\n17 \n \ud835\udc3a\ud835\udc3a\ud835\udc4e\ud835\udc4e and \ud835\udc3a\ud835\udc3a\ud835\udc4f\ud835\udc4f, and also at least one edge between them.  Similar spaces can be defined for graphs \nthat are not necessaril y connected by removing the requirement that \ud835\udc38\ud835\udc38\ud835\udc4e\ud835\udc4e\ud835\udc4f\ud835\udc4f\u2260\u2205. Vertex colours \ncan be incorporated by expanding the basis set \ud835\udc35\ud835\udc35. A graph assembly space can also be defined \nwith edges as the basic objects, instead of vertices. Additional constraints allow for the s tudy \nof spaces of other useful graph structures, for example restriction of vertex degree allow s for \nthe study of the space of molecular graphs, which are studied in an upcoming paper. As in the \nblock structures, the assembly space of graphs can be used to analyse objects that have identical \nnetwork motifs in them while not being identical in other ways. Assembly maps can be defined from the space of graphs to the space of addition chains, as a count of the number of vertices, \nand also to vectorial addition chains if the vertices are coloured.  \n \nThere are various other examples where the pathway assembly approach could be used to provide useful analysis of objects. One example is in audio / electromagnetic signals, or music. By utilising notes and silences as  basic objects, possibly incorporating frequency/pitch, we \ncould use pathway assembly to distinguish natural signals such as those from a pulsar, or the \nsound of wind moving through a complex landscape, from sounds such as birdsong or structured communicat ions. In such a system, abundance could be considered to be the same \nsignal from multiple locations, or from the same location but repeated. We can also consider the morphology of apparent geological formations to look for evidence of biological influence in the form of duplicated complex patterns.  \n Pathway assembly can also be used to define a compression algorithm, similar to the widely \nknown Lempel -Ziv-Welch (LZW) algorithm ( 25). In the LZW algorithm, repeated portions of \ntext are represented by additional symbols in an expanded character set, and the need for a \nseparate dictionary is removed by building the dictionary in such a way that it can be \nreconstructed during decompression. In a pathway assembly -based implementation, we could \ninitially calculate an assembly pathway for the string, and then use the additional character set \nto indicate points at which substrings are duplicated or stored for re -use. It  is unlikely that such \na compression algorithm would be commercially useful due to the computational  complexity \nof finding a minimal assembly pathway, but analysing compressibility in this way could \nprovide further insights around the information content of string- like objects from an assembly \nspace perspective.  \n \n18 \n Conclusions  \nThe pathway assembly model, and pathway information, can be used to explore the possible \nways an object could have formed from its building blocks through random interactions , and \nwe have now built on our initial work (26) by establishing a robust mathematical formalism. \nBy doing so, we can define a threshold above which extrinsic information from a biological \nsource would have been required to create an observable  abundance of an  object because it is \ntoo improbable to have  formed in abundance otherwise. The pathway assembly of an object, \nwhen above the threshold, can be used as an agnostic biosignature, giving a clear indication of \nthe influence of information in constructing objects (e.g. via biological processes) without \nknowledge of the system that produced the end product . In other words, it can be used to detect \nbiological influence even when we don\u2019t know what we are looking for.  Of interest is  the \nability to search  for new types of life forms in the lab, alien life o n other worlds, as well as \nidentifying the conditions under which the random world embarks on the path towards life, as \ncharacterised by the emergence of physical systems that produce objects with high pathway assembly. As such , pathway assembly informatio n might be enable us to  not only look for the \nabiotic  to living transition, identifying the emergence of life, but also to identify \ntechnosignatures associated with intelligent life with  even higher pathway assemblies  within a \nunified quantitative framework. We therefore feel that the concept of pathway assembly can \nbe used to help us explore the universe for structures that must have been produced using an \ninformation -driven construction process; in fact we could go as far as to suggest that any such \nproce ss requiring information is a biological or technological process.  This also means that \npathway assembly information provides a new window on the problem of understanding the \nphysics of life simply because the physics of information is the physics of life . We believe that \nsuch an approach might help us reframe the question from philosophy of what life is  (27), to a \nphysics of what life does. \n \nAcknowledgements  \nThe authors gratefully acknowledge financial support from the EPSRC (Grant Nos \nEP/R01308X/1, EP/L023652/1, EP/P00153X/1), the ERC (project 670467 SMART -POM), the \nJohn Templeton Foundation Grant ID 60625 and Grant ID 61184 and the National Aeronautics \nand Space Administration through grant NNX15AL24G S02. We thank Dr. Cole Mathis  and \nProf. Paul Davies  for useful discussions. \n  \n19 \n Author Contributions  \nL.C. conceived of the overall concept and developed the algorithm together with S.M.M. \nA.R.G.M explored the initial mathematical description, and this was expanded and validated \nby D.G. M and S.I.W. L.C. and S. M. M. wrote the manuscript with input from all the authors.  \n \nReferences  \n1. C. R. S. Banerji, T. Mansour, and S. Severini, A Notion of Graph Likelihood and an \nInfinite Monkey Theorem . J. Phys. A  47, 035101 (2014).  \n2. C. Adami and T. Labar, \u201c From Entropy to Information: Biased Typewriters and the \nOrigin of Life \u201d in From Matter to Life: Information and Causality , G. F. R. Ellis, P. C. \nW. Davies, S. I. Walker , Eds.  (Cambridge University Press, Cambridge, 2017), pp. 130-\n154. \n3. F. Hoyle as Quoted in Hoyle on Evolution. Nature  294, 105 (1981). \n4. D. Deutsch, Constructor Theory. Synthese  190, 4331- 4359 (2013). \n5. C. Marletto, Constructor Theory of Life . J. R. Soc. Interface  12, 20141226 (2015). \n6. J. V. Neumann, Theory of Self -Reproducing Automata  (University of Illinois Press, \nChampaign IL, 1966).  \n7. A. Danchin, Bacteria as Computers Making Computers . FEMS Microbiol. Rev. 33, 3 -\n26 (2009).  \n8. D. H. Wolpert and W. Macready, Using Self -Dissimilarity to Quantify Complexity . \nComplexity  12, 77- 85 (2007). \n9. D. Krakauer, Cryptographic Nature . arXiv:1505.01744 ( 7 May 2015).  \n10. J. P. Crutchfield and O. G\u00f6rnerup, Objects That Make Objects: The Population \nDynamics of Structural Complexity . J. R. Soc. Interface  3, 345- 349 (2006). \n11. S. Kauffman and P. Clayton, On Emergence, Agency, and Organization. Biology & \nPhilosophy  21, 501- 521 (2006).  \n12. S. I. Walker and P. C. W. Davies, The Algorithmic Origins of Life . J. R. Soc. Interface  \n10, 20120869 (2013).  \n13. S. M. Marshall, A. R. G. Murray, and L. Cronin, A Probabilistic Framework for \nIdentifying Biosignatures Using Pathway Complexity. Phil. Trans. R. Soc. A  375, \n20160342 (2017). \n14. C. E. Shannon, A Mathematical Theory of Communication . Bell Syst. Tech. J.  27, 379-\n423 (1948).  \n20 \n 15. A. N. Kolmogorov, Three Approaches to the Quantitative Definition of Information . \nInt. J. Comput. Math. 2, 157- 168 (1968). \n16. D. H. Lee, J. R. Granja, J. A. Martinez, K. Severin, and M. R. Ghadiri, A Self -\nReplicating Peptide . Nature  382, 525- 528 (1996).  \n17. S. Press\u00e9, K. Ghosh, J. Lee, K. A. Dill, Principles of Maximum Entropy and Maximum \nCaliber in Statistical Physics . Rev. Mod. Phys ., 85, 1115- 1141 (2013).  \n18. H. Kim, H. B. Smith, C. Mathis, J. Raymond, and S. I. Walker , Universal Scaling across \nBiochemical Networks on Earth . Science Advances  5, eaau0149 (2019).  \n19. C. Grimaldi and G. W. Marcy, Bayesian Approach to Seti . Proc. Nat l. Acad. Sci. USA , \n201808578 (2018). \n20. S. Steiner, J. Wolf, S. Glatzel, A. Andreou, J. M. Granda, G. Keenan, T. Hinkley, G. \nAragon- Camarasa, P. J. Kitson, D. Angelone, and L. Cronin, Organic Synthesis in a \nModular Robotic System Driven by a Chem ical Programming Language . Science 363 , \n144-152 (2019). \n21. D. Wilson and A. Mathys, Sequence A003313, the O n-Line Encyclopedia of Integer \nSequences. https://oeis.org/A003313 accessed June 2019 . \n22. N. M. Clift, Calculating Optimal Addition Chains . Computing 91, 265- 284 (2011).  \n23. G. J. Chaitin, Information -Theoretic Computational Complexity. IEEE T. Inf. Theory , \n20, 10- 15 (1974)  \n24. J. Olivos, On Vectorial Addition Chains . J. Algorithms  2, 13 -21 (1981).  \n25. T. A. Welch, A Technique for High- Perfor mance Data Compression . Computer  17, 8-\n19 (1984).  \n26. A. R. G. Murray, S. M. Marshall, and L. Cronin, Defining Pathway Assembly and \nExploring Its Applications . arXiv:1804.06972 ( 9 April 2018).  \n27. E. Schr\u00f6dinger, What is Life? The Physical Aspect of the Living Cell  (Cambridge \nUniversity Press, Cambridge,  1944).  \n \nSupplementary Information: Quantifying the pathways to life \nusing assembly spaces  \nStuart M. Marshall,1 Douglas G. Moore,2 Alastair R. G. Murray,1 Sara I. Walker,2,3* and \nLeroy Cronin1* \n1 School of Chemistry, University of Glasgow, Glasgow, G12 8QQ, UK.  \n2 BEYOND Center for Fundamental Concepts in Science, Arizona State University, Tempe, \nAZ, USA  \n3 School of Earth and Space Exploration, Arizona State University, Tempe, AZ, USA  \n*Correspondi ng author email: Lee.Cronin@glasgow.ac.uk , sara.i.walker@asu.edu  \n1. Introduction  \nThis formalism arose as a means of rigorously describing the \u201csimplest\u201d way of assem bling a \ngiven object by combining basing building blocks. With this in mind, we consider a universe \nof objects and binary relations between them signifying that one can be compose with some  \nthird object to create the second. Each relation then is associated with that third object. In this setting, the concrete rules or laws describing this assembly processes are neglected though they are certainly necessary for initially constructing the space. We quickly come to the conclusion that a graph formalization is  appropriate when we consider this kind of process in \ngeneral, but a more general mathematical structure than the standard concept of a graph is necessarily; namely quivers\n1. As such, the fundamental mathematical structure we define and \nexplore herein, ref erred to as an assembly space, can be described as an acyclic quiver with \nedges labeled with vertices in the quiver which satisfies three simple axioms. With assembly spaces defined, we are able to define an assembly index  for each object in the space whic h \ncharacterizes how directly that object can be assembled. Further, we prove several axioms relating to method of bounding the assembly index for a given object and algorithms for computing or approximating it.  \nTo facilitate this exposition, we have broken the text into three sections. First, in Section 2. we describe the graph -theoretic prerequisites associated with quivers and morphisms \n(mappings) between them. We proceed then to define assembly spaces, subspaces and maps between them, and to prove severa l lemmas in Section 3. Finally, we define the assembly \nindex, prove that it is computable and two methods for bounding it above and below, and present algorithms for computing or approximating it in Section 4. \n2. Graph-Theoretic Prerequisites  \nWe begin by cons idering a set of objects, possibly infinitely many objects, which can be \ncombined in various ways to produce others. If an object \ud835\udc4e\ud835\udc4e can be combined with some other \n \n1 Many texts refer to this structure as a multigraph, with the term quiver  preferred in \nsettings where the edges represent morphism or processes rather than simply relationships. \nSince we view the \u201crelations\u201d as an active process of combination, we prefer quiver  in this \ntext. The reader would lose nothing by mentally substituting the terms.  \nobject to yield an object \ud835\udc4f\ud835\udc4f, we represent the relationship between \ud835\udc4e\ud835\udc4e  and \ud835\udc4f\ud835\udc4f  by drawing a \ndirected edge or arrow from \ud835\udc4e\ud835\udc4e  to \ud835\udc4f\ud835\udc4f. Altogether, this structure is a quiver, also called a \nmultigraph, as we allow for the possibility that there is more than one way to produce \ud835\udc4f\ud835\udc4f from \n\ud835\udc4e\ud835\udc4e; that is, there may be more than one edge from \ud835\udc4e\ud835\udc4e to \ud835\udc4f\ud835\udc4f. \nDefinition 1. A quiver  \ud835\udee4\ud835\udee4 consists of  \n1. a set of vertices \ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4) \n2. a set of edges \ud835\udc38\ud835\udc38 (\ud835\udee4\ud835\udee4) \n3. a pair of maps \ud835\udc60\ud835\udc60 \ud835\udee4\ud835\udee4,\ud835\udc61\ud835\udc61\ud835\udee4\ud835\udee4:\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4)\u2192\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4) \nFor an edge \ud835\udc52\ud835\udc52\u2208\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4), \ud835\udc60\ud835\udc60\ud835\udee4\ud835\udee4(\ud835\udc52\ud835\udc52) is referred to as the source and \ud835\udc61\ud835\udc61\ud835\udee4\ud835\udee4(\ud835\udc52\ud835\udc52) the target of the edge, and \nwe will often leave off the subscripts when the context is clear, e.g. \ud835\udc60\ud835\udc60 and \ud835\udc61\ud835\udc61 . We will often \ndescribe an edge \ud835\udc52\ud835\udc52\u2208\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4) with \ud835\udc60\ud835\udc60(\ud835\udc52\ud835\udc52)=\ud835\udc4e\ud835\udc4e and \ud835\udc61\ud835\udc61 (\ud835\udc52\ud835\udc52)=\ud835\udc4f\ud835\udc4f as \ud835\udc52\ud835\udc52\u223c[\ud835\udc4f\ud835\udc4f\ud835\udc4e\ud835\udc4e]. This does not mean that \n\ud835\udc52\ud835\udc52 is a unique edge with endpoints \ud835\udc4e\ud835\udc4e and \ud835\udc4f\ud835\udc4f ; it is possible that two edges \ud835\udc52\ud835\udc52 \u2260\ud835\udc53\ud835\udc53 have the same \nendpoints \ud835\udc52\ud835\udc52\u223c\ud835\udc53\ud835\udc53\u223c[\ud835\udc4f\ud835\udc4f\ud835\udc4e\ud835\udc4e]. \n \nFrom here, we consider paths, that is sequences of edges, which describe the process of \nsequentially combining objects to yield intermediate objects and ultimately some terminal object.  \nDefinition 2.  If \ud835\udee4\ud835\udee4 is a quiver, a path \ud835\udefe\ud835\udefe=\ud835\udc4e\ud835\udc4e\n\ud835\udc5b\ud835\udc5b\u2026\ud835\udc4e\ud835\udc4e1 in \ud835\udee4\ud835\udee4  of length \ud835\udc5b\ud835\udc5b\u22651 is a sequence of edges \nsuch that \ud835\udc61\ud835\udc61(\ud835\udc4e\ud835\udc4e\ud835\udc56\ud835\udc56)=\ud835\udc60\ud835\udc60(\ud835\udc4e\ud835\udc4e\ud835\udc56\ud835\udc56+1) for 1\u2264\ud835\udc56\ud835\udc56\u2264\ud835\udc5b\ud835\udc5b\u22121. The functions \ud835\udc60\ud835\udc60 and \ud835\udc61\ud835\udc61  can be extended to paths \nas \ud835\udc60\ud835\udc60(\ud835\udefe\ud835\udefe)=\ud835\udc60\ud835\udc60(\ud835\udc4e\ud835\udc4e1) and \ud835\udc61\ud835\udc61(\ud835\udefe\ud835\udefe)=\ud835\udc61\ud835\udc61(\ud835\udc4e\ud835\udc4e\ud835\udc5b\ud835\udc5b). We write |\ud835\udefe\ud835\udefe| to denote the length, or number of edges, in \nthe path. Additionally, for each vertex \ud835\udc65\ud835\udc65 \u2208\ud835\udee4\ud835\udee4 there is a zero path , denoted \ud835\udc52\ud835\udc52 \ud835\udc65\ud835\udc65, with length 0 \nand \ud835\udc60\ud835\udc60 (\ud835\udc52\ud835\udc52\ud835\udc65\ud835\udc65)=\ud835\udc61\ud835\udc61(\ud835\udc52\ud835\udc52\ud835\udc65\ud835\udc65)=\ud835\udc65\ud835\udc65. \n \nA natural point is that combining two objects should never yield somethi ng that can be used \nto create either of those objects. Essentially, there are no directed cycles \u2013 sequences of edges \nthat form a closed cycle \u2013 within the quiver.  \nDefinition 3. A path \ud835\udefe\ud835\udefe  in a quiver \ud835\udee4\ud835\udee4  is a directed cycle if |\ud835\udefe\ud835\udefe|\u22651 with \ud835\udc61\ud835\udc61 (\ud835\udefe\ud835\udefe)=\ud835\udc60\ud835\udc60(\ud835\udefe\ud835\udefe). \nDefinition 4. A quiver \ud835\udee4\ud835\udee4 is acyclic  if it has no directed cycles.  \n \nWe can think of an object \ud835\udc4f\ud835\udc4f as being reachable  from an object \ud835\udc4e\ud835\udc4e  if there\u2019s a path from \ud835\udc4e\ud835\udc4e to \ud835\udc4f\ud835\udc4f, \nand this relationship forms a partial ordering on the quiver if the quiver is acyclic.  \nDefinition 5. Let \ud835\udee4\ud835\udee4 be an acyclic quiver and let \ud835\udc65\ud835\udc65,\ud835\udc66\ud835\udc66\u2208\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4). We say \ud835\udc66\ud835\udc66 is reachable  from \ud835\udc65\ud835\udc65  if \nthere exists a path \ud835\udefe\ud835\udefe  such that \ud835\udc60\ud835\udc60(\ud835\udefe\ud835\udefe)=\ud835\udc65\ud835\udc65 and \ud835\udc61\ud835\udc61 (\ud835\udefe\ud835\udefe)=\ud835\udc66\ud835\udc66, where |\ud835\udefe\ud835\udefe|\u22650. \nLemma 1. Let \ud835\udee4\ud835\udee4 be an acyclic quiver, and define a binary relation \u2264  on the vertices of \ud835\udee4\ud835\udee4 \nsuch that \ud835\udc65\ud835\udc65\u2264\ud835\udc66\ud835\udc66 if and only if \ud835\udc66\ud835\udc66 is reachable from \ud835\udc65\ud835\udc65. (\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4),\u2264) is a partially ordered set, and \n\u2264 is referred to as the reachability relation  on \ud835\udee4\ud835\udee4. \nProof . For \u2264 to be a partial ordering on \ud835\udc49\ud835\udc49 (\ud835\udee4\ud835\udee4), we ne ed to show that it is reflexive, transitive \nand antisymmetric. Reflexivity follows directly from the definition of reachability as \ud835\udc65\ud835\udc65 is \nreachable from itself via the zero path \ud835\udc52\ud835\udc52 \ud835\udc65\ud835\udc65. To show transitivity, let \ud835\udc4e\ud835\udc4e\u2264\ud835\udc4f\ud835\udc4f and \ud835\udc4f\ud835\udc4f\u2264\ud835\udc50\ud835\udc50. If \ud835\udc4e\ud835\udc4e=\ud835\udc4f\ud835\udc4f \nor \ud835\udc4f\ud835\udc4f =\ud835\udc50\ud835\udc50, then we\u2019re done. Otherwise there are paths \ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f=\ud835\udc62\ud835\udc62\ud835\udc5a\ud835\udc5a\u2026\ud835\udc62\ud835\udc621 from \ud835\udc4e\ud835\udc4e  to \ud835\udc4f\ud835\udc4f and \ud835\udefe\ud835\udefe\ud835\udc50\ud835\udc50\ud835\udc4f\ud835\udc4f=\n\ud835\udc63\ud835\udc63\ud835\udc5b\ud835\udc5b\u2026\ud835\udc63\ud835\udc631 from \ud835\udc4f\ud835\udc4f to \ud835\udc50\ud835\udc50. The composite path \ud835\udefe\ud835\udefe\ud835\udc50\ud835\udc50\ud835\udc4f\ud835\udc4f\u2218\ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f=\ud835\udc63\ud835\udc63\ud835\udc5b\ud835\udc5b\u2026\ud835\udc63\ud835\udc631\ud835\udc62\ud835\udc62\ud835\udc5b\ud835\udc5b\u2026\ud835\udc62\ud835\udc621 is a path from \ud835\udc4e\ud835\udc4e to \ud835\udc50\ud835\udc50; \nthus \ud835\udc50\ud835\udc50 is reachable from \ud835\udc4e\ud835\udc4e so that \ud835\udc4e\ud835\udc4e\u2264\ud835\udc50\ud835\udc50. Now consider antisymmetry and suppose that \ud835\udc4e\ud835\udc4e\u2264\ud835\udc4f\ud835\udc4f \nand \ud835\udc4f\ud835\udc4f\u2264\ud835\udc4e\ud835\udc4e. Then there exist paths \ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f and \ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f from \ud835\udc4e\ud835\udc4e  to \ud835\udc4f\ud835\udc4f and \ud835\udc4f\ud835\udc4f  to \ud835\udc4e\ud835\udc4e, respectively. Then \n\ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\u2218\ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f is a path from \ud835\udc4e\ud835\udc4e  to itself. Since \ud835\udee4\ud835\udee4  is acyclic, this implies that \ud835\udefe\ud835\udefe \ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\u2218\ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f=\ud835\udc52\ud835\udc52\ud835\udc4f\ud835\udc4f, and \nconsequently that \ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f=\ud835\udefe\ud835\udefe\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f=\ud835\udc52\ud835\udc52\ud835\udc4f\ud835\udc4f. Thus \ud835\udc4e\ud835\udc4e =\ud835\udc4f\ud835\udc4f and \u2264  is antisymmetric. \n \n\u220e \n \nThe idea of reachability allows us to think of all objects that are reachable from (or above) a \ngiven object \ud835\udc65\ud835\udc65 , the upper quiver of \ud835\udc65\ud835\udc65. Similarly, we can think of all objects that can reach \ud835\udc65\ud835\udc65, \nthe lower quiver.  \nDefinition 6. Let \ud835\udee4\ud835\udee4 be an acyclic quiver and let \u2264 be the reachability relation on it. The \nupper quiver  of \ud835\udc65\ud835\udc65\u2208\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4) is \ud835\udc65\ud835\udc65\u2191 with vertices \ud835\udc49\ud835\udc49(\ud835\udc65\ud835\udc65\u2191)={\ud835\udc66\ud835\udc66\u2208\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4) | \ud835\udc65\ud835\udc65\u2264\ud835\udc66\ud835\udc66}, edges \ud835\udc38\ud835\udc38 (\ud835\udc65\ud835\udc65\u2191\n)={\ud835\udc52\ud835\udc52\u2208\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4) | \ud835\udc60\ud835\udc60\ud835\udee4\ud835\udee4(\ud835\udc52\ud835\udc52),\ud835\udc61\ud835\udc61\ud835\udee4\ud835\udee4(\ud835\udc52\ud835\udc52)\u2208\ud835\udc49\ud835\udc49(\ud835\udc65\ud835\udc65\u2191)}, \ud835\udc60\ud835\udc60\ud835\udc65\ud835\udc65\u2191=\ud835\udc60\ud835\udc60\ud835\udee4\ud835\udee4|\ud835\udc38\ud835\udc38(\ud835\udc65\ud835\udc65\u2191), and \ud835\udc61\ud835\udc61\ud835\udc65\ud835\udc65\u2191=\ud835\udc61\ud835\udc61\ud835\udee4\ud835\udee4|\ud835\udc38\ud835\udc38(\ud835\udc65\ud835\udc65\u2191). The lower \nquiver  of \ud835\udc65\ud835\udc65\u2208\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4) is \ud835\udc65\ud835\udc65\u2193 with vertices \ud835\udc49\ud835\udc49 (\ud835\udc65\ud835\udc65\u2193)={\ud835\udc66\ud835\udc66\u2208\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4) | \ud835\udc66\ud835\udc66\u2264\ud835\udc65\ud835\udc65}, edges \ud835\udc38\ud835\udc38(\ud835\udc65\ud835\udc65\u2193)=\n{\ud835\udc52\ud835\udc52\u2208\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4) | \ud835\udc60\ud835\udc60\ud835\udee4\ud835\udee4(\ud835\udc52\ud835\udc52),\ud835\udc61\ud835\udc61\ud835\udee4\ud835\udee4(\ud835\udc52\ud835\udc52)\u2208\ud835\udc49\ud835\udc49(\ud835\udc65\ud835\udc65\u2193)}, \ud835\udc60\ud835\udc60\ud835\udc65\ud835\udc65\u2193=\ud835\udc60\ud835\udc60\ud835\udee4\ud835\udee4|\ud835\udc38\ud835\udc38(\ud835\udc65\ud835\udc65\u2193), and \ud835\udc61\ud835\udc61\ud835\udc65\ud835\udc65\u2193=\ud835\udc61\ud835\udc61\ud835\udee4\ud835\udee4|\ud835\udc38\ud835\udc38(\ud835\udc65\ud835\udc65\u2193). \nSimilarly, the upper quiver of a subset \ud835\udc44\ud835\udc44 \u2286\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4) in \ud835\udee4\ud835\udee4 is \ud835\udc44\ud835\udc44\u2191 with vert ices \ud835\udc49\ud835\udc49(\ud835\udc44\ud835\udc44\u2191)={\ud835\udc66\ud835\udc66\u2208\n\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4) | (\u2203\ud835\udc5e\ud835\udc5e\u2208\ud835\udc44\ud835\udc44)\ud835\udc5e\ud835\udc5e\u2264\ud835\udc66\ud835\udc66}, edges \ud835\udc38\ud835\udc38(\ud835\udc44\ud835\udc44\u2191)={\ud835\udc52\ud835\udc52\u2208\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4) | \ud835\udc60\ud835\udc60\ud835\udee4\ud835\udee4(\ud835\udc52\ud835\udc52),\ud835\udc61\ud835\udc61\ud835\udee4\ud835\udee4(\ud835\udc52\ud835\udc52)\u2208\ud835\udc49\ud835\udc49(\ud835\udc44\ud835\udc44\u2191)}, \ud835\udc60\ud835\udc60\ud835\udc44\ud835\udc44\u2191=\n\ud835\udc60\ud835\udc60\ud835\udee4\ud835\udee4|\ud835\udc38\ud835\udc38(\ud835\udc44\ud835\udc44\u2191), and \ud835\udc61\ud835\udc61\ud835\udc44\ud835\udc44\u2191=\ud835\udc61\ud835\udc61\ud835\udee4\ud835\udee4|\ud835\udc38\ud835\udc38(\ud835\udc44\ud835\udc44\u2191). The lower set of a subset is defined dually.  \n \nGoing further, we can consider those objects that cannot be reached as minimal  and those that \ncannot reach anything as maximal . An object which can be reached by finitely many objects \nis called finite . \nDefinition 7. Let \ud835\udee4\ud835\udee4 be an acyclic quiver, \u2264 be the re achability relation on it and \ud835\udc65\ud835\udc65 a vertex in \n\ud835\udee4\ud835\udee4. Then \ud835\udc65\ud835\udc65  is said to be maximal  in \ud835\udee4\ud835\udee4 if, whenever \ud835\udc65\ud835\udc65\u2264\ud835\udc66\ud835\udc66 in \ud835\udee4\ud835\udee4, we have \ud835\udc65\ud835\udc65 =\ud835\udc66\ud835\udc66. Dually, \ud835\udc65\ud835\udc65 is \nminimal in \ud835\udee4\ud835\udee4 if, whenever \ud835\udc66\ud835\udc66 \u2264\ud835\udc65\ud835\udc65 in \ud835\udee4\ud835\udee4 , we have \ud835\udc65\ud835\udc65 =\ud835\udc66\ud835\udc66. The set of all maximal vertices of \ud835\udee4\ud835\udee4 is \ndenoted max (\ud835\udee4\ud835\udee4) with  min (\ud835\udee4\ud835\udee4) defined dually.  \nDefinition 8.  A quiver \ud835\udee4\ud835\udee4 is said to be \ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f  if its vertex and edge sets are both finite. \nSimilarly, a vertex \ud835\udc65\ud835\udc65  in a quiver \ud835\udee4\ud835\udee4  is said to be finite if \ud835\udc65\ud835\udc65\u2193 in \ud835\udee4\ud835\udee4  is a finite quiver.  \n With this idea of a quiver of objects de fined, we can consider asking about subsets of objects \nand relations between them in the context of the quiver as a whole.  \nDefinition 9. Let \ud835\udee4\ud835\udee4 and \ud835\udee4\ud835\udee4\u2032 be quivers. Then \ud835\udee4\ud835\udee4 \u2032 is a subquiver  of \ud835\udee4\ud835\udee4 if \ud835\udc49\ud835\udc49 (\ud835\udee4\ud835\udee4\u2032)\u2286\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4), \ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4\u2032)\u2286\n\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4), \ud835\udc60\ud835\udc60\n\ud835\udee4\ud835\udee4\u2032=\ud835\udc60\ud835\udc60\ud835\udee4\ud835\udee4|\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4\u2032) and \ud835\udc61\ud835\udc61\ud835\udee4\ud835\udee4\u2032=\ud835\udc61\ud835\udc61\ud835\udee4\ud835\udee4|\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4\u2032). We will denote this relationship as \ud835\udee4\ud835\udee4\u2032\u2286\ud835\udee4\ud835\udee4. \nLemma 2. If \ud835\udc4b\ud835\udc4b , \ud835\udc4c\ud835\udc4c and \ud835\udc4d\ud835\udc4d  are quivers such that \ud835\udc4b\ud835\udc4b\u2286\ud835\udc4c\ud835\udc4c and \ud835\udc4c\ud835\udc4c\u2286\ud835\udc4d\ud835\udc4d, then \ud835\udc4b\ud835\udc4b\u2286\ud835\udc4d\ud835\udc4d. That is, the \nbinary relation \u2286  on quivers is transitive.  \nProof . Suppose \ud835\udc4b\ud835\udc4b , \ud835\udc4c\ud835\udc4c and \ud835\udc4d\ud835\udc4d are quivers with \ud835\udc4b\ud835\udc4b \u2286\ud835\udc4c\ud835\udc4c and \ud835\udc4c\ud835\udc4c\u2286\ud835\udc4d\ud835\udc4d. Then \ud835\udc49\ud835\udc49 (\ud835\udc4b\ud835\udc4b)\u2286\ud835\udc49\ud835\udc49(\ud835\udc4c\ud835\udc4c)\u2286\ud835\udc49\ud835\udc49(\ud835\udc4d\ud835\udc4d), \nso that \ud835\udc49\ud835\udc49(\ud835\udc4b\ud835\udc4b)\u2286\ud835\udc49\ud835\udc49(\ud835\udc4d\ud835\udc4d). Similarly, \ud835\udc38\ud835\udc38(\ud835\udc4b\ud835\udc4b)\u2286\ud835\udc38\ud835\udc38(\ud835\udc4d\ud835\udc4d). Next, since \ud835\udc60\ud835\udc60\ud835\udc4b\ud835\udc4b=\ud835\udc60\ud835\udc60\ud835\udc4c\ud835\udc4c|\ud835\udc38\ud835\udc38(\ud835\udc4b\ud835\udc4b), \ud835\udc60\ud835\udc60\ud835\udc4c\ud835\udc4c=\ud835\udc60\ud835\udc60\ud835\udc4d\ud835\udc4d|\ud835\udc38\ud835\udc38(\ud835\udc4c\ud835\udc4c) and \n\ud835\udc38\ud835\udc38(\ud835\udc4b\ud835\udc4b)\u2286\ud835\udc38\ud835\udc38(\ud835\udc4c\ud835\udc4c), \ud835\udc60\ud835\udc60\ud835\udc4b\ud835\udc4b=\ud835\udc60\ud835\udc60\ud835\udc4d\ud835\udc4d|\ud835\udc38\ud835\udc38(\ud835\udc4b\ud835\udc4b). The same argument applies to show that \ud835\udc61\ud835\udc61\ud835\udc4b\ud835\udc4b=\ud835\udc61\ud835\udc61\ud835\udc4d\ud835\udc4d|\ud835\udc38\ud835\udc38(\ud835\udc4b\ud835\udc4b). Thus \ud835\udc4b\ud835\udc4b\u2286\n\ud835\udc4d\ud835\udc4d, so that \u2286 is transitive. \n \n\u220e \n \nFinally, we will need to consider how to map one quiver to another in a consistent fashion, \nmaintaining the basic relational structure of the original quiver.  \nDefinition 10. Let \ud835\udee4\ud835\udee4 and \ud835\udee4\ud835\udee4\u2032 be quivers. A quiver morphism , denot ed \ud835\udc5a\ud835\udc5a:\ud835\udee4\ud835\udee4\u2192\ud835\udee4\ud835\udee4\u2032, consists of \na pair \ud835\udc5a\ud835\udc5a=(\ud835\udc5a\ud835\udc5a\ud835\udc63\ud835\udc63,\ud835\udc5a\ud835\udc5a\ud835\udc52\ud835\udc52) of functions \ud835\udc5a\ud835\udc5a\ud835\udc63\ud835\udc63:\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4)\u2192\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4\u2032) and \ud835\udc5a\ud835\udc5a\ud835\udc52\ud835\udc52:\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4)\u2192\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4\u2032) such that \ud835\udc5a\ud835\udc5a\ud835\udc63\ud835\udc63\u2218\n\ud835\udc60\ud835\udc60\ud835\udee4\ud835\udee4=\ud835\udc60\ud835\udc60\ud835\udee4\ud835\udee4\u2032\u2218\ud835\udc5a\ud835\udc5a\ud835\udc52\ud835\udc52 and \ud835\udc5a\ud835\udc5a \ud835\udc63\ud835\udc63\u2218\ud835\udc61\ud835\udc61\ud835\udee4\ud835\udee4=\ud835\udc61\ud835\udc61\ud835\udee4\ud835\udee4\u2032\u2218\ud835\udc5a\ud835\udc5a\ud835\udc52\ud835\udc52. That is, the following diagrams commute:  \n \n3. Assembly Spaces, Subspaces and Maps  \nUp to this point, we have focused on the binary idea that one object can be used as a structural ingredient of another. However, we need something more if we want to capture the idea that two things must be combined in order to assemble  another. We do this by labeling \nthe edges of the quiver with the object that the source of the edge is combined with to \nproduce the target. Further, this labeling has to be consistent. If \ud835\udc4e\ud835\udc4e  can be combined with \ud835\udc4f\ud835\udc4f  to \nyield \ud835\udc50\ud835\udc50, then \ud835\udc4f\ud835\udc4f can be combined with \ud835\udc4e\ud835\udc4e to yield \ud835\udc50\ud835\udc50. Additionally, we require that there exists a \nset of minimal objects \u2013 building blocks from which all other objects can be assembled. \nDefinition 11. An assembly space is an acyclic quiver \ud835\udee4\ud835\udee4 together with an edge -labeling map \n\ud835\udf19\ud835\udf19:\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4)\u2192\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4) which satisfies the following axioms:  \n4. min (\ud835\udee4\ud835\udee4) is finite and non -empty  \n5. \ud835\udee4\ud835\udee4=min (\ud835\udee4\ud835\udee4)\u2191 \n6. If \ud835\udc4e\ud835\udc4e is an edge from \ud835\udc65\ud835\udc65 to \ud835\udc67\ud835\udc67 in \ud835\udee4\ud835\udee4  with \ud835\udf19\ud835\udf19 (\ud835\udc4e\ud835\udc4e)=\ud835\udc66\ud835\udc66, then there exists an edge \ud835\udc4f\ud835\udc4f from \ud835\udc66\ud835\udc66  to \n\ud835\udc67\ud835\udc67 with \ud835\udf19\ud835\udf19 (\ud835\udc4f\ud835\udc4f)=\ud835\udc65\ud835\udc65. \nSuch an assembly space is denoted (\ud835\udee4\ud835\udee4,\ud835\udf19\ud835\udf19) or simply \ud835\udee4\ud835\udee4 where appropriate. We will continue \nto write \ud835\udc65\ud835\udc65\u2208\ud835\udee4\ud835\udee4 to mean that \ud835\udc65\ud835\udc65 is a vertex of the quiver.  \nDefinition 12. The set of minimal vertices of an assembly space \ud835\udee4\ud835\udee4  is referred to as the basis  \nof \ud835\udee4\ud835\udee4 and is denoted \ud835\udc35\ud835\udc35\n\ud835\udee4\ud835\udee4. Elements of the basis are referred to as basic objects, basic vertices or \nbasic elements.  \nDefinition 13. An assembly pathway of an assembly space \ud835\udee4\ud835\udee4 is any topological ordering of \nthe vertices of \ud835\udee4\ud835\udee4 with respect to the reachability relation.  \n\nDefinition 14. An assembly space \ud835\udee4\ud835\udee4 with reachability  relation \u2264 is said to be split-branched \nif for all \ud835\udc65\ud835\udc65,\ud835\udc66\ud835\udc66\u2208\ud835\udee4\ud835\udee4, \ud835\udc65\ud835\udc65\u2264\ud835\udc66\ud835\udc66 or \ud835\udc66\ud835\udc66\u2264\ud835\udc65\ud835\udc65 whenever \ud835\udc49\ud835\udc49(\ud835\udc65\ud835\udc65\u2193)\u2229\ud835\udc49\ud835\udc49(\ud835\udc66\ud835\udc66\u2193)\u2260\u2205. \nDefinition 15. Let (\ud835\udee4\ud835\udee4,\ud835\udf19\ud835\udf19) and (\ud835\udee4\ud835\udee4\u2032,\ud835\udf13\ud835\udf13) be assembly spaces. Then (\ud835\udee4\ud835\udee4 \u2032,\ud835\udf13\ud835\udf13) is an assembly \nsubspace  of (\ud835\udee4\ud835\udee4,\ud835\udf19\ud835\udf19) if \ud835\udee4\ud835\udee4\u2032 is a subquiver of \ud835\udee4\ud835\udee4 and \ud835\udf13\ud835\udf13 =\ud835\udf19\ud835\udf19|\ud835\udc38\ud835\udc38(\ud835\udee4\ud835\udee4\u2032). This relationship is denoted as \n(\ud835\udee4\ud835\udee4,\ud835\udf19\ud835\udf19)\u2286(\ud835\udee4\ud835\udee4\u2032,\ud835\udf13\ud835\udf13), or simply \ud835\udee4\ud835\udee4\u2286\ud835\udee4\ud835\udee4\u2032 when there is no ambiguity.  \nDefinition 16. Let \ud835\udee4\ud835\udee4\u2032 be an assembly subspace of \ud835\udee4\ud835\udee4. Then \ud835\udee4\ud835\udee4\u2032 is rooted in \ud835\udee4\ud835\udee4 if \ud835\udc35\ud835\udc35\ud835\udee4\ud835\udee4\u2032\u2286\ud835\udc35\ud835\udc35\ud835\udee4\ud835\udee4 as \nsets. \nLemma 3. Let \ud835\udc48\ud835\udc48, \ud835\udc49\ud835\udc49 and \ud835\udc4a\ud835\udc4a  be assembly spaces with \ud835\udc48\ud835\udc48\u2286\ud835\udc49\ud835\udc49 and \ud835\udc49\ud835\udc49\u2286\ud835\udc4a\ud835\udc4a, then \ud835\udc48\ud835\udc48\u2286\ud835\udc4a\ud835\udc4a. \nFurther, if \ud835\udc48\ud835\udc48 is rooted in \ud835\udc49\ud835\udc49, and \ud835\udc49\ud835\udc49  is rooted in \ud835\udc4a\ud835\udc4a , then \ud835\udc48\ud835\udc48 is rooted in \ud835\udc4a\ud835\udc4a. \nProof. Let (\ud835\udc48\ud835\udc48,\ud835\udf19\ud835\udf19\ud835\udc48\ud835\udc48), (\ud835\udc49\ud835\udc49,\ud835\udf19\ud835\udf19\ud835\udc49\ud835\udc49) and (\ud835\udc4a\ud835\udc4a ,\ud835\udf19\ud835\udf19\ud835\udc4a\ud835\udc4a) be assembly spaces such that (\ud835\udc48\ud835\udc48,\ud835\udf19\ud835\udf19\ud835\udc48\ud835\udc48)\u2286(\ud835\udc49\ud835\udc49,\ud835\udf19\ud835\udf19\ud835\udc49\ud835\udc49) \nand (\ud835\udc49\ud835\udc49 ,\ud835\udf19\ud835\udf19\ud835\udc49\ud835\udc49)\u2286(\ud835\udc4a\ud835\udc4a,\ud835\udf19\ud835\udf19\ud835\udc4a\ud835\udc4a). Since \ud835\udc48\ud835\udc48, \ud835\udc49\ud835\udc49 and \ud835\udc4a\ud835\udc4a  are quivers, \ud835\udc48\ud835\udc48\u2286\ud835\udc4a\ud835\udc4a by the transitivity of \u2286  on \nquivers. Further, since \ud835\udf19\ud835\udf19\ud835\udc48\ud835\udc48=\ud835\udf19\ud835\udf19\ud835\udc49\ud835\udc49|\ud835\udc38\ud835\udc38(\ud835\udc48\ud835\udc48), \ud835\udf19\ud835\udf19\ud835\udc49\ud835\udc49=\ud835\udf19\ud835\udf19\ud835\udc4a\ud835\udc4a|\ud835\udc38\ud835\udc38(\ud835\udc49\ud835\udc49) and \ud835\udc38\ud835\udc38 (\ud835\udc48\ud835\udc48)\u2286\ud835\udc38\ud835\udc38(\ud835\udc4a\ud835\udc4a), we have \ud835\udf19\ud835\udf19 \ud835\udc48\ud835\udc48=\n\ud835\udf19\ud835\udf19\ud835\udc4a\ud835\udc4a|\ud835\udc38\ud835\udc38(\ud835\udc4a\ud835\udc4a). Thus, (\ud835\udc48\ud835\udc48 ,\ud835\udf19\ud835\udf19\ud835\udc48\ud835\udc48)\u2286(\ud835\udc4a\ud835\udc4a,\ud835\udf19\ud835\udf19\ud835\udc4a\ud835\udc4a). That is, \u2286 is transitive on assembly spaces. If \ud835\udc48\ud835\udc48 is \nrooted in \ud835\udc49\ud835\udc49  and \ud835\udc49\ud835\udc49  is rooted in \ud835\udc4a\ud835\udc4a , then \ud835\udc35\ud835\udc35\ud835\udc48\ud835\udc48\u2286\ud835\udc35\ud835\udc35\ud835\udc49\ud835\udc49\u2286\ud835\udc35\ud835\udc35\ud835\udc4a\ud835\udc4a. That is, \ud835\udc48\ud835\udc48 is rooted in \ud835\udc4a\ud835\udc4a. \n \n\u220e \nLemma 4. Let (\ud835\udee4\ud835\udee4,\ud835\udf19\ud835\udf19) be an assembly space and let \ud835\udc65\ud835\udc65\u2208\ud835\udee4\ud835\udee4. If \ud835\udc52\ud835\udc52\u223c[\ud835\udc4f\ud835\udc4f\ud835\udc4e\ud835\udc4e] is an edge in \ud835\udee4\ud835\udee4  with \n\ud835\udc4e\ud835\udc4e,\ud835\udc4f\ud835\udc4f\u2208\ud835\udc65\ud835\udc65\u2193, then \ud835\udf19\ud835\udf19(\ud835\udc52\ud835\udc52)\u2208\ud835\udc65\ud835\udc65\u2193. \nProof. Since \ud835\udee4\ud835\udee4  is an assembly space, we have \ud835\udf19\ud835\udf19(\ud835\udc52\ud835\udc52)\u2264\ud835\udc4f\ud835\udc4f where \u2264  is the reachability relation \non \ud835\udee4\ud835\udee4 . By construction, \ud835\udc4f\ud835\udc4f\u2264\ud835\udc65\ud835\udc65 so that \ud835\udf19\ud835\udf19(\ud835\udc52\ud835\udc52)\u2264\ud835\udc65\ud835\udc65. Therefore \ud835\udf19\ud835\udf19(\ud835\udc52\ud835\udc52)\u2208\ud835\udc65\ud835\udc65\u2193. \n \u220e \nLemma 5. Let (\ud835\udee4\ud835\udee4,\ud835\udf19\ud835\udf19) be an assembly space and let \ud835\udc65\ud835\udc65\u2208\ud835\udee4\ud835\udee4. Then (\ud835\udc65\ud835\udc65 \u2193,\ud835\udf19\ud835\udf19|\ud835\udc65\ud835\udc65\u2193) is a rooted \nassembly subspace of \ud835\udee4\ud835\udee4. \nProof. We first show that (\ud835\udc65\ud835\udc65 \u2193,\ud835\udf19\ud835\udf19|\ud835\udc65\ud835\udc65\u2193) is an assembly space. Since (\ud835\udee4\ud835\udee4 ,\ud835\udf19\ud835\udf19) is an assembly space, \nit is the upper set of its basis \ud835\udc35\ud835\udc35\ud835\udee4\ud835\udee4. As such min (\ud835\udc65\ud835\udc65\u2193) is a non- empty subset of \ud835\udc35\ud835\udc35\ud835\udee4\ud835\udee4 and \ud835\udc65\ud835\udc65\u2193=\nmin (\ud835\udc65\ud835\udc65\u2193)\u2191 giving us axiom 1. The remaining axiom follows directly from lemma 4. What\u2019s \nmore, we already have that min (\ud835\udc65\ud835\udc65\u2193)=\ud835\udc35\ud835\udc35\ud835\udc65\ud835\udc65\u2193\u2286\ud835\udc35\ud835\udc35\ud835\udee4\ud835\udee4, so \ud835\udc65\ud835\udc65\u2193 is rooted in \ud835\udee4\ud835\udee4. \n \u220e \nDefinition 17. Let (\ud835\udee4\ud835\udee4,\ud835\udf19\ud835\udf19) and (\ud835\udee5\ud835\udee5 ,\ud835\udf13\ud835\udf13) be assembly spaces. An assembly map is a quiver \nmorphism \ud835\udc53\ud835\udc53:\ud835\udee4\ud835\udee4\u2192\ud835\udee5\ud835\udee5 such that \ud835\udf13\ud835\udf13\u2218\ud835\udc53\ud835\udc53\n\ud835\udc52\ud835\udc52=\ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63\u2218\ud835\udf19\ud835\udf19. That is, the following diagram commutes:  \n \n \n\nOur first theorem provides a basis for the lower bounds developed in the next section. The \nessential point is that the image of an assembly space under an assembly space is an assembl y \nspace.  \nTheorem 1. If \ud835\udc53\ud835\udc53:\ud835\udee4\ud835\udee4\u2192\ud835\udee5\ud835\udee5 is an assembly map between assembly spaces (\ud835\udee4\ud835\udee4,\ud835\udf19\ud835\udf19) and (\ud835\udee5\ud835\udee5 ,\ud835\udf13\ud835\udf13), \nthen (\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4),\ud835\udf11\ud835\udf11) with \ud835\udf11\ud835\udf11 =\ud835\udf13\ud835\udf13|\ud835\udc38\ud835\udc38(\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4)) is an assembly subspace of \ud835\udee5\ud835\udee5 . \nProof. Since \ud835\udc53\ud835\udc53  is a quiver morphism and \ud835\udee5\ud835\udee5  is acyclic, \ud835\udc53\ud835\udc53 (\ud835\udee4\ud835\udee4) is an acyclic subquiver of \ud835\udee5\ud835\udee5. By \nconstruction, \ud835\udf11\ud835\udf11 =\ud835\udf13\ud835\udf13|\ud835\udc38\ud835\udc38(\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4)). What remains is to prove the three assembly space axioms. Let \n\ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63 and \ud835\udc53\ud835\udc53\ud835\udc52\ud835\udc52 be the vertex and edge maps comprising \ud835\udc53\ud835\udc53. \nAxiom 1 We must show that \ud835\udc26\ud835\udc26\ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f (\ud835\udc87\ud835\udc87(\ud835\udf1e\ud835\udf1e)) is finite and non- empty.  \nWe start by showing that min (\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4))\u2260\u2205. To see this, consider an element \ud835\udc4f\ud835\udc4f\u2208\n\ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63(min (\ud835\udee4\ud835\udee4)), and suppose there exists a path from an element \ud835\udc65\ud835\udc65 \u2208\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4) to \ud835\udc4f\ud835\udc4f. Then let \ud835\udc63\ud835\udc63\u2208\n\ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63\u22121(\ud835\udc65\ud835\udc65) and let \ud835\udefe\ud835\udefe be a path from a basic element \ud835\udc62\ud835\udc62 \u2208min (\ud835\udee4\ud835\udee4) to \ud835\udc63\ud835\udc63 \u2013 which must exist  \nsince \ud835\udee4\ud835\udee4 is an assembly space. The image of this path is a path in \ud835\udc53\ud835\udc53 (\ud835\udee4\ud835\udee4) from \ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63(\ud835\udc62\ud835\udc62) to \ud835\udc65\ud835\udc65, \nand consequently a path from \ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63(\ud835\udc62\ud835\udc62) to \ud835\udc4f\ud835\udc4f. Since \ud835\udc53\ud835\udc53 \ud835\udc63\ud835\udc63(min (\ud835\udee4\ud835\udee4)) is finite, we can repeat this \nprocess beginning with the newly identified element of \ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63(min (\ud835\udee4\ud835\udee4)) only finitely many \ntimes before a cycle is formed. However, that cycle must have length zero since \ud835\udee5\ud835\udee5 \ncontains no cycles of greater length. As such, the final element of \ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63(\ud835\udc62\ud835\udc62) produced is in \nmin (\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4)) since there is nothing below it in \ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4). Thus, min (\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4)) is non- empty.  \nWe now show that, min (\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4)) is in fact finite. In particular, min (\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4)) is a subset of a \nfinite set, namely \ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63(min (\ud835\udee4\ud835\udee4)), so i t too is finite. Let \ud835\udc65\ud835\udc65 \u2208min (\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4)). Then there exists an \nelement \ud835\udc4f\ud835\udc4f\u2208\ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63\u22121(\ud835\udc65\ud835\udc65) and at least one path \ud835\udefe\ud835\udefe from a basic element \ud835\udc4e\ud835\udc4e \u2208min (\ud835\udee4\ud835\udee4) to \ud835\udc4f\ud835\udc4f. The \nimage of \ud835\udefe\ud835\udefe under \ud835\udc53\ud835\udc53 is a path in \ud835\udc53\ud835\udc53 (\ud835\udee4\ud835\udee4) from \ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63(\ud835\udc4f\ud835\udc4f) to \ud835\udc65\ud835\udc65 . Since \ud835\udc65\ud835\udc65 is minimal in \ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4), the \nonly paths that terminate at \ud835\udc65\ud835\udc65 are zero paths. Thus \ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63(\ud835\udc4f\ud835\udc4f)=\ud835\udc65\ud835\udc65. Since \ud835\udc65\ud835\udc65 was a generic \nelement of min (\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4)), every element of min (\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4)) is the image of a basic element of \ud835\udee4\ud835\udee4 . \nThat is min (\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4))\u2286\ud835\udc53\ud835\udc53\ud835\udc63\ud835\udc63(min (\ud835\udee4\ud835\udee4)), so it\u2019s finite.  \nAxiom 2 Next  we prove that \ud835\udc87\ud835\udc87 (\ud835\udf1e\ud835\udf1e) =\ud835\udc26\ud835\udc26\ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f (\ud835\udc87\ud835\udc87(\ud835\udf1e\ud835\udf1e))\u2191. Let \ud835\udc99\ud835\udc99 be an element of \ud835\udc87\ud835\udc87 (\ud835\udf1e\ud835\udf1e). We aim \nto show that there exists a path from a basic element of \ud835\udc87\ud835\udc87(\ud835\udf1e\ud835\udf1e) to \ud835\udc99\ud835\udc99. Let \ud835\udc83\ud835\udc83 be an element of \n\ud835\udf1e\ud835\udf1e which maps to \ud835\udc99\ud835\udc99  under application of \ud835\udc87\ud835\udc87. Then, since \ud835\udf1e\ud835\udf1e is an assembly space, w e know \nthere exists at least one path, \ud835\udf38\ud835\udf38  from a basic element of \ud835\udf1e\ud835\udf1e, say \ud835\udc82\ud835\udc82\u2208\ud835\udc26\ud835\udc26\ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f (\ud835\udf1e\ud835\udf1e), to \ud835\udc83\ud835\udc83 . The \nimage of this path in \ud835\udc87\ud835\udc87(\ud835\udf1e\ud835\udf1e) is itself a path from \ud835\udc87\ud835\udc87\ud835\udc97\ud835\udc97(\ud835\udc82\ud835\udc82) to \ud835\udc99\ud835\udc99 , namely \ud835\udc87\ud835\udc87\ud835\udc86\ud835\udc86(\ud835\udf38\ud835\udf38). If \ud835\udc87\ud835\udc87\ud835\udc97\ud835\udc97(\ud835\udc82\ud835\udc82) is a \nbasic element of \ud835\udc87\ud835\udc87(\ud835\udf1e\ud835\udf1e) the we are done. Otherwise, we can use the processes described in \nthe proof of Axiom 1 to construct a path from \ud835\udc87\ud835\udc87\ud835\udc97\ud835\udc97(\ud835\udc82\ud835\udc82) through basic and non- basic \nelements which will ultimately terminate at a basic element. Composing this path with \n\ud835\udc87\ud835\udc87\ud835\udc86\ud835\udc86(\ud835\udf38\ud835\udf38) then yields a path from a basic element to \ud835\udc99\ud835\udc99. As such, every element of \ud835\udc87\ud835\udc87(\ud835\udf1e\ud835\udf1e) is \nabove at least one basic element of \ud835\udc87\ud835\udc87(\ud835\udf1e\ud835\udf1e), i.e. \ud835\udc87\ud835\udc87(\ud835\udf1e\ud835\udf1e) =\ud835\udc26\ud835\udc26\ud835\udc1f\ud835\udc1f\ud835\udc1f\ud835\udc1f (\ud835\udc87\ud835\udc87(\ud835\udf1e\ud835\udf1e))\u2191. \nAxiom 3 We now must show that for every edge \ud835\udc82\ud835\udc82 \u2208\ud835\udc6c\ud835\udc6c(\ud835\udc87\ud835\udc87(\ud835\udf1e\ud835\udf1e)) with \ud835\udc82\ud835\udc82 \u223c[\ud835\udc9b\ud835\udc9b\ud835\udc99\ud835\udc99] and \n\ud835\udf4b\ud835\udf4b(\ud835\udc82\ud835\udc82)=\ud835\udc9a\ud835\udc9a, then there exists an edge \ud835\udc83\ud835\udc83 \u2208\ud835\udc6c\ud835\udc6c(\ud835\udc87\ud835\udc87(\ud835\udf1e\ud835\udf1e)) with \ud835\udc83\ud835\udc83\u223c[\ud835\udc9b\ud835\udc9b\ud835\udc9a\ud835\udc9a] and \ud835\udf4b\ud835\udf4b (\ud835\udc83\ud835\udc83)=\ud835\udc99\ud835\udc99. To see \nthat this is the case, take \ud835\udc82\ud835\udc82 as described. Then there exists an edge \ud835\udc96\ud835\udc96 \u2208\ud835\udc87\ud835\udc87\ud835\udc86\ud835\udc86\u2212\ud835\udfcf\ud835\udfcf(\ud835\udc82\ud835\udc82) in \ud835\udf1e\ud835\udf1e with \n\ud835\udc96\ud835\udc96\u223c[\ud835\udc93\ud835\udc93\ud835\udc93\ud835\udc93], \ud835\udc87\ud835\udc87\ud835\udc97\ud835\udc97(\ud835\udc93\ud835\udc93)=\ud835\udc9b\ud835\udc9b, \ud835\udc87\ud835\udc87\ud835\udc97\ud835\udc97(\ud835\udc93\ud835\udc93)=\ud835\udc9a\ud835\udc9a and \ud835\udf53\ud835\udf53 (\ud835\udc96\ud835\udc96)=\ud835\udc91\ud835\udc91. Since \ud835\udf1e\ud835\udf1e is an assembly space, there \nexists an edge \ud835\udc97\ud835\udc97\u2208\ud835\udc6c\ud835\udc6c(\ud835\udf1e\ud835\udf1e) with \ud835\udc97\ud835\udc97\u223c[\ud835\udc93\ud835\udc93\ud835\udc91\ud835\udc91] and \ud835\udf53\ud835\udf53 (\ud835\udc97\ud835\udc97) =\ud835\udc93\ud835\udc93. The commutivity property of \nassembly maps then gives us \ud835\udf4b\ud835\udf4b(\ud835\udc87\ud835\udc87\ud835\udc86\ud835\udc86(\ud835\udc97\ud835\udc97)) =\ud835\udc87\ud835\udc87\ud835\udc97\ud835\udc97(\ud835\udf53\ud835\udf53(\ud835\udc97\ud835\udc97)) =\ud835\udc87\ud835\udc87\ud835\udc97\ud835\udc97(\ud835\udc93\ud835\udc93)=\ud835\udc9a\ud835\udc9a. Calling \ud835\udc87\ud835\udc87 \ud835\udc97\ud835\udc97(\ud835\udc91\ud835\udc91)=\ud835\udc99\ud835\udc99 \nwe then have an edge in \ud835\udc87\ud835\udc87(\ud835\udf1e\ud835\udf1e), namely \ud835\udc87\ud835\udc87\ud835\udc86\ud835\udc86(\ud835\udc97\ud835\udc97), which terminates at \ud835\udc9b\ud835\udc9b and is labeled as \ud835\udc9a\ud835\udc9a. \nThis satisfies Axiom 3.  \n \n \n\u220e \n7. The Assembly Index \nThis final section turns to the definition and computation of the assembly index, a measure of \nhow directly an object can be constructed from basic objects.  \nDefinition 18. The cardinality  of an assembly space (\ud835\udee4\ud835\udee4 ,\ud835\udf19\ud835\udf19) is the cardinality of the \nunderl ying quiver\u2019s vertex set, |\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4)|. The augmented cardinality of the (\ud835\udee4\ud835\udee4 ,\ud835\udf19\ud835\udf19) with basis \ud835\udc35\ud835\udc35 \ud835\udee4\ud835\udee4 \nis |\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4)\\\ud835\udc35\ud835\udc35\ud835\udee4\ud835\udee4|=|\ud835\udc49\ud835\udc49(\ud835\udee4\ud835\udee4)|\u2212|\ud835\udc35\ud835\udc35\ud835\udee4\ud835\udee4|. \nDefinition 19. The assembly index  \ud835\udc50\ud835\udc50\ud835\udee4\ud835\udee4(\ud835\udc65\ud835\udc65) of a finite  object \ud835\udc65\ud835\udc65\u2208\ud835\udee4\ud835\udee4 is the minimal augmented \ncardinality of all rooted assembly subspaces containing \ud835\udc65\ud835\udc65. This can be written \ud835\udc50\ud835\udc50 (\ud835\udc65\ud835\udc65) when the \nrelevant assembly space \ud835\udee4\ud835\udee4  is clear from context.  \n4.1 Bounds on the Assembly Index \nFirst of all, we can bound the assembly index of an obj ect from above by computing the \nassembly index of that object in a rooted subspace. Essentially, since assembly subspace generally has fewer edges, there are fewer \u201cshortcuts\u201d to assembly the giving object.  \nLemma 6. Let \ud835\udc4b\ud835\udc4b be an assembly space and \ud835\udc4c\ud835\udc4c  a rooted assembly subspace of \ud835\udc4b\ud835\udc4b. For every \nfinite \ud835\udc66\ud835\udc66\u2208\ud835\udc4c\ud835\udc4c, the assembly index of \ud835\udc66\ud835\udc66 in \ud835\udc4c\ud835\udc4c  is greater than or equal to the assembly index of \ud835\udc66\ud835\udc66 \nin \ud835\udc4b\ud835\udc4b. That is, \ud835\udc50\ud835\udc50\n\ud835\udc4c\ud835\udc4c(\ud835\udc66\ud835\udc66)\u2265\ud835\udc50\ud835\udc50\ud835\udc4b\ud835\udc4b(\ud835\udc66\ud835\udc66) for all \ud835\udc66\ud835\udc66\u2208\ud835\udc4c\ud835\udc4c. \nProof. Let \ud835\udc66\ud835\udc66\u2208\ud835\udc4c\ud835\udc4c and suppose \ud835\udc50\ud835\udc50\ud835\udc4c\ud835\udc4c(\ud835\udc66\ud835\udc66)<\ud835\udc50\ud835\udc50\ud835\udc4b\ud835\udc4b(\ud835\udc66\ud835\udc66). Then there exists a ro oted assembly subspace \n\ud835\udc4d\ud835\udc4d\u2286\ud835\udc4c\ud835\udc4c containing \ud835\udc66\ud835\udc66 such that |\ud835\udc4d\ud835\udc4d\\\ud835\udc35\ud835\udc35\ud835\udc4d\ud835\udc4d|=\ud835\udc50\ud835\udc50\ud835\udc4c\ud835\udc4c(\ud835\udc66\ud835\udc66). But, by the transitivity of subset inclusion \n(lemma 3) \ud835\udc4d\ud835\udc4d is a rooted assembly subspace of \ud835\udc4b\ud835\udc4b. But if that\u2019s the case, there exists a rooted \nassembly subspace of \ud835\udc4b\ud835\udc4b with augmented car dinality less than \ud835\udc50\ud835\udc50\ud835\udc4b\ud835\udc4b(\ud835\udc66\ud835\udc66), namely \ud835\udc4d\ud835\udc4d; a \ncontradiction. \n \n\u220e \n \nSince the lower quiver of an object \ud835\udc65\ud835\udc65 is a rooted assembly subspace, we know the assembly \nindex of the object in \ud835\udc65\ud835\udc65 \u2193 bounds the real assembly index of the object from above. However, \nwe can do better \u2013 \ud835\udc50\ud835\udc50\ud835\udee4\ud835\udee4(\ud835\udc65\ud835\udc65)=\ud835\udc50\ud835\udc50\ud835\udc65\ud835\udc65\u2193(\ud835\udc65\ud835\udc65). This is a very powerful result as it allows us any \ncomputational approaches aiming to compute \ud835\udc50\ud835\udc50(\ud835\udc65\ud835\udc65) to focus only on the objects below \ud835\udc65\ud835\udc65 . \nTheorem 2.  Let \ud835\udee4\ud835\udee4  be an assembly space and let \ud835\udc65\ud835\udc65\u2208\ud835\udee4\ud835\udee4 be finite. Then \ud835\udc50\ud835\udc50 \ud835\udee4\ud835\udee4(\ud835\udc65\ud835\udc65)=\ud835\udc50\ud835\udc50\ud835\udc65\ud835\udc65\u2193(\ud835\udc65\ud835\udc65). \nProof. Since \ud835\udc65\ud835\udc65 \u2193 is finite, we need only consider finite, rooted assembly subspaces of \ud835\udee4\ud835\udee4. Let \n\ud835\udee5\ud835\udee5\u2286\ud835\udee4\ud835\udee4 be such a subspace containing \ud835\udc65\ud835\udc65, and suppose that \ud835\udee5\ud835\udee5 \u2288\ud835\udc65\ud835\udc65\u2193. Let \ud835\udc66\ud835\udc66\u2208\ud835\udee5\ud835\udee5 such that \ud835\udc66\ud835\udc66\u2209\n\ud835\udc65\ud835\udc65\u2193, then (\ud835\udee5\ud835\udee5\\\ud835\udc66\ud835\udc66\u2191) is a rooted assembly subspace of \ud835\udee4\ud835\udee4 containing \ud835\udc65\ud835\udc65  with augmented \ncardinality strictly less than \ud835\udee5\ud835\udee5. As such | \ud835\udee5\ud835\udee5\\\ud835\udc35\ud835\udc35\ud835\udee5\ud835\udee5|\u2260\ud835\udc50\ud835\udc50\ud835\udee4\ud835\udee4(\ud835\udc65\ud835\udc65). In other words, if \ud835\udee5\ud835\udee5 is not a subspace \nof \ud835\udc65\ud835\udc65\u2193, then it cannot have the augmented cardinality \ud835\udc50\ud835\udc50 \ud835\udee4\ud835\udee4(\ud835\udc65\ud835\udc65). Thus, by contrapositive if \n|\ud835\udee5\ud835\udee5\\\ud835\udc35\ud835\udc35\ud835\udee5\ud835\udee5|=\ud835\udc50\ud835\udc50\ud835\udee4\ud835\udee4(\ud835\udc65\ud835\udc65), then \ud835\udee5\ud835\udee5\u2286\ud835\udc65\ud835\udc65\u2193. Since \ud835\udee5\ud835\udee5  is rooted in \ud835\udee4\ud835\udee4 , it must also be rooted in \ud835\udc65\ud835\udc65 \u2193. \nTherefore, if a rooted subspace of \ud835\udee4\ud835\udee4 has the minimal augmented cardinality in \ud835\udee4\ud835\udee4, it must be a \nrooted assembly subspace of \ud835\udc65\ud835\udc65\u2193. This implies that \ud835\udc50\ud835\udc50\ud835\udee4\ud835\udee4(\ud835\udc65\ud835\udc65)\u2265\ud835\udc50\ud835\udc50\ud835\udc65\ud835\udc65\u2193(\ud835\udc65\ud835\udc65). Additionally, by lemma \n6, \ud835\udc50\ud835\udc50\ud835\udee4\ud835\udee4(\ud835\udc65\ud835\udc65)\u2264\ud835\udc50\ud835\udc50\ud835\udc65\ud835\udc65\u2193(\ud835\udc65\ud835\udc65). Then \ud835\udc50\ud835\udc50 \ud835\udee4\ud835\udee4(\ud835\udc65\ud835\udc65)=\ud835\udc50\ud835\udc50\ud835\udc65\ud835\udc65\u2193(\ud835\udc65\ud835\udc65). \n \n\u220e \n \nFinally, assembly maps allow us to place lower -bounds on the assembly index \u2013 the assembly \nindex of the image of an object bounds the object\u2019s actual assembly index below. In other  \nwords, we can place lower bounds on the assembly index of an object by mapping the \nassembly space into a simpler space and computing the assembly index there.  \nTheorem 3. If \ud835\udc53\ud835\udc53:\ud835\udee4\ud835\udee4\u2192\ud835\udee5\ud835\udee5 is an assembly map, then \ud835\udc50\ud835\udc50\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4)(\ud835\udc53\ud835\udc53(\ud835\udc65\ud835\udc65))\u2264\ud835\udc50\ud835\udc50\ud835\udee4\ud835\udee4(\ud835\udc65\ud835\udc65) for all finite \ud835\udc65\ud835\udc65 \u2208\ud835\udee4\ud835\udee4. \nProof. Let \ud835\udef4\ud835\udef4\u2286\ud835\udee4\ud835\udee4 be an assembly subspace containing \ud835\udc65\ud835\udc65 with |\ud835\udef4\ud835\udef4\\\ud835\udc35\ud835\udc35\ud835\udef4\ud835\udef4|=\ud835\udc50\ud835\udc50\ud835\udee4\ud835\udee4(\ud835\udc65\ud835\udc65). The restriction \nof \ud835\udc53\ud835\udc53 to \ud835\udef4\ud835\udef4 is an assembly map \ud835\udc53\ud835\udc53\u2217:\ud835\udef4\ud835\udef4\u2192\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4). Then we have  \n|\ud835\udef4\ud835\udef4\\\ud835\udc35\ud835\udc35\ud835\udef4\ud835\udef4|\u2265|\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4\\\ud835\udc35\ud835\udc35\ud835\udef4\ud835\udef4)|\n=|\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4\\\ud835\udc35\ud835\udc35\ud835\udef4\ud835\udef4)\u2229(\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4)\\\ud835\udc35\ud835\udc35\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4))|+|\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4\\\ud835\udc35\ud835\udc35\ud835\udef4\ud835\udef4)\u2229\ud835\udc35\ud835\udc35\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4)|\n\u2265|\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4\\\ud835\udc35\ud835\udc35\ud835\udef4\ud835\udef4)\u2229(\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4)\\\ud835\udc35\ud835\udc35\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4))|. \nAs an assembly map, \ud835\udc53\ud835\udc53\u2217 maps basis elements of \ud835\udef4\ud835\udef4 onto basis elements of \ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4). So every for \n\ud835\udc62\ud835\udc62\u2208\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4)\\\ud835\udc35\ud835\udc35\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4), there exists a \ud835\udc63\ud835\udc63 \u2208\ud835\udef4\ud835\udef4\\\ud835\udc35\ud835\udc35\ud835\udef4\ud835\udef4 such t hat \ud835\udc53\ud835\udc53\u2217(\ud835\udc63\ud835\udc63)=\ud835\udc62\ud835\udc62. This gives us  \n\ud835\udc50\ud835\udc50\ud835\udee4\ud835\udee4=|\ud835\udef4\ud835\udef4\\\ud835\udc35\ud835\udc35\ud835\udef4\ud835\udef4|\n\u2265|\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4\\\ud835\udc35\ud835\udc35\ud835\udef4\ud835\udef4)\u2229(\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4)\\\ud835\udc35\ud835\udc35\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4))|\n=|\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4)\\\ud835\udc35\ud835\udc35\ud835\udc53\ud835\udc53\u2217(\ud835\udef4\ud835\udef4)|\n\u2265\ud835\udc50\ud835\udc50\ud835\udc53\ud835\udc53(\ud835\udee4\ud835\udee4)(\ud835\udc53\ud835\udc53(\ud835\udc65\ud835\udc65)).  \n \n4.2  Computability and Algorithms  \nTheorem 4. If \ud835\udee4\ud835\udee4 is an assembly space and \ud835\udc65\ud835\udc65 \u2208\ud835\udee4\ud835\udee4 is finite, then \ud835\udc50\ud835\udc50(\ud835\udc65\ud835\udc65) is computable.  \nProof. As shown in the proof of theorem 2, every rooted assembly subspace with minimal \naugmented cardinality and containing \ud835\udc65\ud835\udc65  is a minimal rooted assembly subspace of \ud835\udc65\ud835\udc65\u2193. Since \n\ud835\udc65\ud835\udc65 is finite, \ud835\udc65\ud835\udc65\u2193 is finite, the set of assembly subspace of \ud835\udc65\ud835\udc65 \u2193 is finite, and eac h such subspace \nis finite. Consequently, the basis of each subspace is computable. As such, the set of all \nrooted subspaces is computable. The cardinality of each subspace is computable, so the set of cardinalities of all rooted subspaces is computable. Fi nally, the minimum of a finite set of \nnatural numbers is computable. Therefore, \ud835\udc50\ud835\udc50\n\ud835\udee4\ud835\udee4(\ud835\udc65\ud835\udc65) is computable. \n \n\u220e \nAn algorithm for finding the pathway assembly index of an object within an assembly subspace \nis described below. \nThe Assembly Index in assembly space  \u0393\u2261(\u0393,\ud835\udf19\ud835\udf19) of a target object \ud835\udc61\ud835\udc61\u2208\u0393, with basic objects \n\ud835\udc35\ud835\udc35\u2286\u0393. \n \nFunction Main(B, t)  \nGlobal Variable PA // the pathway assembly index  \nSet PA = upper bound of assembly index + |B|  \nAssemblyIndex(B, t)  \nReturn PA - |B| \nEnd Function  \nFunction AssemblyIndex(S, t)  \n For each pair of objects s 1,s2\u2208S \n  If there exists an edge \ud835\udc52\ud835\udc52~[\ud835\udc61\ud835\udc61\ud835\udc60\ud835\udc601] with \ud835\udf19\ud835\udf19(\ud835\udc52\ud835\udc52)=\ud835\udc60\ud835\udc602 and PA>|S\u222at|  \n   PA=|S\u222aT| \n  Else there exists an edge \ud835\udc52\ud835\udc52~[\ud835\udc62\ud835\udc62\ud835\udc60\ud835\udc601] with \ud835\udf19\ud835\udf19(\ud835\udc52\ud835\udc52)=\ud835\udc60\ud835\udc602 for some u\u2208\u0393 \n   AssemblyIndex (\u0393,S\u222au,t) \n  End If \n End For  \nEnd Function  \n \nWe have also defined above the Split -Branched Assembly Index. Calculation of this index can \nbe more computationally tractable than the assembly index, as often a lower number of pathways will need to be enumerated.  An algorithm to calculate this  index is shown below. \nThe Split -Branched Assembly Index in assembly space \u0393\u2261(\u0393 ,\ud835\udf19\ud835\udf19) of a target object \ud835\udc61\ud835\udc61\u2208\u0393 \nwith, with basic objects \ud835\udc35\ud835\udc35\u2286\ud835\udc49\ud835\udc49(\u0393) \nFunction SplitBranchedAssemblyIndex( \u0393, B, t, I)  \n Set PA = upper bound of assembly index for t  \n For each partition of U into connected sub -objects \u0393P={\u03931\u2026\u0393n} \n  Set PartitionIndex = 0  \n  Partition UP into K={{\u039311,\u2026,\u03931i},\ufffd\u039321,\u2026,\u03932j\ufffd,\u2026,{\u0393m1\u2026\u0393mk}} \n  Where for each K n, the \u0393 nx are identical for all x \n  For each K i\u2208K \n   If Ki1\u2208B \n    PartitionIndex  += 1 \n   Else \n    PartitionIndex  += SplitBranchedAssemblyIndex (\u0393,B,Ki1) \n+ |Ki|\u22121 \n  End If \n End For \n  PA = min  (PartitionIndex, PA ) \n End For \n Return PA  \nEnd Function \nReferences  \n1. S. M. Marshall, A. R. G. Murray, and L. Cronin, A Probabilistic Framework for \nIdentifying Biosignatures Using Pathway Complexity. Phil. Trans. R. Soc. A 375, \n20160342 (2017). \n \n \n ", "url": "https://arxiv.org/abs/1907.04649"}
{"text": "1 Introduction\n---------------\n\n\n\nDeep reinforcement learning (RL) has emerged as a powerful method to solve a variety of sequential decision-making problems, including board games\u00a0Silver et\u00a0al. ([2017](#bib.bib58), [2018](#bib.bib59)), video games\u00a0Berner et\u00a0al. ([2019](#bib.bib10)); Mnih et\u00a0al. ([2015](#bib.bib44)); Vinyals et\u00a0al. ([2019](#bib.bib68)), autonomous control\u00a0Bellemare et\u00a0al. ([2020](#bib.bib9)); Schulman et\u00a0al. ([2015](#bib.bib52)), and robotic manipulation\u00a0Andrychowicz et\u00a0al. ([2020](#bib.bib5)); Kalashnikov et\u00a0al. ([2018](#bib.bib32)); Kober & Peters ([2011](#bib.bib35)); Kober et\u00a0al. ([2013](#bib.bib36)).\nHowever, scaling RL to many applications is difficult\ndue to the challenges associated with defining a suitable reward function,\nwhich often requires substantial human effort.\nSpecifying the reward function becomes harder as the tasks we want the agent to achieve become more complex (e.g., cooking or self-driving).\nIn addition, RL agents are prone to exploit reward functions by discovering ways to achieve high returns in ways the reward designer did not expect nor intend. It is important to consider this phenomenon of reward exploitation, or reward hacking, since it may lead to unintended but dangerous consequences\u00a0(Hadfield-Menell et\u00a0al., [2017](#bib.bib28)).\nFurther, there is nuance in how we might want agents to behave, such as obeying social norms that are difficult to account for and communicate effectively through an engineered reward function\u00a0(Amodei et\u00a0al., [2016](#bib.bib4); Shah et\u00a0al., [2019](#bib.bib57); Turner et\u00a0al., [2020](#bib.bib67)).\n\n\n\n\nPreference-based RL\u00a0(Christiano et\u00a0al., [2017](#bib.bib19); Ibarz et\u00a0al., [2018](#bib.bib31); Lee et\u00a0al., [2021](#bib.bib39)) provides an alternative: a (human) teacher provides preferences between the two agent behaviors, and the agent then uses this feedback to learn desired behaviors (see Figure\u00a0[1](#S2.F1 \"Figure 1 \u2023 2 Preliminaries \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\")).\nThis framework enables us to optimize the agent using RL without hand-engineered rewards by learning a reward function,\nwhich is consistent with the observed preferences\u00a0(Biyik & Sadigh, [2018](#bib.bib11); Biyik et\u00a0al., [2020](#bib.bib12); Sadigh et\u00a0al., [2017](#bib.bib50)).\nBecause a teacher can interactively guide agents according to their progress,\npreference-based RL has shown promising results\n(e.g., solving a range of RL benchmarks\u00a0(Christiano et\u00a0al., [2017](#bib.bib19); Ibarz et\u00a0al., [2018](#bib.bib31)), teaching novel behaviors\u00a0(Stiennon et\u00a0al., [2020](#bib.bib61); Wu et\u00a0al., [2021](#bib.bib71)), and mitigating the effects of reward exploitation\u00a0(Lee et\u00a0al., [2021](#bib.bib39))).\n\n\n\n\nDespite significant progress on RL benchmarks designed for various purposes (e.g., offline RL\u00a0(Fu et\u00a0al., [2020](#bib.bib24); Gulcehre et\u00a0al., [2020](#bib.bib26)), generalization\u00a0Cobbe et\u00a0al. ([2019](#bib.bib20), [2020](#bib.bib21)), meta RL\u00a0(Yu et\u00a0al., [2020](#bib.bib76)), and safe RL\u00a0Ray et\u00a0al. ([2019](#bib.bib48))),\nexisting benchmarks are not tailored towards preference-based RL. The lack of a standard evaluation benchmark makes it hard to quantify scientific progress.\nIndeed, without consistent evaluation, it\nis not easy to understand the effects of algorithmic and design decisions or compare them across papers.\n\n\n\n\n\nIn this paper, we introduce B-Pref: a benchmark for preference-based RL consisting of various locomotion and robotic manipulation tasks from DeepMind Control Suite\u00a0(Tassa et\u00a0al., [2018](#bib.bib65), [2020](#bib.bib66)) and Meta-world\u00a0(Yu et\u00a0al., [2020](#bib.bib76)).\nWhile utilizing real human input is ideal,\nthis is prohibitive because it is hard to evaluate candidate algorithms quickly using real human input.\nPrior works\u00a0(Christiano et\u00a0al., [2017](#bib.bib19); Ibarz et\u00a0al., [2018](#bib.bib31); Lee et\u00a0al., [2021](#bib.bib39)) address this issue by simulating human input as giving perfect preferences with respect to an underlying ground truth reward function. However, evaluation on such ideal teachers is unrealistic because actual humans can exhibit various irrationalities\u00a0(Chipman, [2016](#bib.bib18)) in decision making.\nSo, in our benchmark, we design simulated human teachers with a wide array of irrationalities\nand propose evaluation metrics not solely for performance but also for robustness to these potential irrationalities.\n\n\n\n\n\nTo serve as a reference, we benchmark state-of-the-art preference-based RL algorithms\u00a0(Christiano et\u00a0al., [2017](#bib.bib19); Lee et\u00a0al., [2021](#bib.bib39)) in B-Pref\nand showcase the utility of B-Pref by using it to analyze algorithmic design choices for preference-based RL.\nAlthough existing methods provide fairly efficient performance on perfectly rational teachers,\nthe poor performance on more realistic, irrational teachers calls for new algorithms to be developed.\n\n\n\n\nThe benchmark and reference implementations are available at <https://github.com/rll-research/B-Pref>.\nWe believe that systematic evaluation and comparison will not only further our understanding of the strengths of existing algorithms, but also reveal their limitations and suggest directions for future research.\n\n2 Preliminaries\n----------------\n\n\n![Refer to caption](/html/2111.03026/assets/x1.png)\nFigure 1: Illustration of preference-based RL.\nInstead of assuming that the environment provides a (hand-engineered) reward,\na teacher provides preferences between the agent\u2019s behaviors, and the agent uses this feedback in order to learn the desired behavior.\n\n\nWe consider an agent interacting with an environment in discrete time\u00a0Sutton & Barto ([2018](#bib.bib63)).\nAt each timestep t\ud835\udc61titalic\\_t, the agent receives a state \ud835\udc2ctsubscript\ud835\udc2c\ud835\udc61\\mathbf{s}\\_{t}bold\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT from the environment and chooses an action \ud835\udc1atsubscript\ud835\udc1a\ud835\udc61\\mathbf{a}\\_{t}bold\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT based on its policy \u03c0\ud835\udf0b\\piitalic\\_\u03c0.\n\n\n\n\nIn traditional reinforcement learning,\nthe environment also returns a reward r(\ud835\udc2ct,\ud835\udc1at)\ud835\udc5fsubscript\ud835\udc2c\ud835\udc61subscript\ud835\udc1a\ud835\udc61r(\\mathbf{s}\\_{t},\\mathbf{a}\\_{t})italic\\_r ( bold\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT , bold\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT ) and\nthe goal of agent is to maximize the discounted sum of rewards.\nHowever, for many complex domains and tasks,\nit is difficult to construct a suitable reward function.\nWe consider the preference-based RL framework,\nwhere a (human) teacher provides preferences between the agent\u2019s behaviors\nand the agent uses this feedback to perform the task\u00a0(Christiano et\u00a0al., [2017](#bib.bib19); Ibarz et\u00a0al., [2018](#bib.bib31); Lee et\u00a0al., [2021](#bib.bib39); Leike et\u00a0al., [2018](#bib.bib41)).\n\n\n\n\nFormally, a segment \u03c3\ud835\udf0e\\sigmaitalic\\_\u03c3 is a sequence of observations and actions {(\ud835\udc2c1,\ud835\udc1a1),\u2026,(\ud835\udc2cH,\ud835\udc1aH)}subscript\ud835\udc2c1subscript\ud835\udc1a1\u2026subscript\ud835\udc2c\ud835\udc3bsubscript\ud835\udc1a\ud835\udc3b\\{(\\mathbf{s}\\_{1},\\mathbf{a}\\_{1}),...,(\\mathbf{s}\\_{H},\\mathbf{a}\\_{H})\\}{ ( bold\\_s start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT , bold\\_a start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT ) , \u2026 , ( bold\\_s start\\_POSTSUBSCRIPT italic\\_H end\\_POSTSUBSCRIPT , bold\\_a start\\_POSTSUBSCRIPT italic\\_H end\\_POSTSUBSCRIPT ) }.\nGiven a pair of segments (\u03c30,\u03c31)superscript\ud835\udf0e0superscript\ud835\udf0e1(\\sigma^{0},\\sigma^{1})( italic\\_\u03c3 start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT , italic\\_\u03c3 start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT ),\na teacher indicates which segment is preferred, i.e., y=(0,1)or(1,0)\ud835\udc6601or10y=(0,1)~{}\\text{or}~{}(1,0)italic\\_y = ( 0 , 1 ) or ( 1 , 0 ),\nthat the two segments are equally preferred y=(0.5,0.5)\ud835\udc660.50.5y=(0.5,0.5)italic\\_y = ( 0.5 , 0.5 ),\nor that two segments are incomparable, i.e., discarding the query.\nThe goal of preference-based RL is to train an agent to perform behaviors desirable to a human teacher using as few queries as possible.\n\n3 B-Pref: Benchmarks environments for preference-based RL\n----------------------------------------------------------\n\n\n\n### \n3.1 Design factors\n\n\n\nWhile ideally we would evaluate algorithms\u2019 real-world efficacy using real human feedback,\ndesigning a standardized and broadly available benchmark becomes challenging\nbecause we do not have ground truth access to the human\u2019s reward function.\nInstead, we focus on solving a range of existing RL tasks (see Section\u00a0[3.4](#S3.SS4 \"3.4 Tasks \u2023 3 B-Pref: Benchmarks environments for preference-based RL \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\")) using a simulated human,\nwhose preferences are based on a ground truth reward function.\nBecause simulated human preferences are immediately generated by the ground truth reward,\nwe are able to evaluate the agent quantitatively by measuring the true average return\nand do more rapid experiments.\nA major challenge with simulating human input is that real humans are not perfectly rational and will not provide perfect preferences.\nTo alleviate this challenge, we propose to simulate human input using a wide array of irrationalities (see Section\u00a0[3.2](#S3.SS2 \"3.2 Simulated human teachers \u2023 3 B-Pref: Benchmarks environments for preference-based RL \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\")), and measure an algorithm\u2019s robustness in handling such input (see Section\u00a0[3.3](#S3.SS3 \"3.3 Evaluation metrics \u2023 3 B-Pref: Benchmarks environments for preference-based RL \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\")).\n\n\n\n\nAlgorithm 1  SimTeacher: Simulated human teachers\n\n\n1:Discount factor \u03b3\ud835\udefe\\gammaitalic\\_\u03b3, rationality constant \u03b2\ud835\udefd\\betaitalic\\_\u03b2, probability of making a mistake \u03f5italic-\u03f5\\epsilonitalic\\_\u03f5\n\n\n2:Skip threshold \u03b4\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99subscript\ud835\udeff\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99\\delta\\_{\\tt skip}italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_skip end\\_POSTSUBSCRIPT, equal threshold \u03b4\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude95subscript\ud835\udeff\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude95\\delta\\_{\\tt equal}italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_equal end\\_POSTSUBSCRIPT\n\n\n3:Pair of segments \u03c30,\u03c31superscript\ud835\udf0e0superscript\ud835\udf0e1\\sigma^{0},\\sigma^{1}italic\\_\u03c3 start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT , italic\\_\u03c3 start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT\n\n\n4:if\u00a0maxi\u2208{0,1}\u2211tr(\ud835\udc2cti,\ud835\udc1ati)<\u03b4\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99subscript\ud835\udc5601subscript\ud835\udc61\ud835\udc5fsubscriptsuperscript\ud835\udc2c\ud835\udc56\ud835\udc61subscriptsuperscript\ud835\udc1a\ud835\udc56\ud835\udc61subscript\ud835\udeff\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99\\max\\_{i\\in\\{0,1\\}}\\sum\\_{t}r\\left(\\mathbf{s}^{i}\\_{t},\\mathbf{a}^{i}\\_{t}\\right)<\\delta\\_{\\tt skip}roman\\_max start\\_POSTSUBSCRIPT italic\\_i \u2208 { 0 , 1 } end\\_POSTSUBSCRIPT \u2211 start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT italic\\_r ( bold\\_s start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT , bold\\_a start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT ) < italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_skip end\\_POSTSUBSCRIPT\u00a0then\n// Skipping query\n\n\n5:\u00a0\u00a0\u00a0\u00a0\u00a0y\u2190\u2205\u2190\ud835\udc66y\\leftarrow\\emptysetitalic\\_y \u2190 \u2205\n\n\n6:else\u00a0if\u00a0|\u2211tr(\ud835\udc2ct1,\ud835\udc1at1)\u2212\u2211tr(\ud835\udc2ct0,\ud835\udc1at0)|<\u03b4\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude95subscript\ud835\udc61\ud835\udc5fsubscriptsuperscript\ud835\udc2c1\ud835\udc61subscriptsuperscript\ud835\udc1a1\ud835\udc61subscript\ud835\udc61\ud835\udc5fsubscriptsuperscript\ud835\udc2c0\ud835\udc61subscriptsuperscript\ud835\udc1a0\ud835\udc61subscript\ud835\udeff\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude95\\big{|}\\sum\\_{t}r\\left(\\mathbf{s}^{1}\\_{t},\\mathbf{a}^{1}\\_{t}\\right)-\\sum\\_{t}r\\left(\\mathbf{s}^{0}\\_{t},\\mathbf{a}^{0}\\_{t}\\right)\\big{|}<\\delta\\_{\\tt equal}| \u2211 start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT italic\\_r ( bold\\_s start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT , bold\\_a start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT ) - \u2211 start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT italic\\_r ( bold\\_s start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT , bold\\_a start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT ) | < italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_equal end\\_POSTSUBSCRIPT\u00a0then\n// Equally preferable\n\n\n7:\u00a0\u00a0\u00a0\u00a0\u00a0y\u2190(0.5,0.5)\u2190\ud835\udc660.50.5y\\leftarrow(0.5,0.5)italic\\_y \u2190 ( 0.5 , 0.5 )\n\n\n8:else\u00a0if\u00a0\u03c30\u227b\u03c31\u223cP[\u03c30\u227b\u03c31;\u03b2,\u03b3]succeedssuperscript\ud835\udf0e0superscript\ud835\udf0e1similar-to\ud835\udc43delimited-[]succeedssuperscript\ud835\udf0e0superscript\ud835\udf0e1\ud835\udefd\ud835\udefe\\sigma^{0}\\succ\\sigma^{1}\\sim P[\\sigma^{0}\\succ\\sigma^{1};\\beta,\\gamma]italic\\_\u03c3 start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT \u227b italic\\_\u03c3 start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT \u223c italic\\_P [ italic\\_\u03c3 start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT \u227b italic\\_\u03c3 start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT ; italic\\_\u03b2 , italic\\_\u03b3 ]\u00a0then\n// Sampling preferences from ([1](#S3.E1 \"1 \u2023 3.2 Simulated human teachers \u2023 3 B-Pref: Benchmarks environments for preference-based RL \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\"))\n\n\n9:\u00a0\u00a0\u00a0\u00a0\u00a0y\u2190(1,0)\u2190\ud835\udc6610y\\leftarrow(1,0)italic\\_y \u2190 ( 1 , 0 ) with probability of 1\u2212\u03f51italic-\u03f51-\\epsilon1 - italic\\_\u03f5\n\n\n10:\u00a0\u00a0\u00a0\u00a0\u00a0y\u2190(0,1)\u2190\ud835\udc6601y\\leftarrow(0,1)italic\\_y \u2190 ( 0 , 1 ) otherwise // Making a mistake\n\n\n11:else\n\n\n12:\u00a0\u00a0\u00a0\u00a0\u00a0y\u2190(0,1)\u2190\ud835\udc6601y\\leftarrow(0,1)italic\\_y \u2190 ( 0 , 1 ) with probability of 1\u2212\u03f51italic-\u03f51-\\epsilon1 - italic\\_\u03f5\n\n\n13:\u00a0\u00a0\u00a0\u00a0\u00a0y\u2190(1,0)\u2190\ud835\udc6610y\\leftarrow(1,0)italic\\_y \u2190 ( 1 , 0 ) otherwise // Making a mistake\n\n\n14:end\u00a0if\n\n\n15:\ud835\udc2b\ud835\udc1e\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc27y\ud835\udc2b\ud835\udc1e\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc27\ud835\udc66\\textbf{return}\\;yreturn italic\\_y\n\n\n\n\n\n### \n3.2 Simulated human teachers\n\n\n\nWe start from a (perfectly rational) deterministic teacher, which generates preferences as follows:\n\n\n\n\n|  |  |  |\n| --- | --- | --- |\n|  | y={(1,0)If\u00a0\u2211t=1Hr(\ud835\udc2ct0,\ud835\udc1at0)>\u2211t=1Hr(\ud835\udc2ct1,\ud835\udc1at1)(0,1)otherwise,\ud835\udc66cases10If\u00a0\u2211t=1Hr(\ud835\udc2ct0,\ud835\udc1at0)>\u2211t=1Hr(\ud835\udc2ct1,\ud835\udc1at1)missing-subexpression01otherwisemissing-subexpression\\displaystyle y=\\left\\{\\begin{array}[]{lll}(1,0)&\\mbox{If $\\sum\\_{t=1}^{H}r(\\mathbf{s}\\_{t}^{0},\\mathbf{a}\\_{t}^{0})>\\sum\\_{t=1}^{H}r(\\mathbf{s}\\_{t}^{1},\\mathbf{a}\\_{t}^{1})$}\\\\\n(0,1)&\\mbox{otherwise},\\end{array}\\right.italic\\_y = { start\\_ARRAY start\\_ROW start\\_CELL ( 1 , 0 ) end\\_CELL start\\_CELL If \u2211 start\\_POSTSUBSCRIPT italic\\_t = 1 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_H end\\_POSTSUPERSCRIPT italic\\_r ( bold\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT , bold\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT ) > \u2211 start\\_POSTSUBSCRIPT italic\\_t = 1 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_H end\\_POSTSUPERSCRIPT italic\\_r ( bold\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT , bold\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT ) end\\_CELL start\\_CELL end\\_CELL end\\_ROW start\\_ROW start\\_CELL ( 0 , 1 ) end\\_CELL start\\_CELL otherwise , end\\_CELL start\\_CELL end\\_CELL end\\_ROW end\\_ARRAY |  |\n\n\nwhere H>0\ud835\udc3b0H>0italic\\_H > 0 is a length of segment \u03c3\ud835\udf0e\\sigmaitalic\\_\u03c3 and r\ud835\udc5fritalic\\_r is the ground truth reward.\nWe remark that prior works\u00a0(Christiano et\u00a0al., [2017](#bib.bib19); Ibarz et\u00a0al., [2018](#bib.bib31); Lee et\u00a0al., [2021](#bib.bib39)) evaluated their methods using this ideal teacher.\nHowever, evaluating the performance of preference-based RL only using the ideal teacher is unrealistic because there are many possible irrationalities\u00a0(Chan et\u00a0al., [2021](#bib.bib17); Chipman, [2016](#bib.bib18)) affecting a teacher\u2019s preferences (and expression of preferences) in different ways.\n\n\n\n\nTo design more realistic models of human teachers,\nwe consider a common stochastic model\u00a0(Biyik & Sadigh, [2018](#bib.bib11); Christiano et\u00a0al., [2017](#bib.bib19); Sadigh et\u00a0al., [2017](#bib.bib50))\nand systematically manipulate its terms and operators\n(see Algorithm\u00a0[1](#alg1 \"Algorithm 1 \u2023 3.1 Design factors \u2023 3 B-Pref: Benchmarks environments for preference-based RL \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\")):\n\n\n\n\nStochastic preference model.\nBecause preferences from the human can be noisy,\nwe generate preferences using a stochastic model defined as follows (Line\u00a0[8](#alg1.l8 \"8 \u2023 Algorithm 1 \u2023 3.1 Design factors \u2023 3 B-Pref: Benchmarks environments for preference-based RL \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\")):\n\n\n\n\n|  |  |  |  |\n| --- | --- | --- | --- |\n|  | P[\u03c3i\u227b\u03c3j;\u03b2,\u03b3]=exp\u2061(\u03b2\u2211t=1H\u03b3H\u2212tr(\ud835\udc2cti,\ud835\udc1ati))exp\u2061(\u03b2\u2211t=1H\u03b3H\u2212tr(\ud835\udc2cti,\ud835\udc1ati))+exp\u2061(\u03b2\u2211t=1H\u03b3H\u2212tr(\ud835\udc2ctj,\ud835\udc1atj)),\ud835\udc43delimited-[]succeedssuperscript\ud835\udf0e\ud835\udc56superscript\ud835\udf0e\ud835\udc57\ud835\udefd\ud835\udefe\ud835\udefdsuperscriptsubscript\ud835\udc611\ud835\udc3bsuperscript\ud835\udefe\ud835\udc3b\ud835\udc61\ud835\udc5fsuperscriptsubscript\ud835\udc2c\ud835\udc61\ud835\udc56superscriptsubscript\ud835\udc1a\ud835\udc61\ud835\udc56\ud835\udefdsuperscriptsubscript\ud835\udc611\ud835\udc3bsuperscript\ud835\udefe\ud835\udc3b\ud835\udc61\ud835\udc5fsuperscriptsubscript\ud835\udc2c\ud835\udc61\ud835\udc56superscriptsubscript\ud835\udc1a\ud835\udc61\ud835\udc56\ud835\udefdsuperscriptsubscript\ud835\udc611\ud835\udc3bsuperscript\ud835\udefe\ud835\udc3b\ud835\udc61\ud835\udc5fsuperscriptsubscript\ud835\udc2c\ud835\udc61\ud835\udc57superscriptsubscript\ud835\udc1a\ud835\udc61\ud835\udc57\\displaystyle P[\\sigma^{i}\\succ\\sigma^{j};\\beta,\\gamma]=\\frac{\\exp\\left(\\beta\\sum\\_{t=1}^{H}\\gamma^{H-t}r(\\mathbf{s}\\_{t}^{i},\\mathbf{a}\\_{t}^{i})\\right)}{\\exp\\left(\\beta\\sum\\_{t=1}^{H}\\gamma^{H-t}r(\\mathbf{s}\\_{t}^{i},\\mathbf{a}\\_{t}^{i})\\right)+\\exp\\left(\\beta\\sum\\_{t=1}^{H}\\gamma^{H-t}r(\\mathbf{s}\\_{t}^{j},\\mathbf{a}\\_{t}^{j})\\right)},italic\\_P [ italic\\_\u03c3 start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT \u227b italic\\_\u03c3 start\\_POSTSUPERSCRIPT italic\\_j end\\_POSTSUPERSCRIPT ; italic\\_\u03b2 , italic\\_\u03b3 ] = divide start\\_ARG roman\\_exp ( italic\\_\u03b2 \u2211 start\\_POSTSUBSCRIPT italic\\_t = 1 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_H end\\_POSTSUPERSCRIPT italic\\_\u03b3 start\\_POSTSUPERSCRIPT italic\\_H - italic\\_t end\\_POSTSUPERSCRIPT italic\\_r ( bold\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT , bold\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT ) ) end\\_ARG start\\_ARG roman\\_exp ( italic\\_\u03b2 \u2211 start\\_POSTSUBSCRIPT italic\\_t = 1 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_H end\\_POSTSUPERSCRIPT italic\\_\u03b3 start\\_POSTSUPERSCRIPT italic\\_H - italic\\_t end\\_POSTSUPERSCRIPT italic\\_r ( bold\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT , bold\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT ) ) + roman\\_exp ( italic\\_\u03b2 \u2211 start\\_POSTSUBSCRIPT italic\\_t = 1 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_H end\\_POSTSUPERSCRIPT italic\\_\u03b3 start\\_POSTSUPERSCRIPT italic\\_H - italic\\_t end\\_POSTSUPERSCRIPT italic\\_r ( bold\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_j end\\_POSTSUPERSCRIPT , bold\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_j end\\_POSTSUPERSCRIPT ) ) end\\_ARG , |  | (1) |\n\n\nwhere \u03b3\u2208(0,1]\ud835\udefe01\\gamma\\in(0,1]italic\\_\u03b3 \u2208 ( 0 , 1 ] is a discount factor to model myopic behavior,\n\u03b2\ud835\udefd\\betaitalic\\_\u03b2 is a rationality constant, and \u03c3i\u227b\u03c3jsucceedssuperscript\ud835\udf0e\ud835\udc56superscript\ud835\udf0e\ud835\udc57\\sigma^{i}\\succ\\sigma^{j}italic\\_\u03c3 start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT \u227b italic\\_\u03c3 start\\_POSTSUPERSCRIPT italic\\_j end\\_POSTSUPERSCRIPT denotes the event that segment i\ud835\udc56iitalic\\_i is preferable to segment j\ud835\udc57jitalic\\_j.\nThis follows the Bradley-Terry model\u00a0(Bradley & Terry, [1952](#bib.bib13)),\nwhich can be interpreted as assuming the probability of preferring a segment depends exponentially on the sum over the segment of an underlying reward.\nNote that this teacher becomes a perfectly rational and deterministic as \u03b2\u2192\u221e\u2192\ud835\udefd\\beta\\rightarrow\\inftyitalic\\_\u03b2 \u2192 \u221e, whereas \u03b2=0\ud835\udefd0\\beta=0italic\\_\u03b2 = 0 produces uniformly random choices.\n\n\n\n\nMyopic behavior. Humans are sometimes myopic (short-sighted), so a human teacher may remember and focus more on the behavior at the end of the clip they watched, for example.\nWe model myopic behavior by introducing a weighted sum of rewards with a\ndiscount factor \u03b3\ud835\udefe\\gammaitalic\\_\u03b3 in ([1](#S3.E1 \"1 \u2023 3.2 Simulated human teachers \u2023 3 B-Pref: Benchmarks environments for preference-based RL \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\")), i.e., \u2211t=1H\u03b3H\u2212tr(\ud835\udc2cti,\ud835\udc1ati)superscriptsubscript\ud835\udc611\ud835\udc3bsuperscript\ud835\udefe\ud835\udc3b\ud835\udc61\ud835\udc5fsuperscriptsubscript\ud835\udc2c\ud835\udc61\ud835\udc56superscriptsubscript\ud835\udc1a\ud835\udc61\ud835\udc56\\sum\\_{t=1}^{H}\\gamma^{H-t}r(\\mathbf{s}\\_{t}^{i},\\mathbf{a}\\_{t}^{i})\u2211 start\\_POSTSUBSCRIPT italic\\_t = 1 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_H end\\_POSTSUPERSCRIPT italic\\_\u03b3 start\\_POSTSUPERSCRIPT italic\\_H - italic\\_t end\\_POSTSUPERSCRIPT italic\\_r ( bold\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT , bold\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT ), so that our simulated teacher places more weight on recent timesteps.\n\n\n\n\nSkipping queries.\nIf both segments do not contain a desired behavior, a teacher would like to mark them as incomparable and discard the query.\nWe model this behavior by skipping a query if the sum over the segment of an underlying reward is smaller than skip threshold \u03b4\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99subscript\ud835\udeff\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99\\delta\\_{\\tt skip}italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_skip end\\_POSTSUBSCRIPT, i.e., maxi\u2208{0,1}\u2211tr(\ud835\udc2cti,\ud835\udc1ati)<\u03b4\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99subscript\ud835\udc5601subscript\ud835\udc61\ud835\udc5fsubscriptsuperscript\ud835\udc2c\ud835\udc56\ud835\udc61subscriptsuperscript\ud835\udc1a\ud835\udc56\ud835\udc61subscript\ud835\udeff\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99\\max\\_{i\\in\\{0,1\\}}\\sum\\_{t}r\\left(\\mathbf{s}^{i}\\_{t},\\mathbf{a}^{i}\\_{t}\\right)<\\delta\\_{\\tt skip}roman\\_max start\\_POSTSUBSCRIPT italic\\_i \u2208 { 0 , 1 } end\\_POSTSUBSCRIPT \u2211 start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT italic\\_r ( bold\\_s start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT , bold\\_a start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT ) < italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_skip end\\_POSTSUBSCRIPT (Line\u00a0[4](#alg1.l4 \"4 \u2023 Algorithm 1 \u2023 3.1 Design factors \u2023 3 B-Pref: Benchmarks environments for preference-based RL \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\")).\n\n\n\n\nEqually preferable.\nIf the two segments are equally good,\ninstead of selecting one segment as preferable,\na teacher would like to mark the segments as equally preferable.\nMotivated by this,\nwe provide an uniform distribution (0.5,0.5)0.50.5(0.5,0.5)( 0.5 , 0.5 ) as a response (Line\u00a0[6](#alg1.l6 \"6 \u2023 Algorithm 1 \u2023 3.1 Design factors \u2023 3 B-Pref: Benchmarks environments for preference-based RL \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\"))\nif both segments have similar sum of rewards, i.e., |\u2211tr(\ud835\udc2ct1,\ud835\udc1at1)\u2212\u2211tr(\ud835\udc2ct0,\ud835\udc1at0)|<\u03b4\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude95subscript\ud835\udc61\ud835\udc5fsubscriptsuperscript\ud835\udc2c1\ud835\udc61subscriptsuperscript\ud835\udc1a1\ud835\udc61subscript\ud835\udc61\ud835\udc5fsubscriptsuperscript\ud835\udc2c0\ud835\udc61subscriptsuperscript\ud835\udc1a0\ud835\udc61subscript\ud835\udeff\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude95\\big{|}\\sum\\_{t}r\\left(\\mathbf{s}^{1}\\_{t},\\mathbf{a}^{1}\\_{t}\\right)-\\sum\\_{t}r\\left(\\mathbf{s}^{0}\\_{t},\\mathbf{a}^{0}\\_{t}\\right)\\big{|}<\\delta\\_{\\tt equal}| \u2211 start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT italic\\_r ( bold\\_s start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT , bold\\_a start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT ) - \u2211 start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT italic\\_r ( bold\\_s start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT , bold\\_a start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT ) | < italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_equal end\\_POSTSUBSCRIPT.\n\n\n\n\nMaking a mistake. Humans can make accidental errors when they respond. To reflect this, we flip the preference with probability of \u03f5italic-\u03f5\\epsilonitalic\\_\u03f5\n(Line\u00a0[10](#alg1.l10 \"10 \u2023 Algorithm 1 \u2023 3.1 Design factors \u2023 3 B-Pref: Benchmarks environments for preference-based RL \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\") and Line\u00a0[13](#alg1.l13 \"13 \u2023 Algorithm 1 \u2023 3.1 Design factors \u2023 3 B-Pref: Benchmarks environments for preference-based RL \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\")).\n\n\n\n\n\n### \n3.3 Evaluation metrics\n\n\n\nWe evaluate two key properties of preference-based RL: performance of the RL agent under a fixed budget of feedback and robustness to potential irrationalities.\nBecause the simulated human teacher\u2019s preferences are generated by a ground truth reward, we measure the true average return of trained agents as evaluation metric.\nTo facilitate comparison across different RL algorithms,\nwe normalize returns with respect to the baseline of RL training using the ground truth reward:\n\n\n\n\n|  |  |  |\n| --- | --- | --- |\n|  | Normalized returns=Average returns of preference-based RLAverage returns of RL with ground truth reward.Normalized returnsAverage returns of preference-based RLAverage returns of RL with ground truth reward\\displaystyle\\texttt{Normalized returns}=\\frac{\\texttt{Average returns of preference-based RL}}{\\texttt{Average returns of RL with ground truth reward}}.Normalized returns = divide start\\_ARG Average returns of preference-based RL end\\_ARG start\\_ARG Average returns of RL with ground truth reward end\\_ARG . |  |\n\n\n\n\nTo evaluate the feedback-efficiency of preference-based RL algorithms,\nwe compare normalized returns by varying the maximum budget of queries.\n\n\n\n\nTo evaluate the robustness, we evaluate against the following simulated human teachers with different properties:\n\n\n* [leftmargin=8mm]\n* \u2022\n\nOracle: SimTeacher(\u2192\u03b2\u221e,\u03b3=1,\u03f5=0,\u03b4\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99=0,\u03b4\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude95=0)formulae-sequence\n\t\u2192\u03b2\u221e\ud835\udefe1formulae-sequenceitalic-\u03f50formulae-sequencesubscript\ud835\udeff\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude990subscript\ud835\udeff\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude950\\left(\\definecolor{tcbcolframe}{rgb}{1,1,1}\\definecolor{tcbcolback}{rgb}{1,0.9,0.9}\\definecolor{tcbcol@origin}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\leavevmode\\hbox to31.21pt{\\vbox to16.09pt{\\pgfpicture\\makeatletter\\raise-5.44444pt\\hbox{\\hskip 0.0pt\\lower 0.0pt\\hbox to 0.0pt{\\pgfsys@beginscope\\pgfsys@invoke{ }\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@rgb@stroke{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@color@rgb@fill{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@setlinewidth{0.4pt}\\pgfsys@invoke{ }\\nullfont\\hbox to 0.0pt{{}{}{}{}\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,1,1}\\pgfsys@color@gray@fill{1}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.0pt}{4.5pt}\\pgfsys@lineto{0.0pt}{11.58888pt}\\pgfsys@curveto{0.0pt}{14.07419pt}{2.0147pt}{16.08888pt}{4.5pt}{16.08888pt}\\pgfsys@lineto{26.7117pt}{16.08888pt}\\pgfsys@curveto{29.197pt}{16.08888pt}{31.2117pt}{14.07419pt}{31.2117pt}{11.58888pt}\\pgfsys@lineto{31.2117pt}{4.5pt}\\pgfsys@curveto{31.2117pt}{2.0147pt}{29.197pt}{0.0pt}{26.7117pt}{0.0pt}\\pgfsys@lineto{4.5pt}{0.0pt}\\pgfsys@curveto{2.0147pt}{0.0pt}{0.0pt}{2.0147pt}{0.0pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,0.9,0.9}\\pgfsys@color@rgb@fill{1}{0.9}{0.9}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.5pt}{4.5pt}\\pgfsys@lineto{0.5pt}{11.58888pt}\\pgfsys@curveto{0.5pt}{13.79805pt}{2.29083pt}{15.58888pt}{4.5pt}{15.58888pt}\\pgfsys@lineto{26.7117pt}{15.58888pt}\\pgfsys@curveto{28.92087pt}{15.58888pt}{30.7117pt}{13.79805pt}{30.7117pt}{11.58888pt}\\pgfsys@lineto{30.7117pt}{4.5pt}\\pgfsys@curveto{30.7117pt}{2.29083pt}{28.92087pt}{0.5pt}{26.7117pt}{0.5pt}\\pgfsys@lineto{4.5pt}{0.5pt}\\pgfsys@curveto{2.29083pt}{0.5pt}{0.5pt}{2.29083pt}{0.5pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{{}}{{}}{{}}{{}}{{}}{{}}{{}}\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@transformcm{1.0}{0.0}{0.0}{1.0}{2.5pt}{5.44444pt}\\pgfsys@invoke{ }\\hbox{{\\color[rgb]{0,0,0}\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@gray@stroke{0}\\pgfsys@color@gray@fill{0}\\hbox{\\set@color{\\ignorespaces$\\beta\\rightarrow\\infty$}}}}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope{}{}{}\\hss}\\pgfsys@discardpath\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\hss}}\\lxSVG@closescope\\endpgfpicture}},\\gamma=1,\\epsilon=0,\\delta\\_{\\tt skip}=0,\\delta\\_{\\tt equal}=0\\right)( italic\\_\u03b2 \u2192 \u221e , italic\\_\u03b3 = 1 , italic\\_\u03f5 = 0 , italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_skip end\\_POSTSUBSCRIPT = 0 , italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_equal end\\_POSTSUBSCRIPT = 0 )\n* \u2022\n\nStoc: SimTeacher(=\u03b21,\u03b3=1,\u03f5=0,\u03b4\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99=0,\u03b4\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude95=0)formulae-sequence\n\t=\u03b21\ud835\udefe1formulae-sequenceitalic-\u03f50formulae-sequencesubscript\ud835\udeff\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude990subscript\ud835\udeff\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude950\\left(\\definecolor{tcbcolframe}{rgb}{1,1,1}\\definecolor{tcbcolback}{rgb}{1,0.9,0.9}\\definecolor{tcbcol@origin}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\leavevmode\\hbox to28.99pt{\\vbox to15.89pt{\\pgfpicture\\makeatletter\\raise-5.44444pt\\hbox{\\hskip 0.0pt\\lower 0.0pt\\hbox to 0.0pt{\\pgfsys@beginscope\\pgfsys@invoke{ }\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@rgb@stroke{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@color@rgb@fill{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@setlinewidth{0.4pt}\\pgfsys@invoke{ }\\nullfont\\hbox to 0.0pt{{}{}{}{}\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,1,1}\\pgfsys@color@gray@fill{1}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.0pt}{4.5pt}\\pgfsys@lineto{0.0pt}{11.38889pt}\\pgfsys@curveto{0.0pt}{13.87419pt}{2.0147pt}{15.88889pt}{4.5pt}{15.88889pt}\\pgfsys@lineto{24.48949pt}{15.88889pt}\\pgfsys@curveto{26.9748pt}{15.88889pt}{28.98949pt}{13.87419pt}{28.98949pt}{11.38889pt}\\pgfsys@lineto{28.98949pt}{4.5pt}\\pgfsys@curveto{28.98949pt}{2.0147pt}{26.9748pt}{0.0pt}{24.48949pt}{0.0pt}\\pgfsys@lineto{4.5pt}{0.0pt}\\pgfsys@curveto{2.0147pt}{0.0pt}{0.0pt}{2.0147pt}{0.0pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,0.9,0.9}\\pgfsys@color@rgb@fill{1}{0.9}{0.9}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.5pt}{4.5pt}\\pgfsys@lineto{0.5pt}{11.38889pt}\\pgfsys@curveto{0.5pt}{13.59805pt}{2.29083pt}{15.38889pt}{4.5pt}{15.38889pt}\\pgfsys@lineto{24.48949pt}{15.38889pt}\\pgfsys@curveto{26.69865pt}{15.38889pt}{28.48949pt}{13.59805pt}{28.48949pt}{11.38889pt}\\pgfsys@lineto{28.48949pt}{4.5pt}\\pgfsys@curveto{28.48949pt}{2.29083pt}{26.69865pt}{0.5pt}{24.48949pt}{0.5pt}\\pgfsys@lineto{4.5pt}{0.5pt}\\pgfsys@curveto{2.29083pt}{0.5pt}{0.5pt}{2.29083pt}{0.5pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{{}}{{}}{{}}{{}}{{}}{{}}{{}}\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@transformcm{1.0}{0.0}{0.0}{1.0}{2.5pt}{5.44444pt}\\pgfsys@invoke{ }\\hbox{{\\color[rgb]{0,0,0}\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@gray@stroke{0}\\pgfsys@color@gray@fill{0}\\hbox{\\set@color{\\ignorespaces$\\beta=1$}}}}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope{}{}{}\\hss}\\pgfsys@discardpath\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\hss}}\\lxSVG@closescope\\endpgfpicture}},\\gamma=1,\\epsilon=0,\\delta\\_{\\tt skip}=0,\\delta\\_{\\tt equal}=0\\right)( italic\\_\u03b2 = 1 , italic\\_\u03b3 = 1 , italic\\_\u03f5 = 0 , italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_skip end\\_POSTSUBSCRIPT = 0 , italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_equal end\\_POSTSUBSCRIPT = 0 )\n* \u2022\n\nMistake: SimTeacher(\u2192\u03b2\u221e,\u03b3=1,=\u03f50.1,\u03b4\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99=0,\u03b4\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude95=0)formulae-sequence\n\t\u2192\u03b2\u221e\ud835\udefe1\n\t=\u03f50.1subscript\ud835\udeff\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude990subscript\ud835\udeff\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude950\\left(\\definecolor{tcbcolframe}{rgb}{1,1,1}\\definecolor{tcbcolback}{rgb}{1,0.9,0.9}\\definecolor{tcbcol@origin}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\leavevmode\\hbox to31.21pt{\\vbox to16.09pt{\\pgfpicture\\makeatletter\\raise-5.44444pt\\hbox{\\hskip 0.0pt\\lower 0.0pt\\hbox to 0.0pt{\\pgfsys@beginscope\\pgfsys@invoke{ }\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@rgb@stroke{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@color@rgb@fill{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@setlinewidth{0.4pt}\\pgfsys@invoke{ }\\nullfont\\hbox to 0.0pt{{}{}{}{}\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,1,1}\\pgfsys@color@gray@fill{1}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.0pt}{4.5pt}\\pgfsys@lineto{0.0pt}{11.58888pt}\\pgfsys@curveto{0.0pt}{14.07419pt}{2.0147pt}{16.08888pt}{4.5pt}{16.08888pt}\\pgfsys@lineto{26.7117pt}{16.08888pt}\\pgfsys@curveto{29.197pt}{16.08888pt}{31.2117pt}{14.07419pt}{31.2117pt}{11.58888pt}\\pgfsys@lineto{31.2117pt}{4.5pt}\\pgfsys@curveto{31.2117pt}{2.0147pt}{29.197pt}{0.0pt}{26.7117pt}{0.0pt}\\pgfsys@lineto{4.5pt}{0.0pt}\\pgfsys@curveto{2.0147pt}{0.0pt}{0.0pt}{2.0147pt}{0.0pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,0.9,0.9}\\pgfsys@color@rgb@fill{1}{0.9}{0.9}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.5pt}{4.5pt}\\pgfsys@lineto{0.5pt}{11.58888pt}\\pgfsys@curveto{0.5pt}{13.79805pt}{2.29083pt}{15.58888pt}{4.5pt}{15.58888pt}\\pgfsys@lineto{26.7117pt}{15.58888pt}\\pgfsys@curveto{28.92087pt}{15.58888pt}{30.7117pt}{13.79805pt}{30.7117pt}{11.58888pt}\\pgfsys@lineto{30.7117pt}{4.5pt}\\pgfsys@curveto{30.7117pt}{2.29083pt}{28.92087pt}{0.5pt}{26.7117pt}{0.5pt}\\pgfsys@lineto{4.5pt}{0.5pt}\\pgfsys@curveto{2.29083pt}{0.5pt}{0.5pt}{2.29083pt}{0.5pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{{}}{{}}{{}}{{}}{{}}{{}}{{}}\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@transformcm{1.0}{0.0}{0.0}{1.0}{2.5pt}{5.44444pt}\\pgfsys@invoke{ }\\hbox{{\\color[rgb]{0,0,0}\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@gray@stroke{0}\\pgfsys@color@gray@fill{0}\\hbox{\\set@color{\\ignorespaces$\\beta\\rightarrow\\infty$}}}}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope{}{}{}\\hss}\\pgfsys@discardpath\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\hss}}\\lxSVG@closescope\\endpgfpicture}},\\gamma=1,\\definecolor{tcbcolframe}{rgb}{1,1,1}\\definecolor{tcbcolback}{rgb}{1,0.9,0.9}\\definecolor{tcbcol@origin}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\leavevmode\\hbox to36.84pt{\\vbox to13.44pt{\\pgfpicture\\makeatletter\\raise-3.5pt\\hbox{\\hskip 0.0pt\\lower 0.0pt\\hbox to 0.0pt{\\pgfsys@beginscope\\pgfsys@invoke{ }\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@rgb@stroke{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@color@rgb@fill{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@setlinewidth{0.4pt}\\pgfsys@invoke{ }\\nullfont\\hbox to 0.0pt{{}{}{}{}\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,1,1}\\pgfsys@color@gray@fill{1}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.0pt}{4.5pt}\\pgfsys@lineto{0.0pt}{8.94444pt}\\pgfsys@curveto{0.0pt}{11.42975pt}{2.0147pt}{13.44444pt}{4.5pt}{13.44444pt}\\pgfsys@lineto{32.3367pt}{13.44444pt}\\pgfsys@curveto{34.822pt}{13.44444pt}{36.8367pt}{11.42975pt}{36.8367pt}{8.94444pt}\\pgfsys@lineto{36.8367pt}{4.5pt}\\pgfsys@curveto{36.8367pt}{2.0147pt}{34.822pt}{0.0pt}{32.3367pt}{0.0pt}\\pgfsys@lineto{4.5pt}{0.0pt}\\pgfsys@curveto{2.0147pt}{0.0pt}{0.0pt}{2.0147pt}{0.0pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,0.9,0.9}\\pgfsys@color@rgb@fill{1}{0.9}{0.9}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.5pt}{4.5pt}\\pgfsys@lineto{0.5pt}{8.94444pt}\\pgfsys@curveto{0.5pt}{11.15361pt}{2.29083pt}{12.94444pt}{4.5pt}{12.94444pt}\\pgfsys@lineto{32.3367pt}{12.94444pt}\\pgfsys@curveto{34.54587pt}{12.94444pt}{36.3367pt}{11.15361pt}{36.3367pt}{8.94444pt}\\pgfsys@lineto{36.3367pt}{4.5pt}\\pgfsys@curveto{36.3367pt}{2.29083pt}{34.54587pt}{0.5pt}{32.3367pt}{0.5pt}\\pgfsys@lineto{4.5pt}{0.5pt}\\pgfsys@curveto{2.29083pt}{0.5pt}{0.5pt}{2.29083pt}{0.5pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{{}}{{}}{{}}{{}}{{}}{{}}{{}}\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@transformcm{1.0}{0.0}{0.0}{1.0}{2.5pt}{3.5pt}\\pgfsys@invoke{ }\\hbox{{\\color[rgb]{0,0,0}\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@gray@stroke{0}\\pgfsys@color@gray@fill{0}\\hbox{\\set@color{\\ignorespaces$\\epsilon=0.1$}}}}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope{}{}{}\\hss}\\pgfsys@discardpath\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\hss}}\\lxSVG@closescope\\endpgfpicture}},\\delta\\_{\\tt skip}=0,\\delta\\_{\\tt equal}=0\\right)( italic\\_\u03b2 \u2192 \u221e , italic\\_\u03b3 = 1 , italic\\_\u03f5 = 0.1 , italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_skip end\\_POSTSUBSCRIPT = 0 , italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_equal end\\_POSTSUBSCRIPT = 0 )\n* \u2022\n\nSkip: SimTeacher(\u2192\u03b2\u221e,\u03b3=1,\u03f5=0,>\u03b4skip0,\u03b4\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude95=0)formulae-sequence\n\t\u2192\u03b2\u221e\ud835\udefe1formulae-sequenceitalic-\u03f5\n\t0>\u03b4skip0subscript\ud835\udeff\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude950\\left(\\definecolor{tcbcolframe}{rgb}{1,1,1}\\definecolor{tcbcolback}{rgb}{1,0.9,0.9}\\definecolor{tcbcol@origin}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\leavevmode\\hbox to31.21pt{\\vbox to16.09pt{\\pgfpicture\\makeatletter\\raise-5.44444pt\\hbox{\\hskip 0.0pt\\lower 0.0pt\\hbox to 0.0pt{\\pgfsys@beginscope\\pgfsys@invoke{ }\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@rgb@stroke{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@color@rgb@fill{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@setlinewidth{0.4pt}\\pgfsys@invoke{ }\\nullfont\\hbox to 0.0pt{{}{}{}{}\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,1,1}\\pgfsys@color@gray@fill{1}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.0pt}{4.5pt}\\pgfsys@lineto{0.0pt}{11.58888pt}\\pgfsys@curveto{0.0pt}{14.07419pt}{2.0147pt}{16.08888pt}{4.5pt}{16.08888pt}\\pgfsys@lineto{26.7117pt}{16.08888pt}\\pgfsys@curveto{29.197pt}{16.08888pt}{31.2117pt}{14.07419pt}{31.2117pt}{11.58888pt}\\pgfsys@lineto{31.2117pt}{4.5pt}\\pgfsys@curveto{31.2117pt}{2.0147pt}{29.197pt}{0.0pt}{26.7117pt}{0.0pt}\\pgfsys@lineto{4.5pt}{0.0pt}\\pgfsys@curveto{2.0147pt}{0.0pt}{0.0pt}{2.0147pt}{0.0pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,0.9,0.9}\\pgfsys@color@rgb@fill{1}{0.9}{0.9}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.5pt}{4.5pt}\\pgfsys@lineto{0.5pt}{11.58888pt}\\pgfsys@curveto{0.5pt}{13.79805pt}{2.29083pt}{15.58888pt}{4.5pt}{15.58888pt}\\pgfsys@lineto{26.7117pt}{15.58888pt}\\pgfsys@curveto{28.92087pt}{15.58888pt}{30.7117pt}{13.79805pt}{30.7117pt}{11.58888pt}\\pgfsys@lineto{30.7117pt}{4.5pt}\\pgfsys@curveto{30.7117pt}{2.29083pt}{28.92087pt}{0.5pt}{26.7117pt}{0.5pt}\\pgfsys@lineto{4.5pt}{0.5pt}\\pgfsys@curveto{2.29083pt}{0.5pt}{0.5pt}{2.29083pt}{0.5pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{{}}{{}}{{}}{{}}{{}}{{}}{{}}\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@transformcm{1.0}{0.0}{0.0}{1.0}{2.5pt}{5.44444pt}\\pgfsys@invoke{ }\\hbox{{\\color[rgb]{0,0,0}\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@gray@stroke{0}\\pgfsys@color@gray@fill{0}\\hbox{\\set@color{\\ignorespaces$\\beta\\rightarrow\\infty$}}}}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope{}{}{}\\hss}\\pgfsys@discardpath\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\hss}}\\lxSVG@closescope\\endpgfpicture}},\\gamma=1,\\epsilon=0,\\definecolor{tcbcolframe}{rgb}{1,1,1}\\definecolor{tcbcolback}{rgb}{1,0.9,0.9}\\definecolor{tcbcol@origin}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\leavevmode\\hbox to34.83pt{\\vbox to16.98pt{\\pgfpicture\\makeatletter\\raise-6.53333pt\\hbox{\\hskip 0.0pt\\lower 0.0pt\\hbox to 0.0pt{\\pgfsys@beginscope\\pgfsys@invoke{ }\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@rgb@stroke{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@color@rgb@fill{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@setlinewidth{0.4pt}\\pgfsys@invoke{ }\\nullfont\\hbox to 0.0pt{{}{}{}{}\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,1,1}\\pgfsys@color@gray@fill{1}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.0pt}{4.5pt}\\pgfsys@lineto{0.0pt}{12.47777pt}\\pgfsys@curveto{0.0pt}{14.96307pt}{2.0147pt}{16.97777pt}{4.5pt}{16.97777pt}\\pgfsys@lineto{30.3311pt}{16.97777pt}\\pgfsys@curveto{32.8164pt}{16.97777pt}{34.8311pt}{14.96307pt}{34.8311pt}{12.47777pt}\\pgfsys@lineto{34.8311pt}{4.5pt}\\pgfsys@curveto{34.8311pt}{2.0147pt}{32.8164pt}{0.0pt}{30.3311pt}{0.0pt}\\pgfsys@lineto{4.5pt}{0.0pt}\\pgfsys@curveto{2.0147pt}{0.0pt}{0.0pt}{2.0147pt}{0.0pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,0.9,0.9}\\pgfsys@color@rgb@fill{1}{0.9}{0.9}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.5pt}{4.5pt}\\pgfsys@lineto{0.5pt}{12.47777pt}\\pgfsys@curveto{0.5pt}{14.68694pt}{2.29083pt}{16.47777pt}{4.5pt}{16.47777pt}\\pgfsys@lineto{30.3311pt}{16.47777pt}\\pgfsys@curveto{32.54027pt}{16.47777pt}{34.3311pt}{14.68694pt}{34.3311pt}{12.47777pt}\\pgfsys@lineto{34.3311pt}{4.5pt}\\pgfsys@curveto{34.3311pt}{2.29083pt}{32.54027pt}{0.5pt}{30.3311pt}{0.5pt}\\pgfsys@lineto{4.5pt}{0.5pt}\\pgfsys@curveto{2.29083pt}{0.5pt}{0.5pt}{2.29083pt}{0.5pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{{}}{{}}{{}}{{}}{{}}{{}}{{}}\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@transformcm{1.0}{0.0}{0.0}{1.0}{2.5pt}{6.53333pt}\\pgfsys@invoke{ }\\hbox{{\\color[rgb]{0,0,0}\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@gray@stroke{0}\\pgfsys@color@gray@fill{0}\\hbox{\\set@color{\\ignorespaces$\\delta\\_{\\tt skip}>0$}}}}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope{}{}{}\\hss}\\pgfsys@discardpath\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\hss}}\\lxSVG@closescope\\endpgfpicture}},\\delta\\_{\\tt equal}=0\\right)( italic\\_\u03b2 \u2192 \u221e , italic\\_\u03b3 = 1 , italic\\_\u03f5 = 0 , italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_skip end\\_POSTSUBSCRIPT > 0 , italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_equal end\\_POSTSUBSCRIPT = 0 )\n* \u2022\n\nEqual: SimTeacher(\u2192\u03b2\u221e,\u03b3=1,\u03f5=0,\u03b4\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99=0,>\u03b4equal0)formulae-sequence\n\t\u2192\u03b2\u221e\ud835\udefe1formulae-sequenceitalic-\u03f50subscript\ud835\udeff\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99\n\t0>\u03b4equal0\\left(\\definecolor{tcbcolframe}{rgb}{1,1,1}\\definecolor{tcbcolback}{rgb}{1,0.9,0.9}\\definecolor{tcbcol@origin}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\leavevmode\\hbox to31.21pt{\\vbox to16.09pt{\\pgfpicture\\makeatletter\\raise-5.44444pt\\hbox{\\hskip 0.0pt\\lower 0.0pt\\hbox to 0.0pt{\\pgfsys@beginscope\\pgfsys@invoke{ }\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@rgb@stroke{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@color@rgb@fill{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@setlinewidth{0.4pt}\\pgfsys@invoke{ }\\nullfont\\hbox to 0.0pt{{}{}{}{}\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,1,1}\\pgfsys@color@gray@fill{1}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.0pt}{4.5pt}\\pgfsys@lineto{0.0pt}{11.58888pt}\\pgfsys@curveto{0.0pt}{14.07419pt}{2.0147pt}{16.08888pt}{4.5pt}{16.08888pt}\\pgfsys@lineto{26.7117pt}{16.08888pt}\\pgfsys@curveto{29.197pt}{16.08888pt}{31.2117pt}{14.07419pt}{31.2117pt}{11.58888pt}\\pgfsys@lineto{31.2117pt}{4.5pt}\\pgfsys@curveto{31.2117pt}{2.0147pt}{29.197pt}{0.0pt}{26.7117pt}{0.0pt}\\pgfsys@lineto{4.5pt}{0.0pt}\\pgfsys@curveto{2.0147pt}{0.0pt}{0.0pt}{2.0147pt}{0.0pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,0.9,0.9}\\pgfsys@color@rgb@fill{1}{0.9}{0.9}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.5pt}{4.5pt}\\pgfsys@lineto{0.5pt}{11.58888pt}\\pgfsys@curveto{0.5pt}{13.79805pt}{2.29083pt}{15.58888pt}{4.5pt}{15.58888pt}\\pgfsys@lineto{26.7117pt}{15.58888pt}\\pgfsys@curveto{28.92087pt}{15.58888pt}{30.7117pt}{13.79805pt}{30.7117pt}{11.58888pt}\\pgfsys@lineto{30.7117pt}{4.5pt}\\pgfsys@curveto{30.7117pt}{2.29083pt}{28.92087pt}{0.5pt}{26.7117pt}{0.5pt}\\pgfsys@lineto{4.5pt}{0.5pt}\\pgfsys@curveto{2.29083pt}{0.5pt}{0.5pt}{2.29083pt}{0.5pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{{}}{{}}{{}}{{}}{{}}{{}}{{}}\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@transformcm{1.0}{0.0}{0.0}{1.0}{2.5pt}{5.44444pt}\\pgfsys@invoke{ }\\hbox{{\\color[rgb]{0,0,0}\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@gray@stroke{0}\\pgfsys@color@gray@fill{0}\\hbox{\\set@color{\\ignorespaces$\\beta\\rightarrow\\infty$}}}}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope{}{}{}\\hss}\\pgfsys@discardpath\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\hss}}\\lxSVG@closescope\\endpgfpicture}},\\gamma=1,\\epsilon=0,\\delta\\_{\\tt skip}=0,\\definecolor{tcbcolframe}{rgb}{1,1,1}\\definecolor{tcbcolback}{rgb}{1,0.9,0.9}\\definecolor{tcbcol@origin}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\leavevmode\\hbox to37.91pt{\\vbox to16.98pt{\\pgfpicture\\makeatletter\\raise-6.53333pt\\hbox{\\hskip 0.0pt\\lower 0.0pt\\hbox to 0.0pt{\\pgfsys@beginscope\\pgfsys@invoke{ }\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@rgb@stroke{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@color@rgb@fill{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@setlinewidth{0.4pt}\\pgfsys@invoke{ }\\nullfont\\hbox to 0.0pt{{}{}{}{}\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,1,1}\\pgfsys@color@gray@fill{1}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.0pt}{4.5pt}\\pgfsys@lineto{0.0pt}{12.47777pt}\\pgfsys@curveto{0.0pt}{14.96307pt}{2.0147pt}{16.97777pt}{4.5pt}{16.97777pt}\\pgfsys@lineto{33.41109pt}{16.97777pt}\\pgfsys@curveto{35.8964pt}{16.97777pt}{37.91109pt}{14.96307pt}{37.91109pt}{12.47777pt}\\pgfsys@lineto{37.91109pt}{4.5pt}\\pgfsys@curveto{37.91109pt}{2.0147pt}{35.8964pt}{0.0pt}{33.41109pt}{0.0pt}\\pgfsys@lineto{4.5pt}{0.0pt}\\pgfsys@curveto{2.0147pt}{0.0pt}{0.0pt}{2.0147pt}{0.0pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,0.9,0.9}\\pgfsys@color@rgb@fill{1}{0.9}{0.9}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.5pt}{4.5pt}\\pgfsys@lineto{0.5pt}{12.47777pt}\\pgfsys@curveto{0.5pt}{14.68694pt}{2.29083pt}{16.47777pt}{4.5pt}{16.47777pt}\\pgfsys@lineto{33.41109pt}{16.47777pt}\\pgfsys@curveto{35.62025pt}{16.47777pt}{37.41109pt}{14.68694pt}{37.41109pt}{12.47777pt}\\pgfsys@lineto{37.41109pt}{4.5pt}\\pgfsys@curveto{37.41109pt}{2.29083pt}{35.62025pt}{0.5pt}{33.41109pt}{0.5pt}\\pgfsys@lineto{4.5pt}{0.5pt}\\pgfsys@curveto{2.29083pt}{0.5pt}{0.5pt}{2.29083pt}{0.5pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{{}}{{}}{{}}{{}}{{}}{{}}{{}}\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@transformcm{1.0}{0.0}{0.0}{1.0}{2.5pt}{6.53333pt}\\pgfsys@invoke{ }\\hbox{{\\color[rgb]{0,0,0}\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@gray@stroke{0}\\pgfsys@color@gray@fill{0}\\hbox{\\set@color{\\ignorespaces$\\delta\\_{\\tt equal}>0$}}}}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope{}{}{}\\hss}\\pgfsys@discardpath\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\hss}}\\lxSVG@closescope\\endpgfpicture}}\\right)( italic\\_\u03b2 \u2192 \u221e , italic\\_\u03b3 = 1 , italic\\_\u03f5 = 0 , italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_skip end\\_POSTSUBSCRIPT = 0 , italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_equal end\\_POSTSUBSCRIPT > 0 )\n* \u2022\n\nMyopic: SimTeacher(\u2192\u03b2\u221e,=\u03b30.9,\u03f5=0,\u03b4\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude99=0,\u03b4\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude95=0)formulae-sequence\n\t\u2192\u03b2\u221e=\u03b30.9italic-\u03f50formulae-sequencesubscript\ud835\udeff\ud835\ude9c\ud835\ude94\ud835\ude92\ud835\ude990subscript\ud835\udeff\ud835\ude8e\ud835\ude9a\ud835\ude9e\ud835\ude8a\ud835\ude950\\left(\\definecolor{tcbcolframe}{rgb}{1,1,1}\\definecolor{tcbcolback}{rgb}{1,0.9,0.9}\\definecolor{tcbcol@origin}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\leavevmode\\hbox to31.21pt{\\vbox to16.09pt{\\pgfpicture\\makeatletter\\raise-5.44444pt\\hbox{\\hskip 0.0pt\\lower 0.0pt\\hbox to 0.0pt{\\pgfsys@beginscope\\pgfsys@invoke{ }\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@rgb@stroke{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@color@rgb@fill{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@setlinewidth{0.4pt}\\pgfsys@invoke{ }\\nullfont\\hbox to 0.0pt{{}{}{}{}\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,1,1}\\pgfsys@color@gray@fill{1}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.0pt}{4.5pt}\\pgfsys@lineto{0.0pt}{11.58888pt}\\pgfsys@curveto{0.0pt}{14.07419pt}{2.0147pt}{16.08888pt}{4.5pt}{16.08888pt}\\pgfsys@lineto{26.7117pt}{16.08888pt}\\pgfsys@curveto{29.197pt}{16.08888pt}{31.2117pt}{14.07419pt}{31.2117pt}{11.58888pt}\\pgfsys@lineto{31.2117pt}{4.5pt}\\pgfsys@curveto{31.2117pt}{2.0147pt}{29.197pt}{0.0pt}{26.7117pt}{0.0pt}\\pgfsys@lineto{4.5pt}{0.0pt}\\pgfsys@curveto{2.0147pt}{0.0pt}{0.0pt}{2.0147pt}{0.0pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,0.9,0.9}\\pgfsys@color@rgb@fill{1}{0.9}{0.9}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.5pt}{4.5pt}\\pgfsys@lineto{0.5pt}{11.58888pt}\\pgfsys@curveto{0.5pt}{13.79805pt}{2.29083pt}{15.58888pt}{4.5pt}{15.58888pt}\\pgfsys@lineto{26.7117pt}{15.58888pt}\\pgfsys@curveto{28.92087pt}{15.58888pt}{30.7117pt}{13.79805pt}{30.7117pt}{11.58888pt}\\pgfsys@lineto{30.7117pt}{4.5pt}\\pgfsys@curveto{30.7117pt}{2.29083pt}{28.92087pt}{0.5pt}{26.7117pt}{0.5pt}\\pgfsys@lineto{4.5pt}{0.5pt}\\pgfsys@curveto{2.29083pt}{0.5pt}{0.5pt}{2.29083pt}{0.5pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{{}}{{}}{{}}{{}}{{}}{{}}{{}}\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@transformcm{1.0}{0.0}{0.0}{1.0}{2.5pt}{5.44444pt}\\pgfsys@invoke{ }\\hbox{{\\color[rgb]{0,0,0}\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@gray@stroke{0}\\pgfsys@color@gray@fill{0}\\hbox{\\set@color{\\ignorespaces$\\beta\\rightarrow\\infty$}}}}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope{}{}{}\\hss}\\pgfsys@discardpath\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\hss}}\\lxSVG@closescope\\endpgfpicture}},\\definecolor{tcbcolframe}{rgb}{1,1,1}\\definecolor{tcbcolback}{rgb}{1,0.9,0.9}\\definecolor{tcbcol@origin}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\definecolor{.}{rgb}{0,0,0}\\leavevmode\\hbox to37.95pt{\\vbox to15.39pt{\\pgfpicture\\makeatletter\\raise-5.44444pt\\hbox{\\hskip 0.0pt\\lower 0.0pt\\hbox to 0.0pt{\\pgfsys@beginscope\\pgfsys@invoke{ }\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@rgb@stroke{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@color@rgb@fill{0}{0}{0}\\pgfsys@invoke{ }\\pgfsys@setlinewidth{0.4pt}\\pgfsys@invoke{ }\\nullfont\\hbox to 0.0pt{{}{}{}{}\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,1,1}\\pgfsys@color@gray@fill{1}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.0pt}{4.5pt}\\pgfsys@lineto{0.0pt}{10.88889pt}\\pgfsys@curveto{0.0pt}{13.37419pt}{2.0147pt}{15.38889pt}{4.5pt}{15.38889pt}\\pgfsys@lineto{33.45497pt}{15.38889pt}\\pgfsys@curveto{35.94028pt}{15.38889pt}{37.95497pt}{13.37419pt}{37.95497pt}{10.88889pt}\\pgfsys@lineto{37.95497pt}{4.5pt}\\pgfsys@curveto{37.95497pt}{2.0147pt}{35.94028pt}{0.0pt}{33.45497pt}{0.0pt}\\pgfsys@lineto{4.5pt}{0.0pt}\\pgfsys@curveto{2.0147pt}{0.0pt}{0.0pt}{2.0147pt}{0.0pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }{}{}{}{}{}{}{}{}\\definecolor[named]{pgffillcolor}{rgb}{1,0.9,0.9}\\pgfsys@color@rgb@fill{1}{0.9}{0.9}\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}{{}{}{{}}}{{}{}{{}}}{}{}\\pgfsys@moveto{0.5pt}{4.5pt}\\pgfsys@lineto{0.5pt}{10.88889pt}\\pgfsys@curveto{0.5pt}{13.09805pt}{2.29083pt}{14.88889pt}{4.5pt}{14.88889pt}\\pgfsys@lineto{33.45497pt}{14.88889pt}\\pgfsys@curveto{35.66414pt}{14.88889pt}{37.45497pt}{13.09805pt}{37.45497pt}{10.88889pt}\\pgfsys@lineto{37.45497pt}{4.5pt}\\pgfsys@curveto{37.45497pt}{2.29083pt}{35.66414pt}{0.5pt}{33.45497pt}{0.5pt}\\pgfsys@lineto{4.5pt}{0.5pt}\\pgfsys@curveto{2.29083pt}{0.5pt}{0.5pt}{2.29083pt}{0.5pt}{4.5pt}\\pgfsys@closepath\\pgfsys@fill\\pgfsys@invoke{ }\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@fill@opacity{1.000000}\\pgfsys@invoke{ }{{{}}{{}}{{}}{{}}{{}}{{}}{{}}\\pgfsys@beginscope\\pgfsys@invoke{ }\\pgfsys@transformcm{1.0}{0.0}{0.0}{1.0}{2.5pt}{5.44444pt}\\pgfsys@invoke{ }\\hbox{{\\color[rgb]{0,0,0}\\definecolor[named]{pgfstrokecolor}{rgb}{0,0,0}\\pgfsys@color@gray@stroke{0}\\pgfsys@color@gray@fill{0}\\hbox{\\set@color{\\ignorespaces$\\gamma=0.9$}}}}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope}\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope{}{}{}\\hss}\\pgfsys@discardpath\\pgfsys@invoke{\\lxSVG@closescope }\\pgfsys@endscope\\hss}}\\lxSVG@closescope\\endpgfpicture}},\\epsilon=0,\\delta\\_{\\tt skip}=0,\\delta\\_{\\tt equal}=0\\right)( italic\\_\u03b2 \u2192 \u221e , italic\\_\u03b3 = 0.9 , italic\\_\u03f5 = 0 , italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_skip end\\_POSTSUBSCRIPT = 0 , italic\\_\u03b4 start\\_POSTSUBSCRIPT typewriter\\_equal end\\_POSTSUBSCRIPT = 0 )\n\n\n\n\nIn our evaluations, we consider one modification (i.e., irrationality) to the oracle teacher at a time, which allows us to isolate the individual effects. While each individually may not exactly model real human behavior, it would be straightforward to use our benchmark to create more complex teachers that combine multiple irrationalities.\n\n\n\n\n\n### \n3.4 Tasks\n\n\n\nWe consider two locomotion tasks (Walker-walk and Quadruped-walk) from DeepMind Control Suite (DMControl)\u00a0(Tassa et\u00a0al., [2018](#bib.bib65), [2020](#bib.bib66))\nand two robotic manipulation tasks (Button Press and Sweep Into) from Meta-world\u00a0(Yu et\u00a0al., [2020](#bib.bib76)).\nWe focus on learning from the proprioceptive inputs and dense rewards\nbecause learning from visual observations and sparse rewards can cause additional issues, such as representation learning\u00a0(Laskin et\u00a0al., [2020](#bib.bib37); Schwarzer et\u00a0al., [2021](#bib.bib55); Srinivas et\u00a0al., [2020](#bib.bib60); Stooke et\u00a0al., [2021](#bib.bib62); Yarats et\u00a0al., [2021](#bib.bib74)) and exploration\u00a0(Seo et\u00a0al., [2021](#bib.bib56)).\nHowever, we think it is an interesting and important direction for future work to consider visual observations and sparse rewards.\n\n4 B-Pref: Algorithmic baselines for preference-based RL\n--------------------------------------------------------\n\n\n\nThroughout this paper,\nwe mainly focus on two of the most prominent preference-based RL algorithms\u00a0(Christiano et\u00a0al., [2017](#bib.bib19); Lee et\u00a0al., [2021](#bib.bib39)), which involve reward learning from preferences.\nFormally, a policy \u03c0\u03d5subscript\ud835\udf0bitalic-\u03d5\\pi\\_{\\phi}italic\\_\u03c0 start\\_POSTSUBSCRIPT italic\\_\u03d5 end\\_POSTSUBSCRIPT and reward function r^\u03c8subscript^\ud835\udc5f\ud835\udf13\\widehat{r}\\_{\\psi}over^ start\\_ARG italic\\_r end\\_ARG start\\_POSTSUBSCRIPT italic\\_\u03c8 end\\_POSTSUBSCRIPT are updated as follows (see Algorithm\u00a0[3](#alg3 \"Algorithm 3 \u2023 Appendix B Preference-based reinforcement learning \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\") in the supplementary material):\n\n\n* [leftmargin=8mm]\n* \u2022\n\nStep 1 (agent learning):\nThe policy \u03c0\u03d5subscript\ud835\udf0bitalic-\u03d5\\pi\\_{\\phi}italic\\_\u03c0 start\\_POSTSUBSCRIPT italic\\_\u03d5 end\\_POSTSUBSCRIPT interacts with environment to collect experiences and we update it\nusing existing RL algorithms to maximize the sum of the learned rewards r^\u03c8subscript^\ud835\udc5f\ud835\udf13\\widehat{r}\\_{\\psi}over^ start\\_ARG italic\\_r end\\_ARG start\\_POSTSUBSCRIPT italic\\_\u03c8 end\\_POSTSUBSCRIPT.\n* \u2022\n\nStep 2 (reward learning):\nWe optimize the reward function r^\u03c8subscript^\ud835\udc5f\ud835\udf13\\widehat{r}\\_{\\psi}over^ start\\_ARG italic\\_r end\\_ARG start\\_POSTSUBSCRIPT italic\\_\u03c8 end\\_POSTSUBSCRIPT via supervised learning based on the feedback received from a teacher.\n* \u2022\n\nRepeat Step 1 and Step 2.\n\n\n\n\n### \n4.1 Deep reinforcement learning from human preferences\n\n\n\nIn order to incorporate human preferences into deep RL,\nChristiano et\u00a0al. ([2017](#bib.bib19)) proposed a framework that learns a reward function r^\u03c8subscript^\ud835\udc5f\ud835\udf13\\widehat{r}\\_{\\psi}over^ start\\_ARG italic\\_r end\\_ARG start\\_POSTSUBSCRIPT italic\\_\u03c8 end\\_POSTSUBSCRIPT from preferences\u00a0Sadigh et\u00a0al. ([2017](#bib.bib50)); Wilson et\u00a0al. ([2012](#bib.bib70)).\nSpecifically,\nwe first model a preference predictor using the reward function r^\u03c8subscript^\ud835\udc5f\ud835\udf13\\widehat{r}\\_{\\psi}over^ start\\_ARG italic\\_r end\\_ARG start\\_POSTSUBSCRIPT italic\\_\u03c8 end\\_POSTSUBSCRIPT as follows:\n\n\n\n\n|  |  |  |  |\n| --- | --- | --- | --- |\n|  | P\u03c8[\u03c31\u227b\u03c30]=exp\u2211tr^\u03c8(\ud835\udc2ct1,\ud835\udc1at1)\u2211i\u2208{0,1}exp\u2211tr^\u03c8(\ud835\udc2cti,\ud835\udc1ati),subscript\ud835\udc43\ud835\udf13delimited-[]succeedssuperscript\ud835\udf0e1superscript\ud835\udf0e0subscript\ud835\udc61subscript^\ud835\udc5f\ud835\udf13superscriptsubscript\ud835\udc2c\ud835\udc611superscriptsubscript\ud835\udc1a\ud835\udc611subscript\ud835\udc5601subscript\ud835\udc61subscript^\ud835\udc5f\ud835\udf13superscriptsubscript\ud835\udc2c\ud835\udc61\ud835\udc56superscriptsubscript\ud835\udc1a\ud835\udc61\ud835\udc56\\displaystyle P\\_{\\psi}[\\sigma^{1}\\succ\\sigma^{0}]=\\frac{\\exp\\sum\\_{t}\\widehat{r}\\_{\\psi}(\\mathbf{s}\\_{t}^{1},\\mathbf{a}\\_{t}^{1})}{\\sum\\_{i\\in\\{0,1\\}}\\exp\\sum\\_{t}\\widehat{r}\\_{\\psi}(\\mathbf{s}\\_{t}^{i},\\mathbf{a}\\_{t}^{i})},italic\\_P start\\_POSTSUBSCRIPT italic\\_\u03c8 end\\_POSTSUBSCRIPT [ italic\\_\u03c3 start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT \u227b italic\\_\u03c3 start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT ] = divide start\\_ARG roman\\_exp \u2211 start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT over^ start\\_ARG italic\\_r end\\_ARG start\\_POSTSUBSCRIPT italic\\_\u03c8 end\\_POSTSUBSCRIPT ( bold\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT , bold\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT ) end\\_ARG start\\_ARG \u2211 start\\_POSTSUBSCRIPT italic\\_i \u2208 { 0 , 1 } end\\_POSTSUBSCRIPT roman\\_exp \u2211 start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT over^ start\\_ARG italic\\_r end\\_ARG start\\_POSTSUBSCRIPT italic\\_\u03c8 end\\_POSTSUBSCRIPT ( bold\\_s start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT , bold\\_a start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT ) end\\_ARG , |  | (2) |\n\n\nwhere \u03c3i\u227b\u03c3jsucceedssuperscript\ud835\udf0e\ud835\udc56superscript\ud835\udf0e\ud835\udc57\\sigma^{i}\\succ\\sigma^{j}italic\\_\u03c3 start\\_POSTSUPERSCRIPT italic\\_i end\\_POSTSUPERSCRIPT \u227b italic\\_\u03c3 start\\_POSTSUPERSCRIPT italic\\_j end\\_POSTSUPERSCRIPT denotes the event that segment i\ud835\udc56iitalic\\_i is preferable to segment j\ud835\udc57jitalic\\_j.\nWe remark that this corresponds to assume a stochastic teacher following the Bradley-Terry model\u00a0(Bradley & Terry, [1952](#bib.bib13)) but we do not assume that the type and degree of irrationality or systematic bias is available in our experiments. Because this could lead to a poor preference inference\u00a0(Chan et\u00a0al., [2021](#bib.bib17)),\nfuture work may be able to further improve the efficiency of learning by approximating the teacher\u2019s irrationality.\n\n\n\n\nTo align our preference predictor with the teacher\u2019s preferences,\nwe consider a binary classification problem using the cross-entropy loss.\nSpecifically, given a dataset of preferences \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic\\_D,\nthe reward function, modeled as a neural network with parameters \u03c8\ud835\udf13\\psiitalic\\_\u03c8, is updated by minimizing the following loss:\n\n\n\n\n|  |  |  |  |  |\n| --- | --- | --- | --- | --- |\n|  | \u2112\ud835\ude81\ud835\ude8e\ud835\udea0\ud835\ude8a\ud835\ude9b\ud835\ude8d=\u2212\ud835\udd3c(\u03c30,\u03c31,y)\u223c\ud835\udc9f[\\displaystyle\\mathcal{L}^{\\tt Reward}=-\\operatorname\\*{\\mathbb{E}}\\_{(\\sigma^{0},\\sigma^{1},y)\\sim\\mathcal{D}}\\Big{[}caligraphic\\_L start\\_POSTSUPERSCRIPT typewriter\\_Reward end\\_POSTSUPERSCRIPT = - blackboard\\_E start\\_POSTSUBSCRIPT ( italic\\_\u03c3 start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT , italic\\_\u03c3 start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT , italic\\_y ) \u223c caligraphic\\_D end\\_POSTSUBSCRIPT [ | y(0)logP\u03c8[\u03c30\u227b\u03c31]+y(1)logP\u03c8[\u03c31\u227b\u03c30]].\\displaystyle y(0)\\log P\\_{\\psi}[\\sigma^{0}\\succ\\sigma^{1}]+y(1)\\log P\\_{\\psi}[\\sigma^{1}\\succ\\sigma^{0}]\\Big{]}.italic\\_y ( 0 ) roman\\_log italic\\_P start\\_POSTSUBSCRIPT italic\\_\u03c8 end\\_POSTSUBSCRIPT [ italic\\_\u03c3 start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT \u227b italic\\_\u03c3 start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT ] + italic\\_y ( 1 ) roman\\_log italic\\_P start\\_POSTSUBSCRIPT italic\\_\u03c8 end\\_POSTSUBSCRIPT [ italic\\_\u03c3 start\\_POSTSUPERSCRIPT 1 end\\_POSTSUPERSCRIPT \u227b italic\\_\u03c3 start\\_POSTSUPERSCRIPT 0 end\\_POSTSUPERSCRIPT ] ] . |  | (3) |\n\n\n\n\nOnce we learn a reward function r^\u03c8subscript^\ud835\udc5f\ud835\udf13{\\widehat{r}}\\_{\\psi}over^ start\\_ARG italic\\_r end\\_ARG start\\_POSTSUBSCRIPT italic\\_\u03c8 end\\_POSTSUBSCRIPT,\nwe can update the policy \u03c0\u03d5subscript\ud835\udf0bitalic-\u03d5\\pi\\_{\\phi}italic\\_\u03c0 start\\_POSTSUBSCRIPT italic\\_\u03d5 end\\_POSTSUBSCRIPT using any RL algorithm.\nA caveat is that the reward function may be non-stationary because we update it during training.\nTo mitigate the effects of a non-stationary reward function,\nChristiano et\u00a0al. ([2017](#bib.bib19)) used on-policy RL algorithms, such as TRPO\u00a0(Schulman et\u00a0al., [2015](#bib.bib52)) and A2C\u00a0(Mnih et\u00a0al., [2016](#bib.bib45)).\nWe re-implemented this method using the state-of-the-art on-policy RL algorithm: PPO\u00a0Schulman et\u00a0al. ([2017](#bib.bib54)). We refer to this baseline as PrefPPO.\n\n\n\n\n\n### \n4.2 PEBBLE\n\n\n\nPEBBLE\u00a0(Lee et\u00a0al., [2021](#bib.bib39)) is a state-of-the-art preference-based RL algorithm that improved the framework of Christiano et\u00a0al. ([2017](#bib.bib19)) using the following ideas:\n\n\n\n\nUnsupervised pre-training. In the beginning of training,\na naive agent executing a random policy does not provide good state coverage nor coherent behaviors.\nTherefore, the agent\u2019s queries are not diverse and a teacher can not convey much meaningful information.\nAs a result, it requires many samples (and thus queries) for these methods to show initial progress.\nIbarz et\u00a0al. ([2018](#bib.bib31)) has addressed this issue\nby assuming that demonstrations are available at the beginning of the experiment.\nHowever, this is not ideal since suitable demonstrations are often prohibitively expensive to obtain in practice.\nInstead,\nPEBBLE pre-trains the policy only using intrinsic motivation\u00a0(Oudeyer et\u00a0al., [2007](#bib.bib46); Schmidhuber, [2010](#bib.bib51))\nto learn how to generate diverse behaviors.\nSpecifically,\nby updating the agent to maximize the state entropy \u210b(\ud835\udc2c)=\u2212\ud835\udd3c\ud835\udc2c\u223cp(\ud835\udc2c)[log\u2061p(\ud835\udc2c)]\u210b\ud835\udc2csubscript\ud835\udd3csimilar-to\ud835\udc2c\ud835\udc5d\ud835\udc2cdelimited-[]\ud835\udc5d\ud835\udc2c\\mathcal{H}(\\mathbf{s})=-\\mathbb{E}\\_{\\mathbf{s}\\sim p(\\mathbf{s})}\\left[\\log p(\\mathbf{s})\\right]caligraphic\\_H ( bold\\_s ) = - blackboard\\_E start\\_POSTSUBSCRIPT bold\\_s \u223c italic\\_p ( bold\\_s ) end\\_POSTSUBSCRIPT [ roman\\_log italic\\_p ( bold\\_s ) ],\nit encourages the agent to efficiently explore an environment and collect diverse experiences (see the supplementary material for more details).\n\n\n\n\nOff-policy RL with relabeling.\nTo overcome the poor sample-efficiency of on-policy RL algorithms,\nPEBBLE used the state-of-the-art off-policy RL algorithm: SAC\u00a0(Haarnoja et\u00a0al., [2018](#bib.bib27)).\nHowever, the learning process can be unstable because previous experiences in the replay buffer are labeled with previous learned rewards.\nPEBBLE stabilizes the learning process by relabeling all of the agent\u2019s past experience every time it updates the reward model.\n\n5 Using B-Pref to analyze algorithmic design decisions\n-------------------------------------------------------\n\n\n\n\n\n![Refer to caption](/html/2111.03026/assets/x2.png)\n(a) Walker\n\n\n\n\n![Refer to caption](/html/2111.03026/assets/x3.png)\n(b) Quadruped\n\n\n\n\n![Refer to caption](/html/2111.03026/assets/x4.png)\n(c) Button Press\n\n\n\n\n![Refer to caption](/html/2111.03026/assets/x5.png)\n(d) Sweep Into\n\n\n\nFigure 2: IQM normalized returns with 95% confidence intervals across ten runs. Learning curves and other metrics (median, mean, optimality gap) are in the supplementary material.\n\n\nWe design our experiments to investigate the following:\n\n\n* [leftmargin=8mm]\n* \u2022\n\nHow do existing preference-based RL methods compare against each other across environments with different complexity?\n* \u2022\n\nHow to use B-Pref to analyze algorithmic design decisions for preference-based RL?\n\n\n\n\n### \n5.1 Training details\n\n\n\nWe implement PEBBLE and PrefPPO using publicly released implementations of SAC111<https://github.com/denisyarats/pytorch_sac> and PPO.222<https://github.com/DLR-RM/stable-baselines3>\nAll hyperparameters of all algorithms are optimized independently for each environment.\nAll of the experiments were processed using a single GPU (NVIDIA GTX 1080 Ti) and 8 CPU cores (Intel Xeon Gold 6126).\nFor reliable evaluation\u00a0Agarwal et\u00a0al. ([2021](#bib.bib1)),\nwe measure the normalized returns333On robotic manipulation tasks, we measure the task success rate as defined by the Meta-world authors\u00a0(Yu et\u00a0al., [2020](#bib.bib76)).\nand report the interquartile mean (IQM) across ten runs using an open-source library rliable.444<https://github.com/google-research/rliable>\nMore experimental details (e.g., model architectures and the final hyperparameters) and all learning curves with standard deviation are in the supplementary material.\n\n\n\n\n\n\n![Refer to caption](/html/2111.03026/assets/x6.png)\n(a) PEBBLE with 2000 queries\n\n\n\n\n![Refer to caption](/html/2111.03026/assets/x7.png)\n(b) PEBBLE with 1000 queries\n\n\n\nFigure 3: IQM normalized returns of PEBBLE with various sampling schemes across ten runs on Quadruped.\nLearning curves and other metrics (median, mean, optimality gap) are in the supplementary material.\n\n\n\n### \n5.2 Benchmarking prior methods\n\n\n\nFigure\u00a0[2](#S5.F2 \"Figure 2 \u2023 5 Using B-Pref to analyze algorithmic design decisions \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\") shows the IQM normalized returns of PEBBLE and PrefPPO at convergence on various simulated teachers listed in Section\u00a0[3.2](#S3.SS2 \"3.2 Simulated human teachers \u2023 3 B-Pref: Benchmarks environments for preference-based RL \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\") (see the supplementary material for experimental details).\nFor a fair comparison,\nwe apply unsupervised pre-training and disagreement-based sampling to all methods (including SAC and PPO).\nPEBBLE outperforms PrefPPO in most of the environments (especially achieving large gains on robotic manipulation tasks).\nInterestingly, providing uniform labels to equally preferable segments (Equal) or skipping the queries with similar behaviors (Skip) is more useful than relying only on perfect labels (Oracle) on hard environments like Quadruped (Figure\u00a0[2(b)](#S5.F2.sf2 \"2(b) \u2023 Figure 2 \u2023 5 Using B-Pref to analyze algorithmic design decisions \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\")).\nWhile both PEBBLE and PrefPPO achieve fairly efficient performance on correct labels (Oracle, Equal and Skip),\nthey often suffer from poor performance when teachers can provide the wrong labels (Mistake and Stoc).\nThis suggests opportunities for further investigations and development of techniques that can improve the robustness to corrupted labels.555We find that label smoothing\u00a0(Szegedy et\u00a0al., [2016](#bib.bib64)) is not effective in handling corrupted labels in our experiments (see the supplementary material for supporting results). However, other regularization techniques, like label flipping, L2 regularization and weight decay, would be interesting for further study in future work.\n\n\n\n\n\n### \n5.3 Impact of design decisions in reward learning\n\n\n\nReward learning from preferences involves several design decisions, which can affect the performance of the overall framework.\nWe showcase the utility of B-Pref by using it to analyze the following algorithmic design choices in depth:\n\n\n\n\nSelecting informative queries.\nDuring training, all experiences are stored in an annotation buffer \u212c\u212c\\mathcal{B}caligraphic\\_B\nand we generate N\ud835\ude9a\ud835\ude9e\ud835\ude8e\ud835\ude9b\ud835\udea2subscript\ud835\udc41\ud835\ude9a\ud835\ude9e\ud835\ude8e\ud835\ude9b\ud835\udea2N\\_{\\tt query}italic\\_N start\\_POSTSUBSCRIPT typewriter\\_query end\\_POSTSUBSCRIPT pairs of segments666We do not compare segments of different lengths. to ask teacher\u2019s preferences from this buffer at each feedback session.\nTo reduce the burden on the human, we should solicit preferences so as to maximize the information received.\nWhile finding optimal queries is computationally intractable\u00a0(Ailon, [2012](#bib.bib2)),\nseveral sampling schemes\u00a0(Biyik & Sadigh, [2018](#bib.bib11); Biyik et\u00a0al., [2020](#bib.bib12); Sadigh et\u00a0al., [2017](#bib.bib50)) have been explored to find queries that are likely to change the reward model.\nSpecifically,\nwe consider the following sampling schemes, where more details are in the supplementary material:\n\n\n* [leftmargin=8mm]\n* \u2022\n\nUniform sampling: We pick N\ud835\ude9a\ud835\ude9e\ud835\ude8e\ud835\ude9b\ud835\udea2subscript\ud835\udc41\ud835\ude9a\ud835\ude9e\ud835\ude8e\ud835\ude9b\ud835\udea2N\\_{\\tt query}italic\\_N start\\_POSTSUBSCRIPT typewriter\\_query end\\_POSTSUBSCRIPT pairs of segments uniformly at random from the buffer \u212c\u212c\\mathcal{B}caligraphic\\_B.\n* \u2022\n\nUncertainty-based sampling:\nWe first generate the initial batch of N\ud835\ude92\ud835\ude97\ud835\ude92\ud835\ude9dsubscript\ud835\udc41\ud835\ude92\ud835\ude97\ud835\ude92\ud835\ude9dN\\_{\\tt init}italic\\_N start\\_POSTSUBSCRIPT typewriter\\_init end\\_POSTSUBSCRIPT pairs of segments \ud835\udca2\ud835\ude92\ud835\ude97\ud835\ude92\ud835\ude9dsubscript\ud835\udca2\ud835\ude92\ud835\ude97\ud835\ude92\ud835\ude9d\\mathcal{G}\\_{\\tt init}caligraphic\\_G start\\_POSTSUBSCRIPT typewriter\\_init end\\_POSTSUBSCRIPT uniformly at random, measure the uncertainty (e.g., variance across ensemble of preference predictors \u00a0Christiano et\u00a0al. ([2017](#bib.bib19)) or entropy of a single preference predictor\u00a0(Lee et\u00a0al., [2021](#bib.bib39))),\nand then select the N\ud835\ude9a\ud835\ude9e\ud835\ude8e\ud835\ude9b\ud835\udea2subscript\ud835\udc41\ud835\ude9a\ud835\ude9e\ud835\ude8e\ud835\ude9b\ud835\udea2N\\_{\\tt query}italic\\_N start\\_POSTSUBSCRIPT typewriter\\_query end\\_POSTSUBSCRIPT pairs of segments with high uncertainty.\n* \u2022\n\nCoverage-based sampling: From the initial batch \ud835\udca2\ud835\ude92\ud835\ude97\ud835\ude92\ud835\ude9dsubscript\ud835\udca2\ud835\ude92\ud835\ude97\ud835\ude92\ud835\ude9d\\mathcal{G}\\_{\\tt init}caligraphic\\_G start\\_POSTSUBSCRIPT typewriter\\_init end\\_POSTSUBSCRIPT,\nwe choose N\ud835\ude9a\ud835\ude9e\ud835\ude8e\ud835\ude9b\ud835\udea2subscript\ud835\udc41\ud835\ude9a\ud835\ude9e\ud835\ude8e\ud835\ude9b\ud835\udea2N\\_{\\tt query}italic\\_N start\\_POSTSUBSCRIPT typewriter\\_query end\\_POSTSUBSCRIPT center points such that the largest distance between a data point and its nearest center is minimized using a greedy selection strategy.\n* \u2022\n\nHybrid sampling: Similar to Yu et\u00a0al. ([2006](#bib.bib75)), we also consider hybrid sampling, which combines uncertainty-based sampling and coverage-based sampling.\nFirst, we select the N\ud835\ude92\ud835\ude97\ud835\ude9d\ud835\ude8e\ud835\ude9bsubscript\ud835\udc41\ud835\ude92\ud835\ude97\ud835\ude9d\ud835\ude8e\ud835\ude9bN\\_{\\tt inter}italic\\_N start\\_POSTSUBSCRIPT typewriter\\_inter end\\_POSTSUBSCRIPT pairs of segments \ud835\udca2\ud835\ude9e\ud835\ude97subscript\ud835\udca2\ud835\ude9e\ud835\ude97\\mathcal{G}\\_{\\tt un}caligraphic\\_G start\\_POSTSUBSCRIPT typewriter\\_un end\\_POSTSUBSCRIPT, using uncertainty-based sampling, where N\ud835\ude92\ud835\ude97\ud835\ude92\ud835\ude9d>N\ud835\ude92\ud835\ude97\ud835\ude9d\ud835\ude8e\ud835\ude9bsubscript\ud835\udc41\ud835\ude92\ud835\ude97\ud835\ude92\ud835\ude9dsubscript\ud835\udc41\ud835\ude92\ud835\ude97\ud835\ude9d\ud835\ude8e\ud835\ude9bN\\_{\\tt init}>N\\_{\\tt inter}italic\\_N start\\_POSTSUBSCRIPT typewriter\\_init end\\_POSTSUBSCRIPT > italic\\_N start\\_POSTSUBSCRIPT typewriter\\_inter end\\_POSTSUBSCRIPT, and then choose N\ud835\ude9a\ud835\ude9e\ud835\ude8e\ud835\ude9b\ud835\udea2subscript\ud835\udc41\ud835\ude9a\ud835\ude9e\ud835\ude8e\ud835\ude9b\ud835\udea2N\\_{\\tt query}italic\\_N start\\_POSTSUBSCRIPT typewriter\\_query end\\_POSTSUBSCRIPT center points from \ud835\udca2\ud835\ude9e\ud835\ude97subscript\ud835\udca2\ud835\ude9e\ud835\ude97\\mathcal{G}\\_{\\tt un}caligraphic\\_G start\\_POSTSUBSCRIPT typewriter\\_un end\\_POSTSUBSCRIPT.\n\n\n\n\nFigure\u00a0[3](#S5.F3 \"Figure 3 \u2023 5.1 Training details \u2023 5 Using B-Pref to analyze algorithmic design decisions \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\") shows the IQM normalized returns of PEBBLE with various sampling schemes on Quadruped.\nWe find that the uncertainty-based sampling schemes (i.e., ensemble disagreement and entropy) are superior to other sampling schemes,\nwhile coverage-based sampling schemes do not improve on uniform sampling and slow down the sampling procedures.\nTo analyze the effects of sampling schemes,\nwe measure the fraction of equally preferable queries (i.e., y=(0.5,0.5)\ud835\udc660.50.5y=(0.5,0.5)italic\\_y = ( 0.5 , 0.5 )) on the Equal teacher.\nFigure\u00a0[5(a)](#S5.F5.sf1 \"5(a) \u2023 Figure 5 \u2023 5.3 Impact of design decisions in reward learning \u2023 5 Using B-Pref to analyze algorithmic design decisions \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\") shows that uncertainty-based sampling schemes achieve high returns even though other sampling schemes receive more (non-uniform) perfect labels.\nWe expect that this is because queries with high uncertainty provide significant information to the reward model.\nThis also suggests opportunities for further investigations on uncertainty estimates like Bayesian methods\u00a0(Brown & Niekum, [2019](#bib.bib15); Gal & Ghahramani, [2016](#bib.bib25)).\n\n\n\n\nFeedback schedule.\nWe also investigate the impact of the feedback schedule, which decides the number of queries at each feedback session.\nLee et\u00a0al. ([2021](#bib.bib39)) used a uniform schedule, which always asks the same number of queries, and Christiano et\u00a0al. ([2017](#bib.bib19)); Ibarz et\u00a0al. ([2018](#bib.bib31)) used a decay schedule,\nwhich decreases the number of queries, roughly proportional to Tt+T\ud835\udc47\ud835\udc61\ud835\udc47\\frac{T}{t+T}divide start\\_ARG italic\\_T end\\_ARG start\\_ARG italic\\_t + italic\\_T end\\_ARG, where t\ud835\udc61titalic\\_t is the current timestep and T\ud835\udc47Titalic\\_T is the episode length.\nWe additionally consider an increase schedule, which increases the number of queries, roughly proportional to T+tT\ud835\udc47\ud835\udc61\ud835\udc47\\frac{T+t}{T}divide start\\_ARG italic\\_T + italic\\_t end\\_ARG start\\_ARG italic\\_T end\\_ARG.\n\n\n\n\nFigure\u00a0[4](#S5.F4 \"Figure 4 \u2023 5.3 Impact of design decisions in reward learning \u2023 5 Using B-Pref to analyze algorithmic design decisions \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\") shows the learning curves of PEBBLE with different feedback schedule on the oracle teacher.\nGiven the same total number of queries,\nincrease and decay schedules change the size of the initial queries by a factor of 0.5 and 2, respectively.\nOne can note that there is no big gain from rule-based schedules in most of the environments.\nEven though rule-based schedules are less effective than uniform scheduling,\nusing an adaptive schedule like meta-gradient\u00a0(Xu et\u00a0al., [2018](#bib.bib72), [2020](#bib.bib73)) would be interesting for further study in future work.\n\n\n\n\n\n\n![Refer to caption](/html/2111.03026/assets/x8.png)\n(a) Button Press\n\n\n\n![Refer to caption](/html/2111.03026/assets/x9.png)\n(b) Sweep Into\n\n\n\n![Refer to caption](/html/2111.03026/assets/x10.png)\n(c) Quadruped\n\n\n\n\n![Refer to caption](/html/2111.03026/assets/x11.png)\n(d) Walker\n\n\n\nFigure 4: Learning curves of PEBBLE with different feedback schedules on the oracle teacher.\nThe solid line and shaded regions represent the mean and standard deviation, respectively, across ten runs.\n\n\n\nReward analysis.\nTo investigate the quality of the learned reward function,\nwe compare the learned reward function with the ground truth reward.\nFigure\u00a0[5(b)](#S5.F5.sf2 \"5(b) \u2023 Figure 5 \u2023 5.3 Impact of design decisions in reward learning \u2023 5 Using B-Pref to analyze algorithmic design decisions \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\") and Figure\u00a0[5(c)](#S5.F5.sf3 \"5(c) \u2023 Figure 5 \u2023 5.3 Impact of design decisions in reward learning \u2023 5 Using B-Pref to analyze algorithmic design decisions \u2023 B-Pref: Benchmarking Preference-Based Reinforcement Learning\") show the learned reward function optimized by PEBBLE on the oracle teacher in Sweep Into and Walker, where more evaluation results on other environments are also available\nin the supplementary material.\nBecause we bound the output of the reward function using tanh function, the scale is different with the ground truth reward but the learned reward function is reasonably well-aligned.\n\n\n\n\n\n\n![Refer to caption](/html/2111.03026/assets/x12.png)\n(a) Sampling analysis\n\n\n\n![Refer to caption](/html/2111.03026/assets/x13.png)\n(b) Sweep Into\n\n\n\n![Refer to caption](/html/2111.03026/assets/x14.png)\n(c) Walker\n\n\n\nFigure 5: (a) Fraction of equally preferable queries (red) and average returns (blue) on the Equal teacher.\nWe use PEBBLE with different sampling schemes on Quadruped given a budget of 2000 queries.\nEven though a teacher provides more uniform labels, i.e., y=(0.5,0.5)\ud835\udc660.50.5y=(0.5,0.5)italic\\_y = ( 0.5 , 0.5 ), to uncertainty-based sampling schemes,\nthey achieve higher returns than other sampling schemes. (b/c) Time series of learned reward function (green) and the ground truth reward (red) using rollouts from a policy optimized by PEBBLE.\nLearned reward functions align with the ground truth rewards in (b) Sweep Into and (c) Walker.\n\n6 Related work\n---------------\n\n\n\nBenchmarks for deep reinforcement learning.\nThere is a large body of work focused on designing benchmarks for RL\u00a0Beattie et\u00a0al. ([2016](#bib.bib7)); Bellemare et\u00a0al. ([2013](#bib.bib8)); Brockman et\u00a0al. ([2016](#bib.bib14)); Cobbe et\u00a0al. ([2019](#bib.bib20), [2020](#bib.bib21)); Duan et\u00a0al. ([2016](#bib.bib22)); Fu et\u00a0al. ([2020](#bib.bib24)); Gulcehre et\u00a0al. ([2020](#bib.bib26)); Henderson et\u00a0al. ([2018](#bib.bib30)); Ray et\u00a0al. ([2019](#bib.bib48)); Tassa et\u00a0al. ([2018](#bib.bib65), [2020](#bib.bib66)); Yu et\u00a0al. ([2020](#bib.bib76)).\nThe Arcade Learning Environment\u00a0Bellemare et\u00a0al. ([2013](#bib.bib8)) has becomes a popular benchmark to measure the progress of RL algorithms for discrete control tasks.\nFor continuous control tasks,\nDuan et\u00a0al. ([2016](#bib.bib22)) presented a benchmark with baseline implementations of various RL algorithms, which in turn led to OpenAI Gym\u00a0(Brockman et\u00a0al., [2016](#bib.bib14)).\nThese benchmarks have significantly accelerated progress and have been strong contributors towards the discovery and evaluation of today\u2019s most widely used RL algorithms\u00a0(Haarnoja et\u00a0al., [2018](#bib.bib27); Mnih et\u00a0al., [2015](#bib.bib44); Schulman et\u00a0al., [2015](#bib.bib52), [2016](#bib.bib53), [2017](#bib.bib54)).\n\n\n\n\nRecently, researchers proposed more targeted RL benchmarks that have been designed for specific research purposes.\nCobbe et\u00a0al. ([2020](#bib.bib21)) presented a suite\nof game-like environments where the train and test environments differ for evaluating generalization performance of RL agents.\nRay et\u00a0al. ([2019](#bib.bib48)) provided a Safety Gym for measuring progress towards RL agents that satisfy the safety constraints.\nD4RL\u00a0Fu et\u00a0al. ([2020](#bib.bib24)) and RL Unplugged\u00a0Gulcehre et\u00a0al. ([2020](#bib.bib26)) have been proposed to evaluate and compare offline RL algorithms. Yu et\u00a0al. ([2020](#bib.bib76)) proposed Meta-world to study meta- and multi-task RL.\nURLB\u00a0(Laskin et\u00a0al., [2021](#bib.bib38)) benchmarks performance of unsupervised RL methods.\nHowever, none of the existing RL benchmarks are tailored towards preference-based RL.\n\n\n\n\nFreire et\u00a0al. ([2020](#bib.bib23)) proposed DERAIL, a benchmark suite for preference-based learning, but they focused on simple diagnostic tasks.\nIn B-Pref, we consider learning a variety of complex locomotion and robotic manipulation\ntasks.\nAdditionally, we design teachers with a wide array of irrationalities and benchmark state-of-the-art preference-based RL algorithms\u00a0(Christiano et\u00a0al., [2017](#bib.bib19); Lee et\u00a0al., [2021](#bib.bib39)) in depth.\n\n\n\n\nHuman-in-the-loop reinforcement learning. Several works have successfully utilized feedback from real humans to train RL agents\u00a0(Arumugam et\u00a0al., [2019](#bib.bib6); Christiano et\u00a0al., [2017](#bib.bib19); Ibarz et\u00a0al., [2018](#bib.bib31); Knox & Stone, [2009](#bib.bib34); Lee et\u00a0al., [2021](#bib.bib39); MacGlashan et\u00a0al., [2017](#bib.bib43); Warnell et\u00a0al., [2018](#bib.bib69)).\nMacGlashan et\u00a0al. ([2017](#bib.bib43)) proposed a reward-free method, which utilizes a human feedback as an advantage function and optimizes the agents via a policy gradient.\nKnox & Stone ([2009](#bib.bib34)) trained a reward model via regression using unbounded real-valued feedback.\nHowever, these approaches are difficult to scale to more complex learning problems that require substantial agent experience.\n\n\n\n\nAnother promising direction has focused on utilizing the human preferences\u00a0(Akrour et\u00a0al., [2011](#bib.bib3); Christiano et\u00a0al., [2017](#bib.bib19); Ibarz et\u00a0al., [2018](#bib.bib31); Lee et\u00a0al., [2021](#bib.bib39); Leike et\u00a0al., [2018](#bib.bib41); Pilarski et\u00a0al., [2011](#bib.bib47); Stiennon et\u00a0al., [2020](#bib.bib61); Wilson et\u00a0al., [2012](#bib.bib70); Wu et\u00a0al., [2021](#bib.bib71)).\nChristiano et\u00a0al. ([2017](#bib.bib19)) scaled preference-based learning to utilize modern deep learning techniques,\nand Ibarz et\u00a0al. ([2018](#bib.bib31)) improved the efficiency of this method by introducing additional forms of feedback such as demonstrations.\nRecently, Lee et\u00a0al. ([2021](#bib.bib39)) proposed a feedback-efficient RL algorithm by utilizing off-policy learning and pre-training.\nStiennon et\u00a0al. ([2020](#bib.bib61)) and Wu et\u00a0al. ([2021](#bib.bib71)) showed that preference-based RL can be utilized to fine-tune GPT-3\u00a0(Brown et\u00a0al., [2020](#bib.bib16)) for hard tasks like text and book summarization, respectively.\nWe benchmark these state-of-the-art preference-based RL algorithms in this paper.\n\n7 Conclusion\n-------------\n\n\n\nIn this paper,\nwe present B-Pref, a benchmark specially designed for preference-based RL, covering a wide array of a teacher\u2019s irrationalities.\nWe empirically investigate state-of-the-art preference-based RL algorithms in depth\nand analyze the effects of algorithmic design decisions on our benchmark.\nWe find that existing methods often suffer from poor performance when teachers provide wrong labels,\nand the effects of design decisions are varied depending on the task setups.\nThese observations call for new algorithms in active learning\u00a0(Biyik & Sadigh, [2018](#bib.bib11); Biyik et\u00a0al., [2020](#bib.bib12); Sadigh et\u00a0al., [2017](#bib.bib50)) and meta-learning\u00a0(Xu et\u00a0al., [2018](#bib.bib72), [2020](#bib.bib73)) to be developed.\nBy providing an open-source release of the benchmark,\nwe encourage other researchers to use B-Pref as a common starting point to study preference-based RL more systematically.\n\n\n\n\nLimitations. There are several important properties that are not explored in-depth in B-Pref.\nOne is robustness of learned reward functions to new environments with different dynamics or initial states\u00a0Reddy et\u00a0al. ([2020](#bib.bib49)).\nAlso, we focus on tasks with proprioceptive inputs and dense rewards, but extensions to visual observations and sparse rewards are interesting directions to explore.\n\n\n\n\nPotential negative impacts.\nPreference-based RL has several advantages (e.g., teaching novel behaviors, and mitigating the effects of reward exploitation); however, it also has potential drawbacks.\nMalicious users might teach the bad behaviors/functionality using this framework.\nTherefore, researchers should consider the safety issues with particular thought.\n\nAcknowledgements\n----------------\n\n\n\nThis research is supported in part by\nONR PECASE N000141612723,\nNSF NRI #2024675,\nONR YIP,\nand Berkeley Deep Drive.\nLaura Smith was supported by NSF Graduate Research Fellowship.\nWe thank Qiyang (Colin) Li and Olivia Watkins for providing helpful feedback and suggestions.\nWe also thank anonymous reviewers for critically reading the manuscript and suggesting substantial improvements.", "url": "https://arxiv.org/abs/2111.03026"}
{"text": "1 Introduction\n---------------\n\n\n\nExplainability has emerged as an important requirement for deep neural networks (DNNs).\nExplanations target a number of secondary objectives of model design (in addition to the primary objective of maximizing prediction accuracy), such as informativeness, transferability and audit of ethical values\u00a0[[15](#bib.bib15), [32](#bib.bib32), [36](#bib.bib36)].\nOne of the most important desiderata of explainability is model robustness, whereby\nexplanations\nare used to assess the extent to which some downstream task could rely on the model\u2019s predictions. For instance, a prediction classifying an input as a wolf with the explanation that the background contains snow is unlikely to be trusted by the downstream system\u00a0[[40](#bib.bib40)]. A long line of research has focused on rendering DNN predictions explainable with the\u2014often implicit\u2014goal of assessing prediction robustness\u00a0[[28](#bib.bib28), [40](#bib.bib40), [11](#bib.bib11), [29](#bib.bib29), [43](#bib.bib43), [31](#bib.bib31), [41](#bib.bib41), [33](#bib.bib33), [30](#bib.bib30), [3](#bib.bib3)].\n\n\n\n\nHowever, the scalability of these explanation-based robustness assessment schemes is limited by the need for \"humans-in-the-loop\".\nPrediction robustness checks based on explanations operate as following: Given an input, one or more human-interpretable concepts are identified that have a significant impact on the model prediction. Then an explanation-conformity check is performed to see whether the concept\u2013prediction relationship matches human-reasoning. In the above example of wolf and snow\u00a0[[40](#bib.bib40)], a human may deem the concept\u2013prediction relationship (snow\u2013wolf) to be unreasonable, and consider the prediction to be non-robust.\nHowever, identifying human-interpretable concepts and checking for human-reasoning requires significant human effort by the way of manual annotation of either the inputs (*e.g.*, TCAV\u00a0[[28](#bib.bib28)]), intermediate model components (*e.g.*, LIME\u00a0[[40](#bib.bib40)]) or both (*e.g.*, saliency maps\u00a0[[43](#bib.bib43)]). In practice, human involvement makes many explanation-based robustness assessments unsuitable for large-scale deployment.\n\n\n\n\nGoals and contributions.\nIn this paper, our goal is to design a highly scalable robustness assessment framework that automates the end-to-end process of performing explanation-conformity checks.\nAt the foundation of our framework are concepts with the following key properties:\n\n\n1. 1.\n\nThe concepts are identified automatically from the training data without any human effort.\n2. 2.\n\nThey are machine-checkable , *i.e.*, they lend themselves to \u2018concept\u2013class\u2019 style automated explanation-conformity checks without any human involvement.\n3. 3.\n\nThey can be added to off-the-shelf, pretrained DNNs in a post-hoc manner to assess prediction robustness.\n\n\n\n\nWe devise an intuitive procedure for identifying machine-checkable concepts ( MACCs ) that satisfy the above key properties. Specifically, our framework automatically defines a large number of MACCs, each corresponding to features shared by some subset of one or more classes (and not shared by other classes)\nin the training data. At the end of the concept-identification process, each class in the training data has a unique set of corresponding MACCs.\nFinally, with each prediction of the DNN, our framework performs an automated explanation-conformity check to see if the MACCs corresponding to the predicted class are also detected in the learnt representations of the input (and the MACCs not corresponding to the predicted class are not detected). The predictions passing the explanation-conformity check are deemed robust, even if individual MACCs are hard for humans to recognize.\n\n\n\n\nExperiments and human surveys on real-world image classification datasets show that MACCs help increase the prediction robustness significantly.\nSpecifically, we find that (i) explanation-conformant predictions are not only significantly more accurate, but their corresponding images are also easier for humans to classify confidently than non-conformant predictions, (ii) adversarial attacks against explanation-conformant predictions are significantly harder and in many cases impractical, and (iii) MACCs also provide insights into the potential causes for prediction errors.\n\n2 Methodology\n--------------\n\n\n\nIn this section, we describe our framework for robust prediction.\n\n\n\n\nFormal problem setup and notation.\nLet \ud835\udc9f={(\ud835\udc99i,yi)}i=1N\ud835\udc9fsuperscriptsubscriptsubscript\ud835\udc99\ud835\udc56subscript\ud835\udc66\ud835\udc56\ud835\udc561\ud835\udc41\\mathcal{D}=\\{(\\bm{x}\\_{i},y\\_{i})\\}\\_{i=1}^{N}caligraphic\\_D = { ( bold\\_italic\\_x start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT , italic\\_y start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT ) } start\\_POSTSUBSCRIPT italic\\_i = 1 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_N end\\_POSTSUPERSCRIPT denote a training dataset of N\ud835\udc41Nitalic\\_N examples with \ud835\udc99\u2208\ud835\udcb3=\u211dd\ud835\udc99\ud835\udcb3superscript\u211d\ud835\udc51\\bm{x}\\in\\mathcal{X}=\\mathbb{R}^{d}bold\\_italic\\_x \u2208 caligraphic\\_X = blackboard\\_R start\\_POSTSUPERSCRIPT italic\\_d end\\_POSTSUPERSCRIPT and y\u2208\ud835\udcb4={1,2,\u2026,K}\ud835\udc66\ud835\udcb412\u2026\ud835\udc3ey\\in\\mathcal{Y}=\\{1,2,\\ldots,K\\}italic\\_y \u2208 caligraphic\\_Y = { 1 , 2 , \u2026 , italic\\_K }.\nThe learning task involves obtaining a mapping Fclf:\ud835\udcb3\u2192\ud835\udcb4:subscript\ud835\udc39clf\u2192\ud835\udcb3\ud835\udcb4F\\_{\\text{clf}}:\\mathcal{X}\\to\\mathcal{Y}italic\\_F start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT : caligraphic\\_X \u2192 caligraphic\\_Y .\nFor a (deep) neural network with L\ud835\udc3fLitalic\\_L hidden layers, this mapping consists of applying a set of parameterized layers fl(\ud835\udc99l,\ud835\udf3dl)subscript\ud835\udc53\ud835\udc59subscript\ud835\udc99\ud835\udc59subscript\ud835\udf3d\ud835\udc59f\\_{l}(\\bm{x}\\_{l},\\bm{\\theta}\\_{l})italic\\_f start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT ( bold\\_italic\\_x start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT , bold\\_italic\\_\u03b8 start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT ). Here, \ud835\udc99lsubscript\ud835\udc99\ud835\udc59\\bm{x}\\_{l}bold\\_italic\\_x start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT and \ud835\udf3dlsubscript\ud835\udf3d\ud835\udc59\\bm{\\theta}\\_{l}bold\\_italic\\_\u03b8 start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT denote, respectively, the input and parameters of the lthsuperscript\ud835\udc59\ud835\udc61\u210el^{th}italic\\_l start\\_POSTSUPERSCRIPT italic\\_t italic\\_h end\\_POSTSUPERSCRIPT layer.\nThe whole neural network mapping can be expressed as:\nFclf(\ud835\udc99)=fclf(fL(fL\u22121(\u2026,f1(\ud835\udc99,\ud835\udf3d1))))subscript\ud835\udc39clf\ud835\udc99subscript\ud835\udc53clfsubscript\ud835\udc53\ud835\udc3fsubscript\ud835\udc53\ud835\udc3f1\u2026subscript\ud835\udc531\ud835\udc99subscript\ud835\udf3d1F\\_{\\text{clf}}(\\bm{x})=f\\_{\\text{clf}}(f\\_{L}(f\\_{L-1}(\\ldots,f\\_{1}(\\bm{x},\\bm{\\theta}\\_{1}))))italic\\_F start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT ( bold\\_italic\\_x ) = italic\\_f start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT ( italic\\_f start\\_POSTSUBSCRIPT italic\\_L end\\_POSTSUBSCRIPT ( italic\\_f start\\_POSTSUBSCRIPT italic\\_L - 1 end\\_POSTSUBSCRIPT ( \u2026 , italic\\_f start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT ( bold\\_italic\\_x , bold\\_italic\\_\u03b8 start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT ) ) ) ),\nwhere the output of fclfsubscript\ud835\udc53clff\\_{\\text{clf}}italic\\_f start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT\u2014or the classification layer\u2014is a K-dimensional vector consisting of (potentially un-calibrated) probabilities, generally obtained by applying the softmax function within the layer fclfsubscript\ud835\udc53clff\\_{\\text{clf}}italic\\_f start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT.\nOne then obtains the prediction y^=argmaxFclf(\ud835\udc99)^\ud835\udc66argmaxsubscript\ud835\udc39clf\ud835\udc99\\hat{y}=\\text{argmax}\\ F\\_{\\text{clf}}(\\bm{x})over^ start\\_ARG italic\\_y end\\_ARG = argmax italic\\_F start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT ( bold\\_italic\\_x ).\nThe learning then boils down to minimizing the discrepancy between the predicted and the ground-truth labels.\nFor the sake of computational tractability, this discrepancy is often expressed via the (categorical) cross-entropy loss function, denoted henceforth as \u2112clf(Fclf(\ud835\udc99),y)subscript\u2112clfsubscript\ud835\udc39clf\ud835\udc99\ud835\udc66\\mathcal{L}\\_{\\text{clf}}(F\\_{\\text{clf}}(\\bm{x}),y)caligraphic\\_L start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT ( italic\\_F start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT ( bold\\_italic\\_x ) , italic\\_y ).\n\n\n\n![Refer to caption](/html/2007.00251/assets/x1.png)\nFigure 1: [System overview] We propose the use of (a) Machine-checkable concepts (MACCs), that are defined as concepts shared between inputs of one or more classes\n(Section\u00a0[2.1.1](#S2.SS1.SSS1 \"2.1.1 Automatically defining MACCs \u2023 2.1 Our framework: Robustness via machine-checkable concepts \u2023 2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\"))\u2014the figure only shows the MACCs shared between two classes.\n(b)\nAutomatically detecting MACCs involves adding an additional classification layer (to any hidden layer) of an existing DNN (Section\u00a0[2.1.2](#S2.SS1.SSS2 \"2.1.2 Detecting MACCs in DNNs \u2023 2.1 Our framework: Robustness via machine-checkable concepts \u2023 2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")).\n(c) At test time, we perform the explanation-conformity check to ensure that the MACCs corresponding to the predicted class are also detected in the image (Section\u00a0[2.1.3](#S2.SS1.SSS3 \"2.1.3 Explanation-conformity checks with MACCs \u2023 2.1 Our framework: Robustness via machine-checkable concepts \u2023 2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")). The predictions not passing the explanation-conformity check are deemed non-robust.\n\n\n\n### \n2.1 Our framework: Robustness via machine-checkable concepts\n\n\n\nOur framework, summarized in Figure\u00a0[1](#S2.F1 \"Figure 1 \u2023 2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\"), consists of three main components: Defining machine-checkable concepts (MACCs), leveraging the DNN to detect MACCs, and performing explanation-conformity checks with MACCs to assess prediction robustness. We now describe each of the components individually.\n\n\n\n\n#### \n2.1.1 Automatically defining MACCs\n\n\n\nThe first component of our framework automatically defines MACCs that are amenable to explanation-conformity checks without any human intervention. To define MACCs, we leverage the following key insight\u00a0[[36](#bib.bib36), [25](#bib.bib25)]: one method of composing explanations is to point to presence or absence of concepts in the input, where a concept is a feature that is possessed by inputs of a certain set of classes in the dataset, and not possessed by other classes.\nFor instance, in an animal classification task involving zebras, cats and dogs, zebras might have a unique concept stripes\u00a0[[28](#bib.bib28)], that is not shared by any other class.\nSimilarly, dogs and cats might share a concept paws that is not shared by any other class.\n\n\n\n\nMost prior works detect these concepts by manually annotating (parts of) inputs that contain them (*e.g.*, \u00a0[[28](#bib.bib28), [41](#bib.bib41), [40](#bib.bib40)]).\nInstead of manually annotating the inputs, for every possible subset of one or more classes, we define one MACC that corresponds to the features shared by inputs in that subset. This way of defining MACCs leads to M=2K\u22121\ud835\udc40superscript2\ud835\udc3e1M=2^{K}-1italic\\_M = 2 start\\_POSTSUPERSCRIPT italic\\_K end\\_POSTSUPERSCRIPT - 1 concepts in a dataset with K\ud835\udc3eKitalic\\_K classes.\nFor instance, in a datasets with classes cat, dog and zebra, one can define 23\u22121=7superscript23172^{3}-1=72 start\\_POSTSUPERSCRIPT 3 end\\_POSTSUPERSCRIPT - 1 = 7 MACCs, as follows {ccatsubscript\ud835\udc50catc\\_{\\text{cat}}italic\\_c start\\_POSTSUBSCRIPT cat end\\_POSTSUBSCRIPT, cdogsubscript\ud835\udc50dogc\\_{\\text{dog}}italic\\_c start\\_POSTSUBSCRIPT dog end\\_POSTSUBSCRIPT, czebrasubscript\ud835\udc50zebrac\\_{\\text{zebra}}italic\\_c start\\_POSTSUBSCRIPT zebra end\\_POSTSUBSCRIPT, ccat/dogsubscript\ud835\udc50cat/dogc\\_{\\text{cat/dog}}italic\\_c start\\_POSTSUBSCRIPT cat/dog end\\_POSTSUBSCRIPT, ccat/zebrasubscript\ud835\udc50cat/zebrac\\_{\\text{cat/zebra}}italic\\_c start\\_POSTSUBSCRIPT cat/zebra end\\_POSTSUBSCRIPT, cdog/zebrasubscript\ud835\udc50dog/zebrac\\_{\\text{dog/zebra}}italic\\_c start\\_POSTSUBSCRIPT dog/zebra end\\_POSTSUBSCRIPT, ccat/dog/zebrasubscript\ud835\udc50cat/dog/zebrac\\_{\\text{cat/dog/zebra}}italic\\_c start\\_POSTSUBSCRIPT cat/dog/zebra end\\_POSTSUBSCRIPT}.\nFigure\u00a0[1](#S2.F1 \"Figure 1 \u2023 2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") shows all overlaps involving two classes. In the figure, the concept cdog/catsubscript\ud835\udc50dog/catc\\_{\\text{dog/cat}}italic\\_c start\\_POSTSUBSCRIPT dog/cat end\\_POSTSUBSCRIPT denotes a property shared by dog and cat, but not by zebras. Similarly, cdog/zebrasubscript\ud835\udc50dog/zebrac\\_{\\text{dog/zebra}}italic\\_c start\\_POSTSUBSCRIPT dog/zebra end\\_POSTSUBSCRIPT denotes a property possessed by zebras and dogs but not by cats.\n\n\n\n\n\n#### \n2.1.2 Detecting MACCs in DNNs\n\n\n\nGiven a DNN Fclfsubscript\ud835\udc39clfF\\_{\\text{clf}}italic\\_F start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT as in the formal setup,\ntrained to predict the class labels, we express the MACC detector Fconsubscript\ud835\udc39conF\\_{\\text{con}}italic\\_F start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT as:\nFcon(\ud835\udc99)=fcon(fL(fL\u22121(\u2026,f1(\ud835\udc99,\ud835\udf3d1))))subscript\ud835\udc39con\ud835\udc99subscript\ud835\udc53consubscript\ud835\udc53\ud835\udc3fsubscript\ud835\udc53\ud835\udc3f1\u2026subscript\ud835\udc531\ud835\udc99subscript\ud835\udf3d1F\\_{\\text{con}}(\\bm{x})=f\\_{\\text{con}}(f\\_{L}(f\\_{L-1}(\\ldots,f\\_{1}(\\bm{x},\\bm{\\theta}\\_{1}))))italic\\_F start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT ( bold\\_italic\\_x ) = italic\\_f start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT ( italic\\_f start\\_POSTSUBSCRIPT italic\\_L end\\_POSTSUBSCRIPT ( italic\\_f start\\_POSTSUBSCRIPT italic\\_L - 1 end\\_POSTSUBSCRIPT ( \u2026 , italic\\_f start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT ( bold\\_italic\\_x , bold\\_italic\\_\u03b8 start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT ) ) ) ),111Note that fconsubscript\ud835\udc53conf\\_{\\text{con}}italic\\_f start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT can be attached to any intermediate layer between f1subscript\ud835\udc531f\\_{1}italic\\_f start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT to fLsubscript\ud835\udc53\ud835\udc3ff\\_{L}italic\\_f start\\_POSTSUBSCRIPT italic\\_L end\\_POSTSUBSCRIPT.\nwhere the output of fconsubscript\ud835\udc53conf\\_{\\text{con}}italic\\_f start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT is an M-dimensional vector consisting of (potentially un-calibrated) probabilities, p(\ud835\udc84i=1|\ud835\udc99)\ud835\udc5dsubscript\ud835\udc84\ud835\udc56conditional1\ud835\udc99p(\\bm{c}\\_{i}=1|\\bm{x})italic\\_p ( bold\\_italic\\_c start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT = 1 | bold\\_italic\\_x ).\nSince Fconsubscript\ud835\udc39conF\\_{\\text{con}}italic\\_F start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT attempts a multilabel classification task,\nwe obtain the probabilities using the sigmoid function \u03c3(z)=(1+e\u2212z)\u22121\ud835\udf0e\ud835\udc67superscript1superscript\ud835\udc52\ud835\udc671\\sigma(z)=(1+e^{-z})^{-1}italic\\_\u03c3 ( italic\\_z ) = ( 1 + italic\\_e start\\_POSTSUPERSCRIPT - italic\\_z end\\_POSTSUPERSCRIPT ) start\\_POSTSUPERSCRIPT - 1 end\\_POSTSUPERSCRIPT.\nFinally, one obtains a predicted MACC vector \ud835\udc84^=[c^1,\u2026,c^M]^\ud835\udc84subscript^\ud835\udc501\u2026subscript^\ud835\udc50\ud835\udc40\\hat{\\bm{c}}=[\\hat{c}\\_{1},\\ldots,\\hat{c}\\_{M}]over^ start\\_ARG bold\\_italic\\_c end\\_ARG = [ over^ start\\_ARG italic\\_c end\\_ARG start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT , \u2026 , over^ start\\_ARG italic\\_c end\\_ARG start\\_POSTSUBSCRIPT italic\\_M end\\_POSTSUBSCRIPT ] with c^i=1subscript^\ud835\udc50\ud835\udc561\\hat{c}\\_{i}=1over^ start\\_ARG italic\\_c end\\_ARG start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT = 1 indicating the predicted presence/absence of each MACC in the input. Here, Fcon(\ud835\udc99)i>0.5subscript\ud835\udc39consubscript\ud835\udc99\ud835\udc560.5F\\_{\\text{con}}(\\bm{x})\\_{i}>0.5italic\\_F start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT ( bold\\_italic\\_x ) start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT > 0.5, else c^i=0subscript^\ud835\udc50\ud835\udc560\\hat{c}\\_{i}=0over^ start\\_ARG italic\\_c end\\_ARG start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT = 0.\nLearning Fconsubscript\ud835\udc39conF\\_{\\text{con}}italic\\_F start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT can be done by optimizing the sum of M\ud835\udc40Mitalic\\_M individual binary cross-entropy loss functions, with one loss function for each MACC.\nWe refer to this sum of loss functions as \u2112consubscript\u2112con\\mathcal{L}\\_{\\text{con}}caligraphic\\_L start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT.\n\n\n\n\nOur framework allows for the flexibility to be trained in two different ways: (1) Post-hoc training: Taking a pretrained DNN Fclfsubscript\ud835\udc39clfF\\_{\\text{clf}}italic\\_F start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT as described in the formal setup, and training the MACC detection layer, fconsubscript\ud835\udc53conf\\_{\\text{con}}italic\\_f start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT by attaching it to one of the hidden layers of Fclfsubscript\ud835\udc39clfF\\_{\\text{clf}}italic\\_F start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT. With this method, the pre-learnt representations of Fclfsubscript\ud835\udc39clfF\\_{\\text{clf}}italic\\_F start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT are used and only the parameters of fconsubscript\ud835\udc53conf\\_{\\text{con}}italic\\_f start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT are learnt. (2) Joint training: Training all the parameters of the network from scratch, that is, training the hidden layers fi,\u2200i\u2208{1\u2026L}subscript\ud835\udc53\ud835\udc56subscriptfor-all\ud835\udc56\n1\u2026\ud835\udc3ff\\_{i},\\ \\forall\\_{i}\\in\\{1\\ldots L\\}italic\\_f start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT , \u2200 start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT \u2208 { 1 \u2026 italic\\_L }, the class label layer fclfsubscript\ud835\udc53clff\\_{\\text{clf}}italic\\_f start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT, and the MACC layer fconsubscript\ud835\udc53conf\\_{\\text{con}}italic\\_f start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT by minimizing the joint loss \u03bb\u2112clf+(1\u2212\u03bb)\u2112con\ud835\udf06subscript\u2112clf1\ud835\udf06subscript\u2112con\\lambda\\mathcal{L}\\_{\\text{clf}}+(1-\\lambda)\\mathcal{L}\\_{\\text{con}}italic\\_\u03bb caligraphic\\_L start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT + ( 1 - italic\\_\u03bb ) caligraphic\\_L start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT. Here the parameter \u03bb\ud835\udf06\\lambdaitalic\\_\u03bb trades-off the accuracy between the class labels prediction accuracy and the MACC detection accuracy, and can be determined via cross-validation.\nFinally, a combination of these two techniques (*e.g.*, selectively training only some hidden layers) can also be used.\n\n\n\n\n\n#### \n2.1.3 Explanation-conformity checks with MACCs\n\n\n\nThe final component of our framework constitutes of performing an explanation-conformity check with MACCs to assess prediction robustness.\nOur intuition is that predictions passing the check would be more robust.\nOur explanation-conformity check proceeds as follows:\nGiven an input instance \ud835\udc99\ud835\udc99\\bm{x}bold\\_italic\\_x, let y^=Fclf(\ud835\udc99)^\ud835\udc66subscript\ud835\udc39clf\ud835\udc99\\hat{y}=F\\_{\\text{clf}}(\\bm{x})over^ start\\_ARG italic\\_y end\\_ARG = italic\\_F start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT ( bold\\_italic\\_x ) be the class prediction and \ud835\udc84^=Fcon(\ud835\udc99)^\ud835\udc84subscript\ud835\udc39con\ud835\udc99\\hat{\\bm{c}}=F\\_{\\text{con}}(\\bm{x})over^ start\\_ARG bold\\_italic\\_c end\\_ARG = italic\\_F start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT ( bold\\_italic\\_x ) be the MACC prediction.\nThen, the explanation-conformity check probes if the MACCs corresponding to the predicted class are also detected (and the MACCs not related to the predicted class are not detected). The prediction is deemed robust if, \u2211i\ud835\udd40[\ud835\udc84i^=\ud835\udc84iy^]M\u2265tconsubscript\ud835\udc56\ud835\udd40delimited-[]^subscript\ud835\udc84\ud835\udc56subscriptsuperscript\ud835\udc84^\ud835\udc66\ud835\udc56\ud835\udc40subscript\ud835\udc61con\\frac{\\sum\\_{i}\\mathbb{I}[\\hat{\\bm{c}\\_{i}}=\\bm{c}^{\\hat{y}}\\_{i}]}{M}\\geq t\\_{\\text{con}}divide start\\_ARG \u2211 start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT blackboard\\_I [ over^ start\\_ARG bold\\_italic\\_c start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT end\\_ARG = bold\\_italic\\_c start\\_POSTSUPERSCRIPT over^ start\\_ARG italic\\_y end\\_ARG end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT ] end\\_ARG start\\_ARG italic\\_M end\\_ARG \u2265 italic\\_t start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT,\nfor some tcon\u2208[0,1]subscript\ud835\udc61con01t\\_{\\text{con}}\\in[0,1]italic\\_t start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT \u2208 [ 0 , 1 ]. A higher value of tconsubscript\ud835\udc61cont\\_{\\text{con}}italic\\_t start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT means that fewer predictions would pass the explanation-conformity check, however, the degree of robustness for these predictions is expected to be higher (see Section\u00a0[3](#S3 \"3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") for details).\n\n\n\n\n\n\n\n### \n2.2 Discussion: Salient properties of MACCs\n\n\n\nMACCs and Human-interpretability.\nMost of the existing works on concept-centered explanation-conformity checks\u00a0[[28](#bib.bib28), [40](#bib.bib40)] use human supervision to annotate images as containing a certain concept.\nSuch concepts often correspond to features that are (i) shared by certain classes and not shared by other classes in the data, and, (ii) can be easily recognized and named by humans (*e.g.*, stripes on zebras, paws on cats and dogs).\nWhile MACCs are not explicitly human recognizable,222Instead, MACCs may represent complex polymorphic and composite features in practice, i.e., the MACC corresponding to \u2018features shared by cats and dogs but not zebras\u2019 could correspond to a paw or the non-existence of stripes, or any combination of such distinguishing features.\nand hence do not satisfy criterion (ii), their definition procedure (Section\u00a0[2.1.1](#S2.SS1.SSS1 \"2.1.1 Automatically defining MACCs \u2023 2.1 Our framework: Robustness via machine-checkable concepts \u2023 2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")) ensures that they do indeed satisfy criterion (i).\nIn this sense, MACCs subsume the concepts defined in prior work on concept-centered explainability.\nHowever, our framework trades-off human recognizability of MACCs to enable end-to-end automation of robustness assessments from MACC definition \u2192\u2192\\to\u2192 detection \u2192\u2192\\to\u2192 explanation-conformity checks.\n\n\n\n\nPruning MACCs.\nIt is quite possible that in a K\ud835\udc3eKitalic\\_K-class classification task, some classes may not share any meaningful features, and their corresponding MACCs, may not correspond to any useful concepts. For instance, the class cat may not share any similarities with class kite, and hence, the corresponding MACC might be meaningless. We expect these MACCs to have low detection accuracy. During the training procedure (Section\u00a0[2.1.2](#S2.SS1.SSS2 \"2.1.2 Detecting MACCs in DNNs \u2023 2.1 Our framework: Robustness via machine-checkable concepts \u2023 2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")), such MACCs can be dropped.\nMoreover, since the possible space of MACCs is very large (for a dataset of K=100\ud835\udc3e100K=100italic\\_K = 100 classes, there are a total of 2100\u22121\u22481030superscript21001superscript10302^{100}-1\\approx 10^{30}2 start\\_POSTSUPERSCRIPT 100 end\\_POSTSUPERSCRIPT - 1 \u2248 10 start\\_POSTSUPERSCRIPT 30 end\\_POSTSUPERSCRIPT) possible MACCs, one could use a random subset of MACCs, or only consider MACCs that represent properties shared by exactly two, or exactly three classes (*e.g.*, in Figure\u00a0[1](#S2.F1 \"Figure 1 \u2023 2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")).\nFinally, MACCs that uniquely correspond to a class may be redundant in conformity checks and can be safely pruned.\n\n3 Evaluation of the robustness framework\n-----------------------------------------\n\n\n\nIn this section, we conduct experiments and human surveys on real-world datasets to evaluate the effectiveness of our MACC framework.\nSpecifically, we ask whether the predictions passing the MACC explanation-conformity achieve better robustness.\n\n\n\n\nEvaluation metrics. Inspired by usage of explanation-conformity checks in practice\u00a0[[15](#bib.bib15), [6](#bib.bib6), [44](#bib.bib44)], we use the following evaluation metrics to quantify prediction robustness: (i) Error Estimability , *i.e.*, accuracy on explanation-conformant predictions, (ii) Error Vulnerability , *i.e.*, resistance to adversarial attacks on explanation-conformant predictions, and, (iii), Error Explainability , *i.e.*, ability to map errors to potential issues in the input.\n\n\n\n\nSetup.\nWe conduct experiments on CIFAR-10, CIFAR-100 and Fashion MNIST datasets. We define MACCs such that each class in CIFAR-10 and Fashion MNIST data is accompanied by 9 MACCs whereas in CIFAR-100 data, this number is 99.\n\n\n\n\nWe use simple deep CNN architectures, that have publicly available implementations, and provide comparable performance to state-of-the-art. Additional details on data preprocessing, MACC definition, picking tconsubscript\ud835\udc61cont\\_{\\text{con}}italic\\_t start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT, and training architectures can be found in Appendix\u00a0[A](#A1 \"Appendix A Implementation details and reproducibility \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\").\n\n\n\n\nTraining the models to maximize the classification accuracy leads to a test set accuracy of 88.8%percent88.888.8\\%88.8 %, 92.49%percent92.4992.49\\%92.49 % and 59.41%percent59.4159.41\\%59.41 % on CIFAR-10, Fashion MNIST and CIFAR-100 datasets, respectively. We refer to this model as the vanilla model.\nFor the training of Fconsubscript\ud835\udc39conF\\_{\\text{con}}italic\\_F start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT, we consider the post-hoc training alternative considered in Section\u00a0[2](#S2 \"2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\"). The joint training alternative leads to similar statistics.\nFor the detailed analysis, we focus on the performance of post-hoc training and leave detailed comparison between different training schemes for a future study.\nFor performance comparison, we use the probability calibration method of Guo et\u00a0al. [[24](#bib.bib24)] (see Section\u00a0[3.4](#S3.SS4 \"3.4 Discussion \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")).\n\n\n\n\nWe now present the performance of MACCs in improving prediction robustness.\n\n\n\n\nTable 1: [Error Estimability]\nAccuracy of the vanilla DNN with no explanation-conformity check (Vanilla), accuracy on samples passing the explanation-conformity check (explanation-conf.) and on samples not passing the check (non explanation-conf.).\nNumbers in parentheses show the fraction of samples in each category.\nAccuracy on explanation-conformant predictions is significantly higher.\n\n\n\n|  |  |  |  |  |  |  |\n| --- | --- | --- | --- | --- | --- | --- |\n|  | \n\n|  |\n| --- |\n| Vanilla |\n\n | \n\n|  |\n| --- |\n| Explanation-conf. |\n\n | \n\n|  |\n| --- |\n| Non explanation-conf. |\n\n |\n| CIFAR-10 | 0.89 (1.00) | 0.93 (0.91) | 0.48 (0.09) |\n| Fashion-MNIST | 0.92 (1.00) | 0.99 (0.70) | 0.77 (0.30) |\n| \n\n|  |\n| --- |\n| CIFAR-100 |\n\n | 0.59 (1.00) | 0.65 (0.84) | 0.30 (0.16) |\n\n\n\n\n### \n3.1 Do MACCs provide reliable Error Estimability?\n\n\n\nWe propose and test two hypotheses related to reliable error estimability: (i) predictions that pass the MACC explanation-conformity check are more likely to be accurate, and, (ii) predictions that are not explanation-conformant might consist of inputs with high aleatoric uncertainty\u00a0[[13](#bib.bib13)] and might be more difficult for even humans to classify.\n\n\n\n\nTable\u00a0[1](#S3.T1 \"Table 1 \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") shows that on all three datasets, the prediction accuracy on explanation-conformant predictions is significantly higher than non-conformant predictions, validating our hypothesis (i).\nTo confirm our hypothesis (ii), we show images from CIFAR-10 data to human annotators at Amazon Mechanical Turk (AMT). The AMT annotators are shown an image and asked to choose the class that the image belongs to from the list of 10 classes. Each image is annotated by 30 users. Further details on the experiment can be found in Appendix\u00a0[C](#A3 \"Appendix C MACCs and error interpretability \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\").\n\n\n\n\nThe results show that for explanation-conformant images, humans are able to detect the correct class 91.25%percent91.2591.25\\%91.25 % of the time, whereas accuracy for non-conformant images is 83.19%percent83.1983.19\\%83.19 %. Moreover, the worker disagreement\u2014as measured via average Shannon Entropy\u2014is 0.220.220.220.22 and 0.390.390.390.39 for explanation-conformant, and non-conformant images. The difference in accuracy and worker agreement shows that the non explanation-conformant images are harder not only for the DNN, but also human annotators to classify. We expand on the difficulty of human annotators in Section\u00a0[3.3](#S3.SS3 \"3.3 Do MACCs provide insights into the causes of errors? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\").\n\n\n\n\n\n### \n3.2 Do MACCs defend against Error Vulnerability?\n\n\n\nWe now ask if an explanation-conformity check can help defend against adversarial perturbations.\nSpecifically, we start off with a 50%percent5050\\%50 % random subset of test images that were correctly classified by the vanilla DNN and adversarially perturb them w.r.t. Fclfsubscript\ud835\udc39clfF\\_{\\text{clf}}italic\\_F start\\_POSTSUBSCRIPT clf end\\_POSTSUBSCRIPT so that they are now incorrectly classified. We use a number of popular adversarial attacks (see Table\u00a0[2](#S3.T2 \"Table 2 \u2023 3.2 Do MACCs defend against Error Vulnerability? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")).\nNext, we check if these adversarial perturbation designed to change the class labels also resulted in a corresponding change in the detected MACCs. If that is not the case, then MACC explanation-conformity check could be used as a method to detect adversarial perturbations.\n\n\n\n\nTable\u00a0[2](#S3.T2 \"Table 2 \u2023 3.2 Do MACCs defend against Error Vulnerability? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") shows the fraction of adversarially attacked inputs that fails the MACC explanation-conformity check, revealing that the check is able to detect a vast fraction of adversarial attacks.\n\n\n\n\nWhile MACCs are able to defend against a significant proportion of attacks on class labels, a determined adversary could additionally attack the MACC detection component (Fconsubscript\ud835\udc39conF\\_{\\text{con}}italic\\_F start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT in Section\u00a0[2](#S2 \"2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")) such that not only does the class label get switched, the MACC prediction is also changed such that the explanation-conformity check is passed.\nWe now study the nature of such adversarial perturbations.\nTo perform this attack, we modify the PGD attack (details in Appendix\u00a0[D.1](#A4.SS1 \"D.1 Performing an explanation-conformant adversarial perturbation and comparison with Guo et al. [24] \u2023 Appendix D Additional experiments on Error Vulnerability \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")) such that the class labels and MACCs are changed in a consistent manner to pass the explanation-conformity check.\n\n\n\n\nTable 2: [Error Vulnerability] Attacking class labels. Fraction of adversarially perturbed inputs that fail the explanation-conformity check (meaning the adversarial attack is detected.) On CIFAR-10 and Fashion-MNIST data, >98%absentpercent98>98\\%> 98 % of the attacks are detected, except for DeepFool on CIFAR-10 where around 40%percent4040\\%40 % are detected. On CIFAR-100 data, around half of the adversarial attacks are detected.\n\n\n|  |  |  |  |  |  |  |  |  |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  | \n\n|  |\n| --- |\n| FGSM\u00a0[[21](#bib.bib21)] |\n\n | \n\n|  |\n| --- |\n| DeepFool\u00a0[[37](#bib.bib37)] |\n\n | \n\n|  |\n| --- |\n| C&W (L2)\u00a0[[9](#bib.bib9)] |\n\n | \n\n|  |\n| --- |\n| PGD\u00a0[[35](#bib.bib35)] |\n\n |\n| CIFAR-10 | 0.98 | 0.41 | 1.00 | 0.99 |\n| Fashion-MNIST | 1.00 | 0.99 | 1.00 | 1.00 |\n| \n\n|  |\n| --- |\n| CIFAR-100 |\n\n | 0.50 | 0.45 | 0.49 | 0.50 |\n\n\n\n\n\n\n![Refer to caption](/html/2007.00251/assets/x2.png)\n(a) Original Images\n\n\n\n![Refer to caption](/html/2007.00251/assets/x3.png)\n(b) PGD attack class-only\n\n\n\n![Refer to caption](/html/2007.00251/assets/x4.png)\n(c) PGD attack explanation-conf.\n\n\n\nFigure 2:  [Error Vulnerability]\nAttacking both class labels and MACCs.\nThe figure shows some randomly selected Original Images from CIFAR-10 that were correctly classified by the vanilla DNN.\nAlso shown are the perturbed images obtained by performing a conventional adversarial attack, using the PGD method\u00a0[[35](#bib.bib35)], aimed at switching the predicted class label on the input (Class-only). As is expected of such attacks\u00a0[[38](#bib.bib38), [10](#bib.bib10)], the perturbations are imperceptible to the human eye.\nFinally, we show the perturbed images where the adversarial attack not only changes the predicted class labels, but also the MACCs such that the predictions are explanation-conformant (Explanation-conf.).\nExplanation-conformant perturbations are so large that they are clearly perceptible to the human eye.\n\n\n\nWe note that the perturbation required to perform an explanation-conformant attack is significantly higher than the one required for an attack that aims to change the class label only. Specifically, while the class-only attacks in Table\u00a0[2](#S3.T2 \"Table 2 \u2023 3.2 Do MACCs defend against Error Vulnerability? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")) require a perturbation (based on L2 distance from the original image) of 0.31\u00b10.20plus-or-minus0.310.200.31\\pm 0.200.31 \u00b1 0.20 and 0.26\u00b10.14plus-or-minus0.260.140.26\\pm 0.140.26 \u00b1 0.14 on CIFAR-10 and Fashion-MNIST datasets respectively, the explanation-conformant perturbations have a magnitude of 5.31\u00b15.62plus-or-minus5.315.625.31\\pm 5.625.31 \u00b1 5.62 and 3.16\u00b12.85plus-or-minus3.162.853.16\\pm 2.853.16 \u00b1 2.85. In other words, explanation-conformant attacks require perturbations that are more than an order of magnitude larger.\n\n\n\n\nAre the perturbations still imperceptible to humans?\nWe suspect that the magnitude of the explanation-conformant perturbations is so large that they might not be imperceptible to humans anymore. Perturbations being imperceptible to humans is often considered as a major property adversarial perturbations\u00a0[[38](#bib.bib38), [10](#bib.bib10)].\nTo test this hypothesis, we set up a human survey on AMT where the humans are shown three kinds of images: (i) the original , unperturbed image, (ii) image with class-only perturbation that aims to change the predicted class label, and, (iii) the image with explanation-conformant perturbation that aims to change the predicted class label as well as predicted MACCs such that the prediction passes the explanation-conformity check. AMT workers were then asked to label if the image contained an adversarial perturbation or not. Details of the survey can be found in Appendix\u00a0[D.2](#A4.SS2 \"D.2 Human perceptibility of explanation-conformant adversarial perturbations \u2023 Appendix D Additional experiments on Error Vulnerability \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\").\n\n\n\n\nThe results show that for class-only category, humans are able to detect the images with adversarial perturbations around 49.8%percent49.849.8\\%49.8 % of the time, *i.e.*, the human accuracy is as good as a random guess. On the other hand, for images in the explanation-conformant category, the humans are able to detect the adversarially perturbed images 85%percent8585\\%85 % of the time. This vast difference in human detection accuracy shows that explanation-conformant perturbations are much more noticeable to the human eyes that class-only perturbations. Figure\u00a0[2](#S3.F2 \"Figure 2 \u2023 3.2 Do MACCs defend against Error Vulnerability? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") also shows some examples of the explanation-conformant perturbations (more examples in Appendix\u00a0[D](#A4 \"Appendix D Additional experiments on Error Vulnerability \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")). In summary, the survey shows that it is difficult to attack the MACC explanation-conformity check in a manner that is undetectable by humans. \n\n\n\n\n\n### \n3.3 Do MACCs provide insights into the causes of errors?\n\n\n\n\n\n\n\n\n|  \n\n\nHuman\n\nagreement\n  |  \n\n\n<6absent6<6< 6 MACCs\n\ndetected\n  |  \n\n\n\u22656absent6\\geq 6\u2265 6 MACCs\n\ndetected\n  |\n| --- | --- | --- |\n| \n\u226450%absentpercent50\\leq 50\\%\u2264 50 %\n | 75.4%percent75.475.4\\%75.4 % | 24.6%percent24.624.6\\%24.6 % |\n| \n>50%absentpercent50>50\\%> 50 %\n | 47.7%percent47.747.7\\%47.7 % | 52.3%percent52.352.3\\%52.3 % |\n\n\n(a) Human agreement & num. detected MACCs \n\n\n\n![Refer to caption](/html/2007.00251/assets/figures/error_explainability_survey/low_plurality_images_4.png)\n(b) Images with lowest agreement\n\n\n\nFigure 3: \n[Insights into causes of errors]\nThe table\u00a0([2(a)](#S3.F2.sf1 \"2(a) \u2023 Figure 3 \u2023 3.3 Do MACCs provide insights into the causes of errors? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")) shows that images with less human agreement also tend to have few detected MACCs.\nThe figure\u00a0([2(b)](#S3.F2.sf2 \"2(b) \u2023 Figure 3 \u2023 3.3 Do MACCs provide insights into the causes of errors? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")) shows the images with lowest human agreement.\nFor more examples and details, see Appendix\u00a0[C](#A3 \"Appendix C MACCs and error interpretability \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\").\n\n\n\nInspired by the insight in Section\u00a0[3.1](#S3.SS1 \"3.1 Do MACCs provide reliable Error Estimability? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") that even humans tend to make more errors on non explanation-conformant inputs, we now further explore these cases.\n\n\n\n\nSpecifically, we note that some non explanation-conformant inputs consists of cases where Fconsubscript\ud835\udc39conF\\_{\\text{con}}italic\\_F start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT is able to detect very few MACCs (see Appendix\u00a0[C.3](#A3.SS3 \"C.3 Human Experiment Results \u2023 Appendix C MACCs and error interpretability \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") for a full distribution).333An explanation-conformant prediction, with tcon=1subscript\ud835\udc61con1t\\_{\\text{con}}=1italic\\_t start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT = 1 in CIFAR-10 data would mean that Fconsubscript\ud835\udc39conF\\_{\\text{con}}italic\\_F start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT detects 9 exactly MACCs in the input. See Appendix\u00a0[A](#A1 \"Appendix A Implementation details and reproducibility \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") for details on MACCs for each class.\nThis means that the DNN is struggling to identify concepts related to any class in the input. We hypothesize that low concept detection rate might mean that these inputs might consist of cases where even humans might find it hard to identify the class of the image.\n\n\n\n\nTo test this hypothesis, we divide the non explanation-conformant images from the annotation task described in Section\u00a0[3.1](#S3.SS1 \"3.1 Do MACCs provide reliable Error Estimability? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") into different categories based on the (dis)agreement between human annotators. The agreement here is measured as the fraction of the votes obtained by the class with most votes. Hence, an agreement value of 1.01.01.01.0 means that all humans annotated the image with the same class, whereas a value of 0.10.10.10.1 means that the most-voted-for class received votes that are no better than a random assignment (as the CIFAR-10 dataset consists of 10 classes).\n\n\n\n\nNext, we divide the images into two categories: images where <6absent6<6< 6 MACCs were detected and where \u22656absent6\\geq 6\u2265 6 MACCs were detected.\nFigure\u00a0[2(a)](#S3.F2.sf1 \"2(a) \u2023 Figure 3 \u2023 3.3 Do MACCs provide insights into the causes of errors? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") shows the relative fraction of these two categories against the human agreement.\nThe figure shows that the images with small degree of agreement tend to mostly consist of cases where very few (<6absent6<6< 6 MACCs) are detected.\nSpecifically, out of the images with less or equal to 50%percent5050\\%50 % agreement, 75.4%percent75.475.4\\%75.4 % of them have 5555 or less MACCs detected.\nFigure\u00a0[2(b)](#S3.F2.sf2 \"2(b) \u2023 Figure 3 \u2023 3.3 Do MACCs provide insights into the causes of errors? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") shows the images with lowest human agreement.\n\n\n\n\nThese results show that detection of very few MACCs in an image correlates with the fact that even human judges (who are often the source of ground truth in image classification tasks) would find it difficult to classify these images. Hence, MACCs can serve as a useful tool to pinpoint problematic inputs in the data. However, we do note that MACCs are not able to explain causes of errors for all the misclassified inputs, rather they only explain errors for a certain category of the data (with very few concepts detected).\n\n\n\n\n\n### \n3.4 Discussion\n\n\n\nThe results show that MACCs can be used to perform explainability checks that significantly enhance predictions\u2019 robustness along a wide range of measures. In this section, we discuss some more pertinent points related to the implementation of MACCs.\n\n\n\n\nEffect of varying t\ud835\udc1c\ud835\udc28\ud835\udc27subscript\ud835\udc61\ud835\udc1c\ud835\udc28\ud835\udc27t\\_{\\text{con}}italic\\_t start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT.\nAs described in Section\u00a0[2](#S2 \"2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\"), varying tconsubscript\ud835\udc61cont\\_{\\text{con}}italic\\_t start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT can be thought of as a flexible parameter to fine-tune prediction robustness.\nWe further investigate the effect of tconsubscript\ud835\udc61cont\\_{\\text{con}}italic\\_t start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT on the fraction of samples deemed explanation-conformant and the prediction accuracy on these samples. Results in Appendix\u00a0[B](#A2 \"Appendix B MACC fine-tuning & comparison to calibration methods \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") shows that increasing tconsubscript\ud835\udc61cont\\_{\\text{con}}italic\\_t start\\_POSTSUBSCRIPT con end\\_POSTSUBSCRIPT leads to more samples being marked as explanation-conformant, however, the classification accuracy on explanation-conformant samples decreases.\n\n\n\n\nOther methods for assessing prediction robustness.\nWe also compare the robustness estimates obtained using the MACC explanation-conformity check with the more traditional method of probability calibration.\nSpecifically, we use the temperature scaling method of\u00a0Guo et\u00a0al. [[24](#bib.bib24)] to calibrate the softmax probabilities.444We use the implementation provided by the authors: <github.com/gpleiss/temperature_scaling>\nWe then predictions to be robust if the (calibrated) predicted class probability is above X\ud835\udc4bXitalic\\_X, where X\ud835\udc4bXitalic\\_X is chosen such that the same fraction of predictions are marked robust as by our method in Table\u00a0[1](#S3.T1 \"Table 1 \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\").555Comparison with more thresholds reveals similar insights. Details in Appendix\u00a0[B](#A2 \"Appendix B MACC fine-tuning & comparison to calibration methods \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\").\n\n\n\n\nThe comparison reveals that (i) both the robustness check based on calibrated probabilities and the MACC explanation-conformity check achieve comparable performance in terms of the tradeoff between predictions marked robust and classification accuracy on these predictions, however, (ii) the calibration method leads to much lower performance in terms of Error Vulnerability, *i.e.*, the amount of perturbation required to pass the calibration robustness check is almost an order of magnitude smaller. More details on the comparison can be found in Appendix\u00a0[D](#A4 \"Appendix D Additional experiments on Error Vulnerability \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\").\n\n4 Related work\n---------------\n\n\n\nMost prior approaches to DNN explainability and robustness operate by identifying important features, concepts, or training data instances\u00a0[[40](#bib.bib40), [11](#bib.bib11), [23](#bib.bib23), [14](#bib.bib14), [43](#bib.bib43), [31](#bib.bib31), [26](#bib.bib26), [27](#bib.bib27), [7](#bib.bib7), [15](#bib.bib15)].\nThe main differences between these studies and our approach is that we target a specific application of concept explainability, *i.e.*, the explanation-conformity check, and automate the robustness assessment procedure.\n\n\n\n\nA line of work closely related to ours is that of concept-based explanations.\nKim et\u00a0al. [[28](#bib.bib28)] propose a method to evaluate how important a user-defined concept is in predicting a specific class.\nYeh et\u00a0al. [[45](#bib.bib45)] propose ways to find concepts that are enough to explain a given prediction.\nGhorbani et\u00a0al. [[20](#bib.bib20)] proposed ways to automatically extract concepts from visual data while Bouchacourt and Denoyer [[8](#bib.bib8)] proposed a similar approach for textual data.\nGoyal et\u00a0al. [[22](#bib.bib22)], Shi et\u00a0al. [[42](#bib.bib42)] focus on identifying human-interpretable concepts that have causal relationships with model\u2019s predictions.\nHowever, none of these methods proposes automation of explanation-conformity checks.\n\n\n\n\nSome recent studies\u00a0\u00a0[[44](#bib.bib44), [19](#bib.bib19)] have focused on linking explainability and adversarial robustness.\n\u00a0Ghorbani et\u00a0al. [[19](#bib.bib19)] show that saliency map based explanations are easy to fool via adversarial attacks. On the other hand, MACCs are quite resistant to adversarial perturbations\n(Section\u00a0[3.2](#S3.SS2 \"3.2 Do MACCs defend against Error Vulnerability? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")).\n\u00a0Tao et\u00a0al. [[44](#bib.bib44)] propose an explanation-based check to detect adversarial perturbations. However their approach is limited to hand-crafted features and\nis specialized for facial recognition,\nwhereas our approach can be extended to more general image recognition tasks and also other classification tasks.\n\n\n\n\nPrediction robustness has also been studied in the context of calibration and prediction uncertainty\u00a0[[34](#bib.bib34), [24](#bib.bib24), [16](#bib.bib16), [12](#bib.bib12), [17](#bib.bib17)].\nEmpirical comparison with a recent calibration technique\u00a0[[24](#bib.bib24)] shows that while the robustness check based on this technique provides comparable accuracy,\nMACCs are far more robust to adversarial perturbations (Section\u00a0[3.4](#S3.SS4 \"3.4 Discussion \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")), and additionally help provide insights into the causes of errors (Section\u00a0[3.3](#S3.SS3 \"3.3 Do MACCs provide insights into the causes of errors? \u2023 3 Evaluation of the robustness framework \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")).\nMoreover, unlike many prior works in this line of research, *e.g.*, [[34](#bib.bib34), [17](#bib.bib17)], our proposed framework can be easily plugged into an existing trained model in a post-hoc manner.\n\n\n\n\nFinally, MACCs also share some similarities with redundant output encoding and error correcting output codes (ECOC)\u00a0[[5](#bib.bib5), [18](#bib.bib18)]. However, unlike MACCs, ECOCs do not provide an explanation-conformity check with a built-in reject option.\n\n5 Conclusion, limitations\n& future work\n----------------------------------------\n\n\n\nIn this work, we proposed a robustness assessment framework that uses Machine-checkable Concepts, or MACCs, to automate the end-to-end process of performing explanation-conformity checks.\nThe automation means that our framework can be scaled to a large number of classes.\nMACCs partly achieve this scalability by focusing on a specific explainability desideratum\u2014*i.e.*, assessment of prediction robustness\u2014and potentially sacrificing some other desiderata (details in Section\u00a0[1](#S1 \"1 Introduction \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\")).\nExperiments and human-surveys on several real-world datasets show that\nthe MACC explanation-conformity check facilitates higher prediction accuracy (on predictions passing the explanation-conformity check), adds resistance to adversarial perturbations, and can also help provide insights into the source of errors.\n\n\n\n\nOur work opens several avenues for future work: For now, MACCs are defined such that they are shared between all images of the same class.\nA useful follow-up would be to consider multiple sets of MACCs per class to account for intra-class variability.\nMoreover exploring the MACC pruning strategies, analyzing the effect of the number of MACCs on the robustness, and\na deeper exploration of the tradeoffs provided by different training methodologies mentioned in Section\u00a0[2](#S2 \"2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") (post-hoc, joint, or a combination) are also promising future directions.\n\n\n\n\nWe believe that our work has potential to provide significant positive impact for the society. As machine learning models are deployed in a wide array of real-world domains, the issue of prediction robustness has become increasingly relevant. The ability of our methods to provide improved uncertainty estimates, offer resistance to adversarial perturbations, and the capability to potentially debug the model errors is a useful tool for many societal applications. Examples of these applications include image search in online databases and driver-assistance systems in the automotive domains.\n\n\n\n\nOn the flip side, our methods are evaluated empirically and do not come with theoretical performance guarantees. As a result, appropriate care should be applied before using them in critical life-affecting domains. An analysis exploring the performance guarantees remains an important future research direction.\n\n\n\n\nMost of the prior work on concept-based explanations restricts itself to concepts that can be explicitly named by humans (see Section\u00a0[2.2](#S2.SS2 \"2.2 Discussion: Salient properties of MACCs \u2023 2 Methodology \u2023 Unifying Model Explainability and Robustness via Machine-Checkable Concepts\") for a discussion). Our framework represents a departure from this restriction, and places more emphasis on machine-checkability (much like the line of work on machine-checkable theorem proving\u00a0[[47](#bib.bib47)]). As a result, while our machine-checkable concepts (MACCs) are able to meet the goal that they were designed for, it should be noted that they may not fulfil some other explainability criteria\u00a0[[15](#bib.bib15), [6](#bib.bib6), [32](#bib.bib32)]. Combining machine-checkability with human-interpretability would be a worthwhile future research direction.\n\n6 Acknowledgements\n-------------------\n\n\n\nDickerson and Nanda were supported in part by NSF CAREER Award IIS-1846237, DARPA GARD #HR00112020007, DARPA SI3-CMD #S4761, DoD WHS Award #HQ003420F0035, and a Google Faculty Research Award. This work was supported in part by an ERC Advanced Grant \u201cFoundations for Fair Social Computing\u201d (no. 789373).", "url": "https://arxiv.org/abs/2007.00251"}
{"text": "1 Introduction\n---------------\n\n\n\nThere is a vast and ever-growing body of information about the oceans;\nclearly, society can benefit from artificial intelligence (AI) systems that provide services based on such information.\nAt the same time, the ocean offers the perfect domain in which to test\nthese systems, given the wealth of background knowledge one must handle when\nprocessing ocean data. In this paper, we describe our preliminary efforts\ntowards an \u201cartificial brain\u201d focused on this domain. Admittedly, the word \u201cbrain\u201d is a rather ambitious one, and the reader\nwill notice that our current results do not authorize us to use this word\nwith impunity. In any case, our goals are indeed ambitious:\nwe wish to build an architecture that encapsulates a number of complex and interconnected services concerning ocean knowledge, from question answering to time series analysis.\nOur goal with this is to foster awareness about oceanographic issues \u2014 from biodiversity to food supply, from energy resources to climate forecasts.\n\n\n\n\n\nIt would not be wise to expect that a computational brain could handle questions over\nthe whole ocean; we thus focus on a specific part of it,\nnamely the Brazilian maritime territory.\nThis is a vast region of the South Atlantic, covering a few million\nsquare kilometers, as indicated in Figure\u00a0[1](#S1.F1 \"Figure 1 \u2023 1 Introduction \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\").\nApproximately as big as the Amazon rainforest, this region is often referred to as the *Blue Amazon*.\nFigure [1](#S1.F1 \"Figure 1 \u2023 1 Introduction \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\") depicts the\nBrazilian territorial waters (up to 12 nautical miles from land),\nthe Brazilian exclusive economic zone (up to 200 nautical miles)\nover which Brazil has sea and air sovereignty (the official Blue Amazon), and additional\nterritory of the continental shelf under discussion at the United Nations [[4](#bib.bib3 \"Amaz\u00f4nia azul\")].\nThe Blue Amazon carries 95% of Brazil\u2019s international trade and holds almost all of the country\u2019s (quite large) oil (95%) and gas (80%) reserves [[12](#bib.bib4 \"Encarte de consolida\u00e7\u00e3o da produ\u00e7\u00e3o 2021: boletim da produ\u00e7\u00e3o de petr\u00f3leo e g\u00e1s natural\")]. The region is also a vital source of food supply and a key player in climate regulation [[1](#bib.bib5 \"Brazilian coastal and marine protected areas importance, current status and recommendations\")].\n\n\n\n\nYet the Blue Amazon is not well-known to the wider public or even to those living in the coastal region of Brazil. Information about it is dispersed in academic volumes and government reports, or in obscure databases.\nAs such, the Brazilian maritime territory offers a perfect\ndomain for research on a variety of artificial intelligence themes:\ninstead of relying on\ncurated and worn-out information, say in Wikipedia, a Blue Amazon brain\nmust go through a maze of scattered information to come up with\nuseful information to users. Obviously, this state of affairs makes our\ngoals even more challenging and requires us to move in small steps.\n\n\n\n![The Blue Amazon (extracted from ](https://media.arxiv-vanity.com/render-output/7182053/x1.png)\nFigure 1: The Blue Amazon (extracted from [[42](#bib.bib20 \"The blue amazon: brazil asserts its influence across the atlantic\")]).\n\n\nIn this paper, we report the steps we have already taken towards\nour BLue Amazon Brain (a system we refer to as BLAB).\nIn essence, we envision an architecture that encompasses a number of complex and interwoven services. The most important of these is a conversational agent that can take user requests,\nfrom naive questions to highly technical issues,\nand return relevant and accurate results.\nA key feature of this agent is responding to questions in a way that goes beyond\nmere reproduction of stored templates.\nSuch a question answering ability can be used to satisfy particular user\nneeds but also, more broadly, to educate the public about the domain.222One\nmight note the CliMate conversational agent at\n<https://davidsuzuki.org/climate-conversation-coach/>; another\nexample is the SaveEcoBot that carries information about air quality at\n<https://www.saveecobot.com/us>; in the Portuguese language, one can\nfind for instance the agent AGATA on water and energy waste [[17](#bib.bib23 \"\u00c1gata: um chatbot para difus\u00e3o de pr\u00e1ticas para educa\u00e7\u00e3o ambiental\")]\nand PipaBot on environmental pollutants [[9](#bib.bib12 \"PipaBot: um canal de comunica\u00e7\u00e3o para o pipa ufrj\")].\nOther useful services of BLAB are an automated news generator and a Blue Amazon wiki; additional\nservices are planned for the future.\nWe also envision systems that can provide services\nsuch as predictions based on metocean data.\nHopefully, BLAB can help solidify a conviction\nabout the importance of the ocean to human life.\n\n\n\n\nThe main contributions of this paper are: a formal description of BLAB\u2019s architecture; an assessment of the natural language processing (NLP) modules we have developed so far, their main\nlimitations and our planned future developments; and a description of the resources we have created in connection with the ocean and in particular with the Blue Amazon.\n\n\n\n\n\nThe paper is organized as follows: Section [2](#S2 \"2 An Overview of BLAB \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\") offers an overview of BLAB\u2019s architecture. Section [3](#S3 \"3 Task-oriented NLP modules \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\") goes over the specific NLP modules and\nSection [4](#S4 \"4 Resources \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\") describes the resources we have developed so far. Section [5](#S5 \"5 Conclusion: Lessons Learned, Future Work \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\") concludes the paper with a summary of the challenges we have learned so far and the next steps we plan to give.\n\n\n\n![BLAB\u2019s overall architecture.](https://media.arxiv-vanity.com/render-output/7182053/x2.jpg)\nFigure 2: BLAB\u2019s overall architecture.\n\n\nThis project is hosted by the Center for Artificial Intelligence (C4AI),333Information at <http://c4ai.inova.usp.br/>.\na large research center, headquartered at the Universidade de S\u00e3o Paulo, that congregates\nresearchers and students from a wide variety of fields. A broader goal of this project\nis to investigate how AI can benefit simultaneously\nfrom data and knowledge-driven approaches.\n\n2 An Overview of BLAB\n----------------------\n\n\n\nFigure [2](#S1.F2 \"Figure 2 \u2023 1 Introduction \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\") presents an overview of BLAB\u2019s architecture.\nBLAB has three main components, namely a portal, a set of\nreasoners, and a set of resources.\nOriginally, the portal was developed solely as a way of testing and validating\nthe conversational agent. The portal was later expanded to encompass a number of other services related to the Blue Amazon, serving as a tool for disseminating knowledge on this domain to a wide audience.\n\n\n\n\nCurrently, the portal offers preliminary versions of three services: a conversational agent (BLAB-Chat), a wiki (BLAB-Wiki), and a news reporter (BLAB-Reporter). The conversational agent is managed by a central controller that calls several NLP modules in order to process requests. These modules can be roughly divided in two categories: reasoners, which are directly\nconnected to the dialogue process, working on the inputs received from the user (e.g., question answering system); and harvesters, responsible for pre-processing and structuring data (e.g., multi-document summarizer). To process data, the reasoners have access to a data lake, containing data from multiple sources and of different types, structured and non-structured, such as textual documents and relational databases,\nas well as to third-party services. The other two services, the reporter and the wiki, work independently. The BLAB-Reporter collects structured data from databases and generates reports based on them in natural language; it also summarizes news from the web. The BLAB-Wiki is our content-specific encyclopedia; it can be directly accessed by users through the website and is also mirrored in the data lake to serve as an expert information source for reasoners. \n\n\n\n\nFrom a technical standpoint, the operation of BLAB depends on a service-oriented infrastructure (back-end) and on a web interface (front-end) that accommodates multiple services and promotes user interaction. The next subsections present information about both BLAB layers, along with brief descriptions of the proposed web services.\n\n\n\n\n\n### \n2.1 BLAB back-end\n\n\n\nBLAB\u2019s central controller is responsible for managing the communication between pairs of components. The controller is part of the back-end server, which we have implemented in Python using Django; thus, any SQL engine supported by Django (such as PostgreSQL and MySQL) can be used to manage data. The communication with clients is made through REST APIs and WebSockets created with Django REST Framework and Django Channels, respectively.\n\n\n\n\nCurrently, the controller\u2019s role is to manage, mainly, services related to the dialog web application (chatbot).\nHowever, its service-oriented architecture guarantees flexibility and maintainability, and simplifies the addition of new modules to the system.\nOur team plans, for example, to implement a framework for interactive maps with geo-referencing; the idea is to integrate this service with other BLAB reasoners, such as a tide predictor and a vessel tracker. \n\n\n\n\nBesides the controller, the back-end architecture contains a data lake for loading and storing files. The management is performed by a tool that updates files and folders from Google Drive folders. The data lake stores data from various sources in their original format, from which system components may request specific files (extract-load-transform process). Ideally, when more data becomes available, data conversion routines will allow the direct access of processed data by the component systems (extract-transform-load process).\n\n\n\n\n\n\n### \n2.2 BLAB front-end\n\n\n\nPublic access to BLAB\u2019s features is done through a web interface to provide a portal of intelligent services for the dissemination of information about the Blue Amazon. It was developed to allow the integration of new services on demand. Currently, it hosts preliminary versions of three services: a chatbot, a robot reporter, and a wiki, all specialized in Blue Amazon. Pieces of an interface screenshot can be seen in Figure\u00a0[3](#S2.F3 \"Figure 3 \u2023 2.2 BLAB front-end \u2023 2 An Overview of BLAB \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\"). These services are currently available only for internal testing.\n\n\n\n![On the left: emphasis on BLAB Portal. Next images, in sequence: BLAB-Chat, BLAB-Reporter and BLAB-Wiki.](https://media.arxiv-vanity.com/render-output/7182053/figures/interface_v2.png)\nFigure 3: On the left: emphasis on BLAB Portal. Next images, in sequence: BLAB-Chat, BLAB-Reporter and BLAB-Wiki.\n\n\nThe interface conception considered four fundamental requirements to provide good user experience while interacting with BLAB. These requirements are: (i) internationalization; (ii) modularity; (iii) maintainability; and (iv) accessibility. Having an interface compliant with them, we guarantee: (i) its use by speakers of different languages; (ii) and (iii) easy integration of new services and maintenance of the existing ones due to the adoption of a code style organization and associated documentation; and (iv) universal access to BLAB services, independently of user limitations.\n\n\n\n\nTechnically, the web interface has been developed with the React library, along with the MUI component library. These libraries simplify the development process, as they allow to generate dynamic single-page applications through the exclusive use of Javascript and pre-supplied templates. To facilitate internationalization, the interface uses the i18next-react444<https://react.i18next.com/> framework, which simplifies the translation of textual elements of the website into different languages, by simply providing their translation in JSON files. To comply with accessibility standards, the four basic principles established by by WCAG have been adopted.555<https://www.accessibility.works/blog/2022-ada-wcag-website-accessibility-standards-requirements/> Such principles state that a website must be perceptible, operable, understandable, and robust. Perceptibility means that all users must perceive web interface elements with their senses, which involves creating presentable content in ways that facilitate perception, such as providing alternative texts for non-text content. To guarantee operability, the interface cannot require interactions that a user cannot perform, so one requirement is to allow the use of all possible functionalities from a keyboard. Understandability requires all information to be understandable; i.e., text must be readable and clear, and content must be presented predictably. Finally, robustness requires that content must be interpretable by a variety of user agents, including assistive technologies such as screen-reading tools. Our efforts have complied with these principles.\n\n\n\n\n\n### \n2.3 BLAB web services\n\n\n\nThree web services are currently in operation in the BLAB web interface. Details on each of them are provided below. \n\n\n\n\n#### BLAB-Reporter:\n\n\n\nThe main goal of BLAB is to raise public awareness of ocean-related issues, thus affecting how the population perceives and interacts with the environment. One way to do that is by reporting news about the oceanic domain [[43](#bib.bib68 \"Ocean literacy within the United Nations Decade of Ocean Science for Sustainable development: a framework for action\")]. Unfortunately, most data-stream sources are available only in numerical or machine-readable formats, preventing wider audiences to understand them. To overcome that, we designed the BLAB-Reporter,666<https://twitter.com/BLAB_Reporter> an application that\ncollects data related to the Blue Amazon and publishes it on Twitter in natural language,\nand we integrated it with BLAB Portal. The use of Twitter aims to bring this marine-related content to broader audiences.\nThe\nBLAB-Reporter produces tweets with news through a traditional natural language generating pipeline (details are available in Section\u00a0[3](#S3 \"3 Task-oriented NLP modules \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\")) using accurate real-world data. For future development, we plan to add other discourse intentions to the automated journalist, such as fishing activity watching, oil extraction, spills monitoring, and endangered marine species tracking.\n\n\n\n\n\n#### BLAB-Wiki:\n\n\n\nBLAB provides a service to access our Blue Amazon wiki (still in a preliminary version). The content is stored in the internal data lake and is mirrored through a web view. The purpose of the wiki in BLAB\u2019s architecture is twofold: disseminating knowledge through BLAB Portal, and serving as an important resource for providing content to BLAB reasoners (Subsection [4.2](#S4.SS2 \"4.2 BLAB-Wiki \u2023 4 Resources \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\")).\n\n\n\n\n\n\n#### BLAB-Chat:\n\n\n\nBLAB\u2019s portal provides a generic chat service framework that supports many types of messages (e.g., text, voice recording, file attachment), as well as basic chat features such as timestamps and message quoting; this is also in a preliminary version.\nThe chatbot, whose chatting features rely on IBM\u2019s Watson Assistant,\nis responsible for collecting answers from the QA modules (discussed later) and shipping\nthem to the portal.777Note that IBM Watson is a computer system developed by IBM Research with the aim of competing on the American TV show Jeopardy against human contestants in real time [[15](#bib.bib70 \"Building Watson: an overview of the DeepQA project\")];\nit led to the development of IBM Watson Assistant (<https://cloud.ibm.com/catalog/services/watson-assistant>), a service that allows the creation of conversational agents that can be embedded in any application.\n\n3 Task-oriented NLP modules\n----------------------------\n\n\n\nThe backbone of BLAB is a conversational agent, the BLAB-Chat. Its goal is to directly engage with users, raising their interest and understanding about the Blue Amazon. As mentioned in Section [2](#S2 \"2 An Overview of BLAB \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\"), BLAB also includes a reporter functionality that publishes tweets. Both the conversational agent and the reporter need to understand and generate natural language to properly interact with users.\nThus, to endow BLAB with natural language processing capabilities, we have developed a set of NLP modules,888Available at <https://github.com/C4AI>. which can be broadly divided into reasoners and harvesters.\nReasoners work with the controller directly, providing the required information to the chatbot and the reporter. Currently, this group of modules comprise a natural language generator; a natural language to structured query language (NL2SQL) translator; an open question answering (QA) system; and a third-party service to implement the dialog flow, Watson Assistant from IBM. Harvesters create and structure content about the Blue Amazon domain; this may be done in real time, when called by reasoners, or by directly feeding the data lake. This set of modules is currently formed by a knowledge graph generator; an unsupervised topic model builder; a multi-document summarization module; and a paraphraser. \n\n\n\n\n### \n3.1 BLAB Reasoners\n\n\n\nIn this subsection, we present a brief summary of the existing reasoners.\n\n\n\n\n#### Natural language generator:\n\n\n\nMost information about the Blue Amazon can be found in structured databases or in unstructured data repositories. These data may be used to feed systems which automatically generate reports [[36](#bib.bib64 \"DaMata: A Robot-Journalist Covering the Brazilian Amazon Deforestation\")]. BLAB-Reporter is a data-to-text natural language generation model that publishes real-time recurrent content in a human-readable fashion [[14](#bib.bib19 \"Neural data-to-text generation: a comparison between pipeline and end-to-end architectures\")], by acquiring data from various web sources (information concerning marine and coastal weather, tide charts, marine vessel traffic, and news regarding the Blue Amazon). To prepare content for publication, the system follows a pipeline with six steps: content selection; discourse ordering; text structuring; lexicalization; referring expression generation; and textual realization. Through these steps, the original non-linguistic data passes through a series of intermediate representations, selecting relevant information, organizing it in logical order, determining the proper lexical choices, until finally rendering the text in its final form [[6](#bib.bib9 \"Towards Fully Automated News Reporting in Brazilian Portuguese\")]. These steps follow a template-based format and draw their choices from a list of possibilities built from annotated examples. The use of a rule-based approach ensures high-fidelity for numerical report texts; however, this is done at the expense of textual diversity. To overcome that limitation, we are working on data-driven approaches to the lexicalization and referring expression generation steps of the pipeline. Our aim with that is to provide greater variability and fluency to the text, thus enhancing audience engagement.\n\n\n\n\n\n\n#### NL2SQL translator:\n\n\n\nStructured data can be naturally organized in relational databases. For this type of data, SQL offers an efficient approach for information retrieval. A conversational agent that is able to translate query-type user interactions into SQL statements can recover faster and more robust answers.\nTo implement this sort of interaction, BLAB includes a module that translates natural language into SQL. Our approach is based on the RAT-SQL+GAP\u00a0[[39](#bib.bib56 \"Learning contextual representations for semantic parsing with generation-augmented pre-training\")] architecture, which joins two components: the Relation-Aware Transformer SQL (RAT-SQL)\u00a0[[44](#bib.bib57 \"RAT-SQL: Relation-aware schema encoding and linking for text-to-SQL parsers\")], which encodes the relations between a natural language request and a domain-oriented database schema; and the Generation-Augmented Pre-training (GAP), a BART model [[22](#bib.bib32 \"Bart: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension\")] pretrained for SQL and text-related tasks, and then specifically fine-tuned for NL2SQL using RAT-SQL.\n\n\n\n\nWhen developing the NL2SQL translator for BLAB, we faced the challenge of working with Portuguese, for which no model was yet available. Thus, our work focused mainly on the adaptation of the RAT-SQL+GAP architecture to Portuguese. This required the implementation of UTF-8 encoding in the RAT-SQL component, in order to support characters from languages other than English, as well as multilingual models such as mBART-50\u00a0[[41](#bib.bib38 \"Multilingual Translation with Extensible Multilingual Pretraining and Finetuning\")] and mT5\u00a0[[45](#bib.bib44 \"MT5: a massively multilingual pre-trained text-to-text transformer\")]. We named this language-agnostic model mRAT-SQL. With these adaptations, we were able to fine-tune our model to Portuguese [[20](#bib.bib42 \"MRAT-sql+gap: a portuguese text-to-sql transformer\")]. In addition, we applied a data augmentation strategy based on back-translations of the RAT-SQL+GAP training dataset into several languages. Finally, in order to promote an integration with a QA system, we trained a text classifier using BERTimbau\u00a0[[40](#bib.bib62 \"BERTimbau: pretrained bert models for brazilian portuguese\")], a pre-trained BERT [[10](#bib.bib16 \"Bert: pre-training of deep bidirectional transformers for language understanding\")] model for Portuguese. This classifier produced good results in distinguishing types of questions\u00a0[[21](#bib.bib26 \"Integrating Question Answering and Text-to-SQL in Portuguese\")]. We are currently working to fully attach it to BLAB\u2019s architecture, so it can differentiate questions by type and send them to the appropriate QA modules.\n\n\n\n\n\n\n#### QA system:\n\n\n\nThe first module developed for BLAB was an end-to-end question answering module, called DEEPAG\u00c9 [[5](#bib.bib14 \"DEEPAG\u00c9: answering questions in portuguese about the brazilian environment\")]. Given a question in Portuguese, this module is able to traverse a corpus of documents and gather relevant information, returning\nan appropriate answer in the same language. To choose the best architecture for the QA system, we compared several combinations of BM25 [[35](#bib.bib59 \"The probabilistic relevance framework: BM25 and beyond\")], a sparse retriever, and PTT5 [[7](#bib.bib10 \"PTT5: pretraining and validating the t5 model on brazilian portuguese data\")], a T5-based [[32](#bib.bib54 \"Exploring the limits of transfer learning with a unified text-to-text transformer\")] reader pre-trained on Portuguese textual databases: a retriever-only system (BM525); a reader-only system (PTT5); and a dual system (BM25 + PTT5). We also experimented pre-trained and fine-tuned versions of PTT5. In the dual system, the retriever component is responsible for inspecting the corpus and finding the k most relevant documents to answer a user\u2019s query, and the reader component is responsible for turning these k documents into a final answer. The QA fine-tuning of PTT5 was done with questions from PAQ, a massive open domain QA dataset with 65M question-answer pairs (QA-pairs) [[23](#bib.bib33 \"PAQ: 65 million probably-asked questions and what you can do with them\")], filtered for questions related to Brazil\u2019s environment based on a set of hand-crafted regular expressions. The process resulted in a QA dataset with 14K instances, which were translated into Portuguese with the Google Translation API. As for the reader, we assembled our own corpus of documents. For that, we downloaded and filtered all articles in the category \u201cEnvironment of Brazil\u201d from the Wikipedia in Portuguese (17K articles), and scraped Brazil\u2019s three biggest newspapers within a window of three and a half years, using relevant keywords to find articles on environment (29K articles). As expected, the best result was achieved by the dual system, whose reader component has been fine-tuned on our dataset.\nThis result shows the importance of having a corpus and a QA dataset focused on the Blue Amazon, as well as the gains of fine-tuning PTT5 for questions within this domain. After developing DEEPAG\u00c9, we fine-tuned it on our Blue Amazon-oriented corpus and QA dataset, Pir\u00e1 2.0 (Section [4](#S4 \"4 Resources \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\")).\n\n\n\n\n\n\n\n### \n3.2 BLAB Harvesters\n\n\n\nIn this subsection, we present a brief summary of existing harversters.\n\n\n\n\n#### Knowledge graph generator:\n\n\n\nKnowledge graphs represent entities and the relationships between them. Their usefulness comes from the fact that they provide a defined and direct way of encoding knowledge as a network, which can then be traversed and expanded in a straightforward manner. This makes knowledge graphs useful for enriching QA systems, in which questions provide a starting point and directions, and answers must be found elsewhere within the knowledge base [[19](#bib.bib29 \"What is a knowledge graph?\")]. In the context of BLAB, our intention is to create one or more consistent knowledge graphs from the various independent documents stored in the data lake. The resulting graphs may be used as a first step in formalizing knowledge, such as in an ontology, or as a more transparent way to inspect symbolic representations and reasoning steps.\n\n\n\n\nWe have developed a knowledge graph generator that can be viewed as an extension of AutoKG [[47](#bib.bib2 \"Constructing a knowledge graph from unstructured documents without external alignment\")]. This method comprises four steps. First, sets of triples in the format \u27e8subject, relation, object\u27e9 are extracted from the documents in the corpus through the OpenIE annotator [[2](#bib.bib46 \"Open information extraction from the web\")]. Second, a graph is built for each individual document by going through the triples and identifying entities that can be understood as synonyms (this identification is done by comparing contextual embeddings generated with BERT for each of the entities in the triples). Third, graphs are narrowed down by reducing the group of synonyms to the most recurring entity. Fourth, entities in separate graphs are linked together through the comparison of word embeddings. In the latter step, links between entities are not treated as synonyms, but as \u201cbridges\u201d between different contexts (i.e., documents).\n\n\n\n\n\n\n#### Unsupervised topic model builder:\n\n\n\nThe documents in our knowledge bases go over a wide variety of topics. Treating them as a single block is an ineffective, and perhaps unfeasible, strategy. An alternative to that is using some sort of clustering procedure to model topics of interest, which can offer clues on which documents to look when a specific subject appears on the chatbot agenda.\n\n\n\n\nIn order to model such topics, we employed a co-clustering method. Besides discovering additional information in the form of the co-cluster structures, co-clustering algorithms can frequently find better clusters than standard one-sided clustering techniques [[11](#bib.bib17 \"Information-theoretic co-clustering\")]. Non-negative Matrix Tri-Factorization (NMTF) [[46](#bib.bib69 \"Orthogonal nonnegative matrix tri-factorization for co-clustering: multiplicative updates on stiefel manifolds\")] was chosen as our co-clustering algorithm, due to its simplicity, performance and frequent use in textual analysis [[37](#bib.bib60 \"Word co-occurrence regularized non-negative matrix tri-factorization for text data co-clustering\")]. NMTF was carried out on the set of abstracts of Pir\u00e1 dataset. After co-clustering, the factor matrices were post-processed to achieve additional semantic explanations to the co-cluster structure by interpreting row and column clusters, and their association, as document and word clusters respectively (cf. suggested in [[8](#bib.bib13 \"OvNMTF algorithm: an overlapping non-negative matrix tri-factorization for coclustering\")]). This procedure resulted in each abstract being assigned to a topic which can be summarized by a set of words, allowing us to interpret the underlying material that composes the supporting texts of Pir\u00e1.\n\n\n\n\nAssociating a text with a topic considerably speeds up the retrieval of documents and specializes the knowledge derived from them. For a real-time operation, such as a conversation, this may represent a considerable time reduction and the construction of more precise answers. The effects of using topic modeling on the accuracy and efficiency of reasoners are part of the next testing steps in BLAB\u2019s development. Still, there is considerable room for future exploration in our approach. For instance, the co-clusters structures can be used to analyze overlaps between clusters to show relations between topics; or to measure how representative the associations between words and documents within a topic are,\nopening an opportunity to suggest the basis for argumentation for a debater module.\n\n\n\n\n\n#### Multi-document summarizer:\n\n\n\nEven when documents are organized into smaller groups, scanning full texts may still represent a considerable problem. Larger documents, such as books, may contain hundreds of thousands of words. Then, not only unnecessary time may be spent in irrelevant parts, but QA models may simply drown with that amount of information. Thus, in order to dispose information about the Blue Amazon in a more concise format, we developed a multi-document abstractive summarization model for Portuguese called PLSUM [[29](#bib.bib51 \"PLSUM: generating pt-br wikipedia by summarizing multiple websites\")].\n\n\n\n\nThe multi-document abstractive summarization model receives a summary title as query\u2014which could be, for example, a question made by a user. Next, it accesses a textual corpus, retrieving multiple sentences related to the title. Finally, it uses the sentences to produce an authorial, non-extractive, summary about the title. Another way of seeing a multi-document abstractive summarization is as a system having two major stages: an extractive model that extracts the similarity of the document sentences to the title and outputs the best L sentences in order of relevance; these L sentences are then concatenated with the title and passed through an abstractive model, which generates a summary with a maximum size of n tokens.\n\n\n\n\n\nTo find the best combination of extractive and abstractive components for our summarization task, we tested several candidates and compared them according to standard metrics. For the extractive stage, which infers the relevance of sentences, we tested some variations of the TF-IDF [[33](#bib.bib55 \"Using tf-idf to determine word relevance in document queries\")]. On the abstractive stage, we compared fine-tunings of two encoder-decoder transformers: PTT5 and Longformer [[3](#bib.bib6 \"Longformer: the long-document transformer\")]. To fine-tune the abstractive stage models, we created a new dataset in Portuguese, the BrWac2Wiki [[29](#bib.bib51 \"PLSUM: generating pt-br wikipedia by summarizing multiple websites\")]. Each sample of the\ndataset associates a title and set of documents extracted from the internet (input) with a Wikipedia lead (target summary). As a continuation of this work, we intend to specialize our model in generating summaries about environmental topics, so that it can produce more accurate results in the Blue Amazon domain. We are also working on the improvement of the extractive stage, as to reduce inaccuracy and redundancy.\n\n\n\n\n\n#### Paraphraser:\n\n\n\nAs some of our experiments in the NL2SQL translator have demonstrated, data augmentation can be a valuable tool in NLP applications. By enlarging datasets, it is possible to reduce overfitting, thus allowing the training of bigger models [[24](#bib.bib34 \"Data augmentation approaches in natural language processing: a survey\")]. Data augmentation is particularly useful for low-resource languages and closed domains [[13](#bib.bib18 \"Data Augmentation for Low-Resource Neural Machine Translation\")], two scenarios that apply to BLAB. One particularly interesting form of data augmentation in NLP is paraphrase generation. Paraphrasing methods can be broadly divided into three groups: lexical approaches [[26](#bib.bib43 \"WordNet: A lexical database for english\"), [16](#bib.bib21 \"PPDB: the paraphrase database\")]; back-translation approaches [[25](#bib.bib39 \"Paraphrasing revisited with neural machine translation\")]; and mixed methods [[18](#bib.bib25 \"PARABANK: monolingual bitext generation and sentential paraphrasing via lexically-constrained neural machine translation\")]. In all these cases, there seems to be a trade-off between meaning preservation and diversity.\n\n\n\n\nAs an attempt to overcome such a difficulty, we have developed our own paraphraser, PTT5-Paraphrase [[31](#bib.bib47 \"PTT5-paraphraser: diversity and meaning fidelity in automatic portuguese paraphrasing\")]. PTT5-Paraphrase is a PTT5 model fine-tuned on the Portuguese part of TaPaCo [[38](#bib.bib61 \"TaPaCo: a corpus of sentential paraphrases for 73 languages\")], a large corpus collection of paraphrases in several languages. We compared PTT5-Paraphrase to other approaches according to three metrics: METEOR, BLEU (without brevity penalty), and cosine dissimilarity of sentence embeddings (using Sentence-BERT for encoding sentences [[34](#bib.bib58 \"Sentence-bert: sentence embeddings using siamese bert-networks\")]). On the one hand, PTT5-Paraphrase scores much better than rule-based approaches, such as WordNet [[26](#bib.bib43 \"WordNet: A lexical database for english\")] and PPDB [[16](#bib.bib21 \"PPDB: the paraphrase database\")], as regards diversity (lower METEOR/BLUE). On the other hand, PTT5-Paraphraser is considerably better in preserving meaning (lower cosine dissimilarity) than other neural approaches, such as ParaNet [[25](#bib.bib39 \"Paraphrasing revisited with neural machine translation\")] and Parabank [[18](#bib.bib25 \"PARABANK: monolingual bitext generation and sentential paraphrasing via lexically-constrained neural machine translation\")]. Overall, it achieves a good compromise between diversity and semantic fidelity. PTT5-Paraphraser was then validated on the manual paraphrases from Pir\u00e1 (Subsection [4.1](#S4.SS1 \"4.1 Pir\u00e1 and Pir\u00e1 2.0 \u2023 4 Resources \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\")). No statistical difference in meaning preservation and clarity has been detected, although automatically-generated paraphrases were considerably less creative. Currently, we are working to integrate PTT5-Paraphrase into BLAB\u2019s architecture; the paraphraser will be used to augment existing datasets on a regular basis, thus improving the training and fine-tuning of reasoners.\n\n4 Resources\n------------\n\n\n\nIn this section, we describe the main resources produced for BLAB: two versions of a QA dataset (Pir\u00e1 and Pir\u00e1 2.0), a domain-specific wiki, and a large corpus of documents on the Brazilian maritime territory. Currently, we are also working to populate the data lake with knowledge graphs, text summaries, topic-oriented clusters of texts, and augmented datasets, resources that will be produced by the harverster modules described in Section [3](#S3 \"3 Task-oriented NLP modules \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\"). \n\n\n\n\n### \n4.1 Pir\u00e1 and Pir\u00e1 2.0\n\n\n\nPir\u00e1 is a bilingual (Portuguese-English) reading comprehension dataset about the ocean, the Brazilian coast, and climate change [[30](#bib.bib48 \"Pir\u00e1: a bilingual portuguese-english dataset for question-answering about the ocean\")]. The dataset consists of 2,261 question/answer (QA) sets in both languages. To the best of our knowledge, Pir\u00e1 is the first open-ended QA dataset with questions in Portuguese, and, perhaps more importantly, the first bilingual QA dataset that includes this language. QA sets were manually created based on two corpora: one with scientific abstracts related to the Brazilian coast and the other with excerpts from two United Nation reports about the ocean [[27](#bib.bib66 \"World ocean assessment i\"), [28](#bib.bib67 \"World ocean assessment ii\")]. Next, the QA sets were evaluated in a peer-review process according to several aspects, such as meaningfulness, difficulty, and question type. As part of the assessment, volunteers answered the original questions too, thus providing a natural human baseline for the dataset. Volunteers also produced paraphrases of the original questions, which were later used to validate our paraphraser (Subsection [3.2](#S3.SS2.SSS0.Px4 \"Paraphraser: \u2023 3.2 BLAB Harvesters \u2023 3 Task-oriented NLP modules \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\")).\n\n\n\n\nIn subsequent work, we defined five benchmarks for Pir\u00e1: machine reading comprehension, information retrieval, open question answering, answer triggering, and multiple choice question answering. For each task, we obtained a number of baselines, including human (when available), random, and NLP models\u2019 performance, measuring them against standard metrics. As part of our effort, we also produced a curated version of the original dataset, Pir\u00e1 2.0, obtained by a thorough revision for grammar issues, repeated questions, and other shortcomings.\n\n\n\n\n\nFurthermore, the dataset was extended in a number of new directions required by baselines, such as multiple choice candidates, classification labels, and automatic paraphrases. Multiple choice candidates were created by extending the original QA sets from Pir\u00e1. Each multiple choice set has five alternatives: the correct answer to a question and the answers to four other questions in the dataset. The distractors were selected based on their similarity with the target text, as to make them as plausible as possible. To create the answer triggering dataset, we used the results obtained in the evaluation phase of Pir\u00e1. In this stage, participants had to evaluate the meaningfulness of a question in a Likert scale (1\u20135). Assuming that a meaningless question is one for which there is no answer, we converted the evaluations to 0 (not answerable) or 1 (answerable) based on a threshold. Finally, automatic paraphrases were generated with our paraphraser (Subsection [3.2](#S3.SS2.SSS0.Px4 \"Paraphraser: \u2023 3.2 BLAB Harvesters \u2023 3 Task-oriented NLP modules \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\")), which had been validated on the original dataset.\n\n\n\n\nEach of the benchmarks represents a challenge towards developing a program that can interact with users by answering their questions. Information Retrieval deals with fetching relevant texts. Machine reading comprehension is responsible for generating an answer based on a text which contains the desired information. Open question answering extends this problem to questions with non-extractive answers. Answer triggering is responsible for deciding whether a question should be answered or not. Finally, multiple choice depends on finding the correct answer among a set of candidates; a task that, in our case, simulates the management of multiple question answering systems, in which a single answer has to be selected.\n\n\n\n\nPir\u00e1 2.0 is the main resource used by BLAB\u2019s NLP modules. In the reasoner side, it has been used in the fine-tuning of DEEPAG\u00c9, our main QA system (Subsection [3.1](#S3.SS1.SSS0.Px3 \"QA system: \u2023 3.1 BLAB Reasoners \u2023 3 Task-oriented NLP modules \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\")). The corpus of supporting texts was used both in the training of the knowledge graph generator (Subsection [3.2](#S3.SS2.SSS0.Px1 \"Knowledge graph generator: \u2023 3.2 BLAB Harvesters \u2023 3 Task-oriented NLP modules \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\")) and the unsupervised topic model builder (Subsection [3.2](#S3.SS2.SSS0.Px2 \"Unsupervised topic model builder: \u2023 3.2 BLAB Harvesters \u2023 3 Task-oriented NLP modules \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\")).\n\n\n\n\n\n### \n4.2 BLAB-Wiki\n\n\n\nOne of the main issues we have faced in the development of BLAB modules was the lack of comprehensive texts on basic topics related to the Blue Amazon. Although specialized material can be found in books and articles, accessible texts on the subject are rarely available. For this reason, we decided to develop our own small wiki, named BLAB-Wiki, written by experts in the field.\nThe entries for this encyclopedia present basic topics concerning the Blue Amazon for lay readers based on the scientific literature. These texts serve as summaries of scientific topics, as an entryway to the general public, and as a friendly link to the technical literature. BLAB-Wiki\u2019s content is organized into four main axes: socio-environmental, biodiversity, physicochemical, and legislation and governance. Each axis is composed of entries discussing different aspects of the Blue Amazon, such as marine pollution, effects of climate change on the ocean, and deep sea ecology. BLAB-Wiki will serve as a reliable resource for the various modules of BLAB, such as the QA and summarizer systems. Its content is revised by scientific consultants, and will soon be available in two formats: both as an ebook and as the wiki service that can be directly accessed through the BLAB\u2019s web portal (Subsection [2.3](#S2.SS3 \"2.3 BLAB web services \u2023 2 An Overview of BLAB \u2023 The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory\")).\n\n\n\n\n\n\n### \n4.3 Corpus of documents\n\n\n\nIn order to allow text queries, our data lake gathers a large number of documents on topics related to the Brazilian coast. Among these, we may cite: intergovernmental reports on the ocean, such as those by the UN and UNESCO; reports from the Brazilian government, in particular from the Ministry of the Environment; academic books, such as \u201cNo\u00e7\u00f5es de Oceanografia\u201d, by the Oceanographic Institute of USP, and \u201cBrazil and the Sea in the 21st Century\u201d, by the Center of Excellence for the Brazilian Sea (Cembra); scientific articles, theses, and dissertations from various sources; and legal documents with the main frameworks involving the Brazilian maritime territory, such as the Decree 5,300 from 2004, which established the National Coastal Management Plan.\nDue to copyright issues, this corpus is not directly accessible to users, but only to BLAB\u2019s modules through the data lake. As to avoid any type of plagiarism or misappropriation, we are developing a tool to reference the original sources from where answers were primarily obtained.\n\n5 Conclusion: Lessons Learned, Future Work\n-------------------------------------------\n\n\n\nWe have described in this paper our efforts in building an architecture of complex and interconnected services about the Brazilian maritime territory, the BLue Amazon Brain (BLAB). The main BLAB service is a conversational agent, the BLAB-Chat, with advanced reasoning and user interaction capabilities. The core components of this architecture are\na controller that coordinates a data lake, an interface, and several NLP modules.\nThe latter include a natural language generator,\na QA system, a natural language to SQL converter, a knowledge graph generator,\nan unsupervised topic model builder, a multi-document summarizer, and a paraphraser.\nBLAB also offers services of automated news (the BLAB-Reporter) and a thematic wiki (the BLAB-Wiki).\nThe whole system relies on a set of resources that include two QA datasets on the Blue Amazon, a large corpus of documents, and our wiki.\n\n\n\n\nA large system such as BLAB, and particularly the BLAB-Chat, exercises many aspects of\ncurrent artificial intelligence. Although the required techniques, such as natural language processing and question answering, are getting better every day and are able to display\nsurprising performance, not everything is perfect; thus, we would like to\nshare a few lessons we have learned in the journey:\n\n\n\n\n* Data-driven models, such as transformers and the like, are trained on massive amounts of data which endows them with some linguistic and common sense skills. Nonetheless, they still demand considerable efforts to learn how to handle specialized domains, such as the Blue Amazon: additional data must be collected,\ncorpora must be carefully curated, and optimization runs must be endlessly repeated, often\nto frustrating results.\nMost data-driven models do not perform well when fed with scattered knowledge\nsources. Better techniques to incorporate specific information are sorely needed in AI.\n* There are clear limitations to NLP models when one deals with languages other than English: good trained models are harder to find and data is much more scarce. That led us to build our own resources (aimed at the Portuguese language)\nwhen putting together BLAB. Even though large multilingual models can interpolate significant information across languages,\nit is important to have models and resources directly available in low-resource languages as well, particularly when one is concerned with a topic of universal interest such as the ocean.\n\n\n\n\nIn the near future we expect to expand the number of NLP-based\nmodules and resources in BLAB.\nFor instance, we plan to develop other types of reasoner modules, such as a debater and a sequential planner, which\ncan provide the conversational agent with argumentation skills.\nWe are also working on adding prediction modules based on numeric data, such as\ntide and ocean current forecasters. These modules will generate information that will be useful for people who work, live or intend to carry out some social or economic activity in the Blue Amazon.\nBesides expanding our current wiki, we hope to create\na graph-based question answering dataset\nand an ontology of the Blue Amazon. As the set of resources related to the Blue Amazon grows, NLP modules will get better and easier to train.\nWe hope that BLAB can become a useful tool for environmental education\nand awareness, providing reliable and engaging content on the Blue Amazon to a wide range of users.\n\nAcknowledgement\n---------------\n\n\n\nThe authors would like to thank Gabriel Okamoto Carlos, Caio Fabricio Deberaldini Netto, and Caio Noboru Asai for their previous contribution to this project.\n\n\n\n\nThe authors thank the Center for Artificial Intelligence (C4AI-USP) and the support from the S\u00e3o Paulo Research Foundation (FAPESP grant #2019/07665-4) and from the IBM Corporation. A.\u00a0L.\u00a0C.\u00a0de Oliveira, L.\u00a0C.\u00a0Motheo, L.\u00a0F.\u00a0F., and R.\u00a0M. Tavares were supported by the Programa Institucional de Bolsas de Inicia\u00e7\u00e3o em Desenvolvimento Tecnol\u00f3gico e Inova\u00e7\u00e3o (PIBITI) of CNPq; R.\u00a0S.\u00a0Grava was supported by the Programa Institucional de Bolsas de Inicia\u00e7\u00e3o Cientifica (PIBIC) of CNPq; and A.\u00a0B.\u00a0R.\u00a0Castro was supported by the Programa Unificado de Bolsas de Estudos para Apoio e Forma\u00e7\u00e3o de Estudantes de Gradua\u00e7\u00e3o (PUB) of the Universidade de S\u00e3o Paulo. This research was also partially supported by Ita\u00fa Unibanco S.A.; M.\u00a0M.\u00a0Jos\u00e9, F.\u00a0Nakasato and A.\u00a0S.\u00a0Oliveira have been supported by the Ita\u00fa Scholarship Program (PBI) of the Data Science Center (C2D) of the Escola Polit\u00e9cnica da Universidade de S\u00e3o Paulo. A.\u00a0H.\u00a0R.\u00a0Costa and F.\u00a0G.\u00a0Cozman and D. D. Mau\u00e1 thank the support of the National Council for Scientific and Technological Development of Brazil (CNPq grants #310085/2020-9 and #312180/2018-7 and 304012/2019-0, respectively).", "url": "https://arxiv.org/abs/2209.07928"}
