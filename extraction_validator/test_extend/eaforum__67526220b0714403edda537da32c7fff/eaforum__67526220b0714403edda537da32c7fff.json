{
  "nodes": [
    {
      "name": "Catastrophic outcomes from advanced AI due to governance misunderstandings",
      "aliases": [
        "AI existential risk via policy failure",
        "Governance-related AI catastrophe"
      ],
      "type": "concept",
      "description": "Potential existential or other catastrophic harms from advanced AI systems that arise because governance regimes fail, in part through ineffective policy communication and terminology.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced implicitly in 'Bottom lines' as the overarching danger the terminology discussion aims to mitigate."
    },
    {
      "name": "Policymaker misunderstanding from ambiguous AI terminology",
      "aliases": [
        "Terminology-induced policy confusion",
        "Ambiguity in AI system labels causing misunderstanding"
      ],
      "type": "concept",
      "description": "Use of jargon-laden, speculative or negatively-loaded terms causes non-specialist audiences—including legislators—to misinterpret AI capabilities and risks, hampering effective governance.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Central problem discussed throughout 'Overview of commonly-used terms'."
    },
    {
      "name": "Absence of standardized, audience-tailored AI terms leads to misunderstanding",
      "aliases": [
        "Lack of audience appropriate AI vocabulary",
        "Missing standard terminology for AI governance"
      ],
      "type": "concept",
      "description": "A key theoretical insight: without deliberate, audience-specific choice and definition of AI system labels, communication gaps arise that seed governance failures.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Derived from author and expert comments in 'Thoughts from others'."
    },
    {
      "name": "Framework for selecting context-appropriate AI terms",
      "aliases": [
        "Communication strategy for AI terminology",
        "Audience-specific term selection"
      ],
      "type": "concept",
      "description": "Design principle that communicators should choose among existing AI labels based on audience, policy goal and risk emphasis to maximise clarity and minimise negative connotations.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Outlined in 'Bottom lines' where specific term recommendations are given."
    },
    {
      "name": "Comparative analysis of six AI system terms for suitability in policy communication",
      "aliases": [
        "Evaluation of 'frontier', 'advanced', 'general-purpose', etc.",
        "Term-by-term suitability assessment"
      ],
      "type": "concept",
      "description": "Implementation mechanism in which six labels—frontier AI, advanced AI, general-purpose AI, AGI, TAI and superintelligence—are dissected for connotation, audience reception and policy usefulness.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Main body of 'Overview of commonly-used terms'."
    },
    {
      "name": "Industry adoption and DC reception of 'frontier AI' framing",
      "aliases": [
        "Frontier AI positive policy reception",
        "Frontier AI term adoption evidence"
      ],
      "type": "concept",
      "description": "Observed validation: creation of Frontier Model Forum and favourable reactions to 'frontier' rhetoric in US policy circles demonstrate communicative effectiveness.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Cited under 'Frontier AI' considerations."
    },
    {
      "name": "Neutral perception and definitional flexibility of 'advanced AI' term",
      "aliases": [
        "Advanced AI neutral connotation evidence",
        "Advanced AI communication effectiveness"
      ],
      "type": "concept",
      "description": "Evidence that 'advanced AI' lacks jargon, is broadly acceptable, but requires scope definition; exemplified by Ho et al. (2023).",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Presented in 'Advanced AI' section."
    },
    {
      "name": "EU AI Act operational definition of 'general-purpose AI'",
      "aliases": [
        "General-purpose AI legal grounding",
        "EU legislation usage evidence"
      ],
      "type": "concept",
      "description": "Evidence node: the draft EU AI Act codifies a definition of 'general-purpose AI', indicating policy clarity and acceptance of the term.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Referenced in 'General-purpose AI' examples."
    },
    {
      "name": "Expert critique of jargon-laden 'TAI' and sci-fi 'superintelligence' framing",
      "aliases": [
        "TAI and superintelligence negative reception",
        "Criticism of speculative AI terms"
      ],
      "type": "concept",
      "description": "Expert and public feedback suggests these terms sound speculative or confusing, reducing effectiveness with non-technical audiences.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Captured in 'TAI' and 'Superintelligence' considerations."
    },
    {
      "name": "Use 'frontier AI' label in policy discussions about cutting-edge models",
      "aliases": [
        "Adopt frontier AI terminology",
        "Label frontier models as 'frontier AI'"
      ],
      "type": "intervention",
      "description": "When engaging policymakers on the most capable current systems, explicitly describe them as 'frontier AI' to harness positive innovation connotations and align with industry usage.",
      "concept_category": null,
      "intervention_lifecycle": "5",
      "intervention_lifecycle_rationale": "Applies during real-world policy communication and governance deployment (section: 'Frontier AI').",
      "intervention_maturity": "4",
      "intervention_maturity_rationale": "Term is already operational in policy and industry bodies like Frontier Model Forum (section: examples of term usage).",
      "node_rationale": "Recommended as best practice in 'Bottom lines'."
    },
    {
      "name": "Adopt 'advanced AI' as default non-jargon term with explicit scope definition",
      "aliases": [
        "Use advanced AI wording",
        "Default to 'advanced AI' framing"
      ],
      "type": "intervention",
      "description": "For general audiences, communicate using 'advanced AI' but supply a clear definition of what systems qualify to maintain precision without jargon.",
      "concept_category": null,
      "intervention_lifecycle": "5",
      "intervention_lifecycle_rationale": "Communication guidance executed during deployment of policy or outreach (section: 'Advanced AI').",
      "intervention_maturity": "3",
      "intervention_maturity_rationale": "Widely piloted in reports such as Ho et al. (2023) but not yet universally standard (section: examples).",
      "node_rationale": "Highlighted in 'Bottom lines' as preferred default."
    },
    {
      "name": "Align terminology with EU AI Act by using 'general-purpose AI' in governance texts",
      "aliases": [
        "Use general-purpose AI label",
        "EU-aligned terminology adoption"
      ],
      "type": "intervention",
      "description": "When drafting regulations or analysis, employ the legally grounded term 'general-purpose AI' to match EU legislative language and reduce confusion.",
      "concept_category": null,
      "intervention_lifecycle": "5",
      "intervention_lifecycle_rationale": "Targeted at policy drafting and legislative deployment stages (section: 'General-purpose AI').",
      "intervention_maturity": "4",
      "intervention_maturity_rationale": "Term is already embedded in the draft EU AI Act, indicating operational status (section: examples).",
      "node_rationale": "Recommended variant for contexts requiring legal precision."
    },
    {
      "name": "Avoid 'TAI' and 'superintelligence' when communicating with non-specialist audiences",
      "aliases": [
        "Drop TAI and superintelligence labels",
        "Discourage speculative terminology"
      ],
      "type": "intervention",
      "description": "To minimise sci-fi connotations and jargon, deliberately refrain from using 'transformative AI' and 'superintelligence' in policy or public messaging aimed at lay audiences.",
      "concept_category": null,
      "intervention_lifecycle": "5",
      "intervention_lifecycle_rationale": "Guidance for deployment-phase public and policy communication (sections: 'TAI', 'Superintelligence').",
      "intervention_maturity": "3",
      "intervention_maturity_rationale": "Practice is emerging among communicators but not yet universal (section: author recommendations).",
      "node_rationale": "Listed in 'Bottom lines' as generally worse choices for non-technical audiences."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Catastrophic outcomes from advanced AI due to governance misunderstandings",
      "target_node": "Policymaker misunderstanding from ambiguous AI terminology",
      "description": "Governance failures that can lead to catastrophe are driven in part by policymakers receiving unclear or misleading information due to ambiguous terminology.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Logical linkage repeatedly asserted in the introduction and 'Bottom lines', supported by qualitative reasoning.",
      "edge_rationale": "Paper frames better terminology as a prerequisite for avoiding catastrophic governance errors."
    },
    {
      "type": "caused_by",
      "source_node": "Policymaker misunderstanding from ambiguous AI terminology",
      "target_node": "Absence of standardized, audience-tailored AI terms leads to misunderstanding",
      "description": "Misunderstanding stems from the underlying lack of a standardized, audience-appropriate vocabulary.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicitly discussed in 'Thoughts from others' and throughout term analyses.",
      "edge_rationale": "Author and commentators attribute confusion to missing tailored standard."
    },
    {
      "type": "mitigated_by",
      "source_node": "Absence of standardized, audience-tailored AI terms leads to misunderstanding",
      "target_node": "Framework for selecting context-appropriate AI terms",
      "description": "Implementing a selection framework directly mitigates the absence of standardised, audience-tailored terminology.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Proposed solution in 'Bottom lines' logically addresses identified theoretical gap.",
      "edge_rationale": "Framework supplies the missing standardisation."
    },
    {
      "type": "implemented_by",
      "source_node": "Framework for selecting context-appropriate AI terms",
      "target_node": "Comparative analysis of six AI system terms for suitability in policy communication",
      "description": "The comparative analysis operationalises the framework by evaluating specific term options.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Analysis constitutes the concrete implementation as detailed in 'Overview of commonly-used terms'.",
      "edge_rationale": "Paper's main body carries out the framework."
    },
    {
      "type": "validated_by",
      "source_node": "Comparative analysis of six AI system terms for suitability in policy communication",
      "target_node": "Industry adoption and DC reception of 'frontier AI' framing",
      "description": "Real-world uptake of 'frontier AI' supports the analysis' assessment of that label's effectiveness.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Evidence is observational (Industry examples) and not rigorously quantified.",
      "edge_rationale": "Section cites Frontier Model Forum and DC resonance as confirmation."
    },
    {
      "type": "validated_by",
      "source_node": "Comparative analysis of six AI system terms for suitability in policy communication",
      "target_node": "Neutral perception and definitional flexibility of 'advanced AI' term",
      "description": "Examples such as Ho et al. (2023) illustrate feasibility of using 'advanced AI', validating the comparative assessment.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Based on limited published usage, qualitative support.",
      "edge_rationale": "Paper references external usage as corroboration."
    },
    {
      "type": "validated_by",
      "source_node": "Comparative analysis of six AI system terms for suitability in policy communication",
      "target_node": "EU AI Act operational definition of 'general-purpose AI'",
      "description": "Legal codification in the EU AI Act confirms policy relevance of the term 'general-purpose AI'.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Legislative text provides concrete, externally verifiable evidence.",
      "edge_rationale": "Cited under 'General-purpose AI' examples."
    },
    {
      "type": "validated_by",
      "source_node": "Comparative analysis of six AI system terms for suitability in policy communication",
      "target_node": "Expert critique of jargon-laden 'TAI' and sci-fi 'superintelligence' framing",
      "description": "Negative expert feedback substantively validates the analysis' caution against these terms.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Based on quoted opinions and anecdotal reactions.",
      "edge_rationale": "Presented in consideration sections for TAI and superintelligence."
    },
    {
      "type": "motivates",
      "source_node": "Industry adoption and DC reception of 'frontier AI' framing",
      "target_node": "Use 'frontier AI' label in policy discussions about cutting-edge models",
      "description": "Positive reception motivates the recommendation to actively employ the 'frontier AI' label.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Direct argumentative link in 'Bottom lines'.",
      "edge_rationale": "Evidence feeds into practical advice."
    },
    {
      "type": "motivates",
      "source_node": "Neutral perception and definitional flexibility of 'advanced AI' term",
      "target_node": "Adopt 'advanced AI' as default non-jargon term with explicit scope definition",
      "description": "Validation of neutrality motivates adopting 'advanced AI' as the default label.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicitly recommended in 'Bottom lines'.",
      "edge_rationale": "Evidence underpins recommendation."
    },
    {
      "type": "motivates",
      "source_node": "EU AI Act operational definition of 'general-purpose AI'",
      "target_node": "Align terminology with EU AI Act by using 'general-purpose AI' in governance texts",
      "description": "Legal clarity motivates aligning vocabulary with 'general-purpose AI'.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Presence in legislation provides strong incentive.",
      "edge_rationale": "Paper notes synergy with EU regulation."
    },
    {
      "type": "motivates",
      "source_node": "Expert critique of jargon-laden 'TAI' and sci-fi 'superintelligence' framing",
      "target_node": "Avoid 'TAI' and 'superintelligence' when communicating with non-specialist audiences",
      "description": "Critiques motivate recommendation to avoid these speculative terms in broad communication.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Directly argued in 'Bottom lines' with supporting expert comments.",
      "edge_rationale": "Negative evidence leads to avoidance guidance."
    }
  ],
  "meta": [
    {
      "key": "date_published",
      "value": "2023-09-06T15:08:30Z"
    },
    {
      "key": "url",
      "value": "https://forum.effectivealtruism.org/posts/9Y5YzNDMdYYg6hjwD/what-term-to-use-for-ai-in-different-policy-contexts"
    },
    {
      "key": "title",
      "value": "What term to use for AI in different policy contexts?"
    },
    {
      "key": "authors",
      "value": [
        "oeg"
      ]
    },
    {
      "key": "source",
      "value": "eaforum"
    }
  ]
}