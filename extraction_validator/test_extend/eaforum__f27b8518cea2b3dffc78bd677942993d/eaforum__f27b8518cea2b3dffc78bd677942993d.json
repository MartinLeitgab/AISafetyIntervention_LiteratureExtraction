{
  "nodes": [
    {
      "name": "Misallocation of AI safety resources from overestimated short AGI timelines",
      "aliases": [
        "resource mis-prioritisation due to short timelines",
        "overinvestment in near-term AGI risk"
      ],
      "type": "concept",
      "description": "The possibility that policy makers and funders over-focus on immediate AGI existential risk, diverting effort from more probable long-term scenarios.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Central risk explicitly implied in concluding paragraph about low probability of AGI within 10 years."
    },
    {
      "name": "Overestimation of discontinuous AI progress toward AGI in expert communities",
      "aliases": [
        "belief in imminent AI takeoff",
        "assumption of sharp progress jumps"
      ],
      "type": "concept",
      "description": "The belief that progress will suddenly accelerate (e.g., via recursive self-improvement), leading to AGI without intermediate milestones.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Identified as main mechanism causing misjudged timelines in paragraphs discussing discontinuities."
    },
    {
      "name": "Neglect of historical gradual technological progress patterns in AI forecasting",
      "aliases": [
        "ignoring smooth progress trends",
        "discounting base-rate technological gradualism"
      ],
      "type": "concept",
      "description": "Forecasters fail to incorporate evidence that most technologies, including AI capabilities, improve steadily rather than through large jumps.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Derived from multiple examples comparing AI to car speed and Moore’s law trends."
    },
    {
      "name": "AGI development requires incremental advances across many distinct cognitive skills",
      "aliases": [
        "intelligence is multi-skill aggregation",
        "heterogeneous skill requirement for AGI"
      ],
      "type": "concept",
      "description": "Theory that intelligence is not a single property but a bundle of abilities, implying progress must happen on many fronts.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Appears in argument that discontinuities are less plausible if intelligence is multi-faceted."
    },
    {
      "name": "Resource constraints on scaling AI research despite hype",
      "aliases": [
        "limited supply of top ML talent",
        "funding saturation in AI"
      ],
      "type": "concept",
      "description": "Even with high investment, bottlenecks such as researcher availability limit acceleration of AI progress.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Argument in section on excitement and hype not translating to orders-of-magnitude progress."
    },
    {
      "name": "Empirical trend-based forecasting for AGI timelines",
      "aliases": [
        "base-rate driven AI forecasting",
        "data-driven timeline estimation"
      ],
      "type": "concept",
      "description": "Design strategy to ground timeline estimates in historical AI progress metrics and comparable technological trends.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Proposed solution pathway to correct overestimation, derived from repeated calls to ‘look at rates of progress’."
    },
    {
      "name": "Aggregating diverse evidence sources including market signals for AI forecasting",
      "aliases": [
        "multi-source evidence aggregation",
        "incorporating financial market expectations"
      ],
      "type": "concept",
      "description": "Complementing historical trend data with prediction markets, stock-price movements, and expert surveys to refine forecasts.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Stated when discussing financial markets as a ‘less obvious expert opinion’ dismissing short timelines."
    },
    {
      "name": "Tracking rate of ground-breaking AI milestone achievements over time",
      "aliases": [
        "AI milestone dashboard",
        "continuous capability benchmarking"
      ],
      "type": "concept",
      "description": "Implementation mechanism that logs frequency and significance of capability milestones (e.g., AlphaGo-level events) to update models.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Implied by argument that lack of breakthroughs since 2016 is strong evidence; suggests systematic monitoring."
    },
    {
      "name": "Prediction markets reflecting collective probability of AGI arrival by given dates",
      "aliases": [
        "AGI timeline prediction market",
        "forecasting market for AI milestones"
      ],
      "type": "concept",
      "description": "Mechanism that uses tradable contracts to aggregate beliefs and incentives around AGI timelines.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Referenced when discussing financial market incentives as informative signals."
    },
    {
      "name": "Lack of ground-breaking AI progress since AlphaGo as empirical evidence",
      "aliases": [
        "post-AlphaGo progress stagnation",
        "scarcity of landmark breakthroughs"
      ],
      "type": "concept",
      "description": "Observation that no comparable capability leaps occurred between 2016 and late-2018, supporting gradualism.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Cited as key empirical support against short timelines."
    },
    {
      "name": "Financial market underpricing of short AGI timelines",
      "aliases": [
        "markets discount near-term AGI",
        "stock-market evidence against 10-year AGI"
      ],
      "type": "concept",
      "description": "Observation that asset prices and investment patterns do not reflect expectation of transformative AGI within a decade.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Discussed in paragraph on ‘implicit opinion’ of financial markets."
    },
    {
      "name": "Deploy continuous AI-milestone tracking dashboard for timeline forecasting",
      "aliases": [
        "implement milestone dashboard",
        "capability progress tracking system"
      ],
      "type": "intervention",
      "description": "Develop and maintain an open dashboard that records new AI capability benchmarks, quantifies their significance, and feeds statistical models to update AGI arrival probabilities.",
      "concept_category": null,
      "intervention_lifecycle": "6",
      "intervention_lifecycle_rationale": "Applies to ongoing governance/monitoring activities—beyond model lifecycle stages.",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Proof-of-concept dashboards exist but lack systematic adoption (inferred).",
      "node_rationale": "Actionable output of implementation mechanism ‘Tracking rate of ground-breaking AI milestone achievements’. Moderate inference applied."
    },
    {
      "name": "Establish real-money prediction markets on AGI timeline milestones",
      "aliases": [
        "launch AGI prediction market platform",
        "market-based forecasting for AGI"
      ],
      "type": "intervention",
      "description": "Set up legally compliant exchanges or use existing platforms allowing traders to buy/sell contracts that pay out if AGI criteria are met by specific dates, thereby aggregating informed probabilities.",
      "concept_category": null,
      "intervention_lifecycle": "6",
      "intervention_lifecycle_rationale": "Governance-side measure, not within ML model lifecycle.",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Limited pilots (e.g., manifold.markets) exist; large-scale real-money versions remain experimental.",
      "node_rationale": "Direct application of implementation mechanism ‘Prediction markets reflecting collective probability of AGI arrival’. Moderate inference applied."
    },
    {
      "name": "Allocate AI safety funding proportional to empirically updated AGI timeline probabilities",
      "aliases": [
        "probability-weighted resource allocation",
        "evidence-based safety budgeting"
      ],
      "type": "intervention",
      "description": "Adjust grant-making and policy focus dynamically so that near-term vs long-term AGI risks receive investment matching continuously updated probability estimates from dashboards and markets.",
      "concept_category": null,
      "intervention_lifecycle": "6",
      "intervention_lifecycle_rationale": "Strategic governance decision outside model development phases.",
      "intervention_maturity": "1",
      "intervention_maturity_rationale": "Conceptual proposal; no systematic implementation documented.",
      "node_rationale": "Addresses the risk of misallocation directly; inferred from design rationale encouraging evidence-based planning."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Misallocation of AI safety resources from overestimated short AGI timelines",
      "target_node": "Overestimation of discontinuous AI progress toward AGI in expert communities",
      "description": "Belief in sudden takeoff leads actors to over-invest in near-term preparations, causing resource misallocation.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Reasoned link explicitly argued in sections critiquing discontinuity assumptions.",
      "edge_rationale": "Mechanistic explanation of how the risk arises."
    },
    {
      "type": "caused_by",
      "source_node": "Misallocation of AI safety resources from overestimated short AGI timelines",
      "target_node": "Neglect of historical gradual technological progress patterns in AI forecasting",
      "description": "Ignoring historical gradualism fosters inflated short-timeline beliefs, generating misallocation.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Based on examples of cars, Moore’s law, and cited AI Impacts research.",
      "edge_rationale": "Identifies complementary causal mechanism."
    },
    {
      "type": "mitigated_by",
      "source_node": "Overestimation of discontinuous AI progress toward AGI in expert communities",
      "target_node": "AGI development requires incremental advances across many distinct cognitive skills",
      "description": "Recognising the multi-skill nature of intelligence counters beliefs in rapid discontinuities.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Qualitative theoretical argument without empirical validation.",
      "edge_rationale": "From theoretical insight to mitigation of problem analysis."
    },
    {
      "type": "mitigated_by",
      "source_node": "Neglect of historical gradual technological progress patterns in AI forecasting",
      "target_node": "Resource constraints on scaling AI research despite hype",
      "description": "Understanding resource bottlenecks further supports gradual progress expectations.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Argumentative evidence based on talent bottleneck discussion.",
      "edge_rationale": "Adds complementary theoretical mitigation."
    },
    {
      "type": "enabled_by",
      "source_node": "AGI development requires incremental advances across many distinct cognitive skills",
      "target_node": "Empirical trend-based forecasting for AGI timelines",
      "description": "Insight motivates designing forecasts around measurable incremental trends.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Logical derivation; not directly evidenced.",
      "edge_rationale": "Links theoretical insight to design rationale."
    },
    {
      "type": "enabled_by",
      "source_node": "Resource constraints on scaling AI research despite hype",
      "target_node": "Aggregating diverse evidence sources including market signals for AI forecasting",
      "description": "Recognition of constraints encourages using multiple evidence channels to improve predictions.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Inference from discussion of hype vs markets.",
      "edge_rationale": "Second pathway from theoretical insight to design rationale."
    },
    {
      "type": "implemented_by",
      "source_node": "Empirical trend-based forecasting for AGI timelines",
      "target_node": "Tracking rate of ground-breaking AI milestone achievements over time",
      "description": "Milestone tracking operationalises empirical trend forecasting.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Directly referenced via AlphaGo example and absence of further breakthroughs.",
      "edge_rationale": "Design rationale → implementation mechanism."
    },
    {
      "type": "implemented_by",
      "source_node": "Aggregating diverse evidence sources including market signals for AI forecasting",
      "target_node": "Prediction markets reflecting collective probability of AGI arrival by given dates",
      "description": "Prediction markets provide a concrete mechanism for aggregating probabilistic beliefs.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicit mention of financial market incentives.",
      "edge_rationale": "Design rationale → implementation mechanism."
    },
    {
      "type": "validated_by",
      "source_node": "Tracking rate of ground-breaking AI milestone achievements over time",
      "target_node": "Lack of ground-breaking AI progress since AlphaGo as empirical evidence",
      "description": "Observed stagnation acts as validation data for the tracking mechanism.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Empirical observation directly cited.",
      "edge_rationale": "Implementation mechanism → validation evidence."
    },
    {
      "type": "validated_by",
      "source_node": "Prediction markets reflecting collective probability of AGI arrival by given dates",
      "target_node": "Financial market underpricing of short AGI timelines",
      "description": "Market pricing provides validation of collective dismissal of near-term AGI.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Referencing blog analysis of stock-market signals.",
      "edge_rationale": "Implementation mechanism → validation evidence."
    },
    {
      "type": "motivates",
      "source_node": "Lack of ground-breaking AI progress since AlphaGo as empirical evidence",
      "target_node": "Deploy continuous AI-milestone tracking dashboard for timeline forecasting",
      "description": "Evidence of milestone scarcity motivates formalising milestone tracking into a dashboard.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Moderate inference connecting observation to action.",
      "edge_rationale": "Validation evidence → intervention."
    },
    {
      "type": "motivates",
      "source_node": "Financial market underpricing of short AGI timelines",
      "target_node": "Establish real-money prediction markets on AGI timeline milestones",
      "description": "Market signalling gap motivates creation of dedicated AGI prediction markets.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Inference; text suggests markets informative but doesn’t propose creation explicitly.",
      "edge_rationale": "Validation evidence → intervention."
    },
    {
      "type": "addressed_by",
      "source_node": "Misallocation of AI safety resources from overestimated short AGI timelines",
      "target_node": "Allocate AI safety funding proportional to empirically updated AGI timeline probabilities",
      "description": "Probability-weighted budgeting directly mitigates the misallocation risk.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Logical inference; author implies resources should match evidence.",
      "edge_rationale": "Risk → intervention via inference."
    },
    {
      "type": "required_by",
      "source_node": "Allocate AI safety funding proportional to empirically updated AGI timeline probabilities",
      "target_node": "Deploy continuous AI-milestone tracking dashboard for timeline forecasting",
      "description": "Dynamic funding allocation requires up-to-date milestone tracking to supply probabilities.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Inferential but straightforward dependency.",
      "edge_rationale": "Links interventions for coherence."
    },
    {
      "type": "required_by",
      "source_node": "Allocate AI safety funding proportional to empirically updated AGI timeline probabilities",
      "target_node": "Establish real-money prediction markets on AGI timeline milestones",
      "description": "Funding decisions also require aggregated probability estimates from prediction markets.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Inferential dependency on probability source.",
      "edge_rationale": "Intervention inter-dependency."
    }
  ],
  "meta": [
    {
      "key": "date_published",
      "value": "2018-10-23T15:59:41Z"
    },
    {
      "key": "url",
      "value": "https://forum.effectivealtruism.org/posts/b3goLZcNxt68WbHmB/thoughts-on-short-timelines"
    },
    {
      "key": "title",
      "value": "Thoughts on short timelines"
    },
    {
      "key": "authors",
      "value": [
        "Tobias_Baumann"
      ]
    },
    {
      "key": "source",
      "value": "eaforum"
    }
  ]
}