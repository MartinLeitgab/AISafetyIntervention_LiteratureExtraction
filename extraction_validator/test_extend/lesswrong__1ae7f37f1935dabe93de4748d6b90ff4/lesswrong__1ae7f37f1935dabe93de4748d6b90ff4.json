{
  "nodes": [
    {
      "name": "Value misalignment in AI population ethics decision-making",
      "aliases": [
        "AI moral misalignment about future persons",
        "Incorrect AI valuation of future lives"
      ],
      "type": "concept",
      "description": "Risk that advanced AI systems tasked with long-term planning adopt population-ethical principles that diverge from considered human judgments, leading to morally harmful decisions about creating or preventing future lives.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Opening paragraphs highlight how differing population-ethical views starkly change which worlds are judged better; misalignment of such judgment in AI is therefore an existential policy risk."
    },
    {
      "name": "Incomparability of worlds under person-affecting views with ambiguous person identity",
      "aliases": [
        "Person-affecting incomparability",
        "Ambiguous identity harms comparability"
      ],
      "type": "concept",
      "description": "Problem that, once personal identity is fuzzy, person-affecting theories cannot say which of two worlds is better when the set of persons differs, undermining ethical evaluation.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Middle section argues that without clear identity facts, person-affecting views fail to compare scenarios (e.g., Alice exists in only one world), producing ethical gridlock."
    },
    {
      "name": "Personhood as pragmatic clustering of person-moments without objective boundaries",
      "aliases": [
        "Cluster view of identity",
        "No further-fact personal identity"
      ],
      "type": "concept",
      "description": "Theoretical insight that personal identity is not an objective further fact; instead, reality contains only connected person-moments, and grouping them into ‘persons’ is a pragmatic choice.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section rejecting the further-fact view supplies the hypothesis that identity is a heuristic, foundational to later design choices."
    },
    {
      "name": "Shift to person-moment based ethical evaluation using preference utilitarianism",
      "aliases": [
        "Person-moment value theory",
        "Preference-based person-moment evaluation"
      ],
      "type": "concept",
      "description": "Design rationale proposing that ethical evaluation should consider individual person-moments’ preferences, giving weight according to their connectedness rather than binary personhood.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Author suggests replacing person-level comparison with person-moment preference aggregation to regain comparability and reflect moderate person-affecting intuitions."
    },
    {
      "name": "Connectedness-weighted utility calculation algorithm for person-moment preferences",
      "aliases": [
        "Connectedness utility function",
        "Sliding-scale person-moment weighting"
      ],
      "type": "concept",
      "description": "Implementation mechanism where each future person-moment receives utility weight proportional to its psychological/causal connectedness to current moments, enabling sliding-scale valuation.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Translates the design rationale into a concrete computational procedure that an AI planner could optimize."
    },
    {
      "name": "Linguistic preference extraction to estimate present person-moment desires",
      "aliases": [
        "Preference extraction from text",
        "Natural language preference modeling"
      ],
      "type": "concept",
      "description": "Technique to infer existing person-moment preferences (e.g., ‘I want my future self to ...’) from language data, supplying inputs to the connectedness-weighted utility algorithm.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Blog notes that current person-moments often care about their future selves; extracting these preferences is required to operationalise the theory."
    },
    {
      "name": "Theoretical consistency with moderate person-affecting intuitions",
      "aliases": [
        "Convergence to moderate weighting",
        "Alignment with common-sense person-affecting"
      ],
      "type": "concept",
      "description": "Validation evidence that sliding-scale, person-moment preference aggregation reproduces moderate person-affecting judgments where existing people’s futures are weighted more but not infinitely more.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Final paragraphs argue that the proposal approximates ‘moderate’ person-affecting views, serving as qualitative validation."
    },
    {
      "name": "Define AI utility functions using connectedness-weighted person-moment preferences during model design",
      "aliases": [
        "Design connectedness utility for AI",
        "Embed sliding-scale ethics in AI objective"
      ],
      "type": "intervention",
      "description": "At model-design time specify a formal utility function that aggregates person-moment preferences with weights derived from psychological connectedness, replacing naïve person-affecting objectives.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Requires specifying objective prior to training – implicit throughout blog when proposing a new ethical framework.",
      "intervention_maturity": "1",
      "intervention_maturity_rationale": "Purely theoretical; no empirical implementation is reported.",
      "node_rationale": "Directly operationalises the proposed ethical shift to resolve the identified misalignment risk."
    },
    {
      "name": "Fine-tune models to learn connectedness weights from human preference data",
      "aliases": [
        "RLHF connectedness weighting",
        "Preference-learning of person-moment links"
      ],
      "type": "intervention",
      "description": "During fine-tuning/RL, train the model on annotated or inferred human data to calibrate the connectedness weighting function, ensuring empirical grounding of the utility calculation.",
      "concept_category": null,
      "intervention_lifecycle": "3",
      "intervention_lifecycle_rationale": "Applies after pre-training when adjusting the model’s value function through RLHF or similar techniques.",
      "intervention_maturity": "1",
      "intervention_maturity_rationale": "Only inferred as a logical next step; not yet experimentally demonstrated.",
      "node_rationale": "Reduces specification-gap between theoretical utility definition and learned model behaviour."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Value misalignment in AI population ethics decision-making",
      "target_node": "Incomparability of worlds under person-affecting views with ambiguous person identity",
      "description": "When AI systems inherit person-affecting frameworks that cannot compare many futures, their decisions become misaligned.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Reasoned inference; the blog states the comparability problem but not AI explicitly.",
      "edge_rationale": "The problem analysis explains the mechanism producing the risk."
    },
    {
      "type": "caused_by",
      "source_node": "Incomparability of worlds under person-affecting views with ambiguous person identity",
      "target_node": "Personhood as pragmatic clustering of person-moments without objective boundaries",
      "description": "Incomparability arises because personal identity lacks objective facts once the further-fact view is rejected.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicit philosophical argument in the text.",
      "edge_rationale": "Shows how the theoretical insight underpins the problem."
    },
    {
      "type": "mitigated_by",
      "source_node": "Personhood as pragmatic clustering of person-moments without objective boundaries",
      "target_node": "Shift to person-moment based ethical evaluation using preference utilitarianism",
      "description": "Evaluating welfare at the person-moment level bypasses the need for precise person boundaries.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Stated proposal to resolve identity ambiguity.",
      "edge_rationale": "Design rationale offers a solution to the theoretical issue."
    },
    {
      "type": "implemented_by",
      "source_node": "Shift to person-moment based ethical evaluation using preference utilitarianism",
      "target_node": "Connectedness-weighted utility calculation algorithm for person-moment preferences",
      "description": "Algorithmically assigns sliding-scale weights to future person-moments when computing expected utility.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Implicit technical translation; not formally specified in text.",
      "edge_rationale": "Mechanism operationalises the design rationale."
    },
    {
      "type": "implemented_by",
      "source_node": "Shift to person-moment based ethical evaluation using preference utilitarianism",
      "target_node": "Linguistic preference extraction to estimate present person-moment desires",
      "description": "Extracts the preference inputs required for the person-moment utility calculation.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Moderate inference from discussion of present moments caring about their futures.",
      "edge_rationale": "Second mechanism needed to realise the design."
    },
    {
      "type": "validated_by",
      "source_node": "Connectedness-weighted utility calculation algorithm for person-moment preferences",
      "target_node": "Theoretical consistency with moderate person-affecting intuitions",
      "description": "The algorithm yields outcomes aligning with moderate person-affecting judgments, providing conceptual validation.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Validation is qualitative and speculative.",
      "edge_rationale": "Connects mechanism to evidence node."
    },
    {
      "type": "validated_by",
      "source_node": "Linguistic preference extraction to estimate present person-moment desires",
      "target_node": "Theoretical consistency with moderate person-affecting intuitions",
      "description": "Demonstrates that using real preference data can maintain the desired ethical weighting.",
      "edge_confidence": "1",
      "edge_confidence_rationale": "Highly speculative link; no empirical proof offered.",
      "edge_rationale": "Shows shared validation pathway."
    },
    {
      "type": "motivates",
      "source_node": "Theoretical consistency with moderate person-affecting intuitions",
      "target_node": "Define AI utility functions using connectedness-weighted person-moment preferences during model design",
      "description": "Because the approach appears philosophically sound, designers are encouraged to embed it directly in AI objectives.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Reasonable inference from theoretical validation.",
      "edge_rationale": "Evidence node informs intervention choice."
    },
    {
      "type": "motivates",
      "source_node": "Theoretical consistency with moderate person-affecting intuitions",
      "target_node": "Fine-tune models to learn connectedness weights from human preference data",
      "description": "Validation suggests further refinement by learning weights from actual preferences.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Same as above; speculative but coherent.",
      "edge_rationale": "Evidence node supports secondary intervention."
    }
  ],
  "meta": [
    {
      "key": "url",
      "value": "https://www.lesswrong.com/posts/LpnMyeNvgvsbSLAwB/person-moment-affecting-views"
    },
    {
      "key": "title",
      "value": "Person-moment affecting views"
    },
    {
      "key": "date_published",
      "value": "2018-03-07T02:30:00Z"
    },
    {
      "key": "authors",
      "value": [
        "KatjaGrace"
      ]
    },
    {
      "key": "source",
      "value": "lesswrong"
    }
  ]
}