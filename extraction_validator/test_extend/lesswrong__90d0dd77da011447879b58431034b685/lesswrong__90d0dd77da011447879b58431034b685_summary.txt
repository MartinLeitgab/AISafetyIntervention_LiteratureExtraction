Summary  
Data source overview: The post argues that Functional Decision Theory (FDT) is a better foundation for AI alignment than Causal Decision Theory (CDT).  It reports an experimental attempt to instantiate FDT-style reasoning in GPT-2-xl via Archetypal Transfer Learning (ATL) on a “Set of Robust Concepts” (SoRC) narrative dataset, integrates an explicit shutdown keyword (“activate oath”) for corrigibility, and evaluates the tuned model on three catastrophic-scenario benchmarks.

EXTRACTION CONFIDENCE [83]

Inference strategy justification: All nodes are directly grounded in named sections (“Intro”, “CDT vs FDT”, “Corrigibility and FDT”, “Implementing FDT using ATL”, “Experiment setup”, “Assessment of Results”).  Moderate inference (confidence 2) was only used to turn the empirical observations into four implicit interventions suggested by the author (dataset refinement, systematic evaluation, interpretability, and explicit protocol embedding).

Extraction completeness explanation: 16 nodes capture every distinct claim, mechanism, finding and proposed/implicit intervention spanning the full chain risk→problem→theory→design→implementation→evidence→intervention.  All nodes are connected; no satellites remain.

Key limitations: 1) Results come from a single, small-scale experiment—edge confidences are therefore ≤ 3. 2) Some interventions are inferential rather than explicitly prescribed. 3) The ATL framework may hide additional sub-mechanisms not fully decomposed in the source text.

JSON fabric follows.



Improvements to extraction instructions:  
• Clarify whether multiple design rationales may feed into distinct implementation mechanisms so edge direction conventions remain unambiguous.  
• Provide explicit mapping examples where one validation evidence node motivates several interventions, to avoid guesswork on edge multiplicity.  
• Include “refined_by” and “complemented_by” in the canonical edge list to capture hierarchical and lateral relationships commonly seen.  

Key limitations remain that confidence levels rely on author-reported single-model experiments and no independent replication.