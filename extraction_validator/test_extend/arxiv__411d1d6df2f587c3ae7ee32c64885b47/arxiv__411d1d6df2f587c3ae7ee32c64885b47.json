{
  "nodes": [
    {
      "name": "Uncorrectable analytical errors in fully autonomous information agents for intelligence analysis",
      "aliases": [
        "irreversible mistakes by autonomous intelligence agents",
        "agent misanalysis without human correction"
      ],
      "type": "concept",
      "description": "Fully autonomous intelligence-collection agents may misinterpret or misclassify data and produce wrong hypotheses without any human ability to notice or repair the error, endangering decision quality.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Highlighted as downside (1) of autonomous mode in section “Collaborative Intelligence Analysis (CIA) tool”."
    },
    {
      "name": "Privacy violations due to uncontrolled data source access by autonomous information agents",
      "aliases": [
        "unethical data collection by AI agents",
        "unauthorised source access"
      ],
      "type": "concept",
      "description": "When agents autonomously pull data, they can access sensitive or legally restricted sources, infringing privacy and ethical constraints.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Presented as downside (2) of autonomous mode in “Collaborative Intelligence Analysis (CIA) tool”."
    },
    {
      "name": "Delayed intelligence decision-making from manual intelligence analysis",
      "aliases": [
        "inefficient manual analysis",
        "slow situational assessment"
      ],
      "type": "concept",
      "description": "Purely manual collection and cross-referencing of vast data sets is time-consuming and tedious, risking late or missed decisions.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Discussed in “Collaborative Intelligence Analysis (CIA) tool” where manual mode is described as time-consuming and tedious."
    },
    {
      "name": "Lack of human oversight in autonomous intelligence collection",
      "aliases": [
        "absent human monitoring",
        "no human-in-the-loop"
      ],
      "type": "concept",
      "description": "When agents operate autonomously, humans cannot monitor, steer, or correct their actions or intermediate conclusions.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Explained in “Collaborative Intelligence Analysis (CIA) tool” as root cause of both errors and privacy concerns."
    },
    {
      "name": "Human cognitive limitations in manual intelligence analysis",
      "aliases": [
        "limited human processing capacity",
        "information overload for analysts"
      ],
      "type": "concept",
      "description": "Humans alone cannot cross-reference or process the volume and velocity of modern open-source data efficiently.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Stated in “Collaborative Intelligence Analysis (CIA) tool” where manual mode is contrasted with agent speed."
    },
    {
      "name": "Balancing human expertise with agent processing through teaming intelligence",
      "aliases": [
        "teaming intelligence concept",
        "human-AI complementarity"
      ],
      "type": "concept",
      "description": "Theoretical view that optimal performance arises from combining humans’ domain intuition with machines’ data-processing capabilities.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced in “Introduction” citing ‘no AI is an island’ argument for teaming intelligence."
    },
    {
      "name": "Team design patterns enable structured human-agent collaboration",
      "aliases": [
        "teamwork pattern language",
        "collaboration pattern framework"
      ],
      "type": "concept",
      "description": "Reusable design patterns (manual, supervisory control, phased autonomy, etc.) provide structure for specifying and analysing human-agent work distribution.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Described in “Team design patterns for information agents”."
    },
    {
      "name": "Phased autonomy pattern facilitating dynamic handover and monitoring",
      "aliases": [
        "graduated autonomy pattern",
        "dynamic handover model"
      ],
      "type": "concept",
      "description": "Design rationale in which a task transitions from manual execution through a handover phase to high autonomy while maintaining minimal human monitoring capacity.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Explained with subtleties (handover phase, residual monitoring) in “Team design patterns for information agents”."
    },
    {
      "name": "Collaborative analysis mode combining agent speed with human guidance",
      "aliases": [
        "mixed-initiative intelligence analysis",
        "human-agent collaborative mode"
      ],
      "type": "concept",
      "description": "Design rationale where both human and agents work simultaneously: the agent gathers/processes data quickly while the human guides hypotheses and ethical constraints.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Outlined in “Collaborative Intelligence Analysis (CIA) tool” as desirable balance."
    },
    {
      "name": "CIA tool implementing team design patterns in intelligence analysis scenario",
      "aliases": [
        "Collaborative Intelligence Analysis framework",
        "CIA experimental platform"
      ],
      "type": "concept",
      "description": "Software environment built on MATRXS that can run manual, autonomous, and collaborative modes to instantiate and test specific team design patterns.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Implementation vehicle described in “Collaborative Intelligence Analysis (CIA) tool”."
    },
    {
      "name": "Monitoring interface for source selection and error correction",
      "aliases": [
        "supervisory control UI",
        "human oversight dashboard"
      ],
      "type": "concept",
      "description": "Interface elements allowing humans to approve sensitive sources, observe agent reasoning, and intervene to correct mistakes during analysis.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Implied necessity in “Collaborative Intelligence Analysis (CIA) tool” downsides and proposed collaboration features."
    },
    {
      "name": "Preliminary observations of efficiency gains in CIA collaborative mode",
      "aliases": [
        "early CIA results",
        "qualitative performance comparison"
      ],
      "type": "concept",
      "description": "Initial comparisons suggest collaborative mode reduces analyst workload and maintains or improves accuracy relative to manual or autonomous modes.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Mentioned as expectation and early observation in “Collaborative Intelligence Analysis (CIA) tool”, pending full evaluation."
    },
    {
      "name": "Design intelligence information agents with phased autonomy pattern",
      "aliases": [
        "apply phased autonomy to agents",
        "embed dynamic handover design"
      ],
      "type": "intervention",
      "description": "During system design, architect information-collection agents to operate under phased autonomy, including mandatory handover phases and continuous minimal monitoring hooks.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Pattern is a core architectural choice made in design stage (section “Team design patterns for information agents”).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Currently demonstrated only in proof-of-concept CIA tool, no systematic deployment (section “Collaborative Intelligence Analysis (CIA) tool”).",
      "node_rationale": "Actionable design step directly derived from phased autonomy rationale."
    },
    {
      "name": "Deploy CIA collaborative mode for operational intelligence analysis",
      "aliases": [
        "use CIA tool collaboratively",
        "operate mixed-initiative CIA"
      ],
      "type": "intervention",
      "description": "Roll out the collaborative mode of the CIA tool (or equivalent systems) in live intelligence workflows so humans and agents jointly collect and process data.",
      "concept_category": null,
      "intervention_lifecycle": "5",
      "intervention_lifecycle_rationale": "This action occurs at deployment into operational settings (section “Collaborative Intelligence Analysis (CIA) tool”).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Tool is at proof-of-concept; deployment would be initial pilot rather than large-scale operational (same section).",
      "node_rationale": "Converts validated mechanism into real-world practice to address identified risks."
    },
    {
      "name": "Implement supervisory control interfaces for source approval in information agents",
      "aliases": [
        "build oversight dashboards",
        "add human approval checkpoints"
      ],
      "type": "intervention",
      "description": "Create user interfaces and control protocols that require human approval for sensitive data-source access and allow live correction of agent errors during collection.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Interface and protocol design decisions are part of initial system specification (section “Collaborative Intelligence Analysis (CIA) tool”).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Described conceptually and partially in CIA prototype; not yet validated at scale.",
      "node_rationale": "Directly mitigates privacy and error risks by inserting human oversight."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Uncorrectable analytical errors in fully autonomous information agents for intelligence analysis",
      "target_node": "Lack of human oversight in autonomous intelligence collection",
      "description": "Errors become uncorrectable precisely because no human monitors or can intervene.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicit statement in CIA tool section; qualitative but clear.",
      "edge_rationale": "Downside (1) links absence of oversight to inability to fix mistakes."
    },
    {
      "type": "caused_by",
      "source_node": "Privacy violations due to uncontrolled data source access by autonomous information agents",
      "target_node": "Lack of human oversight in autonomous intelligence collection",
      "description": "Without oversight, agents may query restricted or sensitive sources, leading to privacy breaches.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Directly stated in CIA tool downside (2).",
      "edge_rationale": "Paper ties privacy risk to lack of human control over source selection."
    },
    {
      "type": "caused_by",
      "source_node": "Delayed intelligence decision-making from manual intelligence analysis",
      "target_node": "Human cognitive limitations in manual intelligence analysis",
      "description": "Slow decision-making results from analysts’ limited ability to process large data volumes rapidly.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Described in CIA tool section comparing manual workload with agent speed.",
      "edge_rationale": "Manual mode delay is attributed to human capacity limits."
    },
    {
      "type": "addressed_by",
      "source_node": "Lack of human oversight in autonomous intelligence collection",
      "target_node": "Balancing human expertise with agent processing through teaming intelligence",
      "description": "The concept of teaming intelligence proposes re-introducing human capabilities into otherwise autonomous workflows.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Link is logical extrapolation of ‘no AI is an island’ argument; moderately explicit.",
      "edge_rationale": "Teaming intelligence is presented as general solution to oversight gaps."
    },
    {
      "type": "addressed_by",
      "source_node": "Human cognitive limitations in manual intelligence analysis",
      "target_node": "Balancing human expertise with agent processing through teaming intelligence",
      "description": "Teaming intelligence supplements human capacity with automated processing, resolving overload.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Supported by introduction but not empirically measured.",
      "edge_rationale": "Combining strengths mitigates human limits."
    },
    {
      "type": "refined_by",
      "source_node": "Balancing human expertise with agent processing through teaming intelligence",
      "target_node": "Team design patterns enable structured human-agent collaboration",
      "description": "Team design patterns operationalise the abstract concept of teaming intelligence.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Patterns described as implementation of teaming principles in Team Design Patterns section.",
      "edge_rationale": "Patterns are concrete refinement."
    },
    {
      "type": "mitigated_by",
      "source_node": "Team design patterns enable structured human-agent collaboration",
      "target_node": "Phased autonomy pattern facilitating dynamic handover and monitoring",
      "description": "Phased autonomy is one specific pattern to achieve collaboration.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Pattern illustrated explicitly in Figure 1.",
      "edge_rationale": "Phased autonomy is subset of pattern language aimed at mitigation."
    },
    {
      "type": "mitigated_by",
      "source_node": "Team design patterns enable structured human-agent collaboration",
      "target_node": "Collaborative analysis mode combining agent speed with human guidance",
      "description": "Collaborative analysis mode is another pattern instance for structured teaming.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Described as one of three modes in CIA tool.",
      "edge_rationale": "Provides alternative design direction."
    },
    {
      "type": "implemented_by",
      "source_node": "Phased autonomy pattern facilitating dynamic handover and monitoring",
      "target_node": "CIA tool implementing team design patterns in intelligence analysis scenario",
      "description": "CIA platform can be configured to exercise phased autonomy through mode switching and handover.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Tool supports mode transitions discussed in pattern section.",
      "edge_rationale": "Tool realises the pattern in practice."
    },
    {
      "type": "implemented_by",
      "source_node": "Phased autonomy pattern facilitating dynamic handover and monitoring",
      "target_node": "Monitoring interface for source selection and error correction",
      "description": "Monitoring interface is necessary component enabling residual human oversight in phased autonomy.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Interface requirement implied but not fully detailed; moderate inference.",
      "edge_rationale": "Interface realises monitoring aspect of pattern."
    },
    {
      "type": "implemented_by",
      "source_node": "Collaborative analysis mode combining agent speed with human guidance",
      "target_node": "CIA tool implementing team design patterns in intelligence analysis scenario",
      "description": "CIA’s collaborative mode embodies simultaneous human-agent work distribution.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Tool explicitly supports collaborative mode.",
      "edge_rationale": "Software instantiates mode."
    },
    {
      "type": "implemented_by",
      "source_node": "Collaborative analysis mode combining agent speed with human guidance",
      "target_node": "Monitoring interface for source selection and error correction",
      "description": "Collaborative mode depends on interfaces that let the human steer agents and correct them.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Interface necessity inferred from described downsides; partially explicit.",
      "edge_rationale": "Interface operationalises collaboration."
    },
    {
      "type": "validated_by",
      "source_node": "CIA tool implementing team design patterns in intelligence analysis scenario",
      "target_node": "Preliminary observations of efficiency gains in CIA collaborative mode",
      "description": "Early qualitative comparisons serve as validation that tool-based collaboration improves efficiency.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Observations are preliminary, not rigorous.",
      "edge_rationale": "Tool performance data supports mechanism."
    },
    {
      "type": "validated_by",
      "source_node": "Monitoring interface for source selection and error correction",
      "target_node": "Preliminary observations of efficiency gains in CIA collaborative mode",
      "description": "Initial tests indicate that oversight interfaces help achieve better outcomes.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Only anticipated benefits, weak empirical backing.",
      "edge_rationale": "Evidence links interface to improved collaboration."
    },
    {
      "type": "motivates",
      "source_node": "Preliminary observations of efficiency gains in CIA collaborative mode",
      "target_node": "Design intelligence information agents with phased autonomy pattern",
      "description": "Positive early results motivate adopting phased autonomy in future agent designs.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Motivation statement inferred from authors’ future-work plans.",
      "edge_rationale": "Evidence encourages specific design intervention."
    },
    {
      "type": "motivates",
      "source_node": "Preliminary observations of efficiency gains in CIA collaborative mode",
      "target_node": "Deploy CIA collaborative mode for operational intelligence analysis",
      "description": "Efficiency gains motivate deploying the collaborative mode operationally.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Proposal mentioned but not yet enacted.",
      "edge_rationale": "Evidence supports operational deployment."
    },
    {
      "type": "motivates",
      "source_node": "Preliminary observations of efficiency gains in CIA collaborative mode",
      "target_node": "Implement supervisory control interfaces for source approval in information agents",
      "description": "Findings highlight need for robust supervision interfaces before wider rollout.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Interface motivation inferred from identified downsides and preliminary tests.",
      "edge_rationale": "Validation informs design refinement."
    }
  ],
  "meta": [
    {
      "key": "source",
      "value": "arxiv"
    },
    {
      "key": "date_published",
      "value": "2021-01-15T00:00:00Z"
    },
    {
      "key": "url",
      "value": "https://arxiv.org/abs/2101.06133"
    },
    {
      "key": "authors",
      "value": [
        "Jurriaan van Diggelen",
        "Wiard Jorritsma",
        "Bob van der Vecht"
      ]
    },
    {
      "key": "title",
      "value": "Teaming up with information agents"
    }
  ]
}