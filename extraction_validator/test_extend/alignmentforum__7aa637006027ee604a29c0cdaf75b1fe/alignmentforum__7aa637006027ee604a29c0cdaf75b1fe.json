{
  "nodes": [
    {
      "name": "Incorrect predictions of AI behaviour due to anthropomorphic conflation",
      "aliases": [
        "Mischaracterisation of AI goal-directedness",
        "Predictive errors from human-centric abstractions"
      ],
      "type": "concept",
      "description": "Using human-like notions of agency to model dissimilar artificial systems can lead to systematic prediction errors, especially off-distribution, threatening alignment and safety.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Opening paragraphs describing dangers of conflating dissimilar actors"
    },
    {
      "name": "Abstractive conflation of goal-directed phenomena across dissimilar systems",
      "aliases": [
        "Over-generalised goal-directed abstraction",
        "Conflation of distinct computational behaviours"
      ],
      "type": "concept",
      "description": "Humans merge superficially similar behaviours of different systems into one coarse concept of 'goal-directedness', ignoring deep mechanistic differences.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Paragraphs on conflation due to similar actors and predictive sufficiency"
    },
    {
      "name": "Coupled impressions of separable properties in goal-directedness",
      "aliases": [
        "Coupling of independent behavioural facets",
        "Assumed co-occurrence of distinct goal properties"
      ],
      "type": "concept",
      "description": "Observers often assume that if one hallmark of agency is present, others must be too, even though these properties are conceptually separable (e.g., deliberation vs reflex).",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Footnote 2 explanation of separability and coupling"
    },
    {
      "name": "Decoupling computational abstractions enhances out-of-distribution behaviour prediction",
      "aliases": [
        "Refined abstractions improve extrapolation",
        "Separating properties aids forecasting"
      ],
      "type": "concept",
      "description": "Recognising and modelling distinct components of goal-directed behaviour allows more reliable forecasts when systems operate outside their typical domains.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Stated motivation to predict counterfactual/off-distribution implications"
    },
    {
      "name": "Conceptual framework decomposition of goal-directed behaviour components",
      "aliases": [
        "Framework for granular goal analysis",
        "Structured decomposition of agency"
      ],
      "type": "concept",
      "description": "A deliberate effort to build terminology and structure that distinguish multiple facets (e.g., deliberation, reflexes, generation process) of goal-directed systems.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Author's stated aim to build 'conceptual framework of computational abstractions'"
    },
    {
      "name": "Taxonomy of goal-directed dimensions across diverse system menagerie",
      "aliases": [
        "Goal-directedness taxonomy",
        "Multi-dimensional agent property table"
      ],
      "type": "concept",
      "description": "Implementation of the framework using a variety of natural and artificial examples to instantiate axes such as deliberation vs reflex and generation vs runtime behaviour.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "References to 'diverse menagerie' and forthcoming sections 'Deliberation and Reflexes'"
    },
    {
      "name": "Cross-domain analogy clarity between ants, genes and chess engines",
      "aliases": [
        "Menagerie comparison findings",
        "Qualitative evidence from diverse agents"
      ],
      "type": "concept",
      "description": "Using the taxonomy reveals where analogies hold or break, demonstrating its usefulness in discriminating behavioural mechanisms.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section describing how diverse examples informed and validated abstractions"
    },
    {
      "name": "Adopt granular goal-directedness taxonomy in AI risk assessment processes",
      "aliases": [
        "Apply refined agency framework during safety reviews",
        "Use decomposition taxonomy for model evaluation"
      ],
      "type": "intervention",
      "description": "During pre-deployment safety analyses, practitioners explicitly rate AI systems along the taxonomy’s dimensions to uncover mispredictions arising from anthropomorphic conflation.",
      "concept_category": null,
      "intervention_lifecycle": "4",
      "intervention_lifecycle_rationale": "Applies in 'Pre-Deployment Testing' phase where risk assessment occurs; inferred from discussion of predicting counterfactual behaviours",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Framework is conceptual and experimental; no systematic large-scale validation yet",
      "node_rationale": "Logical next step to operationalise the proposed framework for safety impact"
    },
    {
      "name": "Educate AI researchers on decoupled abstractions via interdisciplinary venues",
      "aliases": [
        "Interdisciplinary training to reduce anthropomorphism",
        "Workshops on goal-directedness decomposition"
      ],
      "type": "intervention",
      "description": "Create forums where entomologists, economists, AI researchers, etc., share domain insights, fostering uptake of the taxonomy and reducing conflation biases.",
      "concept_category": null,
      "intervention_lifecycle": "6",
      "intervention_lifecycle_rationale": "An organisational/educational measure beyond the system life-cycle phases",
      "intervention_maturity": "1",
      "intervention_maturity_rationale": "Speculative, foundational outreach activity suggested by footnote 5 about experts rarely meeting",
      "node_rationale": "Addresses communication gaps identified as root cause of abstraction errors"
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Incorrect predictions of AI behaviour due to anthropomorphic conflation",
      "target_node": "Abstractive conflation of goal-directed phenomena across dissimilar systems",
      "description": "Prediction errors stem from using over-generalised abstractions that ignore mechanistic differences.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicit logical argument in opening paragraphs but no quantitative data",
      "edge_rationale": "Opening discussion of conflation causing poor out-of-distribution prediction"
    },
    {
      "type": "caused_by",
      "source_node": "Abstractive conflation of goal-directed phenomena across dissimilar systems",
      "target_node": "Coupled impressions of separable properties in goal-directedness",
      "description": "Conflation is aggravated when observers assume separable properties always co-exist.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Footnote 2 explicitly states coupling leads to mistaken assumptions",
      "edge_rationale": "Footnote 2 elaboration"
    },
    {
      "type": "mitigated_by",
      "source_node": "Abstractive conflation of goal-directed phenomena across dissimilar systems",
      "target_node": "Decoupling computational abstractions enhances out-of-distribution behaviour prediction",
      "description": "Separating abstractions directly addresses the root conflation problem.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Author claims refined abstractions improve prediction but lacks empirical study",
      "edge_rationale": "Paragraph stating goal to better predict implications"
    },
    {
      "type": "implemented_by",
      "source_node": "Decoupling computational abstractions enhances out-of-distribution behaviour prediction",
      "target_node": "Conceptual framework decomposition of goal-directed behaviour components",
      "description": "The framework operationalises the theoretical insight by defining distinct components.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Framework presented as the concrete product of the insight",
      "edge_rationale": "Author’s description of 'take steps to break down'"
    },
    {
      "type": "implemented_by",
      "source_node": "Conceptual framework decomposition of goal-directed behaviour components",
      "target_node": "Taxonomy of goal-directed dimensions across diverse system menagerie",
      "description": "The taxonomy instantiates the framework with concrete dimensions and examples.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Text references menagerie grounding the framework",
      "edge_rationale": "Paragraphs introducing diverse examples"
    },
    {
      "type": "validated_by",
      "source_node": "Taxonomy of goal-directed dimensions across diverse system menagerie",
      "target_node": "Cross-domain analogy clarity between ants, genes and chess engines",
      "description": "Comparative analysis across domains shows taxonomy discriminates behaviours effectively.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Qualitative examples, no formal study",
      "edge_rationale": "Section describing insights from menagerie"
    },
    {
      "type": "motivates",
      "source_node": "Cross-domain analogy clarity between ants, genes and chess engines",
      "target_node": "Adopt granular goal-directedness taxonomy in AI risk assessment processes",
      "description": "Demonstrated utility suggests integrating taxonomy into practical risk assessment.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Inference from qualitative success to proposed application",
      "edge_rationale": "Logical extension from validation findings to safety practice"
    },
    {
      "type": "motivates",
      "source_node": "Coupled impressions of separable properties in goal-directedness",
      "target_node": "Educate AI researchers on decoupled abstractions via interdisciplinary venues",
      "description": "Identified communication gaps among experts motivate educational interventions.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Based on footnote 5 observation; intervention inferred",
      "edge_rationale": "Footnote 5 noting experts rarely interact"
    },
    {
      "type": "addressed_by",
      "source_node": "Incorrect predictions of AI behaviour due to anthropomorphic conflation",
      "target_node": "Adopt granular goal-directedness taxonomy in AI risk assessment processes",
      "description": "Applying the taxonomy during assessments directly reduces misprediction risk.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Intervention inferred as logical mitigation; no empirical validation",
      "edge_rationale": "Combined reasoning from risk statement and framework purpose"
    }
  ],
  "meta": [
    {
      "key": "url",
      "value": "https://www.alignmentforum.org/posts/WhETfFgkfNSTShc4y/breaking-down-goal-directed-behaviour"
    },
    {
      "key": "title",
      "value": "Breaking Down Goal-Directed Behaviour"
    },
    {
      "key": "date_published",
      "value": "2022-06-16T18:45:12Z"
    },
    {
      "key": "authors",
      "value": [
        "Oliver Sourbut"
      ]
    },
    {
      "key": "source",
      "value": "alignmentforum"
    }
  ]
}