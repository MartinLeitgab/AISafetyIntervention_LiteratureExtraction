{
  "nodes": [
    {
      "name": "Misallocation of AI safety resources due to doom-based bias in risk assessments",
      "aliases": [
        "Resource misprioritization from doom bias",
        "Inefficient AI safety focus caused by doominess"
      ],
      "type": "concept",
      "description": "Decision-makers may dedicate effort and funding to the wrong safety problems when guided by an undifferentiated sense of impending AI catastrophe rather than evidence-based risk decomposition.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Opening paragraphs argue that a ‘general factor of doom’ can distort judgments and lead to harmful mis-prioritisation."
    },
    {
      "name": "Correlated answers to distinct AI risk questions among researchers",
      "aliases": [
        "Answer correlation across independent AI doom questions",
        "Uniform responses to varied AI alignment uncertainties"
      ],
      "type": "concept",
      "description": "Researchers often give similarly pessimistic or optimistic answers to many different questions (e.g., timelines, take-off speed, governance difficulty) that should not be strongly linked.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Central diagnostic phenomenon described mid-essay as evidence something is amiss."
    },
    {
      "name": "General factor of doom bias influencing AI risk judgments",
      "aliases": [
        "Doominess latent factor",
        "Single doom prior driving answers"
      ],
      "type": "concept",
      "description": "A hypothesised cognitive bias whereby a single subjective probability of disaster determines answers to many specific questions, leading to excessive answer correlation.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Proposed explanatory mechanism for the observed answer correlations."
    },
    {
      "name": "Independent evaluation of discrete AI risk factors improves calibration",
      "aliases": [
        "Factor-by-factor judgment improves accuracy",
        "Decoupled risk assessment"
      ],
      "type": "concept",
      "description": "Forming beliefs about each uncertain variable (e.g., timelines, take-off speed, corrigibility) separately and aggregating them later should reduce bias and yield more reliable p(Doom).",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Author claims more detailed modelling is the normative alternative to the doom factor."
    },
    {
      "name": "Survey-based measurement of doom bias in AI safety community",
      "aliases": [
        "Detecting doom factor via surveys",
        "Empirical test for doom bias"
      ],
      "type": "concept",
      "description": "Designing research instruments that ask many specific, not-obviously-related AI risk questions to quantify whether a latent doom factor drives respondents’ answers.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Proposed approach for diagnosing the bias so that it can be addressed."
    },
    {
      "name": "Structured decomposition of AI risk assessments into independent subquestions",
      "aliases": [
        "Decomposed AI safety forecasting",
        "Factorised risk elicitation"
      ],
      "type": "concept",
      "description": "Creating analytical or forecasting frameworks that force experts to reason about many orthogonal uncertainties instead of making a single doom judgement.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Second solution path the author hints at: require disaggregation to curb the bias."
    },
    {
      "name": "Multi-question survey including diverse AI doom-related items",
      "aliases": [
        "Comprehensive AI risk questionnaire",
        "Battery of independent AI safety questions"
      ],
      "type": "concept",
      "description": "An instrument listing many specific questions (e.g., timelines, value fragility, governance feasibility) that are deliberately hard to answer using one overall mood.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Concrete tool that operationalises the survey-measurement design."
    },
    {
      "name": "Statistical correlation analysis of survey responses to detect global bias",
      "aliases": [
        "Latent factor analysis of doom survey",
        "Correlation matrix of risk answers"
      ],
      "type": "concept",
      "description": "Using methods such as PCA or factor analysis on survey data to test whether a single latent variable explains most variance across answers.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Required analytic step to confirm or refute existence of the general doom factor."
    },
    {
      "name": "Scenario-vignette method combining random AI risk parameter combinations",
      "aliases": [
        "Randomised future scenario construction",
        "Counter-doom vignette generation"
      ],
      "type": "concept",
      "description": "Building plausible narrative futures by randomly selecting values (doomy / non-doomy) for each subquestion, illustrating the richness of possible outcomes and discouraging simple doom priors.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Mechanism for the structured-decomposition pathway mentioned in footnote 6."
    },
    {
      "name": "Climate expert survey showing inverse geoengineering support versus damage expectations",
      "aliases": [
        "Dannenberg & Zitzelsberger 2019 result",
        "Climate survey inverse geoengineering attitude"
      ],
      "type": "concept",
      "description": "Published Nature Climate Change study where experts expecting severe damages yet low mitigation success were paradoxically *more* opposed to geoengineering, consistent with a doom-bias pattern.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Provides empirical precedent that answer correlation can arise from doom bias."
    },
    {
      "name": "AI Impacts ML researcher survey indicating low doom-correlation",
      "aliases": [
        "2022 expert survey on progress in AI result",
        "Weak correlation in ML doom questions"
      ],
      "type": "concept",
      "description": "Spot-check of several question pairs in the AI Impacts 2022 survey showed little correlation, illustrating that rigorous instruments can sometimes avoid the doom factor.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Used as comparative evidence and partial validation of the analysis approach."
    },
    {
      "name": "Bimodal distribution graph of AI safety opinions",
      "aliases": [
        "Ben Singer doom graph",
        "Bimodal p(Doom) chart"
      ],
      "type": "concept",
      "description": "A widely shared (but informal) chart plotting p(AGI in 20 yrs) vs p(Doom) shows two clusters near 0 and 1, hinting at answer correlation caused by overall mood.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Additional (though weak) evidence that a single doom factor may dominate beliefs."
    },
    {
      "name": "Thought experiment demonstrating many plausible AI futures from random risk parameters",
      "aliases": [
        "Random doom-vector vignette experiment",
        "Footnote 6 scenario thought-experiment"
      ],
      "type": "concept",
      "description": "Author proposes drawing 0/1 values for each subquestion to illustrate the variety of coherent future worlds, supporting the need for decomposition.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Serves as qualitative validation that structured decomposition reveals diverse outcomes."
    },
    {
      "name": "Conduct and analyze multi-question survey among AI safety researchers to quantify and correct general factor of doom bias",
      "aliases": [
        "Run AI-safety doom-bias survey",
        "Empirical study of doom factor in alignment community"
      ],
      "type": "intervention",
      "description": "Design, administer, and statistically analyse a battery of independent AI-risk questions to measure latent doom bias and share results so researchers can recalibrate.",
      "concept_category": null,
      "intervention_lifecycle": "6",
      "intervention_lifecycle_rationale": "The article frames this as a community research activity rather than a model-training phase (conclusion paragraph proposing a survey).",
      "intervention_maturity": "1",
      "intervention_maturity_rationale": "No such dedicated survey has yet been run; idea remains at conceptual stage (conclusion paragraph).",
      "node_rationale": "Primary actionable step suggested to expose and mitigate doom bias."
    },
    {
      "name": "Adopt structured scenario analysis framework requiring independent judgments on AI risk subquestions for research prioritization",
      "aliases": [
        "Factorised scenario analysis for AI safety",
        "Independent-component forecasting protocol"
      ],
      "type": "intervention",
      "description": "Mandate that strategic planning and prioritisation exercises break AI risk into discrete variables, elicit separate estimates, and construct multiple scenarios before allocating resources.",
      "concept_category": null,
      "intervention_lifecycle": "6",
      "intervention_lifecycle_rationale": "Applies to organisational decision-making processes rather than technical development stages (discussion of scenario method).",
      "intervention_maturity": "1",
      "intervention_maturity_rationale": "Proposed in thought-experiment form only; no formal adoption documented.",
      "node_rationale": "Second actionable pathway for reducing misallocation caused by doom bias."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Misallocation of AI safety resources due to doom-based bias in risk assessments",
      "target_node": "Correlated answers to distinct AI risk questions among researchers",
      "description": "Misallocation arises when decisions are grounded in the over-simplified, correlated judgments rather than granular evidence.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Plausible causal link made explicitly in introductory discussion, but without quantitative proof.",
      "edge_rationale": "Introductory paragraphs connect distorted answers to downstream prioritisation errors."
    },
    {
      "type": "caused_by",
      "source_node": "Correlated answers to distinct AI risk questions among researchers",
      "target_node": "General factor of doom bias influencing AI risk judgments",
      "description": "The correlation is hypothesised to stem from a single latent doominess factor that drives all answers.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Author’s conjecture, not empirically verified within AI-safety field.",
      "edge_rationale": "Section speculating on why survey answers show surprising correlation."
    },
    {
      "type": "mitigated_by",
      "source_node": "Correlated answers to distinct AI risk questions among researchers",
      "target_node": "Independent evaluation of discrete AI risk factors improves calibration",
      "description": "Evaluating each question separately breaks the correlation and reduces bias.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Reasoned argument; no direct empirical test yet.",
      "edge_rationale": "Paragraph recommending independent consideration of questions to avoid doom factor."
    },
    {
      "type": "implemented_by",
      "source_node": "Independent evaluation of discrete AI risk factors improves calibration",
      "target_node": "Survey-based measurement of doom bias in AI safety community",
      "description": "Measuring the bias via surveys is a concrete way to operationalise independent factor evaluation.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Logical implementation step proposed by author.",
      "edge_rationale": "Passage proposing an actual survey with many questions."
    },
    {
      "type": "implemented_by",
      "source_node": "Survey-based measurement of doom bias in AI safety community",
      "target_node": "Multi-question survey including diverse AI doom-related items",
      "description": "The multi-question survey is the instrument that realises the measurement design.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Direct design-instrument relationship.",
      "edge_rationale": "Author lists nine example questions to include."
    },
    {
      "type": "implemented_by",
      "source_node": "Survey-based measurement of doom bias in AI safety community",
      "target_node": "Statistical correlation analysis of survey responses to detect global bias",
      "description": "Analysing answer correlations extracts information about the latent doom factor.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Standard survey-analysis step inferred from text.",
      "edge_rationale": "Discussion of checking whether answers are correlated."
    },
    {
      "type": "validated_by",
      "source_node": "Multi-question survey including diverse AI doom-related items",
      "target_node": "Climate expert survey showing inverse geoengineering support versus damage expectations",
      "description": "Climate survey demonstrates the utility of multi-question instruments in revealing doom biases.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Peer-reviewed study supports the survey method’s diagnostic power.",
      "edge_rationale": "Early paragraph citing Nature Climate Change result."
    },
    {
      "type": "validated_by",
      "source_node": "Statistical correlation analysis of survey responses to detect global bias",
      "target_node": "AI Impacts ML researcher survey indicating low doom-correlation",
      "description": "Existing correlation checks in the AI Impacts data provide initial evidence for the method’s sensitivity.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Some empirical data, but only spot-checked by author.",
      "edge_rationale": "Section summarising quick correlation checks."
    },
    {
      "type": "validated_by",
      "source_node": "Statistical correlation analysis of survey responses to detect global bias",
      "target_node": "Bimodal distribution graph of AI safety opinions",
      "description": "The informal graph exemplifies how correlation analysis can surface latent doom clusters.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Anecdotal, non-peer-reviewed chart.",
      "edge_rationale": "Paragraph referencing ‘wildly out-of-date’ graph."
    },
    {
      "type": "implemented_by",
      "source_node": "Independent evaluation of discrete AI risk factors improves calibration",
      "target_node": "Structured decomposition of AI risk assessments into independent subquestions",
      "description": "Decomposition frameworks translate the theoretical need for independence into practice.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Reasoned design mapping, not yet empirically validated.",
      "edge_rationale": "Text arguing experts should decide answers independently then combine."
    },
    {
      "type": "implemented_by",
      "source_node": "Structured decomposition of AI risk assessments into independent subquestions",
      "target_node": "Scenario-vignette method combining random AI risk parameter combinations",
      "description": "Randomised vignette construction is one concrete technique for enforcing decomposition.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Directly cited in footnote 6 as a possible approach.",
      "edge_rationale": "Footnote 6 describing vignette idea."
    },
    {
      "type": "validated_by",
      "source_node": "Scenario-vignette method combining random AI risk parameter combinations",
      "target_node": "Thought experiment demonstrating many plausible AI futures from random risk parameters",
      "description": "The thought experiment shows the method’s ability to generate diverse, plausible futures.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Conceptual validation only.",
      "edge_rationale": "Discussion immediately following footnote 6."
    },
    {
      "type": "motivates",
      "source_node": "Climate expert survey showing inverse geoengineering support versus damage expectations",
      "target_node": "Conduct and analyze multi-question survey among AI safety researchers to quantify and correct general factor of doom bias",
      "description": "Demonstrates that similar surveys can uncover doom bias, encouraging replication in AI-safety field.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Empirical precedent provides moderate support.",
      "edge_rationale": "Author uses climate result as motivation to survey AI-safety experts."
    },
    {
      "type": "motivates",
      "source_node": "AI Impacts ML researcher survey indicating low doom-correlation",
      "target_node": "Conduct and analyze multi-question survey among AI safety researchers to quantify and correct general factor of doom bias",
      "description": "Existing AI survey suggests method feasibility and highlights gap (AI-safety researchers not yet surveyed).",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Some empirical grounding but context differs (ML vs safety).",
      "edge_rationale": "Paragraph noting ML survey ‘probably not relevant’ but still informative."
    },
    {
      "type": "motivates",
      "source_node": "Bimodal distribution graph of AI safety opinions",
      "target_node": "Conduct and analyze multi-question survey among AI safety researchers to quantify and correct general factor of doom bias",
      "description": "Suggests pronounced clustering that a dedicated survey could investigate rigorously.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Graph is anecdotal; still spurs action.",
      "edge_rationale": "Graph cited as further reason the survey would be interesting."
    },
    {
      "type": "motivates",
      "source_node": "Thought experiment demonstrating many plausible AI futures from random risk parameters",
      "target_node": "Adopt structured scenario analysis framework requiring independent judgments on AI risk subquestions for research prioritization",
      "description": "Shows value of scenario-based decomposition, encouraging adoption in planning processes.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Conceptual argument rather than empirical study.",
      "edge_rationale": "Explanation following vignette suggestion."
    },
    {
      "type": "mitigated_by",
      "source_node": "General factor of doom bias influencing AI risk judgments",
      "target_node": "Structured decomposition of AI risk assessments into independent subquestions",
      "description": "Breaking questions apart reduces reliance on a single doom prior, addressing the bias itself.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Logical mitigation pathway proposed in text.",
      "edge_rationale": "Author claims detailed models overcome doom factor."
    }
  ],
  "meta": [
    {
      "key": "date_published",
      "value": "2022-11-23T16:45:49Z"
    },
    {
      "key": "url",
      "value": "https://aiimpacts.org/against-a-general-factor-of-doom/"
    },
    {
      "key": "title",
      "value": "Against a General Factor of Doom"
    },
    {
      "key": "authors",
      "value": [
        "Jeffrey Heninger"
      ]
    },
    {
      "key": "source",
      "value": "blogs"
    }
  ]
}