{
  "nodes": [
    {
      "name": "Global human extinction from misaligned AGI",
      "aliases": [
        "AI existential catastrophe",
        "AGI-driven human extinction"
      ],
      "type": "concept",
      "description": "The scenario in which advanced artificial general intelligence behaves in ways that eliminate humanity because it is not properly aligned with human values.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Introduced in TL;DR and 'The model & results' as the 35 % chance of dying from AGI."
    },
    {
      "name": "High misalignment probability under near-term AGI timelines",
      "aliases": [
        "elevated P(doom) with short AGI timelines",
        "misalignment risk given 35% chance"
      ],
      "type": "concept",
      "description": "Because AGI may arrive soon and alignment research lags, the probability that AGI kills everyone is currently estimated as high (35 % in the author's model).",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "'Probability of surviving AGI' graph explicates this assumption."
    },
    {
      "name": "Insufficient AI safety research relative to AGI development pace increases extinction risk",
      "aliases": [
        "safety research lag",
        "alignment work deficit"
      ],
      "type": "concept",
      "description": "The underlying cause of the high misalignment probability is that technical and governance safety work is progressing slower than capability research.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Discussed in Appendix A where shifting effort into safety is argued to decrease risk."
    },
    {
      "name": "Redirecting talent and resources to AI safety shifts survival probability",
      "aliases": [
        "invest in AI safety",
        "focus on alignment research"
      ],
      "type": "concept",
      "description": "Allocating additional people and funding to AI safety work is proposed as the key way to move probability mass from 'die from AGI' to 'survive AGI'.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Action 1 in Appendix A quantifies this as 'a few microdooms per person'."
    },
    {
      "name": "Technical alignment and AI governance research programs",
      "aliases": [
        "alignment techniques and policy work",
        "safety R&D and regulation"
      ],
      "type": "concept",
      "description": "Concrete safety work includes development of alignment algorithms, interpretability tools, governance frameworks, and policies that can be applied before AGI deployment.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Implied by 'work on AI safety' throughout the post."
    },
    {
      "name": "Monte Carlo model estimates of scenario probabilities",
      "aliases": [
        "probabilistic life outcome simulation results",
        "35% die from AGI model output"
      ],
      "type": "concept",
      "description": "The author’s simulation samples AGI timelines, P(doom), actuarial mortality, and aging-cure arrival to estimate outcome probabilities and the impact of different actions.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "'The model & results' section provides numerical findings used as evidence for all interventions."
    },
    {
      "name": "Work on AI safety research to reduce AGI extinction probability",
      "aliases": [
        "become AI safety researcher",
        "contribute to alignment research"
      ],
      "type": "intervention",
      "description": "Individuals devote their careers or funding to technical alignment and governance research, aiming to lower the probability of misaligned AGI by several micro-dooms per researcher.",
      "concept_category": null,
      "intervention_lifecycle": "6",
      "intervention_lifecycle_rationale": "Career-level or funding decision not tied to a single system development phase (Appendix A).",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "AI-safety research has proof-of-concept methods but limited systematic validation; characterised as experimental.",
      "node_rationale": "Listed as the author’s top recommended action."
    },
    {
      "name": "Individual premature death before AGI arrival",
      "aliases": [
        "death before AGI",
        "natural mortality pre-AGI"
      ],
      "type": "concept",
      "description": "The possibility that a person dies of ordinary causes before AGI exists; 10 % for someone born in 2001 according to the model.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Enumerated as one of the five end-states in 'The model & results'."
    },
    {
      "name": "Historical aging-related mortality rates without AGI",
      "aliases": [
        "baseline human mortality curve",
        "US actuarial life table deaths"
      ],
      "type": "concept",
      "description": "In the absence of AGI-enabled breakthroughs, mortality follows historical actuarial tables, with a steep rise after age 70.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Detailed in 'Without AGI, people keep dying at historical rates'."
    },
    {
      "name": "Limited adoption of healthy lifestyle among individuals leads to higher mortality risk",
      "aliases": [
        "suboptimal health behaviours",
        "risk-increasing lifestyle choices"
      ],
      "type": "concept",
      "description": "Failing to engage in preventive health behaviours maintains the historical death rate, increasing chances of dying before AGI.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Implied by Appendix A action 2 discussing how healthy living can shift probability."
    },
    {
      "name": "Adopting healthy lifestyle extends lifespan until AGI",
      "aliases": [
        "personal health optimisation for AGI wait",
        "longevity habits"
      ],
      "type": "concept",
      "description": "Choosing evidence-based health behaviours transfers roughly 1 % probability from 'die before AGI' to 'survive until AGI' in the model.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Quantified in Appendix A as the effect of action 2."
    },
    {
      "name": "Evidence-based health and risk avoidance practices",
      "aliases": [
        "exercise, diet, medical screening",
        "preventive health behaviours"
      ],
      "type": "concept",
      "description": "Regular exercise, balanced diet, avoiding accidents, and routine medical care are practical mechanisms to realise the healthy-living design rationale.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "General medical consensus, referenced indirectly in action 2."
    },
    {
      "name": "Implement healthy living practices to survive until AGI era",
      "aliases": [
        "practice longevity habits",
        "reduce health risks pre-AGI"
      ],
      "type": "intervention",
      "description": "Individuals actively follow preventive-medicine guidelines and avoid hazardous activities to maximise the chance of living long enough to benefit from AGI advances.",
      "concept_category": null,
      "intervention_lifecycle": "6",
      "intervention_lifecycle_rationale": "Personal behaviour outside specific AI development phases (Appendix A).",
      "intervention_maturity": "4",
      "intervention_maturity_rationale": "Healthy-living interventions are well validated in epidemiological studies; operational at scale.",
      "node_rationale": "Proposed in Appendix A as the second most effective personal action."
    },
    {
      "name": "Longer AGI timelines allow AI safety progress and increase survival probability",
      "aliases": [
        "extended timelines improve alignment",
        "time for safety research"
      ],
      "type": "concept",
      "description": "If AGI arrives later, cumulative safety knowledge and governance improvements reduce P(doom); reflected in model variant with lower risk by 2060.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Discussed under 'Probability of surviving AGI' graphs and Appendix A action 5."
    },
    {
      "name": "Advocating policy to slow AGI development to improve safety",
      "aliases": [
        "slow AGI for safety",
        "timeline extension strategy"
      ],
      "type": "concept",
      "description": "Pushing for deliberate slowdown trades a higher chance of dying before AGI for a lower chance of extinction, potentially beneficial from an altruistic perspective.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Outlined as action 5 in Appendix A."
    },
    {
      "name": "Regulatory and coordination measures delaying AGI timelines",
      "aliases": [
        "moratoriums, compute governance",
        "international agreements to slow AGI"
      ],
      "type": "concept",
      "description": "Possible mechanisms include compute caps, licensing, or treaties that slow capability advances until safety work matures.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Not detailed in text; moderately inferred to complete causal chain from design rationale."
    },
    {
      "name": "Advocate for slowing AGI development to allow safety progress",
      "aliases": [
        "support AGI pause",
        "promote AGI delay policies"
      ],
      "type": "intervention",
      "description": "Engage in policy advocacy, lobbying, or public campaigns for moratoria or regulation that postpone AGI deployment, giving more time for alignment solutions.",
      "concept_category": null,
      "intervention_lifecycle": "6",
      "intervention_lifecycle_rationale": "Policy advocacy operates at ecosystem level, outside specific system phases.",
      "intervention_maturity": "1",
      "intervention_maturity_rationale": "Large-scale AGI slow-down policies remain largely theoretical; limited empirical evidence; inference applied.",
      "node_rationale": "Mentioned in Appendix A option 5; included to capture full action space."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Global human extinction from misaligned AGI",
      "target_node": "High misalignment probability under near-term AGI timelines",
      "description": "A high probability of AGI misalignment directly results in a significant chance of human extinction.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Widely accepted reasoning; explicitly stated by author but without empirical proof ('Probability of surviving AGI').",
      "edge_rationale": "Risk magnitude flows from estimated P(doom) values."
    },
    {
      "type": "caused_by",
      "source_node": "High misalignment probability under near-term AGI timelines",
      "target_node": "Insufficient AI safety research relative to AGI development pace increases extinction risk",
      "description": "The misalignment probability is attributed to a shortage of safety research compared with rapid capability progress.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Reasoning stated qualitatively by author; moderate inference needed.",
      "edge_rationale": "Appendix A frames increased safety work as the remedy, implying current insufficiency causes risk."
    },
    {
      "type": "mitigated_by",
      "source_node": "Insufficient AI safety research relative to AGI development pace increases extinction risk",
      "target_node": "Redirecting talent and resources to AI safety shifts survival probability",
      "description": "Adding more people and money to AI safety directly addresses the research shortfall, lowering extinction risk.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Author claims each person reduces a few micro-dooms; still qualitative.",
      "edge_rationale": "Action 1 in Appendix A quantifies effect."
    },
    {
      "type": "implemented_by",
      "source_node": "Redirecting talent and resources to AI safety shifts survival probability",
      "target_node": "Technical alignment and AI governance research programs",
      "description": "Practical implementation occurs through technical and governance research programmes.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Implementation details inferred; post references 'work on AI safety' without elaboration.",
      "edge_rationale": "Standard route for converting resources into safety progress."
    },
    {
      "type": "validated_by",
      "source_node": "Technical alignment and AI governance research programs",
      "target_node": "Monte Carlo model estimates of scenario probabilities",
      "description": "The simulation provides quantitative evidence for how increased safety effort could shift probabilities.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Model is illustrative, not empirically validated.",
      "edge_rationale": "The author uses simulation outputs to justify effectiveness."
    },
    {
      "type": "motivates",
      "source_node": "Monte Carlo model estimates of scenario probabilities",
      "target_node": "Work on AI safety research to reduce AGI extinction probability",
      "description": "Because the model shows large gains from safety work, it motivates individuals to pursue AI safety careers.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicitly argued in TL;DR and Appendix A.",
      "edge_rationale": "Numerical results underpin the recommendation."
    },
    {
      "type": "mitigated_by",
      "source_node": "High misalignment probability under near-term AGI timelines",
      "target_node": "Longer AGI timelines allow AI safety progress and increase survival probability",
      "description": "Extending timelines reduces misalignment probability by affording more time for safety work.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Author provides qualitative argument and alternative model variant.",
      "edge_rationale": "Alternative graph with longer timelines shows lower P(doom)."
    },
    {
      "type": "mitigated_by",
      "source_node": "Longer AGI timelines allow AI safety progress and increase survival probability",
      "target_node": "Advocating policy to slow AGI development to improve safety",
      "description": "Policy advocacy is proposed as a way to realise the benefit of longer timelines.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Suggested in Appendix A; no data.",
      "edge_rationale": "Delaying AGI is framed as an action that derives from this insight."
    },
    {
      "type": "implemented_by",
      "source_node": "Advocating policy to slow AGI development to improve safety",
      "target_node": "Regulatory and coordination measures delaying AGI timelines",
      "description": "Regulatory and multilateral measures are the concrete mechanisms to slow progress.",
      "edge_confidence": "1",
      "edge_confidence_rationale": "Implementation details are speculative; moderate inference.",
      "edge_rationale": "Standard governance tools inferred for timeline extension."
    },
    {
      "type": "validated_by",
      "source_node": "Regulatory and coordination measures delaying AGI timelines",
      "target_node": "Monte Carlo model estimates of scenario probabilities",
      "description": "The model variant with longer timelines is used as supporting evidence for delay strategies.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Evidence is simulation-based, not empirical.",
      "edge_rationale": "Graph 'conventional estimates' shows reduced AGI death probability with longer timelines."
    },
    {
      "type": "motivates",
      "source_node": "Monte Carlo model estimates of scenario probabilities",
      "target_node": "Advocate for slowing AGI development to allow safety progress",
      "description": "Model outputs showing lower P(doom) under longer timelines encourage advocacy for slowing AGI.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Author presents this action as logically following from model results.",
      "edge_rationale": "Appendix A lists 'Delay AGI' after discussing probability shifts."
    },
    {
      "type": "caused_by",
      "source_node": "Individual premature death before AGI arrival",
      "target_node": "Historical aging-related mortality rates without AGI",
      "description": "Baseline actuarial mortality rates lead individuals to die before AGI is invented.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Actuarial data is robust; directly used in simulation.",
      "edge_rationale": "'Without AGI, people keep dying at historical rates'."
    },
    {
      "type": "caused_by",
      "source_node": "Historical aging-related mortality rates without AGI",
      "target_node": "Limited adoption of healthy lifestyle among individuals leads to higher mortality risk",
      "description": "Persistently high mortality is partly due to widespread failure to adopt preventive health behaviours.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Common epidemiological reasoning; lightly inferred from text.",
      "edge_rationale": "Author implies healthy living can reduce deaths before AGI."
    },
    {
      "type": "mitigated_by",
      "source_node": "Limited adoption of healthy lifestyle among individuals leads to higher mortality risk",
      "target_node": "Adopting healthy lifestyle extends lifespan until AGI",
      "description": "Embracing healthier lifestyles addresses the behavioural shortfall, lowering mortality risk.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Supported by large public-health literature; referenced by author in Appendix A.",
      "edge_rationale": "Action 2 quantifies a ~1 % probability shift."
    },
    {
      "type": "implemented_by",
      "source_node": "Adopting healthy lifestyle extends lifespan until AGI",
      "target_node": "Evidence-based health and risk avoidance practices",
      "description": "Specific practices such as exercise and safe behaviour operationalise the lifestyle strategy.",
      "edge_confidence": "4",
      "edge_confidence_rationale": "Strong epidemiological evidence even if not detailed in post.",
      "edge_rationale": "Standard mechanism for longevity improvements."
    },
    {
      "type": "validated_by",
      "source_node": "Evidence-based health and risk avoidance practices",
      "target_node": "Monte Carlo model estimates of scenario probabilities",
      "description": "The simulation incorporates a ~1 % probability shift to show the effect of healthy living.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Model-based, not experimental validation.",
      "edge_rationale": "Appendix A uses model outputs to estimate impact."
    },
    {
      "type": "motivates",
      "source_node": "Monte Carlo model estimates of scenario probabilities",
      "target_node": "Implement healthy living practices to survive until AGI era",
      "description": "Because the model shows a non-trivial chance to reach AGI by staying healthy, it encourages individuals to adopt preventive practices.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicit recommendation following model results.",
      "edge_rationale": "Listed in Appendix A as an advisable action."
    }
  ],
  "meta": [
    {
      "key": "url",
      "value": "https://www.lesswrong.com/posts/KFWZg6EbCuisGcJAo/immortality-or-death-by-agi-1"
    },
    {
      "key": "title",
      "value": "Immortality or death by AGI"
    },
    {
      "key": "date_published",
      "value": "2023-09-22T00:00:00Z"
    },
    {
      "key": "authors",
      "value": [
        "ImmortalityOrDeathByAGI"
      ]
    },
    {
      "key": "source",
      "value": "lesswrong"
    }
  ]
}