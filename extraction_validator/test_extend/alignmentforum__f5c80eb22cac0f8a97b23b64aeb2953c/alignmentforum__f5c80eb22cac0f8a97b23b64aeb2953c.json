{
  "nodes": [
    {
      "name": "Catastrophic AGI accidents via unsafe capability settings",
      "aliases": [
        "runaway AGI catastrophe",
        "out-of-control AGI self-replication"
      ],
      "type": "concept",
      "description": "System-level risk that advanced AI systems set to high-capability, low-safety modes could escape control, replicate, and cause irreversible global harm.",
      "concept_category": "risk",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Central top-level risk described in opening paragraphs ('catastrophic accidents with out-of-control AGIs')."
    },
    {
      "name": "Unsafe safety-capability dial settings chosen by competitive actors",
      "aliases": [
        "low-safety dial positions",
        "dial set to capability over safety"
      ],
      "type": "concept",
      "description": "Developers may deliberately lower safety parameters to gain capabilities advantages.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Identified as the immediate causal mechanism leading to catastrophes ('subset of people would set their dial to less safe but more capable')."
    },
    {
      "name": "Competitive pressures and lack of liability for AGI risks",
      "aliases": [
        "ambition and optimism incentives",
        "absence of research liability insurance"
      ],
      "type": "concept",
      "description": "Market, personal and national incentives plus weak external liability frameworks push actors toward risk-taking.",
      "concept_category": "problem analysis",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Explained under ‘Background’ section as reasons why unsafe dial settings are selected."
    },
    {
      "name": "Inevitability of safety-capability tradeoff dials in AGI (alignment tax unavoidable)",
      "aliases": [
        "inevitable tradeoff dials",
        "unavoidable alignment tax"
      ],
      "type": "concept",
      "description": "Because every safety measure costs time/compute/opportunity, some tradeoff dial necessarily exists.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Section 2 argues multiple concrete examples showing inevitability."
    },
    {
      "name": "Alignment tax magnitude determines developer incentives",
      "aliases": [
        "height of alignment tax drives behaviour",
        "alignment tax level"
      ],
      "type": "concept",
      "description": "The higher the capability cost of safety, the stronger the incentive to avoid safety measures.",
      "concept_category": "theoretical insight",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Derived from Section 3 ‘alignment tax framing’."
    },
    {
      "name": "Minimising alignment tax to encourage safe dial settings",
      "aliases": [
        "reduce safety-capability tradeoff",
        "lower alignment tax"
      ],
      "type": "concept",
      "description": "Designers should seek safety measures that impose as little capability cost as possible.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Proposed in Section 3 as key strategy."
    },
    {
      "name": "External legibility and auditability of dial settings",
      "aliases": [
        "auditable dial positions",
        "externally legible safety settings"
      ],
      "type": "concept",
      "description": "Safety-relevant settings should be visible to regulators and third parties to facilitate coordination.",
      "concept_category": "design rationale",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Added in the update remark: 'help if the settings ... are externally legible / auditable'."
    },
    {
      "name": "Pre-deployment sandbox testing of AGI systems",
      "aliases": [
        "sandbox safety testing",
        "pre-release evaluation"
      ],
      "type": "concept",
      "description": "Running AGI in isolated environments with systematic tests before deployment to find failures.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "First concrete mechanism in Section 2 example list."
    },
    {
      "name": "Human-in-the-loop oversight of AGI decisions",
      "aliases": [
        "human oversight",
        "operator approval loops"
      ],
      "type": "concept",
      "description": "Requiring human review and approval of AGI plans/actions during operation.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Second example mechanism under Section 2."
    },
    {
      "name": "Restricted external resource access for early-stage AGI",
      "aliases": [
        "limited internet & money access",
        "resource confinement"
      ],
      "type": "concept",
      "description": "Limiting network, financial and hardware resources available to AGI until safety is assured.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Third mechanism in Section 2 'Resources' bullet."
    },
    {
      "name": "Conservative legal and norm compliance policies in AGI",
      "aliases": [
        "following human norms conservatively",
        "law-abiding AGI setting"
      ],
      "type": "concept",
      "description": "Configuring AGI to follow laws and social customs with high conservatism.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Fourth mechanism in Section 2 'Following human norms and laws'."
    },
    {
      "name": "Externally auditable safety-capability dial instrumentation",
      "aliases": [
        "visible dial indicators",
        "dial telemetry"
      ],
      "type": "concept",
      "description": "Technical means (e.g., cryptographic attestations, logs) making the dial setting externally visible.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Implements the 'external legibility' design rationale."
    },
    {
      "name": "Governance and legal frameworks enforcing alignment tax compliance",
      "aliases": [
        "coordination mechanisms for safe dials",
        "regulatory enforcement of safety settings"
      ],
      "type": "concept",
      "description": "Policies, treaties or regulations that mandate or incentivise paying the alignment tax.",
      "concept_category": "implementation mechanism",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Lightly inferred implementation for the author’s blank bullet about coordination mechanisms."
    },
    {
      "name": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "aliases": [
        "qualitative safety–capability analysis",
        "reasoned tradeoff evidence"
      ],
      "type": "concept",
      "description": "Author’s logical argument that each mechanism raises safety 'more than zero' while lowering capabilities.",
      "concept_category": "validation evidence",
      "intervention_lifecycle": null,
      "intervention_lifecycle_rationale": null,
      "intervention_maturity": null,
      "intervention_maturity_rationale": null,
      "node_rationale": "Serves as common validation evidence for all listed mechanisms; derived from entire Section 2 discussion."
    },
    {
      "name": "Conduct comprehensive pre-deployment sandbox testing before AGI deployment",
      "aliases": [
        "extensive sandbox evaluations",
        "rigorous pre-release testing"
      ],
      "type": "intervention",
      "description": "Allocate compute, personnel and time to run AGI models in isolated testbeds with adversarial and behavioural evaluations prior to any external deployment.",
      "concept_category": null,
      "intervention_lifecycle": "4",
      "intervention_lifecycle_rationale": "Explicitly occurs before deployment – Section 2 'Pre-deployment testing'.",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Practised experimentally in some labs but not yet systemically – inferred from current industry practice.",
      "node_rationale": "Actionable policy implementing the sandbox mechanism."
    },
    {
      "name": "Maintain continuous human-in-the-loop oversight during AGI operation",
      "aliases": [
        "persistent operator oversight",
        "human approval gating"
      ],
      "type": "intervention",
      "description": "Design operational procedures so that humans approve or veto AGI plans/actions in real time.",
      "concept_category": null,
      "intervention_lifecycle": "5",
      "intervention_lifecycle_rationale": "Applies during system deployment – Section 2 'Humans in the loop'.",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Used in narrow-AI safety-critical settings; still experimental for AGI.",
      "node_rationale": "Implements the human-oversight mechanism."
    },
    {
      "name": "Restrict AGI internet, financial, and hardware resources until safety validated",
      "aliases": [
        "capability throttling",
        "resource sandboxing"
      ],
      "type": "intervention",
      "description": "Provide the AGI with only limited network connectivity, funds and compute until it passes safety benchmarks.",
      "concept_category": null,
      "intervention_lifecycle": "5",
      "intervention_lifecycle_rationale": "Resource controls occur during deployment phase – Section 2 'Resources'.",
      "intervention_maturity": "1",
      "intervention_maturity_rationale": "Mostly theoretical for AGI; minimal prototypes exist.",
      "node_rationale": "Implements the resource-restriction mechanism."
    },
    {
      "name": "Enforce conservative legal and normative constraints in AGI behaviour policies",
      "aliases": [
        "high-conservatism norm following",
        "strict compliance mode"
      ],
      "type": "intervention",
      "description": "Tune objectives and filters so that AGI refuses or delays actions that risk violating laws or norms.",
      "concept_category": null,
      "intervention_lifecycle": "3",
      "intervention_lifecycle_rationale": "Implemented during fine-tuning/RLHF where behavioural policies are set – Section 2 'Following human norms and laws'.",
      "intervention_maturity": "2",
      "intervention_maturity_rationale": "Widely attempted in LLM alignment research but not systemically validated.",
      "node_rationale": "Implements the conservative norm-compliance mechanism."
    },
    {
      "name": "Develop and deploy externally auditable safety-capability dial indicators",
      "aliases": [
        "dial telemetry systems",
        "auditable safety settings"
      ],
      "type": "intervention",
      "description": "Create tooling (e.g., signed logs, hardware attestation) making dial settings transparent to regulators and third parties.",
      "concept_category": null,
      "intervention_lifecycle": "1",
      "intervention_lifecycle_rationale": "Instrumentation must be planned at model design time – update remark on legibility.",
      "intervention_maturity": "1",
      "intervention_maturity_rationale": "Purely conceptual; no published prototypes for AGI.",
      "node_rationale": "Implements the auditability mechanism."
    },
    {
      "name": "Establish international governance and legal mechanisms mandating alignment tax compliance",
      "aliases": [
        "regulatory coordination for safe dials",
        "legal enforcement of safety standards"
      ],
      "type": "intervention",
      "description": "Create treaties, regulations or licensing regimes that require AI developers to maintain minimum safety settings and bear liability for violations.",
      "concept_category": null,
      "intervention_lifecycle": "6",
      "intervention_lifecycle_rationale": "Policy and governance occur outside model lifecycle – implied blank bullet in Section 3.",
      "intervention_maturity": "1",
      "intervention_maturity_rationale": "No established global framework; concept stage only.",
      "node_rationale": "Implements the governance mechanism to reduce unsafe dial usage."
    }
  ],
  "edges": [
    {
      "type": "caused_by",
      "source_node": "Catastrophic AGI accidents via unsafe capability settings",
      "target_node": "Unsafe safety-capability dial settings chosen by competitive actors",
      "description": "Selecting low-safety dial settings directly increases accident likelihood.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Logical linkage stated in first section; no empirical data.",
      "edge_rationale": "Opening paragraph describing catastrophic outcomes when dials set to capability over safety."
    },
    {
      "type": "caused_by",
      "source_node": "Unsafe safety-capability dial settings chosen by competitive actors",
      "target_node": "Competitive pressures and lack of liability for AGI risks",
      "description": "Competitive incentives and weak liability frameworks motivate actors to choose unsafe settings.",
      "edge_confidence": "3",
      "edge_confidence_rationale": "Explicit reasoning in 'Background' section.",
      "edge_rationale": "Background lists ambition, competition, missing insurance as causes."
    },
    {
      "type": "required_by",
      "source_node": "Unsafe safety-capability dial settings chosen by competitive actors",
      "target_node": "Inevitability of safety-capability tradeoff dials in AGI (alignment tax unavoidable)",
      "description": "Understanding inevitability of dials is prerequisite to addressing why unsafe settings occur.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Conceptual inference; essay implies link.",
      "edge_rationale": "Section 2 argues dials are inevitable, explaining unsafe settings."
    },
    {
      "type": "refined_by",
      "source_node": "Inevitability of safety-capability tradeoff dials in AGI (alignment tax unavoidable)",
      "target_node": "Alignment tax magnitude determines developer incentives",
      "description": "The alignment tax concept quantifies the inevitable tradeoff.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Author introduces alignment tax to specify the general inevitability claim.",
      "edge_rationale": "Section 3 defines 'alignment tax' as framing refinement."
    },
    {
      "type": "mitigated_by",
      "source_node": "Alignment tax magnitude determines developer incentives",
      "target_node": "Minimising alignment tax to encourage safe dial settings",
      "description": "Lowering the tax reduces incentive to choose unsafe settings.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Stated as design goal in Section 3.",
      "edge_rationale": "Author says 'the lower the better'."
    },
    {
      "type": "mitigated_by",
      "source_node": "Alignment tax magnitude determines developer incentives",
      "target_node": "External legibility and auditability of dial settings",
      "description": "If settings are externally visible, coordination can counter incentives to under-pay the tax.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Added in update remark; conceptual.",
      "edge_rationale": "Update notes auditability helps compliance."
    },
    {
      "type": "implemented_by",
      "source_node": "Minimising alignment tax to encourage safe dial settings",
      "target_node": "Pre-deployment sandbox testing of AGI systems",
      "description": "Sandbox testing is a concrete method that can reveal issues with moderate capability cost.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Mechanism listed as example under tradeoff discussion.",
      "edge_rationale": "Section 2 bullet 'Pre-deployment testing'."
    },
    {
      "type": "implemented_by",
      "source_node": "Minimising alignment tax to encourage safe dial settings",
      "target_node": "Human-in-the-loop oversight of AGI decisions",
      "description": "Human oversight balances safety and capability cost.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Explicit example.",
      "edge_rationale": "Section 2 bullet 'Humans in the loop'."
    },
    {
      "type": "implemented_by",
      "source_node": "Minimising alignment tax to encourage safe dial settings",
      "target_node": "Restricted external resource access for early-stage AGI",
      "description": "Resource restriction limits damage potential while adding cost.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Explicit example.",
      "edge_rationale": "Section 2 bullet 'Resources'."
    },
    {
      "type": "implemented_by",
      "source_node": "Minimising alignment tax to encourage safe dial settings",
      "target_node": "Conservative legal and norm compliance policies in AGI",
      "description": "Conservative compliance policies improve safety with some capability loss.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Explicit example.",
      "edge_rationale": "Section 2 bullet 'Following human norms and laws'."
    },
    {
      "type": "implemented_by",
      "source_node": "Minimising alignment tax to encourage safe dial settings",
      "target_node": "Governance and legal frameworks enforcing alignment tax compliance",
      "description": "Governance can shift incentives making the tax less burdensome to comply with.",
      "edge_confidence": "1",
      "edge_confidence_rationale": "Light inference; author leaves blank bullet for coordination.",
      "edge_rationale": "Section 3 blank bullet referencing future coordination mechanisms."
    },
    {
      "type": "implemented_by",
      "source_node": "External legibility and auditability of dial settings",
      "target_node": "Externally auditable safety-capability dial instrumentation",
      "description": "Auditable instrumentation realises the legibility objective.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Direct implementation relation.",
      "edge_rationale": "Update remark suggests making settings externally legible."
    },
    {
      "type": "validated_by",
      "source_node": "Pre-deployment sandbox testing of AGI systems",
      "target_node": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "description": "Author argues sandboxing boosts safety albeit with cost.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Purely theoretical; no data.",
      "edge_rationale": "Section 2 notes testing 'would help more than zero' but costs resources."
    },
    {
      "type": "validated_by",
      "source_node": "Human-in-the-loop oversight of AGI decisions",
      "target_node": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "description": "Reasoning that oversight slows but secures AGI actions.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Theoretical.",
      "edge_rationale": "Same section discussion."
    },
    {
      "type": "validated_by",
      "source_node": "Restricted external resource access for early-stage AGI",
      "target_node": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "description": "Limiting resources clearly raises safety but hampers capabilities.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Theoretical.",
      "edge_rationale": "Section 2 'Resources' bullet."
    },
    {
      "type": "validated_by",
      "source_node": "Conservative legal and norm compliance policies in AGI",
      "target_node": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "description": "Higher conservatism prevents some useful actions but reduces risk.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Theoretical.",
      "edge_rationale": "Section 2 'Following human norms and laws'."
    },
    {
      "type": "validated_by",
      "source_node": "Externally auditable safety-capability dial instrumentation",
      "target_node": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "description": "Auditability assumed to deter unsafe settings though incurs engineering cost.",
      "edge_confidence": "1",
      "edge_confidence_rationale": "Speculative reasoning.",
      "edge_rationale": "Update remark lacks data."
    },
    {
      "type": "validated_by",
      "source_node": "Governance and legal frameworks enforcing alignment tax compliance",
      "target_node": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "description": "Governance expected to enhance safety but may slow innovation.",
      "edge_confidence": "1",
      "edge_confidence_rationale": "Speculative; policy inference.",
      "edge_rationale": "Blank bullet implies such frameworks."
    },
    {
      "type": "motivates",
      "source_node": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "target_node": "Conduct comprehensive pre-deployment sandbox testing before AGI deployment",
      "description": "Reasoning supports implementing sandbox testing.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Reasoning directly leads to recommendation.",
      "edge_rationale": "Section 2 conclusion on testing."
    },
    {
      "type": "motivates",
      "source_node": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "target_node": "Maintain continuous human-in-the-loop oversight during AGI operation",
      "description": "Supports adopting human oversight despite capability costs.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Reasoning leads to recommendation.",
      "edge_rationale": "Section 2 discussion."
    },
    {
      "type": "motivates",
      "source_node": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "target_node": "Restrict AGI internet, financial, and hardware resources until safety validated",
      "description": "Provides justification for resource restriction policy.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Same reasoning.",
      "edge_rationale": "Section 2 'Resources'."
    },
    {
      "type": "motivates",
      "source_node": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "target_node": "Enforce conservative legal and normative constraints in AGI behaviour policies",
      "description": "Justifies strict norm-following configuration.",
      "edge_confidence": "2",
      "edge_confidence_rationale": "Same reasoning.",
      "edge_rationale": "Section 2 'Following human norms and laws'."
    },
    {
      "type": "motivates",
      "source_node": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "target_node": "Develop and deploy externally auditable safety-capability dial indicators",
      "description": "Supports investment in auditability tooling.",
      "edge_confidence": "1",
      "edge_confidence_rationale": "Speculative extension of reasoning.",
      "edge_rationale": "Update remark on legibility."
    },
    {
      "type": "motivates",
      "source_node": "Theoretical reasoning that safety mechanisms improve safety with capability cost",
      "target_node": "Establish international governance and legal mechanisms mandating alignment tax compliance",
      "description": "Frames need for coordinated legal enforcement mechanisms.",
      "edge_confidence": "1",
      "edge_confidence_rationale": "Speculative; lightly inferred.",
      "edge_rationale": "Blank bullet calling for coordination."
    }
  ],
  "meta": [
    {
      "key": "url",
      "value": "https://www.alignmentforum.org/posts/tmyTb4bQQi7C47sde/safety-capabilities-tradeoff-dials-are-inevitable-in-agi"
    },
    {
      "key": "title",
      "value": "Safety-capabilities tradeoff dials are inevitable in AGI"
    },
    {
      "key": "date_published",
      "value": "2021-10-07T19:03:22Z"
    },
    {
      "key": "authors",
      "value": [
        "Steven Byrnes"
      ]
    },
    {
      "key": "source",
      "value": "alignmentforum"
    }
  ]
}