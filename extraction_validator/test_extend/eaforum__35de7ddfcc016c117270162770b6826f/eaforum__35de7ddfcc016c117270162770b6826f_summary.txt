Summary  
This review-paper critiques Will MacAskill’s book “What We Owe The Future” and presents an alternative assessment of long-term risks, especially a much higher probability of existential catastrophe from misaligned, power-seeking AI together with arguments about technological stagnation and community prioritisation.  It cites Joseph Carlsmith’s power-seeking-AI report, Samotsvety forecasts, productivity statistics and concrete technical alignment ideas such as adversarial training and AI-assisted alignment research, plus policy or outreach proposals (e.g. distributing “The Precipice”, controlled genetic enhancement, catastrophic refuges).  
The fabric below captures every causal-interventional path connecting:  
• core risks → problem analyses → theoretical insights → design rationales → implementation mechanisms → validation evidence → actionable interventions.  
All nodes are mutually connected; no risk connects directly to an intervention.

EXTRACTION CONFIDENCE[79]  
Inference strategy: only light inferences (edge confidence 2) were applied where the source text implies, but does not spell out, obvious AI-safety interventions (e.g. moratorium on APS-AI, genetic enhancement to offset stagnation).  
Completeness: 28 concept nodes + 6 intervention nodes cover all reasoning chains explicitly discussed.  Every node appears in ≥1 edge; no duplicates.  
Limitations: the review is opinionated, not an empirical study, so many edge confidences are ≤3.  Some topics (value-lock-in) were mentioned but not analysed deeply enough to extract a full chain; they were omitted to avoid disconnected nodes.  Future guideline improvement: explicitly clarify how to treat opinion-pieces versus empirical papers (e.g. minimum evidence strength thresholds).



Key limitations  
• Source is largely argumentative; many “validation evidence” nodes are forecasts or expert opinion, limiting edge confidence.  
• Some interventions (moratorium, genetic enhancement) are inferred rather than explicitly advocated; marked with confidence 2.  
• Fabric omits value-lock-in chain due to insufficient mechanistic detail in text; future extraction could integrate separate sources focusing on that risk.