Data source overview  
The 2013 FHI technical report “Racing to the Precipice: a Model of Artificial Intelligence Development” develops a simple Nash-equilibrium model of an AI arms race. It shows how teams racing to build the first transformative AI are incentivised to skimp on safety precautions, and analytically derives how disaster probability varies with (i) relative importance of capability vs. risk-taking, (ii) enmity between teams, (iii) number of teams, and (iv) the amount of information teams have about capabilities. The authors discuss qualitative levers—coordination, information containment, team consolidation, and research-path steering—that could mitigate the risk.

EXTRACTION CONFIDENCE[87]  
Inference strategy justification: The paper is purely theoretical, so proposed interventions are not tested empirically. I extracted explicit levers named by the authors and decomposed them into rationale, mechanism, validation (model results) and actionable policy interventions, assigning low maturity (1) and lifecycle “6-Other” for governance actions.  
Extraction completeness: All causal chains from the single top-level risk through problem analyses, insights, rationales, mechanisms and four concrete intervention nodes are captured and interconnected; no isolated nodes remain (see JSON).  
Key limitations: 1) The model’s assumptions are stylised; real-world empirical validation is missing, limiting edge confidence to 2–3. 2) Some implementation details are moderately inferred (marked confidence 2). 3) Policy interventions are broad; downstream work must refine them for specific organisational contexts.

JSON knowledge fabric