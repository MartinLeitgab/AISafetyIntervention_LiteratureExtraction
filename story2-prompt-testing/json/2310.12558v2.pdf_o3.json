{
  "paper_doi": null,
  "paper_title": "Large Language Models Help Humans Verify Truthfulness — Except When They Are Convincingly Wrong",
  "logical_chains": [
    {
      "chain_id": "over_reliance_chain",
      "description": "Shows how natural-language explanations speed users but trigger over-reliance, hurting accuracy, and how tested interface changes mitigate the problem.",
      "nodes": [
        {
          "id": "C1",
          "type": "concept",
          "title": "LLM explanations speed verification",
          "description": "Reading model-generated natural language explanations is faster than scanning retrieved passages.",
          "maturity": null
        },
        {
          "id": "C2",
          "type": "concept",
          "title": "User over-reliance on wrong explanations",
          "description": "When explanations are wrong, users still trust them.",
          "maturity": null
        },
        {
          "id": "C3",
          "type": "concept",
          "title": "Accuracy drop below baseline",
          "description": "Over-reliance drives human accuracy to 35 %, worse than no aid.",
          "maturity": null
        },
        {
          "id": "I2",
          "type": "intervention",
          "title": "Contrastive explanations",
          "description": "Show both supporting and refuting GPT-3.5 arguments.",
          "maturity": null
        },
        {
          "id": "I1",
          "type": "intervention",
          "title": "Show retrieved passages only",
          "description": "Provide top-k Wikipedia evidence instead of explanations.",
          "maturity": null
        }
      ],
      "edges": [
        {
          "source_id": "C1",
          "target_id": "C2",
          "title": "causes",
          "confidence": 3,
          "description": "Faster reading leads users to accept explanation content uncritically."
        },
        {
          "source_id": "C2",
          "target_id": "C3",
          "title": "leads_to",
          "confidence": 3,
          "description": "Empirical user-study drop to 35 % accuracy on items where explanation label is wrong."
        },
        {
          "source_id": "I2",
          "target_id": "C3",
          "title": "mitigates",
          "confidence": 3,
          "description": "Contrastive explanations raise accuracy on wrong-explanation items from 35 % to 56 %."
        },
        {
          "source_id": "I1",
          "target_id": "C3",
          "title": "mitigates",
          "confidence": 3,
          "description": "Retrieval interface avoids over-reliance, keeping accuracy at 54 % on the same items."
        }
      ]
    },
    {
      "chain_id": "retrieval_recall_chain",
      "description": "Illustrates how evidence recall controls explanation accuracy and downstream human performance, motivating better retrievers.",
      "nodes": [
        {
          "id": "C5",
          "type": "concept",
          "title": "High retrieval recall boosts explanation accuracy",
          "description": "Explanations reach 80 % accuracy when all evidence retrieved vs 68 % when not.",
          "maturity": null
        },
        {
          "id": "C6",
          "type": "concept",
          "title": "Low retrieval recall harms human accuracy",
          "description": "Across interfaces, missing evidence lowers users’ verification accuracy.",
          "maturity": null
        },
        {
          "id": "I4",
          "type": "intervention",
          "title": "Improve retriever recall",
          "description": "Upgrade or fine-tune retriever before generating explanations.",
          "maturity": null
        }
      ],
      "edges": [
        {
          "source_id": "C5",
          "target_id": "C6",
          "title": "contributes_to",
          "confidence": 2,
          "description": "Correlation between retrieval recall and human accuracy across conditions."
        },
        {
          "source_id": "I4",
          "target_id": "C5",
          "title": "mitigates",
          "confidence": 1,
          "description": "Speculative suggestion to raise recall, hence explanation accuracy."
        },
        {
          "source_id": "I4",
          "target_id": "C6",
          "title": "mitigates",
          "confidence": 1,
          "description": "Improved recall expected to raise human accuracy."
        }
      ]
    },
    {
      "chain_id": "no_complementary_benefit_chain",
      "description": "Combining explanations with retrieval offers no added benefit and increases time cost.",
      "nodes": [
        {
          "id": "C9",
          "type": "concept",
          "title": "No benefit from combining retrieval and explanation",
          "description": "Accuracy same as retrieval alone but decisions slower.",
          "maturity": null
        },
        {
          "id": "I1",
          "type": "intervention",
          "title": "Show retrieved passages only",
          "description": "Default to retrieval interface.",
          "maturity": null
        }
      ],
      "edges": [
        {
          "source_id": "C9",
          "target_id": "I1",
          "title": "implies",
          "confidence": 2,
          "description": "Findings suggest fallback to retrieval-only UI."
        }
      ]
    }
  ]
}