{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc0fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from typing import Any, Dict, List, Literal, Optional\n",
    "from pydantic import BaseModel, Field, ConfigDict, ValidationError\n",
    "\n",
    "from plot_json_graphviz import render_json_graph\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5a4310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# models\n",
    "cheap = 'gpt-4o'\n",
    "best = 'o3'\n",
    "\n",
    "# prompts\n",
    "from prompts import PROMPT_REASONING_STRICT_DEV, PROMPT_JSON_STRICT_DEV, PROMPT_JSON_STRICT_DEV, PROMPT_STRUCT_STRICT_DEV, PROMPT_RESPONSE_EVAL_DEV, PROMPT_REASONING_FLEX_DEV\n",
    "\n",
    "# io\n",
    "input_dir = 'input'\n",
    "json_dir = 'json'\n",
    "traces_dir = 'traces'\n",
    "evals_dir = 'evals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe56da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run once to upload all papers from /input directory\n",
    "\n",
    "# all_papers = []\n",
    "\n",
    "# for paper in os.listdir(input_dir):\n",
    "#     if not paper.endswith('.pdf'):\n",
    "#         continue\n",
    "\n",
    "#     paper_path = os.path.join(input_dir, paper)\n",
    "    \n",
    "#     file = client.files.create(\n",
    "#         file=open(paper_path, \"rb\"),\n",
    "#         purpose=\"user_data\"\n",
    "#     )\n",
    "\n",
    "#     all_papers.append({\n",
    "#         \"id\": paper,\n",
    "#         \"file_id\": file.id,\n",
    "#         \"file_name\": paper.removesuffix('.pdf'),\n",
    "#         \"file_path\": paper_path,\n",
    "#         \"file_size\": os.path.getsize(paper_path),\n",
    "#         \"file_created_at\": datetime.fromtimestamp(os.path.getctime(paper_path)).isoformat(),\n",
    "#         \"file_modified_at\": datetime.fromtimestamp(os.path.getmtime(paper_path)).isoformat(),\n",
    "#         \"file_uploaded_at\": datetime.now().isoformat(),\n",
    "#     })\n",
    "\n",
    "# # save all_papers to file\n",
    "# with open(os.path.join('all_papers.json'), 'w') as f:\n",
    "#     json.dump(all_papers, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bb1f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all_papers from file\n",
    "with open(os.path.join('all_papers.json'), 'r') as f:\n",
    "    all_papers = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c909ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset papers\n",
    "all_papers = all_papers[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b290ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions \n",
    "\n",
    "def read_file(file_path, encoding='utf-8'):\n",
    "    with open(file_path, 'r', encoding=encoding) as f:\n",
    "        return f.read()\n",
    "    \n",
    "# Get json from non-serial (Response) objects\n",
    "def get_json(obj):\n",
    "    if hasattr(obj, \"__dict__\"):\n",
    "        return {k: get_json(v) for k, v in vars(obj).items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [get_json(v) for v in obj]\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: get_json(v) for k, v in obj.items()}\n",
    "    return obj\n",
    "    \n",
    "# json extraction\n",
    "def extract_first_json(text):\n",
    "    start = text.find('{')\n",
    "    if start == -1:\n",
    "        return None\n",
    "    count = 0\n",
    "    for i in range(start, len(text)):\n",
    "        if text[i] == '{':\n",
    "            count += 1\n",
    "        elif text[i] == '}':\n",
    "            count -= 1\n",
    "            if count == 0:\n",
    "                return json.loads(text[start:i+1])\n",
    "    return None\n",
    "\n",
    "# json validation\n",
    "def validate_with_paths(model: type[BaseModel], data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    try:\n",
    "        instance = model.model_validate(data)  # Pydantic v2\n",
    "        return {\n",
    "            \"ok\": True,\n",
    "            \"errors\": [],\n",
    "            \"instance\": instance\n",
    "        }\n",
    "    except ValidationError as e:\n",
    "        def path(loc: List[Any]) -> str:\n",
    "            parts = []\n",
    "            for p in loc:\n",
    "                if isinstance(p, int):\n",
    "                    parts[-1] = f\"{parts[-1]}.{p}\"  # attach index to previous name\n",
    "                else:\n",
    "                    parts.append(str(p))\n",
    "            return \".\".join(parts)\n",
    "\n",
    "        errors = [\n",
    "            {\n",
    "                \"path\": path(err.get(\"loc\", [])),\n",
    "                \"msg\": err.get(\"msg\", \"\"),\n",
    "                \"type\": err.get(\"type\", \"\")\n",
    "            }\n",
    "            for err in e.errors()\n",
    "        ]\n",
    "        return {\n",
    "            \"ok\": False,\n",
    "            \"errors\": errors\n",
    "        }\n",
    "\n",
    "# Save freeform response as txt\n",
    "def save_reasoning_response(resp: str, file_name: str, model: str): \n",
    "    trace_path = os.path.join(traces_dir, f\"{file_name}_{model}.txt\")\n",
    "    usage = json.dumps(get_json(resp.usage))\n",
    "\n",
    "    with open(trace_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(resp.output_text + '\\n\\n' + usage)\n",
    "\n",
    "# Save structured response as JSON\n",
    "def save_json_response(resp: str, file_name: str, model: str):\n",
    "    if model == 'o3':\n",
    "        structured_data = json.loads(resp.model_dump()['output'][1]['arguments'])\n",
    "    else:\n",
    "        structured_data = json.loads(resp.model_dump()['output'][0]['arguments'])\n",
    "\n",
    "    structured_json_path = os.path.join(json_dir, f\"{file_name}_{model}.json\")\n",
    "    usage = json.dumps(get_json(resp.usage))\n",
    "\n",
    "    with open(structured_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(structured_data, f, ensure_ascii=False, indent=2)\n",
    "        f.write('\\n\\n' + usage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d51feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pydantic classes\n",
    "\n",
    "# Schema 1 - Strict\n",
    "class Node1(BaseModel):\n",
    "    name: str = Field(default=None, description=\"concise natural-language description of node\")\n",
    "    aliases: List[str] = Field(default=None, description=\"2-3 alternative concise descriptions of node\")\n",
    "    type: Literal[\"concept\", \"intervention\"]\n",
    "    description: str= Field(default=None, description=\"detailed technical description of node (1-2 sentences only)\")\n",
    "    concept_category: Optional[str] = Field(default=None, description=\"from examples or create a new category (concept nodes only, otherwise null)\")\n",
    "    intervention_lifecycle: Optional[int] = Field(default=None, ge=1, le=6, description=\"1-6 (only for intervention nodes)\")\n",
    "    intervention_maturity: Optional[int] = Field(default=None, ge=1, le=4, description=\"1-4 (only for intervention nodes)\")\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "class Edge1(BaseModel):\n",
    "    type: str = Field(default=None, description=\"relationship label verb\")\n",
    "    source_node: str = Field(default=None, description=\"source node name\")\n",
    "    target_node: str = Field(default=None, description=\"target node name\")\n",
    "    description: str = Field(default=None, description=\"concise description of logical connection\")\n",
    "    edge_confidence: int = Field(default=None, ge=1, le=5, description=\"1-5\")\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    \n",
    "class LogicalChain1(BaseModel):\n",
    "    title: str = Field(default=None, description=\"concise natural-language description of logical chain\")\n",
    "    edges: List[Edge1]\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "class PaperSchema1(BaseModel):\n",
    "    nodes: List[Node1]\n",
    "    logical_chains: List[LogicalChain1]\n",
    "    model_config = ConfigDict(extra=\"forbid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52327c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema 2 - Flex\n",
    "class Node2(BaseModel):\n",
    "    type: str\n",
    "    name: str\n",
    "    canonical_name: str\n",
    "    aliases: List[str]\n",
    "    confidence: float = Field(..., ge=0.0, le=1.0)\n",
    "    notes: str\n",
    "\n",
    "class Edge2(BaseModel):\n",
    "    type: str\n",
    "    rationale: str\n",
    "    confidence: float = Field(..., ge=0.0, le=1.0)\n",
    "    source_node: Node2\n",
    "    target_node: Node2\n",
    "\n",
    "class PaperSchema2(BaseModel):\n",
    "    nodes: List[Node1]\n",
    "    logical_chains: List[LogicalChain1]\n",
    "    model_config = ConfigDict(extra=\"forbid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155c60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text response from model\n",
    "def get_single_response(file_id: str, prompt_text: str, model: str = 'gpt-4.0'):\n",
    "\n",
    "    input = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_file\", \"file_id\": file_id},\n",
    "            {\"type\": \"input_text\", \"text\": prompt_text}\n",
    "        ]\n",
    "    }]\n",
    "    \n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        input=input,\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d70bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get text and structured json in single response -- models won't comply\n",
    "# def get_single_tool_response(file_id: str, prompt_text: str, schema: object, model: str = 'gpt-4.0'):\n",
    "\n",
    "#     input = [{\n",
    "#         \"role\": \"system\",\n",
    "#         \"content\": \"Provide a detailed analysis in text format, then call the causal_chain_structure tool to provide a structured json. Always provide BOTH outputs.\"\n",
    "#     }, {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": [\n",
    "#             {\"type\": \"input_file\", \"file_id\": file_id},\n",
    "#             {\"type\": \"input_text\", \"text\": prompt_text}\n",
    "#         ]\n",
    "#     }]\n",
    "\n",
    "#     tools = [{\n",
    "#         \"type\": \"function\",\n",
    "#         \"name\": \"causal_chain_structure\",\n",
    "#         \"description\": \"Capture the paper's Logical Chain analysis as a structured JSON object.\",\n",
    "#         \"parameters\": schema.model_json_schema()\n",
    "#     }]\n",
    "    \n",
    "#     response = client.responses.create(\n",
    "#         model=model,\n",
    "#         input=input,\n",
    "#         tools=tools,\n",
    "#         tool_choice={\"type\": \"allowed_tools\", \n",
    "#                      \"mode\": \"required\",\n",
    "#                      \"tools\": [{\"type\": \"function\", \"name\": \"causal_chain_structure\"}]\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "#     return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "521ade2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dual responses from model (reasoning + json in separate requests)\n",
    "def get_dual_response(file_id: str, prompt_text: str, schema: object, model: str = 'gpt-4.0'):\n",
    "    \"\"\"\n",
    "    Get response from model in two steps:\n",
    "    1. Freeform analysis of the paper based on the prompt_text.\n",
    "    2. Structured json using the causal_chain_structure tool based on the freeform analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    # First call - get reasoning\n",
    "    reasoning_input = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_file\", \"file_id\": file_id},\n",
    "            {\"type\": \"input_text\", \"text\": prompt_text}\n",
    "        ]\n",
    "    }]\n",
    "    \n",
    "    reasoning_response = client.responses.create(\n",
    "        model=model,\n",
    "        input=reasoning_input,\n",
    "        tools=None  # No tools for reasoning\n",
    "    )\n",
    "\n",
    "    # Second call - get structured json\n",
    "    json_input = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Use the following detailed analysis to help create the structured json:\"\n",
    "    }, {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": reasoning_response.output_text\n",
    "    },{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            # {\"type\": \"input_file\", \"file_id\": file_id},\n",
    "            {\"type\": \"input_text\", \"text\": PROMPT_STRUCT_STRICT_DEV}\n",
    "        ]\n",
    "    }]\n",
    "\n",
    "    tools = [{\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"causal_chain_structure\",\n",
    "        \"description\": \"Capture the paper's Logical Chain analysis as a structured JSON object.\",\n",
    "        \"parameters\": schema.model_json_schema()\n",
    "    }]\n",
    "    \n",
    "    json_response = client.responses.create(\n",
    "        model=model,\n",
    "        input=json_input,\n",
    "        tools=tools,\n",
    "        tool_choice={\"type\": \"allowed_tools\", \n",
    "                     \"mode\": \"auto\",\n",
    "                     \"tools\": [{\"type\": \"function\", \"name\": \"causal_chain_structure\"}]\n",
    "        }  # force tool use\n",
    "    )\n",
    "\n",
    "    return reasoning_response, json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f8b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to analyze paper\n",
    "def analyze_paper(file_name: str, file_id: str, prompt_text: str, schema: object, dual: bool = False, label: str = '', model: str = 'gpt-4.0'):\n",
    "    \n",
    "    if dual:\n",
    "        reasoning_response, json_response = get_dual_response(\n",
    "            file_id=file_id,\n",
    "            prompt_text=prompt_text,\n",
    "            schema=schema,\n",
    "            model=model)\n",
    "        save_reasoning_response(reasoning_response, file_name + label, model=model)\n",
    "        save_json_response(json_response, file_name + label, model=model)\n",
    "        return reasoning_response, json_response\n",
    "    else:\n",
    "        response = get_single_response(\n",
    "            file_id=file_id,\n",
    "            prompt_text=prompt_text,\n",
    "            model=model)\n",
    "        save_reasoning_response(response, file_name + label, model=model)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e9e1ae",
   "metadata": {},
   "source": [
    "Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431688c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # single pass, reasoning only\n",
    "# file_name = all_papers[2]['file_name']\n",
    "# file_id = all_papers[2]['file_id']\n",
    "\n",
    "# resp = analyze_paper(\n",
    "#     file_name=file_name,\n",
    "#     file_id=file_id,\n",
    "#     prompt_text=PROMPT_REASONING_STRICT_DEV,\n",
    "#     schema=PaperSchema1,\n",
    "#     model=best,\n",
    "#     label='_reason'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec40fe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single pass, reasoning + json\n",
    "file_name = all_papers[2]['file_name']\n",
    "file_id = all_papers[2]['file_id']\n",
    "\n",
    "resp = analyze_paper(\n",
    "    file_name=file_name,\n",
    "    file_id=file_id,\n",
    "    prompt_text=PROMPT_REASONING_STRICT_DEV + PROMPT_JSON_STRICT_DEV,\n",
    "    schema=PaperSchema1,\n",
    "    model=best,\n",
    "    label='_strict_final_1p'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6532fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # single pass with struct -- models tend to call tool only\n",
    "\n",
    "# file_name = all_papers[2]['file_name']\n",
    "# file_id = all_papers[2]['file_id']\n",
    "\n",
    "# response = get_single_tool_response(\n",
    "#         file_id=file_id,\n",
    "#         prompt_text=PROMPT_REASONING_STRICT_DEV+PROMPT_STRUCT_STRICT_DEV,\n",
    "#         schema=PaperSchema1,\n",
    "#         model=best\n",
    "#         )\n",
    "\n",
    "# resp = get_json(response)\n",
    "# print(json.loads(resp['output'][1]['arguments']))\n",
    "# print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d64ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dual pass\n",
    "# file_name = all_papers[2]['file_name']\n",
    "# file_id = all_papers[2]['file_id']\n",
    "\n",
    "# resp = analyze_paper(\n",
    "#     file_name=file_name,\n",
    "#     file_id=file_id,\n",
    "#     prompt_text=PROMPT_REASONING_STRICT_DEV,\n",
    "#     schema=PaperSchema1,\n",
    "#     dual = True,\n",
    "#     model=best,\n",
    "#     label='_2pass'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e60afc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# extract all papers, single-pass\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m paper \u001b[38;5;129;01min\u001b[39;00m all_papers:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43manalyze_paper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpaper\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfile_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpaper\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfile_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPROMPT_REASONING_STRICT_DEV\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROMPT_JSON_STRICT_DEV\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPaperSchema1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_strict_final_1p\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# for paper in all_papers:\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#     analyze_paper(\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#         file_name=paper['file_name'],\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#         label='_flex_1p'\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#     )\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36manalyze_paper\u001b[39m\u001b[34m(file_name, file_id, prompt_text, schema, dual, label, model)\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m reasoning_response, json_response\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     response = \u001b[43mget_single_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     save_reasoning_response(response, file_name + label, model=model)\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mget_single_response\u001b[39m\u001b[34m(file_id, prompt_text, model)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_single_response\u001b[39m(file_id: \u001b[38;5;28mstr\u001b[39m, prompt_text: \u001b[38;5;28mstr\u001b[39m, model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33mgpt-4.0\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28minput\u001b[39m = [{\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m         ]\n\u001b[32m     10\u001b[39m     }]\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/openai/resources/responses/responses.py:795\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, background, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    759\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    760\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    761\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    793\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    794\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    811\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    814\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    815\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-OneWorkplace/Documents/Dev/AISafetyIntervention_LiteratureExtraction/.venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1285\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1284\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1140\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# extract all papers, single-pass\n",
    "\n",
    "for paper in all_papers:\n",
    "    analyze_paper(\n",
    "        file_name=paper['file_name'],\n",
    "        file_id=paper['file_id'],\n",
    "        prompt_text=PROMPT_REASONING_STRICT_DEV + PROMPT_JSON_STRICT_DEV,\n",
    "        schema=PaperSchema1,\n",
    "        model=best,\n",
    "        label='_strict_final_1p'\n",
    "    )\n",
    "\n",
    "\n",
    "# for paper in all_papers:\n",
    "#     analyze_paper(\n",
    "#         file_name=paper['file_name'],\n",
    "#         file_id=paper['file_id'],\n",
    "#         prompt_text=PROMPT_REASONING_FLEX_DEV,\n",
    "#         schema=PaperSchema2,\n",
    "#         model=best,\n",
    "#         label='_flex_1p'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all papers, dual-pass\n",
    "\n",
    "# for paper in all_papers:\n",
    "#     analyze_paper(\n",
    "#         file_name=paper['file_name'],\n",
    "#         file_id=paper['file_id'],\n",
    "#         prompt_text=PROMPT_REASONING_STRICT_DEV,\n",
    "#         schema=PaperSchema1,\n",
    "#         dual=True,\n",
    "#         model=best,\n",
    "#         label='_strict_2p'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650cb4c7",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbf6375",
   "metadata": {},
   "source": [
    "## evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfce1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dual-pass \n",
    "dual_json_data = {}\n",
    "\n",
    "for filename in os.listdir(json_dir):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(json_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            json_part = extract_first_json(content)\n",
    "            dual_json_data[filename] = json_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dual_json_data.keys():\n",
    "    print(validate_with_paths(PaperSchema1, dual_json_data[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04960ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load single-pass\n",
    "single_json_data = {}\n",
    "keyword = 'flex'\n",
    "\n",
    "for filename in sorted(os.listdir(traces_dir)):\n",
    "    if keyword in filename:\n",
    "        file_path = os.path.join(traces_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            json_part = extract_first_json(content)\n",
    "            single_json_data[filename] = json_part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f995cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in single_json_data.keys():\n",
    "    print(validate_with_paths(PaperSchema2, single_json_data[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "single_json_data.keys()\n",
    "\n",
    "# due to a new type, validation schema format incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849e940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd4f627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reasoning evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3009e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm-as-judge, feed paper and concat responses\n",
    "def eval_analyses(file_id: str, eval_text: str, prompt_text: str, model: str = 'gpt-4.0'):\n",
    "\n",
    "    input = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_file\", \"file_id\": file_id},\n",
    "            {\"type\": \"input_text\", \"text\": prompt_text},\n",
    "            {\"type\": \"input_text\", \"text\": eval_text},\n",
    "        ]\n",
    "    }]\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        input=input,\n",
    "    )\n",
    "\n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval 1p vs 2p\n",
    "for paper in all_papers:\n",
    "\n",
    "    file_name = paper['file_name']\n",
    "    file_id = paper['file_id']\n",
    "\n",
    "    run1 = '_strict_1p_o3'\n",
    "    run2 = '_strict_2p_o3'\n",
    "\n",
    "    label = '_1p2p'\n",
    "\n",
    "    eval_1 = f\"Analysis 1: {file_name}{run1}\\n\\n\" + read_file(os.path.join(traces_dir, f\"{file_name}{run1}.txt\")) + \"\\n\"\n",
    "    eval_2 = f\"Analysis 2: {file_name}{run2}\\n\\n\" + read_file(os.path.join(traces_dir, f\"{file_name}{run2}.txt\")) + \"\\n\" + read_file(os.path.join(json_dir, f\"{file_name}{run2}.json\")) + \"\\n\"\n",
    "    eval_text = eval_1 + eval_2\n",
    "\n",
    "    resp = eval_analyses(\n",
    "        file_id=file_id,\n",
    "        prompt_text=PROMPT_RESPONSE_EVAL_DEV,\n",
    "        eval_text=eval_text,\n",
    "        model=best\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(evals_dir, f\"{file_name}_{label}_eval.md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57361e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval strict 1p vs flex 1p\n",
    "\n",
    "for paper in all_papers:\n",
    "\n",
    "    file_name = paper['file_name']\n",
    "    file_id = paper['file_id']\n",
    "\n",
    "    run1 = '_strict_1p_o3'\n",
    "    run2 = '_flex_1p_o3'\n",
    "\n",
    "    label = '_fs'\n",
    "\n",
    "    eval_1 = f\"Analysis 1: {file_name}{run1}\\n\\n\" + read_file(os.path.join(traces_dir, f\"{file_name}{run1}.txt\")) + \"\\n\"\n",
    "    eval_2 = f\"Analysis 2: {file_name}{run2}\\n\\n\" + read_file(os.path.join(traces_dir, f\"{file_name}{run2}.txt\")) + \"\\n\"\n",
    "    eval_text = eval_1 + eval_2\n",
    "\n",
    "    resp = eval_analyses(\n",
    "        file_id=file_id,\n",
    "        prompt_text=PROMPT_RESPONSE_EVAL_DEV,\n",
    "        eval_text=eval_text,\n",
    "        model=best\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(evals_dir, f\"{file_name}_{label}_eval.md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f5f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22167fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd97d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cca9675",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterative analysis\n",
    "def analyze_paper_iteratively(file_name: str, file_id: str, prompt_text: str, iterations: int = 3, schema: object, model: str = 'gpt-4.0'):\n",
    "    \"\"\"\n",
    "    Iteratively analyze a paper multiple times, asking the model to find more connections each time.\n",
    "    \n",
    "    Args:\n",
    "        file_name (str): Name of the file to analyze.\n",
    "        file_id (str): ID of the file in OpenAI.\n",
    "        prompt_text (str): The base prompt to use for analysis.\n",
    "        iterations (int): Number of iterations to perform (default 3).\n",
    "        model (str): The model to use for analysis.\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples containing (freeform_response, structured_response) for each iteration.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    current_prompt = prompt_text\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        print(f\"\\nIteration {i+1}/{iterations}\")\n",
    "        \n",
    "        # For iterations after the first, add the improvement request\n",
    "        if i > 0:\n",
    "            current_prompt = (\n",
    "                current_prompt + \n",
    "                \"\\n\\nIMPORTANT: You missed many causal connections and relationships in your previous analysis. \" +\n",
    "                \"Please analyze again more thoroughly, looking specifically for:\\n\" +\n",
    "                \"1. Additional connections between existing concepts\\n\" +\n",
    "                \"2. Implicit relationships that weren't directly stated\\n\" +\n",
    "                \"3. Higher-order effects and consequences\\n\" +\n",
    "                \"4. Cross-cutting themes and patterns\\n\" +\n",
    "                \"5. Alternative interpretations of the findings\"\n",
    "            )\n",
    "        \n",
    "        # Run the analysis\n",
    "        freeform_response, structured_response = get_dual_response(\n",
    "            file_id=file_id,\n",
    "            prompt_text=current_prompt,\n",
    "            schema=schema,\n",
    "            model=model\n",
    "        )\n",
    "        \n",
    "        # Save responses with iteration number in filename\n",
    "        save_trace_response(freeform_response, f\"{file_name}_iter{i+1}\", model=model)\n",
    "        save_json_response(structured_response, f\"{file_name}_iter{i+1}\", model=model)\n",
    "        \n",
    "        results.append((freeform_response, structured_response))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7871b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test iterative analysis\n",
    "file_name = all_papers[0]['file_name']\n",
    "file_id = all_papers[0]['file_id']\n",
    "\n",
    "iterative_results = analyze_paper_iteratively(\n",
    "    file_name=file_name,\n",
    "    file_id=file_id,\n",
    "    prompt_text=PROMPT_FREEFORM,\n",
    "    iterations=3,\n",
    "    schema=PaperSchema1,\n",
    "    model=cheap\n",
    ")\n",
    "\n",
    "# Print the freeform responses from each iteration\n",
    "# for i, (freeform_resp, _) in enumerate(iterative_results, 1):\n",
    "#     print(f\"\\n=== Iteration {i} Analysis ===\")\n",
    "#     print(freeform_resp.output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AISafetyIntervention_LiteratureExtraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
