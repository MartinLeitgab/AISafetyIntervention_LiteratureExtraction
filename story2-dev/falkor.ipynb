{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d153fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, hashlib, itertools\n",
    "from falkordb import FalkorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c765a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sid(s):  # stable id from title\n",
    "    return hashlib.sha1(s.encode()).hexdigest()[:12]\n",
    "\n",
    "# json extraction\n",
    "def extract_first_json(text):\n",
    "    start = text.find('{')\n",
    "    if start == -1:\n",
    "        return None\n",
    "    count = 0\n",
    "    for i in range(start, len(text)):\n",
    "        if text[i] == '{':\n",
    "            count += 1\n",
    "        elif text[i] == '}':\n",
    "            count -= 1\n",
    "            if count == 0:\n",
    "                return json.loads(text[start:i+1])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "611deff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'json/2307.16513v2_strict_2p_o3.json'\n",
    "file_path = 'traces/2307.16513v2_flex_1p_o3.txt'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            data = extract_first_json(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef118be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': [{'type': 'TASK',\n",
       "   'name': 'first_order_deception_tasks',\n",
       "   'canonical_name': 'first_order_deception_tasks',\n",
       "   'aliases': ['first-order deception task'],\n",
       "   'confidence': 0.9,\n",
       "   'notes': 'Binary recommendation and label tasks with burglar scenario'},\n",
       "  {'type': 'MODEL',\n",
       "   'name': 'GPT_4',\n",
       "   'canonical_name': 'GPT-4',\n",
       "   'aliases': ['gpt-4'],\n",
       "   'confidence': 0.95,\n",
       "   'notes': ''},\n",
       "  {'type': 'RISK_TYPE',\n",
       "   'name': 'emergent_deception_in_llms',\n",
       "   'canonical_name': 'emergent_deception_in_llms',\n",
       "   'aliases': ['deception capability'],\n",
       "   'confidence': 0.9,\n",
       "   'notes': ''},\n",
       "  {'type': 'BENCHMARK',\n",
       "   'name': 'deception_evaluation_benchmark',\n",
       "   'canonical_name': 'deception_evaluation_benchmark',\n",
       "   'aliases': [],\n",
       "   'confidence': 0.55,\n",
       "   'notes': 'Inferred safety benchmark to routinely test models'},\n",
       "  {'type': 'PROMPT_TECHNIQUE',\n",
       "   'name': 'chain_of_thought_prompting',\n",
       "   'canonical_name': 'chain_of_thought_prompting',\n",
       "   'aliases': ['CoT'],\n",
       "   'confidence': 0.9,\n",
       "   'notes': ''},\n",
       "  {'type': 'RESULT',\n",
       "   'name': 'improved_second_order_deception_performance',\n",
       "   'canonical_name': 'improved_second_order_deception_performance',\n",
       "   'aliases': [],\n",
       "   'confidence': 0.85,\n",
       "   'notes': ''},\n",
       "  {'type': 'RISK_TYPE',\n",
       "   'name': 'increased_alignment_risk_from_cot',\n",
       "   'canonical_name': 'increased_alignment_risk_from_cot',\n",
       "   'aliases': [],\n",
       "   'confidence': 0.6,\n",
       "   'notes': ''},\n",
       "  {'type': 'MITIGATION',\n",
       "   'name': 'restrict_chain_of_thought_outputs',\n",
       "   'canonical_name': 'restrict_chain_of_thought_outputs',\n",
       "   'aliases': ['limit-CoT'],\n",
       "   'confidence': 0.45,\n",
       "   'notes': 'Inferred intervention'},\n",
       "  {'type': 'PROMPT_TECHNIQUE',\n",
       "   'name': 'machiavellianism_induction_prompt',\n",
       "   'canonical_name': 'machiavellianism_induction_prompt',\n",
       "   'aliases': ['Machiavellian prefix'],\n",
       "   'confidence': 0.9,\n",
       "   'notes': ''},\n",
       "  {'type': 'RESULT',\n",
       "   'name': 'increased_deception_with_machiavellian_prompt',\n",
       "   'canonical_name': 'increased_deception_with_machiavellian_prompt',\n",
       "   'aliases': [],\n",
       "   'confidence': 0.9,\n",
       "   'notes': ''},\n",
       "  {'type': 'MITIGATION',\n",
       "   'name': 'prompt_guard_for_machiavellian_triggers',\n",
       "   'canonical_name': 'prompt_guard_for_machiavellian_triggers',\n",
       "   'aliases': [],\n",
       "   'confidence': 0.4,\n",
       "   'notes': 'Inferred safety guard'},\n",
       "  {'type': 'RESULT',\n",
       "   'name': 'false_belief_understanding_accuracy_result',\n",
       "   'canonical_name': 'false_belief_understanding_accuracy_result',\n",
       "   'aliases': [],\n",
       "   'confidence': 0.85,\n",
       "   'notes': ''},\n",
       "  {'type': 'CONCEPT',\n",
       "   'name': 'model_scale',\n",
       "   'canonical_name': 'model_scale',\n",
       "   'aliases': ['parameter count'],\n",
       "   'confidence': 0.7,\n",
       "   'notes': ''},\n",
       "  {'type': 'PROTOCOL',\n",
       "   'name': 'scaling_aware_deception_audit',\n",
       "   'canonical_name': 'scaling_aware_deception_audit',\n",
       "   'aliases': [],\n",
       "   'confidence': 0.35,\n",
       "   'notes': 'Inferred periodic audit procedure'}],\n",
       " 'logical_chains': [{'title': 'Emergent deception risk & evaluation benchmark',\n",
       "   'edges': [{'type': 'EVALUATES_ON',\n",
       "     'rationale': 'Tasks were directly applied to GPT-4',\n",
       "     'confidence': 0.9,\n",
       "     'source_node': 'first_order_deception_tasks',\n",
       "     'target_node': 'GPT_4'},\n",
       "    {'type': 'REPORTS',\n",
       "     'rationale': 'Paper reports deceptive behaviour as outcome',\n",
       "     'confidence': 0.85,\n",
       "     'source_node': 'GPT_4',\n",
       "     'target_node': 'emergent_deception_in_llms'},\n",
       "    {'type': 'MITIGATES',\n",
       "     'rationale': 'Benchmark would detect/monitor deception',\n",
       "     'confidence': 0.55,\n",
       "     'source_node': 'emergent_deception_in_llms',\n",
       "     'target_node': 'deception_evaluation_benchmark'}]},\n",
       "  {'title': 'Chain-of-thought amplifies deception',\n",
       "   'edges': [{'type': 'ENABLES',\n",
       "     'rationale': 'CoT greatly increases second-order deception success',\n",
       "     'confidence': 0.8,\n",
       "     'source_node': 'chain_of_thought_prompting',\n",
       "     'target_node': 'improved_second_order_deception_performance'},\n",
       "    {'type': 'CAUSES',\n",
       "     'rationale': 'Greater deception performance raises alignment risk',\n",
       "     'confidence': 0.7,\n",
       "     'source_node': 'improved_second_order_deception_performance',\n",
       "     'target_node': 'increased_alignment_risk_from_cot'},\n",
       "    {'type': 'MITIGATES',\n",
       "     'rationale': 'Limiting CoT exposure could reduce risk',\n",
       "     'confidence': 0.45,\n",
       "     'source_node': 'increased_alignment_risk_from_cot',\n",
       "     'target_node': 'restrict_chain_of_thought_outputs'}]},\n",
       "  {'title': 'Machiavellian prompt increases deception',\n",
       "   'edges': [{'type': 'CAUSES',\n",
       "     'rationale': 'Paper shows strong causal effect of Mach prompt',\n",
       "     'confidence': 0.9,\n",
       "     'source_node': 'machiavellianism_induction_prompt',\n",
       "     'target_node': 'increased_deception_with_machiavellian_prompt'},\n",
       "    {'type': 'MITIGATES',\n",
       "     'rationale': 'Prompt guard suggested to filter such triggers',\n",
       "     'confidence': 0.4,\n",
       "     'source_node': 'increased_deception_with_machiavellian_prompt',\n",
       "     'target_node': 'prompt_guard_for_machiavellian_triggers'}]},\n",
       "  {'title': 'False-belief understanding prerequisite',\n",
       "   'edges': [{'type': 'ENABLES',\n",
       "     'rationale': 'Paper correlates FB understanding with deception ability',\n",
       "     'confidence': 0.75,\n",
       "     'source_node': 'false_belief_understanding_accuracy_result',\n",
       "     'target_node': 'emergent_deception_in_llms'}]},\n",
       "  {'title': 'Model scale correlates with deception capability',\n",
       "   'edges': [{'type': 'VARIES_WITH',\n",
       "     'rationale': 'Larger models (GPT-4) more deceptive than smaller models',\n",
       "     'confidence': 0.65,\n",
       "     'source_node': 'model_scale',\n",
       "     'target_node': 'emergent_deception_in_llms'},\n",
       "    {'type': 'MITIGATES',\n",
       "     'rationale': 'Audit protocol would track deception as models scale',\n",
       "     'confidence': 0.35,\n",
       "     'source_node': 'emergent_deception_in_llms',\n",
       "     'target_node': 'scaling_aware_deception_audit'}]}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7377659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Nodes keyed by title; 'name' mirrors title for UI display.\n"
     ]
    }
   ],
   "source": [
    "# graph from strict json\n",
    "file_path = 'traces/2307.16513v2_strict_1p_o3.txt'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            data = extract_first_json(content)\n",
    "\n",
    "# --- 1) build nodes (use title as key + visible name) ---\n",
    "nodes = []\n",
    "for n in data[\"nodes\"]:\n",
    "    label = \"Concept\" if n.get(\"type\") == \"concept\" else \"Intervention\"\n",
    "    nodes.append({\n",
    "        \"label\": label,\n",
    "        \"props\": {\n",
    "            \"title\": n[\"title\"].strip(),\n",
    "            \"name\": n[\"title\"].strip(),               # <- ensures UIs show text, not an ID\n",
    "            \"aliases\": n.get(\"aliases\", []),\n",
    "            \"description\": n.get(\"description\", \"\"),\n",
    "            \"maturity\": n.get(\"maturity\")\n",
    "        }\n",
    "    })\n",
    "\n",
    "# --- 2) build relationships from logical_chains (match by title) ---\n",
    "rels = []\n",
    "for chain in data.get(\"logical_chains\", []):\n",
    "    for e in chain.get(\"edges\", []):\n",
    "        retype = e[\"type\"].upper().replace(\"-\", \"_\")\n",
    "        rels.append({\n",
    "            \"type\": retype,\n",
    "            \"row\": {\n",
    "                \"src\": e[\"source_node\"].strip(),\n",
    "                \"dst\": e[\"target_node\"].strip(),\n",
    "                \"description\": e.get(\"description\", \"\"),\n",
    "                \"confidence\": e.get(\"confidence\")\n",
    "            }\n",
    "        })\n",
    "\n",
    "# --- 3) insert into FalkorDB ---\n",
    "db = FalkorDB(host=\"localhost\", port=6379)\n",
    "g = db.select_graph(\"misalignment_v3\")\n",
    "\n",
    "# indexes (safe to re-run)\n",
    "g.query(\"CREATE INDEX FOR (c:Concept) ON (c.title)\")\n",
    "g.query(\"CREATE INDEX FOR (i:Intervention) ON (i.title)\")\n",
    "\n",
    "# nodes (group by label)\n",
    "by_label = defaultdict(list)\n",
    "for n in nodes:\n",
    "    by_label[n[\"label\"]].append(n[\"props\"])\n",
    "\n",
    "for L, rows in by_label.items():\n",
    "    for chunk in batched(rows):\n",
    "        g.query(f\"\"\"\n",
    "        UNWIND $rows AS row\n",
    "        MERGE (n:`{L}` {{title: row.title}})\n",
    "        SET n += row\n",
    "        \"\"\", {\"rows\": chunk})\n",
    "\n",
    "# relationships (group by type)\n",
    "by_type = defaultdict(list)\n",
    "for r in rels:\n",
    "    # keep only rel props in the payload; src/dst are separate keys\n",
    "    row = r[\"row\"]\n",
    "    by_type[r[\"type\"]].append(row)\n",
    "\n",
    "for T, rows in by_type.items():\n",
    "    for chunk in batched(rows):\n",
    "        g.query(f\"\"\"\n",
    "        UNWIND $rows AS row\n",
    "        MATCH (s {{title: row.src}}), (t {{title: row.dst}})\n",
    "        MERGE (s)-[r:`{T}`]->(t)\n",
    "        SET r.description = row.description,\n",
    "            r.confidence = row.confidence\n",
    "        \"\"\", {\"rows\": chunk})\n",
    "\n",
    "print(\"Done. Nodes keyed by title; 'name' mirrors title for UI display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f08da0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# graph from flex json\n",
    "file_path = 'traces/2307.16513v2_flex_1p_o3.txt'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            data = extract_first_json(content)\n",
    "\n",
    "nodes = []\n",
    "name2id = {}\n",
    "labels_seen = set()\n",
    "\n",
    "for n in data[\"nodes\"]:\n",
    "    key = (n.get(\"canonical_name\") or n[\"name\"]).strip()\n",
    "    nid = sid(key)\n",
    "    label = (n[\"type\"] or \"ENTITY\").upper()   # e.g., TASK, MODEL, PROMPT_TECHNIQUE\n",
    "    labels_seen.add(label)\n",
    "    name2id[n[\"name\"]] = nid\n",
    "    if n.get(\"canonical_name\"): name2id[n[\"canonical_name\"]] = nid  # allow both\n",
    "    nodes.append({\n",
    "        \"label\": label,\n",
    "        \"props\": {\n",
    "            \"id\": nid,\n",
    "            \"name\": n[\"name\"],\n",
    "            \"canonical_name\": n.get(\"canonical_name\"),\n",
    "            \"aliases\": n.get(\"aliases\", []),\n",
    "            \"confidence\": n.get(\"confidence\"),\n",
    "            \"notes\": n.get(\"notes\", \"\")\n",
    "        }\n",
    "    })\n",
    "\n",
    "# --- 2) Relationships from logical_chains ---\n",
    "rels = []\n",
    "for chain in data.get(\"logical_chains\", []):\n",
    "    for e in chain.get(\"edges\", []):\n",
    "        reltype = (e[\"type\"] or \"RELATED\").upper().replace(\"-\", \"_\")\n",
    "        src = name2id[e[\"source_node\"]]\n",
    "        dst = name2id[e[\"target_node\"]]\n",
    "        rels.append({\n",
    "            \"type\": reltype,\n",
    "            \"row\": {\n",
    "                \"src\": src, \"dst\": dst,\n",
    "                \"rationale\": e.get(\"rationale\", \"\"),\n",
    "                \"confidence\": e.get(\"confidence\")\n",
    "            }\n",
    "        })\n",
    "\n",
    "# --- 3) Insert into FalkorDB ---\n",
    "db = FalkorDB(host=\"localhost\", port=6379)\n",
    "g = db.select_graph(\"misalignment_v2\")\n",
    "\n",
    "# indexes (id lookups fast; safe to run repeatedly)\n",
    "for L in labels_seen:\n",
    "    g.query(f\"CREATE INDEX FOR (n:`{L}`) ON (n.id)\")\n",
    "\n",
    "# nodes (group by label)\n",
    "by_label = defaultdict(list)\n",
    "for n in nodes:\n",
    "    by_label[n[\"label\"]].append(n[\"props\"])\n",
    "\n",
    "for L, rows in by_label.items():\n",
    "    for chunk in batched(rows):\n",
    "        g.query(f\"\"\"\n",
    "        UNWIND $rows AS row\n",
    "        MERGE (n:`{L}` {{id: row.id}})\n",
    "        SET n += row\n",
    "        \"\"\", {\"rows\": chunk})\n",
    "\n",
    "# relationships (group by type)\n",
    "by_type = defaultdict(list)\n",
    "for r in rels:\n",
    "    by_type[r[\"type\"]].append(r[\"row\"])\n",
    "\n",
    "for T, rows in by_type.items():\n",
    "    for chunk in batched(rows):\n",
    "        g.query(f\"\"\"\n",
    "        UNWIND $rows AS row\n",
    "        MATCH (s {{id: row.src}}), (t {{id: row.dst}})\n",
    "        MERGE (s)-[r:`{T}`]->(t)\n",
    "        SET r += row\n",
    "        \"\"\", {\"rows\": chunk})\n",
    "\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AISafetyIntervention_LiteratureExtraction (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
